diff -crB --new-file ./openfl/CITATION ../mlwins-simulation-framework/ml-frameworks/federated-learning/CITATION
*** ./openfl/CITATION	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/CITATION	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,8 ****
- @misc{reina2021openfl,
-       title={OpenFL: An open-source framework for Federated Learning}, 
-       author={G Anthony Reina and Alexey Gruzdev and Patrick Foley and Olga Perepelkina and Mansi Sharma and Igor Davidyuk and Ilya Trushkin and Maksim Radionov and Aleksandr Mokrov and Dmitry Agapov and Jason Martin and Brandon Edwards and Micah J. Sheller and Sarthak Pati and Prakash Narayana Moorthy and Shih-han Wang and Prashant Shah and Spyridon Bakas},
-       year={2021},
-       eprint={2105.06413},
-       archivePrefix={arXiv},
-       primaryClass={cs.LG}
- }
--- 0 ----
diff -crB --new-file ./openfl/CLA.md ../mlwins-simulation-framework/ml-frameworks/federated-learning/CLA.md
*** ./openfl/CLA.md	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/CLA.md	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,16 ****
- # Open Federated Learning (OpenFL) Contributor License Agreement
- 
- In order to clarify the intellectual property license granted with Contributions from any person or entity, Intel Corporation ("Intel") must have a Contributor License Agreement ("CLA") on file that has been signed by each Contributor, indicating agreement to the license terms below. This license is for your protection as a Contributor as well as the protection of Intel; it does not change your rights to use your own Contributions for any other purpose.
- You accept and agree to the following terms and conditions for Your present and future Contributions submitted to Intel. Except for the license granted herein to Intel and recipients of software distributed by Intel, You reserve all right, title, and interest in and to Your Contributions.
- 
- 1.	Definitions.
- "You" (or "Your") shall mean the copyright owner or legal entity authorized by the copyright owner that is making this Agreement with Intel. For legal entities, the entity making a Contribution and all other entities that control, are controlled by, or are under common control with that entity are considered to be a single Contributor. For the purposes of this definition, "control" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity.
- "Contribution" shall mean any original work of authorship, including any modifications or additions to an existing work, that is intentionally submitted by You to Intel for inclusion in, or documentation of, any of the products owned or managed by Intel (the "Work"). For the purposes of this definition, "submitted" means any form of electronic, verbal, or written communication sent to Intel or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, Intel for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by You as "Not a Contribution."
- 2.	Grant of Copyright License. Subject to the terms and conditions of this Agreement, You hereby grant to Intel and to recipients of software distributed by Intel a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare derivative works of, publicly display, publicly perform, sublicense, and distribute Your Contributions and such derivative works.
- 3.	Grant of Patent License. Subject to the terms and conditions of this Agreement, You hereby grant to Intel and to recipients of software distributed by Intel a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by You that are necessarily infringed by Your Contribution(s) alone or by combination of Your Contribution(s) with the Work to which such Contribution(s) was submitted. If any entity institutes patent litigation against You or any other entity (including a cross-claim or counterclaim in a lawsuit) alleging that your Contribution, or the Work to which you have contributed, constitutes direct or contributory patent infringement, then any patent licenses granted to that entity under this Agreement for that Contribution or Work shall terminate as of the date such litigation is filed.
- 4.	You represent that you are legally entitled to grant the above license. If your employer(s) has rights to intellectual property that you create that includes your Contributions, you represent that you have received permission to make Contributions on behalf of that employer, that your employer has waived such rights for your Contributions to Intel, or that your employer has executed a separate Corporate CLA with Intel.
- 5.	You represent that each of Your Contributions is Your original creation (see section 7 for submissions on behalf of others). You represent that Your Contribution submissions include complete details of any third-party license or other restriction (including, but not limited to, related patents and trademarks) of which you are personally aware and which are associated with any part of Your Contributions.
- 6.	You are not expected to provide support for Your Contributions, except to the extent You desire to provide support. You may provide support for free, for a fee, or not at all. Unless required by applicable law or agreed to in writing, You provide Your Contributions on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON- INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE.
- 7.	Should You wish to submit work that is not Your original creation, You may submit it to Intel separately from any Contribution, identifying the complete details of its source and of any license or other restriction (including, but not limited to, related patents, trademarks, and license agreements) of which you are personally aware, and conspicuously marking the work as "Submitted on behalf of a third-party: [named here]".
- 8.	You agree to notify Intel of any facts or circumstances of which you become aware that would make these representations inaccurate in any respect.
- 
--- 0 ----
diff -crB --new-file ./openfl/CODE_OF_CONDUCT.md ../mlwins-simulation-framework/ml-frameworks/federated-learning/CODE_OF_CONDUCT.md
*** ./openfl/CODE_OF_CONDUCT.md	2022-11-18 11:06:29.707187478 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/CODE_OF_CONDUCT.md	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,76 ****
- # Contributor Covenant Code of Conduct
- 
- ## Our Pledge
- 
- In the interest of fostering an open and welcoming environment, we as
- contributors and maintainers pledge to making participation in our project and
- our community a harassment-free experience for everyone, regardless of age, body
- size, disability, ethnicity, sex characteristics, gender identity and expression,
- level of experience, education, socio-economic status, nationality, personal
- appearance, race, religion, or sexual identity and orientation.
- 
- ## Our Standards
- 
- Examples of behavior that contributes to creating a positive environment
- include:
- 
- * Using welcoming and inclusive language
- * Being respectful of differing viewpoints and experiences
- * Gracefully accepting constructive criticism
- * Focusing on what is best for the community
- * Showing empathy towards other community members
- 
- Examples of unacceptable behavior by participants include:
- 
- * The use of sexualized language or imagery and unwelcome sexual attention or
-  advances
- * Trolling, insulting/derogatory comments, and personal or political attacks
- * Public or private harassment
- * Publishing others' private information, such as a physical or electronic
-  address, without explicit permission
- * Other conduct which could reasonably be considered inappropriate in a
-  professional setting
- 
- ## Our Responsibilities
- 
- Project maintainers are responsible for clarifying the standards of acceptable
- behavior and are expected to take appropriate and fair corrective action in
- response to any instances of unacceptable behavior.
- 
- Project maintainers have the right and responsibility to remove, edit, or
- reject comments, commits, code, wiki edits, issues, and other contributions
- that are not aligned to this Code of Conduct, or to ban temporarily or
- permanently any contributor for other behaviors that they deem inappropriate,
- threatening, offensive, or harmful.
- 
- ## Scope
- 
- This Code of Conduct applies both within project spaces and in public spaces
- when an individual is representing the project or its community. Examples of
- representing a project or community include using an official project e-mail
- address, posting via an official social media account, or acting as an appointed
- representative at an online or offline event. Representation of a project may be
- further defined and clarified by project maintainers.
- 
- ## Enforcement
- 
- Instances of abusive, harassing, or otherwise unacceptable behavior may be
- reported by contacting the project team at webadmin@linux.intel.com. All
- complaints will be reviewed and investigated and will result in a response that
- is deemed necessary and appropriate to the circumstances. The project team is
- obligated to maintain confidentiality with regard to the reporter of an incident.
- Further details of specific enforcement policies may be posted separately.
- 
- Project maintainers who do not follow or enforce the Code of Conduct in good
- faith may face temporary or permanent repercussions as determined by other
- members of the project's leadership.
- 
- ## Attribution
- 
- This Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,
- available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html
- 
- [homepage]: https://www.contributor-covenant.org
- 
- For answers to common questions about this code of conduct, see
- https://www.contributor-covenant.org/faq
--- 0 ----
diff -crB --new-file ./openfl/.dockerignore ../mlwins-simulation-framework/ml-frameworks/federated-learning/.dockerignore
*** ./openfl/.dockerignore	2022-11-18 11:06:29.703187478 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.dockerignore	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- .git
- *.egg-info
- build
--- 0 ----
diff -crB --new-file ./openfl/docs/advanced_topics.rst ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/advanced_topics.rst
*** ./openfl/docs/advanced_topics.rst	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/advanced_topics.rst	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,50 ****
- .. # Copyright (C) 2020-2021 Intel Corporation
- .. # SPDX-License-Identifier: Apache-2.0
- 
- .. _advanced_topics:
- 
- ***************
- Advanced Topics
- ***************
- **General**
- 
-     Speed up activating Open Federated Learning (|productName|) commands:
- 
-     - :doc:`bash_autocomplete_activation`
- 
- **Aggregator-Based Workflow**
- 
-     Learn to manage multiple Federation Learning plans (FL plan) in the same workspace:
- 
-     - :doc:`multiple_plans`
- 
-     Reduce the amount of data transferred in a federation through compression pipelines available in |productName|:
- 
-     - :doc:`compression_settings`
-     
-     Customize the aggregation function for each task:
-     
-     - :doc:`overriding_agg_fn`
- 
- **Director-Based Workflow**
- 
-     Customize the logging function for each task:
- 
-     - :doc:`log_metric_callback`
- 
- 
- 
- 
- 
- .. toctree::
-    :maxdepth: 4
-    :hidden:
- 
-    bash_autocomplete_activation
-    multiple_plans
-    compression_settings
-    overriding_agg_fn
-    log_metric_callback
-    supported_aggregation_algorithms
-    
-    
--- 0 ----
diff -crB --new-file ./openfl/docs/bash_autocomplete_activation.rst ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/bash_autocomplete_activation.rst
*** ./openfl/docs/bash_autocomplete_activation.rst	2022-11-18 11:06:29.707187478 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/bash_autocomplete_activation.rst	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,97 ****
- .. # Copyright (C) 2020-2021 Intel Corporation
- .. # SPDX-License-Identifier: Apache-2.0
- 
- **************************
- Activate Bash Autocomplete
- **************************
- 
- Get faster access to available commands by activating bash completion in CLI mode.
- 
- STEP 1: Preparation
- ===================
- 
- Make sure you are inside a virtual environment with Open Federated Learning (|productName|) installed. See :ref:`install_package` for details.
- 
- 
- STEP 2: Create the fx-autocomplete.sh Script
- ============================================
- 
- .. note::
- 
-     Perform this procedure if you don't have a **~/.fx-autocomplete.sh** script or if the existing **~/.fx-autocomplete.sh** script is corrupted.
- 
- 1. Create the script.
-    
-    .. code-block:: console
- 
-       _FX_COMPLETE=bash_source fx > ~/.fx-autocomplete.sh
- 
-    
- 2. Check that the script was created properly.
- 
-    .. code-block:: console
- 
-       cat ~/.fx-autocomplete.sh
- 
-  The output should look like the example below (Click==8.0.1), but could be different depend on `Click <https://click.palletsprojects.com/en/8.0.x/>`_ version:
-    
-    .. code-block:: console
- 
-       _fx_completion() {
-           local IFS=$'\n'
-           local response
- 
-           response=$(env COMP_WORDS="${COMP_WORDS[*]}" COMP_CWORD=$COMP_CWORD _FX_COMPLETE=bash_complete $1)
- 
-           for completion in $response; do
-               IFS=',' read type value <<< "$completion"
- 
-               if [[ $type == 'dir' ]]; then
-                   COMREPLY=()
-                   compopt -o dirnames
-               elif [[ $type == 'file' ]]; then
-                   COMREPLY=()
-                   compopt -o default
-               elif [[ $type == 'plain' ]]; then
-                   COMPREPLY+=($value)
-               fi
-           done
- 
-           return 0
-       }
- 
-       _fx_completion_setup() {
-           complete -o nosort -F _fx_completion fx
-       }
- 
-       _fx_completion_setup;
- 
- 
- STEP 3: Activate the Autocomplete Feature
- =========================================
- 
- Perform this command every time you open a new terminal window.
- 
-    .. code-block:: console
- 
-       source ~/.fx-autocomplete.sh
- 
- 
- To save time, add the script into **.bashrc** so the script is activated when you log in.
- 
- 1. Edit the **.bashrc** file. The **nano** command line editor is used in this example.
- 
-    .. code-block:: console
- 
-       nano ~/.bashrc
- 
- 2. Add the script.
- 
-    .. code-block:: bash
-    
-       . ~/.fx-autocomplete.sh
- 
- 3. Save your changes.
- 
- 4. Open a new terminal to use the updated bash shell.
- 
--- 0 ----
diff -crB --new-file ./openfl/docs/compression_settings.rst ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/compression_settings.rst
*** ./openfl/docs/compression_settings.rst	2022-11-18 11:06:29.707187478 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/compression_settings.rst	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,56 ****
- .. # Copyright (C) 2020-2021 Intel Corporation
- .. # SPDX-License-Identifier: Apache-2.0
- 
- .. _compression_settings:
- 
- **************************
- Apply Compression Settings
- **************************
- 
- The Open Federated Learning (|productName|) framework supports lossless and lossy compression pipelines. Federated learning enables a large number of participants to work together on the same model. Without a compression pipeline, this scalability results in increased communication cost. Furthermore, large models exacerbate this problem.
- 
- .. note::
-     In general, the weights of a model are typically not robust to information loss, so no compression is applied by default to the model weights sent bidirectionally; however, the deltas between the model weights for each round are inherently more sparse and better suited for lossy compression.
- 
- The following are the compression pipelines supported in |productName|:
- 
- ``NoCompressionPipeline``
-     The default option applied to model weights
- 
- ``RandomShiftPipeline``
-     A **lossless** pipeline that randomly shifts the weights during transport
-     
- ``STCPipeline``
-     A **lossy** pipeline consisting of three transformations: 
-     
-         - *Sparsity Transform* (p_sparsity=0.1), which by default retains only the (p*100)% absolute values of greatest magnitude. 
-         - *Ternary Transform*, which discretizes the sparse array into three buckets
-         - *GZIP Transform*
- 
- ``SKCPipeline``
-     A **lossy** pipeline consisting of three transformations:
-     
-         - *Sparsity Transform* (p=0.1), which by default retains only the(p*100)% absolute values of greatest magnitude. 
-         - *KMeans Transform* (k=6), which applies the KMeans algorithm to the sparse array with *k* centroids
-         - *GZIP Transform*
-         
- ``KCPipeline``
-     A **lossy** pipeline consisting of two transformations: 
-     
-         - *KMeans Transform* (k=6), which applies the KMeans algorithm to the original weight array with *k* centroids
-         - *GZIP Transform* 
- 
- 
- Demonstration of a Compression Pipeline
- =======================================
- 
- The example template, **keras_cnn_with_compression**, uses the ``KCPipeline`` with six centroids for KMeans. To gain a better understanding of how experiments perform with greater or fewer centroids, you can modify the **n_clusters** parameter in the template **plan.yaml**:
- 
-     .. code-block:: console
-     
-        compression_pipeline :
-          defaults : plan/defaults/compression_pipeline.yaml
-          template : openfl.pipelines.KCPipeline
-          settings :
-            n_clusters : 6
- 
--- 0 ----
diff -crB --new-file ./openfl/docs/conf.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/conf.py
*** ./openfl/docs/conf.py	2022-11-18 11:06:29.707187478 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/conf.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,93 ****
- """Docs configuration module."""
- 
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- 
- # Configuration file for the Sphinx documentation builder.
- #
- # This file only contains a selection of the most common options. For a full
- # list see the documentation:
- # http://www.sphinx-doc.org/en/master/config
- 
- # -- Path setup --------------------------------------------------------------
- 
- # If extensions (or modules to document with autodoc) are in another directory,
- # add these directories to sys.path here. If the directory is relative to the
- # documentation root, use os.path.abspath to make it absolute, like shown here.
- #
- import os
- import sys
- from datetime import datetime
- 
- sys.path.insert(0, os.path.abspath('../'))
- 
- # -- General configuration ---------------------------------------------------
- 
- # Add any Sphinx extension module names here, as strings. They can be
- # extensions coming with Sphinx (named 'sphinx.ext.*') or your custom
- # ones.
- # import sphinx_rtd_theme # NOQA:E800
- # import sphinxcontrib.napoleon # NOQA:E800
- 
- extensions = [
-     'sphinx_rtd_theme',
-     'sphinx.ext.autosectionlabel',
-     'sphinx.ext.napoleon',
-     'sphinx-prompt',
-     'sphinx_substitution_extensions',
-     'sphinx.ext.ifconfig',
-     'sphinxcontrib.kroki'
- ]
- 
- # -- Project information -----------------------------------------------------
- 
- # This will replace the |variables| within the rST documents automatically
- 
- PRODUCT_VERSION = 'Intel'
- 
- project = 'OpenFL'
- copyright = f'{datetime.now().year}, Intel' # NOQA
- author = 'Intel Corporation'
- version = f'{datetime.now().year}.{datetime.now().month}'
- release = version
- master_doc = 'index'
- 
- # Global variables for rST
- rst_prolog = '''
- .. |productName| replace:: OpenFL
- .. |productZip| replace:: openfl.zip
- .. |productDir| replace:: openfl
- .. |productWheel| replace:: openfl
- 
- '''
- 
- napoleon_google_docstring = True
- 
- # Add any paths that contain templates here, relative to this directory.
- templates_path = ['_templates']
- 
- # List of patterns, relative to source directory, that match files and
- # directories to ignore when looking for source files.
- # This pattern also affects html_static_path and html_extra_path.
- exclude_patterns = ['_build', 'Thumbs.db', '.DS_Store', 'tutorials/*', 'graveyard/*']
- # add temporary unused files
- exclude_patterns.extend(['modules.rst',
-                          'install.singularity.rst',
-                          'overview.what_is_intel_federated_learning.rst',
-                          'overview.how_can_intel_protect_federated_learning.rst',
-                          'source/workflow/running_the_federation.singularity.rst'])
- 
- # -- Options for HTML output -------------------------------------------------
- 
- # The theme to use for HTML and HTML Help pages.  See the documentation for
- # a list of builtin themes.
- #
- html_theme = 'sphinx_rtd_theme'
- 
- # Add any paths that contain custom static files (such as style sheets) here,
- # relative to this directory. They are copied after the builtin static files,
- # so a file named "default.css" will overwrite the builtin "default.css".
- html_static_path = []
- 
- autosectionlabel_prefix_document = True
--- 0 ----
diff -crB --new-file ./openfl/docs/.gitignore ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/.gitignore
*** ./openfl/docs/.gitignore	2022-11-18 11:06:29.707187478 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/.gitignore	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,5 ****
- # openfl*
- # models*
- # data*
- /_build
- **/.ipynb_checkpoints
\ No newline at end of file
--- 0 ----
Binary files ./openfl/docs/images/ct_vs_fl.png and ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/images/ct_vs_fl.png differ
Binary files ./openfl/docs/images/diagram_fl_new.png and ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/images/diagram_fl_new.png differ
Binary files ./openfl/docs/images/diagram_fl.png and ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/images/diagram_fl.png differ
Binary files ./openfl/docs/images/docker_design.png and ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/images/docker_design.png differ
Binary files ./openfl/docs/images/fx_help.png and ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/images/fx_help.png differ
Binary files ./openfl/docs/images/graphene.png and ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/images/graphene.png differ
Binary files ./openfl/docs/images/hls_fl_graphic.png and ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/images/hls_fl_graphic.png differ
Binary files ./openfl/docs/images/openfl_flow.png and ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/images/openfl_flow.png differ
Binary files ./openfl/docs/images/pki_creation.png and ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/images/pki_creation.png differ
Binary files ./openfl/docs/images/sgx.png and ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/images/sgx.png differ
Binary files ./openfl/docs/images/trusted_fl.png and ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/images/trusted_fl.png differ
Binary files ./openfl/docs/images/why_intel_fl.png and ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/images/why_intel_fl.png differ
diff -crB --new-file ./openfl/docs/index.rst ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/index.rst
*** ./openfl/docs/index.rst	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/index.rst	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,38 ****
- .. # Copyright (C) 2020-2021 Intel Corporation
- .. # SPDX-License-Identifier: Apache-2.0.
- 
- 
- .. Documentation master file, created by
-    sphinx-quickstart on Thu Oct 24 15:07:19 2019.
-    You can adapt this file completely to your liking, but it should at least
-    contain the root `toctree` directive.
- 
- *********************************************************************
- Welcome to the Open Federated Learning (|productName|) Documentation!
- *********************************************************************
- 
- Open Federated Learning (|productName|) is a Python\* \ 3 library for federated learning that enables organizations to collaboratively train a model without sharing sensitive information.
- 
- Open Federated Learning (|productName|) is Deep Learning framework-agnostic. 
- Training of statistical models may be done with any deep learning framework, such as 
- `TensorFlow <https://www.tensorflow.org/>`_\* \ or `PyTorch <https://pytorch.org/>`_\*\, via a plugin mechanism.
- 
- 
- |productName| is developed by Intel Labs and Intel Internet of Things Group.
- 
- .. toctree::
-    :maxdepth: 2
-    :caption: Contents:
- 
-    manual
-    openfl
-    troubleshooting
-    notices_and_disclaimers
- 
- 
- .. Indices and tables
- .. ==================
- 
- .. * :ref:`genindex`
- .. * :ref:`modindex`
- .. * :ref:`search`
--- 0 ----
diff -crB --new-file ./openfl/docs/install.rst ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/install.rst
*** ./openfl/docs/install.rst	2022-11-18 11:06:29.731187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/install.rst	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,111 ****
- .. # Copyright (C) 2020-2021 Intel Corporation
- .. # SPDX-License-Identifier: Apache-2.0
- 
- .. _install_software_root:
- 
- =====================
- Installation
- =====================
- 
- Depending on how you want to set up |productName|, choose one of the following installation procedure.
- 
- 
- .. _install_package:
- 
- *********************************
- Install the Package
- *********************************
- 
- Follow this procedure to prepare the environment and install the |productName| package.
- Perform this procedure on every node in the federation.
- 
- 1. Install a Python 3.8 (>=3.6, <3.9) virtual environment using venv.
-    
-  See the `Venv installation guide <https://docs.python.org/3/library/venv.html>`_ for details.
- 
- 2. Create a new Virtualenv environment for the project.
- 
-    .. code-block:: console
- 
-       python3 -m venv venv
- 
- 3. Activate the virtual environment.
- 
-    .. code-block:: console
- 
-       source venv/bin/activate
- 
- 4. Install the |productName| package.
- 
-     A. Installation from PyPI: 
-     
-         .. code-block:: console
-         
-             pip install openfl
-    
-     B. Installation from source:
- 
-         #. Clone the |productName| repository:
-         
-             .. code-block:: console
-             
-                 git clone https://github.com/intel/openfl.git 
- 
- 
-         #. From inside the Python environment, call :code:`pip install`: 
- 
-             .. code-block:: console
-             
-                 cd openfl/
-                 pip install .
- 
- 
- 
- 5. Run the :code:`fx` command in the virtual environment to confirm |productName| is installed.
- 
-    .. figure:: images/fx_help.png
-       :scale: 70 %
- 
- .. centered:: Output of the fx Command
- 
- 
- .. _install_docker:
- 
- ****************************************
- |productName| with Docker\* \ 
- ****************************************
- 
- Follow this procedure to download or build a Docker\*\  image of |productName|, which you can use to run your federation in an isolated environment.
- 
- .. note::
- 
-    The Docker\* \  version of |productName| is to provide an isolated environment complete with the prerequisites to run a federation. When the execution is over, the container can be destroyed and the results of the computation will be available on a directory on the local host.
- 
- 1. Install Docker on all nodes in the federation.
- 
-  See the `Docker installation guide <https://docs.docker.com/engine/install/>`_ for details. 
- 
- 2. Check that Docker is running properly with the *Hello World* command:
- 
-     .. code-block:: console
- 
-       $ docker run hello-world
-       Hello from Docker!
-       This message shows that your installation appears to be working correctly.
-       ...
-       ...
-       ...
-       
- 3. Build an image from the latest official |productName| release:
- 
- 	.. code-block:: console
- 
- 	   docker pull intel/openfl
-    
- 	If you prefer to build an image from a specific commit or branch, perform the following commands:
- 
- 	.. code-block:: console
- 
- 	   git clone https://github.com/intel/openfl.git
- 	   cd openfl
- 	   docker build -f openfl-docker/Dockerfile.base .
--- 0 ----
diff -crB --new-file ./openfl/docs/install.singularity.rst ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/install.singularity.rst
*** ./openfl/docs/install.singularity.rst	2022-11-18 11:06:29.731187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/install.singularity.rst	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,43 ****
- .. # Copyright (C) 2020-2021 Intel Corporation
- .. # SPDX-License-Identifier: Apache-2.0
- 
- .. _install_singularity:
- 
- Singularity Installation
- ########################
- 
- .. note::
- 
-    Make sure you've run the :ref:`the initial steps <install_package>` section first.
- 
- .. note::
-     You'll need Docker installed on the node where you'll 
-     be building the Singularity containers. To check
-     that Docker is installed and running properly, you
-     can run the Docker *Hello World* command like this:
- 
-     .. code-block:: console
- 
-       $ docker run hello-world
-       Hello from Docker!
-       This message shows that your installation appears to be working correctly.
-       ...
-       ...
-       ...
- 
- .. note::
-     You'll need Singularity installed on all nodes. 
-     To check that Singularity is installed, run the following:
- 
-     .. code-block:: console
- 
-       $ singularity help
-      
-       Linux container platform optimized for High Performance Computing (HPC) and
-       Enterprise Performance Computing (EPC)
-       ...
-       ...
-       ...
- 
- 
- 1. TODO
--- 0 ----
diff -crB --new-file ./openfl/docs/log_metric_callback.rst ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/log_metric_callback.rst
*** ./openfl/docs/log_metric_callback.rst	2022-11-18 11:06:29.731187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/log_metric_callback.rst	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,73 ****
- .. # Copyright (C) 2020-2021 Intel Corporation
- .. # SPDX-License-Identifier: Apache-2.0
- 
- .. _log_metric_callback:
- 
- ***********************
- Metric Logging Callback
- ***********************
- 
- With the director-based workflow, you can use custom metric logging function for each task via Python\*\  API or command line interface. This function calls on the aggregator node.
- 
- 
- Python API
- ==========
- 
- Define the function with the follow signature:
- 
- .. code-block:: python
- 
-     def callback_name(node_name, task_name, metric_name, metric, round_number):
-         """
-         Write metric callback 
- 
-         Args:
-             node_name (str): Name of node, which generate metric 
-             task_name (str): Name of task
-             metric_name (str): Name of metric 
-             metric (np.ndarray): Metric value
-             round_number (int): Round number
-         """
-         your code 
- 
- Command Line Interface
- ======================
- 
- 1. Define the callback function, like how you defined in Python API, in the **src** directory in your workspace.
- 
- 2. Provide a way to your function with the ``log_metric_callback`` key in the ``aggregator`` section of the **plan.yaml** file in your workspace. 
- 
- .. code-block:: yaml
- 
-   aggregator :
-     defaults : plan/defaults/aggregator.yaml
-     template : openfl.component.Aggregator
-     settings :
-       init_state_path     : save/torch_cnn_mnist_init.pbuf
-       best_state_path     : save/torch_cnn_mnist_best.pbuf
-       last_state_path     : save/torch_cnn_mnist_last.pbuf
-       rounds_to_train     : 10
-       write_logs          : true
-       log_metric_callback :
-         template : src.mnist_utils.callback_name
- 
- 
- 
- Example of a Metric Callback
- ============================
- 
- The following is an example of a log metric callback, which writes metric values to the TensorBoard.
- 
- .. code-block:: python
- 
-     from torch.utils.tensorboard import SummaryWriter
- 
-     writer = SummaryWriter('./logs/cnn_mnist', flush_secs=5)
- 
- 
-     def write_metric(node_name, task_name, metric_name, metric, round_number):
-         writer.add_scalar("{}/{}/{}".format(node_name, task_name, metric_name),
-                         metric, round_number) 
- 
- 
- A full implementation can be found at `Federated_Pytorch_MNIST_Tutorial.ipynb <https://github.com/intel/openfl/blob/develop/openfl-tutorials/Federated_Pytorch_MNIST_Tutorial.ipynb>`_ and in the **torch_cnn_mnist** workspace.
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/docs/make.bat ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/make.bat
*** ./openfl/docs/make.bat	2022-11-18 11:06:29.731187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/make.bat	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,35 ****
- @ECHO OFF
- 
- pushd %~dp0
- 
- REM Command file for Sphinx documentation
- 
- if "%SPHINXBUILD%" == "" (
- 	set SPHINXBUILD=sphinx-build
- )
- set SOURCEDIR=.
- set BUILDDIR=_build
- 
- if "%1" == "" goto help
- 
- %SPHINXBUILD% >NUL 2>NUL
- if errorlevel 9009 (
- 	echo.
- 	echo.The 'sphinx-build' command was not found. Make sure you have Sphinx
- 	echo.installed, then set the SPHINXBUILD environment variable to point
- 	echo.to the full path of the 'sphinx-build' executable. Alternatively you
- 	echo.may add the Sphinx directory to PATH.
- 	echo.
- 	echo.If you don't have Sphinx installed, grab it from
- 	echo.http://sphinx-doc.org/
- 	exit /b 1
- )
- 
- %SPHINXBUILD% -M %1 %SOURCEDIR% %BUILDDIR% %SPHINXOPTS% %O%
- goto end
- 
- :help
- %SPHINXBUILD% -M help %SOURCEDIR% %BUILDDIR% %SPHINXOPTS% %O%
- 
- :end
- popd
--- 0 ----
diff -crB --new-file ./openfl/docs/Makefile ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/Makefile
*** ./openfl/docs/Makefile	2022-11-18 11:06:29.707187478 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/Makefile	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,24 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- 
- # Minimal makefile for Sphinx documentation
- #
- 
- # You can set these variables from the command line, and also
- # from the environment for the first two.
- SPHINXOPTS    ?=
- SPHINXBUILD   ?= sphinx-build
- SOURCEDIR     = .
- BUILDDIR      = _build
- 
- # Put it first so that "make" without argument is like "make help".
- help:
- 	@$(SPHINXBUILD) -M help "$(SOURCEDIR)" "$(BUILDDIR)" $(SPHINXOPTS) $(O)
- 
- .PHONY: help Makefile
- 
- # Catch-all target: route all unknown targets to Sphinx using the new
- # "make mode" option.  $(O) is meant as a shortcut for $(SPHINXOPTS).
- %: Makefile
- 	@$(SPHINXBUILD) -M $@ "$(SOURCEDIR)" "$(BUILDDIR)" $(SPHINXOPTS) $(O)
--- 0 ----
diff -crB --new-file ./openfl/docs/manual.rst ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/manual.rst
*** ./openfl/docs/manual.rst	2022-11-18 11:06:29.731187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/manual.rst	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,35 ****
- .. # Copyright (C) 2020-2021 Intel Corporation
- .. # SPDX-License-Identifier: Apache-2.0
- 
- ******
- Manual
- ******
- 
- What is Open Federated Learning (|productName|):
- 
- - :doc:`overview`
- 
- Establish a federation with |productName|:
- 
- - :doc:`install`
- - :doc:`running_the_federation`
- 
- Customize the federation:
- 
- - :doc:`source/utilities/utilities`
- - :doc:`advanced_topics`
- 
- Familiarize with the APIs:
- 
- - :doc:`source/workflow/running_the_federation.tutorial`
- 
- .. toctree::
-    :maxdepth: 2
-    :hidden:
- 
-    overview
-    install
-    running_the_federation
-    source/utilities/utilities
-    advanced_topics
-    source/workflow/running_the_federation.tutorial
--- 0 ----
diff -crB --new-file ./openfl/docs/mermaid/CSR_signing.mmd ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/mermaid/CSR_signing.mmd
*** ./openfl/docs/mermaid/CSR_signing.mmd	2022-11-18 11:06:29.731187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/mermaid/CSR_signing.mmd	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,17 ****
- sequenceDiagram
- Title: Collaborator Certificate Signing Flow 
-   participant A as Alice
-   participant AC as Alice's Collaborator Node
-   participant B as Bob
-   participant BG as Bob's Certificate Signing System
-   A->>AC: Alice runs<br>`fx collaborator generate-cert-request`<br>to create .key and .csr file<br>
-   AC->>A: PKI script outputs a hash to the screen
-   A->>B: Alice sends the .csr to Bob
-   B->>BG: Bob moves the .csr<br/> to the signing system with<br>`fx collaborator certify --request-pkg`
-   B-->>A: Bob Calls Alice to confirm PKI
-   Note over A,B: This is the **root of trust** : Bob called Alice to verify the hash 
-   A-->>B: Alice reads the hash to Bob
-   Note over A,B: This ensures Bob is signing the same .csr Alice generated
-   B->>BG: Bob runs script to sign .csr,<br/> confirming the hash as input,<br/> creating the .crt file
-   B->>A: Bob sends the .crt file back to Alice
-   A->>AC: Alice copies the signed certificate (.crt)<br/>to her collaborator node.<br/>She now has a signed certificate.
--- 0 ----
diff -crB --new-file ./openfl/docs/mermaid/pki_scheme.mmd ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/mermaid/pki_scheme.mmd
*** ./openfl/docs/mermaid/pki_scheme.mmd	2022-11-18 11:06:29.731187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/mermaid/pki_scheme.mmd	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,20 ****
- sequenceDiagram
- Title: Collaborator Certificate Signing Flow
-   participant A as Aggregator
-   participant CA as CA
-   participant C as Collaborator
-   CA->>CA: 1. Create CA:<br>`step ca init --password-file pass_file`
-   CA->>CA: 2. Up HTTPS CA server:<br>`step_ca ca_config.json`
-   CA->>CA: 3. Generate JWK pair:<br>`step crypto jwk create pub.json priv.json --password-file pass_file`
-   CA->>CA: 4. Get JWT for aggregator:<br>`step ca token localhost --key priv.json --password-file pass_file --ca-url ca_url`
-   CA->>A: 5. Copy JWT to aggregator. 
-   A->>CA: 6. Certify node:<br>`step ca certificate localhost agg.crt agg.key --token AbC1d2E..`
-   Note over A,CA: Get agg.crt
-   CA->>CA: 7. Get JWT for collaborator:<br>`step ca token col_name --key priv.json --password-file pass_file --ca-url ca_url`
-   CA->>C: 8. Copy JWT to collaborator. 
-   C->>CA: 9. Certify node:<br>`step ca certificate col_name col_name.crt col_name.key --token AbC1d2E..`
-   Note over C,CA: Get col_name.crt
-   CA->>A: 10. Copy root_ca.crt to aggregator
-   Note over A,CA: This could be done at step 5 with token
-   CA->>C: 11. Copy root_ca.crt to collaborator
-   Note over C,CA: This could be done at step 8 with token
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/docs/modules.rst ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/modules.rst
*** ./openfl/docs/modules.rst	2022-11-18 11:06:29.731187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/modules.rst	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,7 ****
- openfl
- ======
- 
- .. toctree::
-    :maxdepth: 4
- 
-    openfl
--- 0 ----
diff -crB --new-file ./openfl/docs/multiple_plans.rst ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/multiple_plans.rst
*** ./openfl/docs/multiple_plans.rst	2022-11-18 11:06:29.731187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/multiple_plans.rst	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,69 ****
- .. # Copyright (C) 2020-2021 Intel Corporation
- .. # SPDX-License-Identifier: Apache-2.0
- 
- .. _multiple_plans:
- 
- ***********************
- Manage Multiple Plans
- ***********************
- 
- With aggregator-based workflow, you can use multiple Federated Learning plans (FL plan) for the same workspace. All FL plans are located in the **WORKSPACE.FOLDER/plan/plans** directory. 
- 
- The following are the :code:`fx` commands to manage your FL plans:
- 
-     - :ref:`creating_new_plans`
-     - :ref:`saving_new_plans`
-     - :ref:`switching_plans`
-     - :ref:`removing_plans`
-     
- .. _creating_new_plans:
- 
- Create a New FL Plan
- ====================
- 
- All workspaces begin with a :code:`default` FL plan. See :ref:`Create a Workspace on the Aggregator <creating_workspaces>` for details.
- 
- .. _saving_new_plans:
- 
- Save a New FL Plan
- ==================
- 
- When you are working on an FL plan, you can save it for future use.
- 
-     .. code-block:: console
-     
-        fx plan save -n NEW.PLAN.NAME
-       
-  
-     where :code:`NEW.PLAN.NAME` is the new FL plan for your workspace. 
-     This command also combines switching to the :code:`NEW.PLAN.NAME` plan.
-     
- .. _switching_plans:
- 
- Switch FL Plans
- ===============
- 
- To switch to a different FL plan, run the following command from the workspace directory.
- 
-     .. code-block:: console
-     
-        fx plan switch -n PLAN.NAME
- 
-     where :code:`PLAN.NAME` is the FL plan to which you want to switch. 
- 
-     .. note::
- 
-        If you have changed the **plan.yaml** file, you should :ref:`save the FL plan <creating_new_plans>` before switching. Otherwise, any changes will be lost.
-        
- .. _removing_plans:
- 
- Remove FL Plans
- ===============
- 
- To remove an FL plan, run the following command from the workspace directory.
- 
-     .. code-block:: console
-     
-         fx plan remove -n PLAN.NAME
- 
-     where :code:`PLAN.NAME` is the FL plan you wish to remove. 
--- 0 ----
diff -crB --new-file ./openfl/docs/notices_and_disclaimers.rst ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/notices_and_disclaimers.rst
*** ./openfl/docs/notices_and_disclaimers.rst	2022-11-18 11:06:29.731187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/notices_and_disclaimers.rst	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,16 ****
- .. # Copyright (C) 2020-2021 Intel Corporation
- .. # SPDX-License-Identifier: Apache-2.0
- 
- ***********************
- Notices and Disclaimers
- ***********************
- 
- © Intel Corporation. Intel, the Intel logo, and other Intel marks are trademarks of Intel Corporation or its subsidiaries. Other names and brands may be claimed as the property of others. 
- 
- ​​Intel technologies may require enabled hardware, software or service activation.​​​​
- 
- ​No product or compon​ent can be absolutely secure. ​
- 
- Your costs and results may vary. 
- 
- ​​No license (express or implied, by estoppel or otherwise) to any intellectual property rights is granted by this document.
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/docs/openfl.rst ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/openfl.rst
*** ./openfl/docs/openfl.rst	2022-11-18 11:06:29.731187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/openfl.rst	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,27 ****
- .. # Copyright (C) 2020-2021 Intel Corporation
- .. # SPDX-License-Identifier: Apache-2.0
- 
- *************************************************
- |productName| Structure
- *************************************************
- 
- Learn about the short-lived and long-lived components that compose Open Federated Learning (|productName|):
- 
- - :doc:`source/openfl/components`
- 
- Understand the procedure calls to the Director service.
- 
- - :doc:`source/openfl/communication`
- 
- Learn about the plugin framework that makes |productName| flexible and extensible for your use:
- 
- - :doc:`source/openfl/plugins`
- 
- 
- .. toctree::
-    :maxdepth: 4
-    :hidden:
- 
-    source/openfl/components
-    source/openfl/communication
-    source/openfl/plugins
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/docs/overriding_agg_fn.rst ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/overriding_agg_fn.rst
*** ./openfl/docs/overriding_agg_fn.rst	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/overriding_agg_fn.rst	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,291 ****
- .. # Copyright (C) 2020-2021 Intel Corporation
- .. # SPDX-License-Identifier: Apache-2.0
- 
- .. _overriding_agg_fn:
- 
- *****************************
- Override Aggregation Function
- *****************************
- 
- With the aggregator-based workflow, you can use custom aggregation functions for each task via Python\*\  API or command line interface.
- 
- 
- Python API
- ==========
- 
- 1. Create an implementation of :class:`openfl.component.aggregation_functions.core.AggregationFunction`.
- 
- 2. In the ``override_config`` keyword argument of the :func:`openfl.native.run_experiment` native function, pass the implementation as a ``tasks.{task_name}.aggregation_type`` parameter.
- 
- .. note::
-     See `Federated PyTorch MNIST Tutorial <https://github.com/intel/openfl/blob/develop/openfl-tutorials/Federated_Pytorch_MNIST_custom_aggregation_Tutorial.ipynb>`_ for an example of the custom aggregation function.
-     
- 
- Command Line Interface
- ======================
- 
- Predefined Aggregation Functions
- --------------------------------
- 
- Choose from the following predefined aggregation functions:
- 
- - ``openfl.component.aggregation_functions.WeightedAverage`` (default)
- - ``openfl.component.aggregation_functions.Median``
- - ``openfl.component.aggregation_functions.GeometricMedian``
- - ``openfl.component.aggregation_functions.AdagradAdaptiveAggregation``
- - ``openfl.component.aggregation_functions.AdamAdaptiveAggregation``
- - ``openfl.component.aggregation_functions.YogiAdaptiveAggregation``
- 
- 
- .. _adaptive_aggregation_functions:
- 
- Adaptive Aggregation Functions
- ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
- 
- .. note::
-     To create adaptive aggregation functions,
-     the user must specify parameters for the aggregation optimizer
-     (``NumPyAdagrad``, ``NumPyAdam`` or ``NumPyYogi``) that will aggregate
-     the global model. Theese parameters parameters are passed via **keywords**.
- 
-     Also, user must pass one of the arguments: ``params``
-     - model parameters (a dictionary with named model parameters
-     in the form of numpy arrays), or pass ``model_interface``
-     - an instance of the `ModelInterface <https://github.com/intel/openfl/blob/develop/openfl/interface/interactive_api/experiment.py>`_ class.
-     If user pass both ``params`` and ``model_interface``,
-     then the optimizer parameters are initialized via
-     ``params``, ignoring ``model_interface`` argument.
- 
-     See the `AdagradAdaptiveAggregation
-     <https://github.com/intel/openfl/blob/develop/openfl/component/aggregation_functions/adagrad_adaptive_aggregation.py>`_
-     definitions for details.
- 
-     `Adaptive federated optimization <https://arxiv.org/pdf/2003.00295.pdf>`_ original paper.
- 
- ``AdagradAdaptiveAggregation`` usage example:
- 
- .. code-block:: python
- 
-     from openfl.interface.interactive_api.experiment import TaskInterface, ModelInterface
-     from openfl.component.aggregation_functions import AdagradAdaptiveAggregation
- 
-     TI = TaskInterface()
-     MI = ModelInterface(model=model,
-                         optimizer=optimizer,
-                         framework_plugin=framework_adapter)
-     ...
- 
-     # Creating aggregation function
-     agg_fn = AdagradAdaptiveAggregation(model_interface=MI,
-                                         learning_rate=0.4)
- 
-     # Define training task
-     @TI.register_fl_task(model='model', data_loader='train_loader', \
-                             device='device', optimizer='optimizer')
-     @TI.set_aggregation_function(agg_fn)
-     def train(...):
-     ...
- 
- You can define your own numpy based optimizer,
- which will be used for global model aggreagation:
- 
- .. code-block:: python
- 
-     from openfl.utilities.optimizers.numpy.base_optimizer import Optimizer
- 
-     class MyOpt(Optimizer):
-         """My optimizer implementation."""
- 
-         def __init__(
-             self,
-             *,
-             params: Optional[Dict[str, np.ndarray]] = None,
-             model_interface=None,
-             learning_rate: float = 0.001,
-             param1: Any = None,
-             param2: Any = None
-         ) -> None:
-             """Initialize.
- 
-             Args:
-                 params: Parameters to be stored for optimization.
-                 model_interface: Model interface instance to provide parameters.
-                 learning_rate: Tuning parameter that determines
-                     the step size at each iteration.
-                 param1: My own defined parameter.
-                 param2: My own defined parameter.
-             """
-             super().__init__()
-             pass # Your code here!
- 
-         def step(self, gradients: Dict[str, np.ndarray]) -> None:
-             """
-             Perform a single step for parameter update.
- 
-             Implement your own optimizer weights update rule.
- 
-             Args:
-                 gradients: Partial derivatives with respect to optimized parameters.
-             """
-             pass # Your code here!
-     ...
- 
-     from openfl.component.aggregation_functions import WeightedAverage
-     from openfl.component.aggregation_functions.core import AdaptiveAggregation
- 
-     # Creating your implemented optimizer instance based on numpy:
-     my_own_optimizer = MyOpt(model_interface=MI, learning_rate=0.01)
- 
-     # Creating aggregation function
-     agg_fn = AdaptiveAggregation(optimizer=my_own_optimizer,
-                                  agg_func=WeightedAverage()) # WeightedAverage() is used for aggregating
-                                                              # parameters that are not inside the given optimizer.
- 
-     # Define training task
-     @TI.register_fl_task(model='model', data_loader='train_loader', \
-                             device='device', optimizer='optimizer')
-     @TI.set_aggregation_function(agg_fn)
-     def train(...):
-     ...
- 
- .. note::
-     If you do not understand how to write your own numpy based optimizer, please see the `NumPyAdagrad <https://github.com/intel/openfl/blob/develop/openfl/utilities/optimizers/numpy/adagrad_optimizer.py>`_ and
-     `AdaptiveAggregation <https://github.com/intel/openfl/blob/develop/openfl/component/aggregation_functions/core/adaptive_aggregation.py>`_ definitions for details.
- 
- Custom Aggregation Functions
- ----------------------------
- 
- You can also create your own implementation of :class:`openfl.component.aggregation_functions.core.AggregationFunction`. See `example <https://github.com/intel/openfl/blob/develop/openfl-tutorials/Federated_Pytorch_MNIST_custom_aggregation_Tutorial.ipynb>`_ for details.
- 
- 1. Define the behavior of the aggregation.
- 
- 2. Include the implementation in the **plan.yaml** file in the **plan** directory of your workspace.
- 
- 3. In the **tasks** section,  pick a task for which you want to change the aggregation and insert ``aggregation_type`` section with a single ``template`` key that defines a module path to your class.
- 
- The following is an example of a **plan.yaml** with a modified aggregation function:
-   
- .. code-block:: yaml
- 
-   # ...
-   # other top-level sections
-   # ...
-   tasks:
-     aggregated_model_validation:
-       function: validate
-       kwargs:
-         apply: global
-         metrics:
-         - acc
-     defaults: plan/defaults/tasks_torch.yaml
-     locally_tuned_model_validation:
-       function: validate
-       kwargs:
-       apply: local
-       metrics:
-       - acc
-     settings: {}
-     train:
-       function: train_batches
-       aggregation_type:
-         template: openfl.component.aggregation_functions.Median  
-       kwargs:
-         metrics:
-         - loss
- 
- 
- Interactive API
- ================
- You can override aggregation function that will be used for the task this function corresponds to.
- In order to do this, call the ``set_aggregation_function`` decorator method of ``TaskInterface`` and pass ``AggregationFunction`` subclass instance as a parameter.
- For example, you can try:
- 
- .. code-block:: python
- 
-     from openfl.component.aggregation_functions import Median
-     TI = TaskInterface()
-     agg_fn = Median()
-     @TI.register_fl_task(model='model', data_loader='train_loader', \
-                          device='device', optimizer='optimizer')
-     @TI.set_aggregation_function(agg_fn)
- 
- .. warning::
-     All tasks with the same type of aggregation use the same class instance.
-     If ``AggregationFunction`` implementation has its own state, then this state will be shared across tasks.
- 
- 
- ``AggregationFunction`` requires a single ``call`` function.
- This function receives tensors for a single parameter from multiple collaborators with additional metadata (see definition of :meth:`openfl.component.aggregation_functions.core.AggregationFunction.call`) and returns a single tensor that represents the result of aggregation.
- 
- 
- .. note::
-     See the `definition <https://github.com/intel/openfl/blob/develop/openfl/component/aggregation_functions/core/interface.py>`_ of :class:`openfl.component.aggregation_functions.core.AggregationFunction.call` for details.
- 
- 
- Example of a Custom Aggregation Function
- ========================================
- 
- This is an example of a custom tensor clipping aggregation function that multiplies all local tensors by 0.3 and averages them according to weights equal to data parts to produce the resulting global tensor.
- 
- .. code-block:: python
- 
-     from openfl.component.aggregation_functions import AggregationFunction
-     import numpy as np
- 
-     class ClippedAveraging(AggregationFunction):
-         def __init__(self, ratio):
-             self.ratio = ratio
-             
-         def call(self,
-                 local_tensors,
-                 db_iterator,
-                 tensor_name,
-                 fl_round,
-                 *__):
-             """Aggregate tensors.
- 
-             Args:
-                 local_tensors(list[openfl.utilities.LocalTensor]): List of local tensors to aggregate.
-                 db_iterator: iterator over history of all tensors. Columns:
-                     - 'tensor_name': name of the tensor.
-                         Examples for `torch.nn.Module`s: 'conv1.weight', 'fc2.bias'.
-                     - 'round': 0-based number of round corresponding to this tensor.
-                     - 'tags': tuple of tensor tags. Tags that can appear:
-                         - 'model' indicates that the tensor is a model parameter.
-                         - 'trained' indicates that tensor is a part of a training result.
-                             These tensors are passed to the aggregator node after local learning.
-                         - 'aggregated' indicates that tensor is a result of aggregation.
-                             These tensors are sent to collaborators for the next round.
-                         - 'delta' indicates that value is a difference between rounds
-                             for a specific tensor.
-                         also one of the tags is a collaborator name
-                         if it corresponds to a result of a local task.
- 
-                     - 'nparray': value of the tensor.
-                 tensor_name: name of the tensor
-                 fl_round: round number
-                 tags: tuple of tags for this tensor
-             Returns:
-                 np.ndarray: aggregated tensor
-             """
-             clipped_tensors = []
-             previous_tensor_value = None
-             for record in db_iterator:
-                 if (
-                     record['round'] == (fl_round - 1)
-                     and record['tensor_name'] == tensor_name
-                     and 'aggregated' in record['tags']
-                     and 'delta' not in record['tags']
-                 ):
-                     previous_tensor_value = record['nparray']
-             weights = []
-             for local_tensor in local_tensors:
-                 prev_tensor = previous_tensor_value if previous_tensor_value is not None else local_tensor.tensor
-                 delta = local_tensor.tensor - prev_tensor
-                 new_tensor = prev_tensor + delta * self.ratio
-                 clipped_tensors.append(new_tensor)
-                 weights.append(local_tensor.weight)
- 
-             return np.average(clipped_tensors, weights=weights, axis=0)
- 
- A full implementation can be found at `Federated_Pytorch_MNIST_custom_aggregation_Tutorial.ipynb <https://github.com/intel/openfl/blob/develop/openfl-tutorials/Federated_Pytorch_MNIST_custom_aggregation_Tutorial.ipynb>`_
--- 0 ----
diff -crB --new-file ./openfl/docs/overview.how_can_intel_protect_federated_learning.rst ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/overview.how_can_intel_protect_federated_learning.rst
*** ./openfl/docs/overview.how_can_intel_protect_federated_learning.rst	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/overview.how_can_intel_protect_federated_learning.rst	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,60 ****
- .. # Copyright (C) 2020-2021 Intel Corporation
- .. # SPDX-License-Identifier: Apache-2.0
- 
- *****************************************
- How Can Intel Protect Federated Learning?
- *****************************************
- 
- Intel\ :sup:`®` \ Software Guard Extensions (`SGX <https://software.intel.com/content/www/us/en/develop/topics/software-guard-extensions.html>`_)
- are a set of CPU instructions that
- can be used by developers to set aside private regions of code and data
- (`Bahmani, et al., 2017 <https://hal.archives-ouvertes.fr/hal-01898742/file/2016-1057.pdf>`_).
- These private regions, called `enclaves <https://en.wikipedia.org/wiki/Software_Guard_Extensions>`_,
- are isolated sections of memory and compute that cannot be accessed
- without a `cryptographic key <https://en.wikipedia.org/wiki/Cryptographic_key_types>`_. Even users with root access or physical
- access to the CPU cannot access the enclave without the authorized key.
- 
- 
- .. figure:: images/sgx.png
-    :alt: Intel\ :sup:`®` \ Software Guard Extensions
-    :scale: 50%
- 
- .. centered:: Intel\ :sup:`®` \ Software Guard Extensions
- 
- 
- This allows for developers to deploy their code and data on untrusted
- machines in a secure manner. In 2015, Intel\ :sup:`®` \ SGX was launched as the
- `first commercial implementation <https://software.intel.com/content/www/us/en/develop/topics/software-guard-extensions/details.html>`_
- of what is more formally called a
- trusted execution environment (`TEE <https://en.wikipedia.org/wiki/Trusted_execution_environment>`_).
- 
- One path to enable Intel\ :sup:`®` \ SGX in an application is to refactor the
- application code to use the `Intel SDK for SGX <https://software.intel.com/content/www/us/en/develop/topics/software-guard-extensions/sdk.html>`_. However, many developers
- are reluctant to change their existing code.
- 
- `Graphene <https://github.com/oscarlab/graphene>`_ is an
- open-source library OS (LibOS) that was created by Intel and its partners to
- provide developers an easy way to leverage SGX without the need
- to change their existing applications. Several commercial implementations
- of SGX-enabled LibOSes have been created by our partners, including
- `Fortanix <https://fortanix.com>`_ and `SContain <https://scontain.com>`_.
- 
- .. figure:: images/graphene.png
-   :alt: graphene
-   :scale: 40%
- 
- .. centered:: Graphene allows unmodified programs to be protected by SGX.
- 
- With Graphene, the developer simply defines a manifest file
- that describes which code and data is allowed within the enclave.
- This manifest file is used to automatically create the enclave on an
- SGX-compatible CPU. For example, once Graphene is installed and the
- manifest file is specified, the command
- 
- .. code-block:: console
- 
-   $ SGX=1 ./pal_loader httpd
- 
- will use the pal_loader command to create the enclave from the
- manifest and run the web server (:code:`http`) within the enclave. No other
- modifications are needed to protect the :code:`httpd` application with a SGX enclave.
--- 0 ----
diff -crB --new-file ./openfl/docs/overview.rst ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/overview.rst
*** ./openfl/docs/overview.rst	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/overview.rst	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,57 ****
- .. # Copyright (C) 2020-2021 Intel Corporation
- .. # SPDX-License-Identifier: Apache-2.0
- 
- ==========
- Overview
- ==========
- 
- 
- .. note::
- 
-    This project is continually being developed and improved. Expect changes to this manual, the project code, and the project design.
-    
- Open Federated Learning (OpenFL) is a Python\*\  3 project developed by Intel Internet of Things Group (IOTG) and Intel Labs.
- 
- .. figure:: images/ct_vs_fl.png
- 
- .. centered:: Federated Learning
- 
- .. _what_is_openfl:
- 
- ***************************
- What is Federated Learning?
- ***************************
- 
- `Federated learning <https://en.wikipedia.org/wiki/Federated_learning>`_ is a distributed machine learning approach that
- enables collaboration on machine learning projects without sharing sensitive data, such as patient records, financial data,
- or classified secrets (`McMahan, 2016 <https://arxiv.org/abs/1602.05629>`_;
- `Sheller, Reina, Edwards, Martin, & Bakas, 2019 <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6589345/>`_;
- `Yang, Liu, Chen, & Tong, 2019 <https://arxiv.org/abs/1902.04885>`_; 
- `Sheller et al., 2020 <https://www.nature.com/articles/s41598-020-69250-1>`_).
- In federated learning, the model moves to meet the data rather than the data moving to meet the model. The movement of data across the federation are the model parameters and their updates.
- 
- .. figure:: images/diagram_fl_new.png
- 
- .. centered:: Federated Learning
- 
- .. _definitions_and_conventions:
- 
- ***************************
- Definitions and Conventions
- ***************************
- 
- Federated learning brings in a few more components to the traditional data science training pipeline:
- 
- Collaborator
- 	A collaborator is a client in the federation that has access to the local training, validation, and test datasets. By design, the collaborator is the only component of the federation with access to the local data. The local dataset should never leave the collaborator.
- 	
- Aggregator
- 	A parameter server sends a global model to the collaborators. Parameter servers are often combined with aggregators on the same compute node.
- 	An aggregator receives locally tuned models from collaborators and combines the locally tuned models into a new global model. Typically, `federated averaging <https://arxiv.org/abs/1602.05629>`_, (a weighted average) is the algorithm used to combine the locally tuned models. 
- 
- Round
- 	A federation round is defined as the interval (typically defined in terms of training steps) where an aggregation is performed. Collaborators may perform local training on the model for multiple epochs (or even partial epochs) within a single training round.
- 
- .. toctree
- ..    overview.how_can_intel_protect_federated_learning
- ..    overview.what_is_intel_federated_learning
--- 0 ----
diff -crB --new-file ./openfl/docs/overview.what_is_intel_federated_learning.rst ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/overview.what_is_intel_federated_learning.rst
*** ./openfl/docs/overview.what_is_intel_federated_learning.rst	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/overview.what_is_intel_federated_learning.rst	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,36 ****
- .. # Copyright (C) 2020-2021 Intel Corporation
- .. # SPDX-License-Identifier: Apache-2.0
- 
- *********************************************
- What is Intel\ :sup:`®` \ Federated Learning?
- *********************************************
- 
- By leveraging the security provided by Intel\ :sup:`®` \ `SGX <https://software.intel.com/content/www/us/en/develop/topics/software-guard-extensions.html>`_ and the ease of deployment
- provided by `Graphene <https://github.com/oscarlab/graphene>`_, Federated Learning can be protected from adversarial
- attacks that are well documented in the literature. With Intel\ :sup:`®` \ SGX on
- every node in the federation, risks are mitigated even if the nodes are
- not fully-controlled by the federation owner.
- 
- .. figure:: images/trusted_fl.png
- 
- .. centered:: Intel\ :sup:`®` \ Federated Learning
- 
- Previous attacks have shown that adversaries may be able to steal the model,
- reconstruct data based on the model updates, and/or prevent convergence of
- the training when using untrusted nodes
- (`Bagdasaryan, Veit, Hua, Estrin, & Shmatikov, 2018 <https://arxiv.org/abs/1807.00459>`_;
- `Bhagoji, Chakraborty, Supriyo, & Calo, 2018 <https://arxiv.org/abs/1811.12470>`_).
- With Intel\ :sup:`®` \ Federated Learning protected via Intel\ :sup:`®` \ SGX,
- adversaries are unable to use the model and unable to adapt their
- attacks because the actual training is only visible to those with an
- approved key.
- 
- Additionally, Intel\ :sup:`®` \ SGX allows developers to require attestation
- from collaborators which proves that the collaborator actually
- ran the expected code within the enclave. Attestation can either
- be done via a trusted Intel server or by the developers own server.
- This stops attackers from injecting their own code into the federated training.
- 
- .. figure:: images/why_intel_fl.png
- 
- .. centered:: Why Intel\ :sup:`®` \ Federated Learning
--- 0 ----
diff -crB --new-file ./openfl/docs/README.md ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/README.md
*** ./openfl/docs/README.md	2022-11-18 11:06:29.707187478 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/README.md	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,23 ****
- # How to update the documentation
- 
- We use sphinx to generate the documentation for this project.
- The documentation project has been initialized properly and we basically just need to update the actual content.
- 
- Install requirements for building documentation:
- 
- ```sh
- pip install -r requirements-docs.txt
- ```
- 
- 
- The Makefile supports many targets. We choose html because we can easily host the documentation on a remote server. Compile the documentation source code:
- ```sh
- make clean
- make html
- ```
- 
- Open documentation locally:
- ```sh
- cd _build/html
- python -m http.server
- ```
--- 0 ----
diff -crB --new-file ./openfl/docs/requirements-docs.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/requirements-docs.txt
*** ./openfl/docs/requirements-docs.txt	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/requirements-docs.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,6 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- sphinx-rtd-theme
- sphinx-prompt 
- sphinx_substitution_extensions 
- sphinxcontrib-kroki
--- 0 ----
diff -crB --new-file ./openfl/docs/resources/arch.gv ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/resources/arch.gv
*** ./openfl/docs/resources/arch.gv	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/resources/arch.gv	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,101 ****
- digraph arch {
-     rankdir = LR;
-     // concentrate = true;
-     compound = true;
-     // newrank = true;
-     label = "High-Level Trusted Federated Learning Architecture and Data Flow"
-     node [ shape = box ];
-     
-     subgraph cluster_Governor {
-         label = < <B>FL Governor / Admin</B> >;
-         // fontsize = 24;
-         node [ shape = box ];
- 
-         gov_net_server [ label = "Server Socket (REP)" ];
-         gov_root_cert [ label = "Root Cert" ];
-         gov_flplans [ label = "Signed FL Plans" ];
-     }
-     
-     subgraph cluster_CollaboratorFrontend {
-         label = < <B>Collaborator Frontend UI</B> >;
-         // fontsize = 24;
-         node [ shape = box ];
- 
-         ui_model_library [ label = "Model Library" ];
-         ui_local_data [ label = "Local Data" ];
-         ui_flplan_approval [ label = "FLPlan Approval Interface " ];
-     }
- 
-     subgraph cluster_Aggregator {
-         label = < <B>Aggregator</B> >;
-         // fontsize = 24;
-         node [ shape = box ];
- 
-         agg_flplans [ label = "FL Plans" ];
-         agg_net_server [ label = "Server Socket (REP)" ];
-         agg_net_client [ label = "Client Socket (REQ)" ];
-         agg_cert [ label = "Signed Cert" ];
- 
-         subgraph cluster_PerFLPlan {
-             label = < <B>Per FL Plan</B> >;
-             // fontsize = 18;
-             // color = blue;
-             style = "dotted";
- 
-             subgraph cluster_AggFLPlanExecutor {            
-                 label = < Agg FL Plan Executor >;
-                 // fontsize = 18;
-                 // color = blue;
-                 style = "solid";
-                 job_sel [ label = "Job Selector" ];
-                 agg_col_results [ label = "Collaborator Results" ];
-                 agg_results [ label = "Aggregated Results" ];
-             }
-         }
-     }
- 
-     subgraph cluster_Collaborator {
-         label = < <B>Collaborator</B> >;
-         // fontsize = 24;
-         node [ shape = box ];
-         
-         subgraph cluster_ColPerFLPlan {
-             label = < <B>Per FL Plan</B> >;
-             // fontsize = 18;
-             // color = blue;
-             style = "dotted";
-             
-             subgraph cluster_ColFLPlanExecutor {         
-                 label = < Col FL Plan Executor >;
-                 style = "solid";
-                 // fontsize = 18;
-                 // color = blue;
-                 col_model [ label = "Model / Job Handler" ];
-             }
-         }
-         col_flplans [ label = "FL Plans" ];
-         col_net_client [ label = "Client Socket (REQ)" ];
-         col_cert [ label = "Signed Cert" ];
-         // col_local_data [ label = "Local Data" ];
-     }
-     
-     // {rank = same; cluster_ColFLPlanExecutor; cluster_AggFLPlanExecutor}
-     ui_local_data -> col_model
-     ui_model_library -> col_model
-     ui_flplan_approval -> col_model [ltail=ui_flplan_approval, lhead=cluster_ColFLPlanExecutor dir=both];
-     gov_flplans -> agg_flplans [ label = "Signed FL Plans" style = "dotted" ];
-     gov_flplans -> col_flplans [ label = "Signed FL Plans" style = "dotted" ];
-     agg_cert -> gov_root_cert [ label = "Cert Signing Requests" style = "dotted" ];
-     col_cert -> gov_root_cert [ label = "Cert Signing Requests" style = "dotted" ];
-     job_sel -> col_model [ label = "Jobs (e.g. train, validate)" style = "dotted" ];
-     col_model -> agg_col_results [ label = "Job results (e.g. model updates, val scores, losses)" style = "dotted" ];
-     agg_col_results -> agg_results [ label = "Aggregation Functions" ];
- 
-     agg_results -> col_model [ label = "Shared model updates" ];
- 
-     edge  [dir="both" ]
-     gov_net_server -> col_net_client [ label = "Secure Channel" ];
-     agg_net_server -> col_net_client [ label = "Secure Channel" ];
-     gov_net_server -> agg_net_client [ label = "Secure Channel" ];
-     
- }
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/docs/running_the_federation.rst ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/running_the_federation.rst
*** ./openfl/docs/running_the_federation.rst	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/running_the_federation.rst	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,1181 ****
- .. # Copyright (C) 2020-2021 Intel Corporation
- .. # SPDX-License-Identifier: Apache-2.0
- 
- .. _running_the_federation:
- 
- ******************
- Run the Federation
- ******************
- 
- OpenFL currently supports two types of workflow for how to set up and run a federation: Director-based workflow (preferrable) and Aggregator-based workflow (old workflow, will not be supported soon). Director-based workflow introduces a new and more convenient way to set up a federation and brings "long-lived" components in a federation ("Director" and "Envoy").
- 
- `Director-Based Workflow`_
-     A federation created with this workflow continues to be available to distribute more experiments in series.
- 
- `Aggregator-Based Workflow`_
-     With this workflow, the federation is terminated when the experiment is finished.
- 
- 
- .. _director_workflow:
- 
- 
- Director-Based Workflow
- =======================
- 
- A director-based workflow uses long-lived components in a federation. These components continue to be available to distribute more experiments in the federation.
- 
- - The *Director* is the central node of the federation. This component starts an *Aggregator* for each experiment, sends data to connected collaborator nodes, and provides updates on the status.
- - The *Envoy* runs on collaborator nodes connected to the *Director*. When the *Director* starts an experiment, the *Envoy* starts the *Collaborator* to train the global model.
- 
- 
- The director-based workflow comprises the following roles and their tasks:
- 
-     - `Director Manager: Set Up the Director`_
-     - `Collaborator Manager: Set Up the Envoy`_
-     - `Experiment Manager: Describe an Experiment`_
- 
- Follow the procedure in the director-based workflow to become familiar with the setup required and APIs provided for each role in the federation: *Experiment manager (Data scientist)*, *Director manager*, and *Collaborator manager*.
- 
- - *Experiment manager* (or Data scientist) is a person or group of people using OpenFL.
- - *Director Manager* is ML model creator's representative controlling Director.
- - *Collaborator manager* is Data onwer's representative controlling Envoy.
- 
- .. note::
-     The Open Federated Learning (|productName|) interactive Python API enables the Experiment manager (data scientists) to define and start a federated learning experiment from a single entry point: a Jupyter\*\  notebook or a Python\*\  script.
- 
-     See `Interactive Python API (Beta)`_ for details.
- 
- An overview of this workflow is shown below.
- 
- .. figure:: ./source/openfl/director_workflow.svg
- 
- .. centered:: Overview of the Director-Based Workflow
- 
- 
- .. # Copyright (C) 2020-2021 Intel Corporation
- .. # SPDX-License-Identifier: Apache-2.0
- 
- 
- .. _establishing_federation_director:
- 
- Director Manager: Set Up the Director
- -------------------------------------
- 
- The *Director manager* sets up the *Director*, which is the central node of the federation.
- 
- .. _optional_step_create_pki_using_step_ca:
- 
- OPTIONAL STEP: Create PKI Certificates Using Step-CA
- ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
- 
- The use of mutual Transport Layer Security (mTLS) is recommended for deployments in untrusted environments to establish participant identity and to encrypt communication. You may either import certificates provided by your organization or generate certificates with the :ref:`semi-automatic PKI <semi_automatic_certification>` provided by |productName|.
- 
- .. _step0_install_director_prerequisites:
- 
- STEP 1: Install Open Federated Learning (|productName|)
- ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
- 
- Install |productName| in a virtual Python\*\  environment. See :ref:`install_package` for details.
- 
- .. _step1_start_the_director:
- 
- STEP 2: Start the Director
- ^^^^^^^^^^^^^^^^^^^^^^^^^^
- 
- Start the Director on a node with at least two open ports. See :ref:`openfl_ll_components` to learn more about the Director entity.
- 
- 1. Create a Director workspace with a default config file.
- 
-     .. code-block:: console
- 
-         fx director create-workspace -p path/to/director_workspace_dir
- 
-  This workspace will contain received experiments and supplementary files (Director config file and certificates).
- 
- 2. Modify the Director config file according to your federation setup.
- 
-  The default config file contains the Director node FQDN, an open port, path of certificates, and :code:`sample_shape` and :code:`target_shape` fields with string representation of the unified data interface in the federation.
- 
- 3. Start the Director.
- 
-  If mTLS protection is not set up, run this command.
- 
-     .. code-block:: console
- 
-        fx director start --disable-tls -c director_config.yaml
- 
-  If you have a federation with PKI certificates, run this command.
- 
-     .. code-block:: console
- 
-        fx director start -c director_config.yaml \
-             -rc cert/root_ca.crt \
-             -pk cert/priv.key \
-             -oc cert/open.crt
- 
- 
- 
- .. _establishing_federation_envoy:
- 
- Collaborator Manager: Set Up the Envoy
- --------------------------------------
- 
- The *Collaborator manager* sets up the *Envoys*, which are long-lived components on collaborator nodes. When started, Envoys will try to connect to the Director. Envoys receive an experiment archive and provide access to local data.
- 
-     - :ref:`optional_step_sign_pki_envoy`
-     - :ref:`step0_install_envoy_prerequisites`
-     - :ref:`step1_start_the_envoy`
- 
- .. _optional_step_sign_pki_envoy:
- 
- OPTIONAL STEP: Sign PKI Certificates (Optional)
- ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
- 
- The use of mTLS is recommended for deployments in untrusted environments to establish participant identity and to encrypt communication. You may either import certificates provided by your organization or use the :ref:`semi-automatic PKI certificate <semi_automatic_certification>` provided by |productName|.
- 
- 
- .. _step0_install_envoy_prerequisites:
- 
- STEP 1: Install |productName|
- ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
- 
- Install |productName| in a Python\*\ virtual environment. See :ref:`install_package` for details.
- 
- 
- .. _step1_start_the_envoy:
- 
- STEP 2: Start the Envoy
- ^^^^^^^^^^^^^^^^^^^^^^^
- 
- 1. Create an Envoy workspace with a default config file and shard descriptor Python\*\  script.
- 
-     .. code-block:: console
- 
-         fx envoy create-workspace -p path/to/envoy_workspace_dir
- 
- 2. Modify the Envoy config file and local shard descriptor template.
- 
-     - Provide the settings field with the arbitrary settings required to initialize the shard descriptor.
-     - Complete the shard descriptor template field with the address of the local shard descriptor class.
- 
-     .. note::
-         The shard descriptor is an object to provide a unified data interface for FL experiments.
-         The shard descriptor implements :code:`get_dataset()` method as well as several additional
-         methods to access **sample shape**, **target shape**, and **shard description** that may be used to identify
-         participants during experiment definition and execution.
- 
-         :code:`get_dataset()` method accepts the dataset_type (for instance train, validation, query, gallery) and returns
-         an iterable object with samples and targets.
- 
-         User's implementation of ShardDescriptor should be inherented from :code:`openfl.interface.interactive_api.shard_descriptor.ShardDescriptor`. It should implement :code:`get_dataset`, :code:`sample_shape` and :code:`target_shape` methods to describe the way data samples and labels will be loaded from disk during training.
- 
- 3. Start the Envoy.
- 
-  If mTLS protection is not set up, run this command.
- 
-     .. code-block:: console
- 
-         ENVOY_NAME=envoy_example_name
- 
-         fx envoy start \
-             -n "$ENVOY_NAME" \
-             --disable-tls \
-             --envoy-config-path envoy_config.yaml \
-             -dh director_fqdn \
-             -dp port
- 
-  If you have a federation with PKI certificates, run this command.
- 
-     .. code-block:: console
- 
-         ENVOY_NAME=envoy_example_name
- 
-         fx envoy start \
-             -n "$ENVOY_NAME" \
-             --envoy-config-path envoy_config.yaml \
-             -dh director_fqdn \
-             -dp port \
-             -rc cert/root_ca.crt \
-             -pk cert/"$ENVOY_NAME".key \
-             -oc cert/"$ENVOY_NAME".crt
- 
- 
- .. _establishing_federation_experiment_manager:
- 
- Experiment Manager: Describe an Experiment
- ------------------------------------------
- 
- The process of defining an experiment is decoupled from the process of establishing a federation.
- The Experiment manager (or data scientist) is able to prepare an experiment in a Python environment.
- Then the Experiment manager registers experiments into the federation using `Interactive Python API (Beta)`_
- that is allow to communicate with the Director using a gRPC client.
- 
- 
- .. _interactive_python_api:
- 
- Interactive Python API (Beta)
- -----------------------------
- 
- The Open Federated Learning (|productName|) interactive Python API enables the Experiment manager (data scientists) to define and start a federated learning experiment from a single entry point: a Jupyter\*\  notebook or a Python script.
- 
-     - `Prerequisites`_
-     - `Define a Federated Learning Experiment`_
-     - `Federation API`_
-     - `Experiment API`_
-     - `Start an FL Experiment`_
- 
- 
- .. _prerequisites:
- 
- Prerequisites
- ^^^^^^^^^^^^^
- 
- The Experiment manager requires the following:
- 
- Python Intepreter
-     Create a virtual Python environment with packages required for conducting the experiment. The Python environment is replicated on collaborator nodes.
- 
- A Local Experiment Workspace
-     Initialize a workspace by creating an empty directory and placing inside the workspace a Jupyter\*\  notebook or a Python script.
- 
-     Items in the workspace may include:
- 
-         - source code of objects imported into the notebook from local modules
-         - local test data stored in a **data** directory
-         - certificates stored in a **cert** directory
- 
-     .. note::
- 
-         This workspace will be archived and transferred to collaborator nodes. Ensure only relevant source code or resources are stored in the workspace.
-          **data** and **cert** directories will not be included in the archive.
- 
- 
- .. _federation_api_define_fl_experiment:
- 
- Define a Federated Learning Experiment
- ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
- 
- The definition process of a federated learning experiment uses the interactive Python API to set up several interface entities and experiment parameters.
- 
- The following are the interactive Python API to define an experiment:
- 
-     - `Federation API`_
-     - `Experiment API`_
-     - `Start an FL Experiment`_
-     - `Observe the Experiment Execution`_
- 
- .. note::
-     Each federation is bound to some Machine Learning problem in a sense that all collaborators dataset shards should allow to solve the same data science problem.
-     For example object detection and semantic segmentation problems should be solved in different federations. \
- 
- 
- .. _federation_api:
- 
- Federation API
- """"""""""""""
- 
- The *Federation* entity is designed to be a bridge between a notebook and *Director*.
- 
- 
- 1. Import the Federation class from openfl package
- 
-     .. code-block:: python
- 
-         from openfl.interface.interactive_api.federation import Federation
- 
- 
- 2. Initialize the Federation object with the Director node network address and encryption settings.
- 
-     .. code-block:: python
- 
-         federation = Federation(
-             client_id: str, director_node_fqdn: str, director_port: str
-             tls: bool, cert_chain: str, api_cert: str, api_private_key: str)
- 
-     .. note::
-         You may disable mTLS in trusted environments or enable mTLS by providing paths to the certificate chain of the API authority, aggregator certificate, and a private key.
- 
- 
- .. note::
-     Methods available in the Federation API:
- 
-         - :code:`get_dummy_shard_descriptor`: creates a dummy shard descriptor for debugging the experiment pipeline
-         - :code:`get_shard_registry`: returns information about the Envoys connected to the Director and their shard descriptors
- 
- .. _experiment_api:
- 
- Experiment API
- """"""""""""""
- 
- The *Experiment* entity registers training-related objects, federated learning (FL) tasks, and settings.
- 
- 1. Import the FLExperiment class from openfl package
- 
-     .. code-block:: python
- 
-         from openfl.interface.interactive_api.experiment import FLExperiment
- 
- 2. Initialize the experiment with the following parameters: a federation object and a unique experiment name.
- 
-     .. code-block:: python
- 
-         fl_experiment = FLExperiment(federation: Federation, experiment_name: str)
- 
- 3. Import these supplementary interface classes: :code:`TaskInterface`, :code:`DataInterface`, and :code:`ModelInterface`.
- 
-     .. code-block:: python
- 
-         from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface
- 
- 
- .. _experiment_api_modelinterface:
- 
- Register the Model and Optimizer ( :code:`ModelInterface` )
- 
- Instantiate and initialize a model and optimizer in your preferred deep learning framework.
- 
-     .. code-block:: python
- 
-         from openfl.interface.interactive_api.experiment import ModelInterface
-         MI = ModelInterface(model, optimizer, framework_plugin: str)
- 
- The initialized model and optimizer objects should be passed to the :code:`ModelInterface` along with the path to correct Framework Adapter plugin inside the |productName| package
- or from local workspace.
- 
- .. note::
-     The |productName| interactive API supports *TensorFlow* and *PyTorch* frameworks via existing plugins.
-     User can add support for other deep learning frameworks via the plugin interface and point to your implementation of a :code:`framework_plugin` in :code:`ModelInterface`.
- 
- 
- .. _experiment_api_taskinterface:
- 
- Register FL Tasks ( :code:`TaskInterface` )
- 
- An FL task accepts the following objects:
- 
-     - :code:`model` - will be rebuilt with relevant weights for every task by `TaskRunner`
-     - :code:`data_loader` - data loader that will provide local data
-     - :code:`device` - a device to be used for execution on collaborator machines
-     - :code:`optimizer` (optional) - model optimizer; only for training tasks
- 
- Register an FL task and accompanying information.
- 
-     .. code-block:: python
- 
-         TI = TaskInterface()
- 
-         task_settings = {
-             'batch_size': 32,
-             'some_arg': 228,
-         }
-         @TI.add_kwargs(**task_settings)
-         @TI.register_fl_task(model='my_model', data_loader='train_loader',
-                 device='device', optimizer='my_Adam_opt')
-         def foo(my_model, train_loader, my_Adam_opt, device, batch_size, some_arg=356):
-             # training or validation logic
-         ...
- 
- FL tasks return a dictionary object with metrics: :code:`{metric name: metric value for this task}`.
- 
- .. note::
-     The |productName| interactive API currently allows registering only standalone functions defined in the main module or imported from other modules inside the workspace.
- 
-     The :code:`TaskInterface` class must be instantiated before you can use its methods to register FL tasks.
- 
-         - :code:`@TI.register_fl_task()` needs tasks argument names for :code:`model`, :code:`data_loader`, :code:`device` , and :code:`optimizer` (optional) that constitute a *task contract*. This method adds the callable and the task contract to the task registry.
-         - :code:`@TI.add_kwargs()` should be used to set up arguments that are not included in the contract.
- 
- 
- .. _experiment_api_datainterface:
- 
- Register Federated Data Loader ( :code:`DataInterface` )
- 
- A *shard descriptor* defines how to read and format the local data. Therefore, the *data loader* contains the batching and augmenting data logic, which are common for all collaborators.
- 
- Subclass :code:`DataInterface` and implement the following methods.
- 
-     .. code-block:: python
- 
-         class CustomDataLoader(DataInterface):
-             def __init__(self, **kwargs):
-                 # Initialize superclass with kwargs: this array will be passed
-                 # to get_data_loader methods
-                 super().__init__(**kwargs)
-                 # Set up augmentation, save required parameters,
-                 # use it as you regular dataset class
-                 validation_fraction = kwargs.get('validation_fraction', 0.5)
-                 ...
- 
-             @property
-             def shard_descriptor(self):
-                 return self._shard_descriptor
- 
-             @shard_descriptor.setter
-             def shard_descriptor(self, shard_descriptor):
-                 self._shard_descriptor = shard_descriptor
-                 # You can implement data splitting logic here
-                 # Or update your data set according to local Shard Descriptor atributes if required
- 
-             def get_train_loader(self, **kwargs):
-                 # these are the same kwargs you provided to __init__,
-                 # But passed on a collaborator machine
-                 bs = kwargs.get('train_batch_size', 32)
-                 return foo_loader()
- 
-             # so on, see the full list of methods below
- 
- 
- The following are shard descriptor setter and getter methods:
- 
-     - :code:`shard_descriptor(self, shard_descriptor)` is called during the *Collaborator* initialization procedure with the local shard descriptor. Include in this method any logic that is triggered with the shard descriptor replacement.
-     - :code:`get_train_loader(self, **kwargs)` is called before the execution of training tasks. This method returns the outcome of the training task according to the :code:`data_loader` contract argument. The :code:`kwargs` dict returns the same information that was provided during the :code:`DataInterface` initialization.
-     - :code:`get_valid_loader(self, **kwargs)` is called before the execution of validation tasks. This method returns the outcome of the validation task according to the :code:`data_loader` contract argument. The :code:`kwargs` dict returns the same information that was provided during the :code:`DataInterface` initialization.
-     - :code:`get_train_data_size(self)` returns the number of samples in the local dataset for training. Use the information provided by the shard descriptor to determine how to split your training and validation tasks.
-     - :code:`get_valid_data_size(self)` returns the number of samples in the local dataset for validation.
- 
- 
- .. note::
- 
-     - The *User Dataset* class should be instantiated to pass further to the *Experiment* object.
-     - Dummy *shard descriptor* (or a custom local one) may be set up to test the augmentation or batching pipeline.
-     - Keyword arguments used during initialization on the frontend node may be used during dataloaders construction on collaborator machines.
- 
- 
- 
- .. _federation_api_start_fl_experiment:
- 
- Start an FL Experiment
- ^^^^^^^^^^^^^^^^^^^^^^
- 
- Use the Experiment API to prepare a workspace archive to transfer to the *Director*.
- 
-     .. code-block:: python
- 
-         FLExperiment.start()
- 
-   .. note::
-     Instances of interface classes :code:`(TaskInterface, DataInterface, ModelInterface)` must be passed to :code:`FLExperiment.start()` method along with other parameters.
- 
-     This method:
- 
-         - Compiles all provided settings to a Plan object. The Plan is the central place where all actors in federation look up their parameters.
-         - Saves **plan.yaml** to the :code:`plan` folder inside the workspace.
-         - Serializes interface objects on the disk.
-         - Prepares **requirements.txt** for remote Python environment setup.
-         - Compresses the whole workspace to an archive.
-         - Sends the experiment archive to the *Director* so it may distribute the archive across the federation and start the *Aggregator*.
- 
- FLExperiment :code:`start()` Method Parameters
- """"""""""""""""""""""""""""""""""""""""""""""
- 
- The following are parameters of the :code:`start()` method in FLExperiment:
- 
- :code:`model_provider`
-     This parameter is defined earlier by the :code:`ModelInterface` object.
- 
- :code:`task_keeper`
-     This parameter is defined earlier by the :code:`TaskInterface` object.
- 
- :code:`data_loader`
-     This parameter is defined earlier by the :code:`DataInterface` object.
- 
- :code:`task_assigner`
-     This parameter is optional. You can pass a `Custom task assigner function`_.
- 
- :code:`rounds_to_train`
-     This parameter defines the number of aggregation rounds needed to be conducted before the experiment is considered finished.
- 
- :code:`delta_updates`
-     This parameter sets up the aggregation to use calculated gradients instead of model checkpoints.
- 
- :code:`opt_treatment`
-     This parameter defines the optimizer state treatment in the federation. The following are available values:
- 
-     - **RESET**: the optimizer state is initialized each round from noise
-     - **CONTINUE_LOCAL**: the optimizer state will be reused locally by every collaborator
-     - **CONTINUE_GLOBAL**: the optimizer's state will be aggregated
- 
- :code:`device_assignment_policy`
-     The following are available values:
- 
-     - **CPU_ONLY**: the :code:`device` parameter (which is a part of a task contract) that is passed to an FL task each round will be **cpu**
-     - **CUDA_PREFFERED**: the :code:`device` parameter will be **cuda:{index}** if CUDA devices are enabled in the Envoy config and **cpu** otherwise.
- 
- 
- .. _federation_api_observe_fl_experiment:
- 
- Observe the Experiment Execution
- ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
- 
- If the experiment was accepted by the *Director*, you can oversee its execution with the :code:`FLexperiment.stream_metrics()` method. This method prints metrics from the FL tasks (and saves TensorBoard logs).
- 
- 
- .. _federation_api_complete_fl_experiment:
- 
- Complete the Experiment
- ^^^^^^^^^^^^^^^^^^^^^^^
- 
- When the experiment has completed:
- 
-     - retrieve trained models in the native format using :code:`FLexperiment.get_best_model()` and :code:`FLexperiment.get_last_model()`.
-     - erase experiment artifacts from the Director with :code:`FLexperiment.remove_experiment_data()`.
- 
- 
- You may use the same federation object to report another experiment or even schedule several experiments that will be executed in series.
- 
- Custom task assigner function
- ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
- OpenFL has an entity named Task Assigner, that responsible for aggregator task assigning to collaborators.
- There are three default tasks that are used: :code:`train`, :code:`locally_tuned_model_validate`,
- :code:`aggregated_model_validate`.
- When you register a train function and pass optimizer it generates a train task:
- 
-     .. code-block:: python
- 
-         task_keeper = TaskInterface()
- 
- 
-         @task_keeper.register_fl_task(model='net_model', data_loader='train_loader',
-                                       device='device', optimizer='optimizer')
-         def train(net_model, train_loader, optimizer, device, loss_fn=cross_entropy, some_parameter=None):
-             torch.manual_seed(0)
-             ...
- 
- When you register a validate function, it generates two tasks: :code:`locally_tuned_model_validate` and
- :code:`aggregated_model_validate`.
- :code:`locally_tuned_model_validate` is applied by collaborator to locally trained model,
- :code:`aggregated_model_validate` - to a globally aggregated model.
- If there not a train task only aggregated_model_validate are generated.
- 
- Since 1.3 version it is possible to create a custom task assigner function to implement your own task assigning logic.
- You can get registered task from :code:`task_keeper` calling method :code:`get_registered_tasks`:
- 
-     .. code-block:: python
- 
-         tasks = task_keeper.get_registered_tasks()
- 
- 
- And  then implement your own assigner function:
- 
-     .. code-block:: python
- 
-         def random_assigner(collaborators, round_number, **kwargs):
-             """Assigning task groups randomly while ensuring target distribution"""
-             import random
-             random.shuffle(collaborators)
-             collaborator_task_map = {}
-             for idx, col in enumerate(collaborators):
-                 # select only 70% collaborators for training and validation, 30% for validation
-                 if (idx+1)/len(collaborators) <= 0.7:
-                     collaborator_task_map[col] = tasks.values()  # all three tasks
-                 else:
-                     collaborator_task_map[col] = [tasks['aggregated_model_validate']]
-             return collaborator_task_map
- 
- And then pass that function to fl_experiment start method:
-     .. code-block:: python
- 
-         fl_experiment.start(
-             model_provider=model_interface,
-             task_keeper=task_keeper,
-             data_loader=fed_dataset,
-             task_assigner=random_assigner,
-             rounds_to_train=50,
-             opt_treatment='CONTINUE_GLOBAL',
-             device_assignment_policy='CUDA_PREFERRED'
-         )
- 
- 
- It will be passed to assigner and tasks will be assigned to collaborators by using this function.
- 
- Another example.
- If you want only exclude some collaborators from experiment, you can define next assigner function:
- 
-     .. code-block:: python
- 
-         def filter_assigner(collaborators, round_number, **kwargs):
-             collaborator_task_map = {}
-             exclude_collaborators = ['env_two', 'env_three']
-             for collaborator_name in collaborators:
-                 if collaborator_name in exclude_collaborators:
-                     continue
-                 collaborator_task_map[collaborator_name] = [
-                     tasks['train'],
-                     tasks['locally_tuned_model_validate'],
-                     tasks['aggregated_model_validate']
-                 ]
-             return collaborator_task_map
- 
- 
- Also you can use static shard information to exclude any collaborators without cuda devices from training:
- 
-     .. code-block:: python
- 
-         shard_registry = federation.get_shard_registry()
-         def filter_by_shard_registry_assigner(collaborators, round_number, **kwargs):
-             collaborator_task_map = {}
-             for collaborator in collaborators:
-                 col_status = shard_registry.get(collaborator)
-                 if not col_status or not col_status['is_online']:
-                     continue
-                 node_info = col_status['shard_info'].node_info
-                 # Assign train task if collaborator has GPU with total memory more that 8 GB
-                 if len(node_info.cuda_devices) > 0 and node_info.cuda_devices[0].memory_total > 8 * 1024**3:
-                     collaborator_task_map[collaborator] = [
-                         tasks['train'],
-                         tasks['locally_tuned_model_validate'],
-                         tasks['aggregated_model_validate'],
-                     ]
-                 else:
-                     collaborator_task_map[collaborator] = [
-                         tasks['aggregated_model_validate'],
-                     ]
-             return collaborator_task_map
- 
- 
- Assigner with additional validation round:
- 
-     .. code-block:: python
- 
-         rounds_to_train = 3
-         total_rounds = rounds_to_train + 1 # use fl_experiment.start(..., rounds_to_train=total_rounds,...)
- 
-         def assigner_with_last_round_validation(collaborators, round_number, **kwargs):
-             collaborator_task_map = {}
-             for collaborator in collaborators:
-                 if round_number == total_rounds - 1:
-                     collaborator_task_map[collaborator] = [
-                         tasks['aggregated_model_validate'],
-                     ]
-                 else:
-                     collaborator_task_map[collaborator] = [
-                         tasks['train'],
-                         tasks['locally_tuned_model_validate'],
-                         tasks['aggregated_model_validate']
-                     ]
-             return collaborator_task_map
- 
- 
- .. _running_the_federation_aggregator_based:
- 
- Aggregator-Based Workflow
- =========================
- 
- An overview of this workflow is shown below.
- 
- .. figure:: /images/openfl_flow.png
- 
- .. centered:: Overview of the Aggregator-Based Workflow
- 
- There are two ways to run federation without Director:
- 
- - `Bare Metal Approach`_
- - `Docker Approach`_
- 
- 
- This workflow uses short-lived components in a federation, which is terminated when the experiment is finished. The components are as follows:
- 
- - The *Collaborator* uses a local dataset to train a global model and the *Aggregator* receives model updates from *Collaborators* and aggregates them to create the new global model.
- - The *Aggregator* is framework-agnostic, while the *Collaborator* can use any deep learning frameworks, such as `TensorFlow <https://www.tensorflow.org/>`_\* \  or `PyTorch <https://pytorch.org/>`_\*\.
- 
- 
- For this workflow, you modify the federation workspace to your requirements by editing the Federated Learning plan (FL plan) along with the Python\*\  code that defines the model and the data loader. The FL plan is a `YAML <https://en.wikipedia.org/wiki/YAML>`_ file that defines the collaborators, aggregator, connections, models, data, and any other parameters that describe the training.
- 
- 
- .. _plan_settings:
- 
- 
- Federated Learning Plan (FL Plan) Settings
- ------------------------------------------
- 
- .. note::
-     Use the Federated Learning plan (FL plan) to modify the federation workspace to your requirements in an **aggregator-based workflow**.
- 
- 
- The FL plan is described by the **plan.yaml** file located in the **plan** directory of the workspace.
- 
- 
- Each YAML top-level section contains the following subsections:
- 
- - ``template``: The name of the class including top-level packages names. An instance of this class is created when the plan gets initialized.
- - ``settings``: The arguments that are passed to the class constructor.
- - ``defaults``: The file that contains default settings for this subsection.
-   Any setting from defaults file can be overridden in the **plan.yaml** file.
- 
- The following is an example of a **plan.yaml**:
- 
- .. literalinclude:: ../openfl-workspace/torch_cnn_mnist/plan/plan.yaml
-   :language: yaml
- 
- 
- Configurable Settings
- ^^^^^^^^^^^^^^^^^^^^^
- 
- - :class:`Aggregator <openfl.component.Aggregator>`
-     `openfl.component.Aggregator <https://github.com/intel/openfl/blob/develop/openfl/component/aggregator/aggregator.py>`_
- 
- - :class:`Collaborator <openfl.component.Collaborator>`
-     `openfl.component.Collaborator <https://github.com/intel/openfl/blob/develop/openfl/component/collaborator/collaborator.py>`_
- 
- - :class:`Data Loader <openfl.federated.data.loader.DataLoader>`
-     `openfl.federated.data.loader.DataLoader <https://github.com/intel/openfl/blob/develop/openfl/federated/data/loader.py>`_
- 
- - :class:`Task Runner <openfl.federated.task.runner.TaskRunner>`
-     `openfl.federated.task.runner.TaskRunner <https://github.com/intel/openfl/blob/develop/openfl/federated/task/runner.py>`_
- 
- - :class:`Assigner <openfl.component.Assigner>`
-     `openfl.component.Assigner <https://github.com/intel/openfl/blob/develop/openfl/component/assigner/assigner.py>`_
- 
- 
- Tasks
- ^^^^^
- 
- Each task subsection contains the following:
- 
- - ``function``: The function name to call.
-   The function must be the one defined in :class:`TaskRunner <openfl.federated.TaskRunner>` class.
- - ``kwargs``: kwargs passed to the ``function``.
- 
- .. note::
-     See an `example <https://github.com/intel/openfl/blob/develop/openfl/federated/task/runner.py>`_ of the :class:`TaskRunner <openfl.federated.TaskRunner>` class for details.
- 
- 
- .. _running_the_federation_manual:
- 
- 
- .. _interactive_api:
- 
- 
- 
- Bare Metal Approach
- -------------------
- 
- .. note::
- 
-     Ensure you have installed the |productName| package on every node (aggregator and collaborators) in the federation.
- 
-     See :ref:`install_package` for details.
- 
- 
- You can use the `"Hello Federation" bash script <https://github.com/intel/openfl/blob/develop/tests/github/test_hello_federation.sh>`_ to quickly create a federation (an aggregator node and two collaborator nodes) to test the project pipeline.
- 
- .. literalinclude:: ../tests/github/test_hello_federation.sh
-   :language: bash
- 
- However, continue with the following procedure for details in creating a federation with an aggregator-based workflow.
- 
-     `STEP 1: Create a Workspace on the Aggregator`_
- 
-         - Creates a federated learning workspace on one of the nodes.
- 
- 
-     `STEP 2: Configure the Federation`_
- 
-         - Ensures each node in the federation has a valid public key infrastructure (PKI) certificate.
-         - Distributes the workspace from the aggregator node to the other collaborator nodes.
- 
- 
-     `STEP 3: Start the Federation`_
- 
- 
- .. _creating_workspaces:
- 
- 
- STEP 1: Create a Workspace on the Aggregator
- ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
- 
- 1.	Start a Python 3.8 (>=3.6, <3.9) virtual environment and confirm |productName| is available.
- 
- 	.. code-block:: python
- 
- 		fx
- 
- 
- 2. 	This example uses the :code:`keras_cnn_mnist` template.
- 
- 	Set the environment variables to use the :code:`keras_cnn_mnist` as the template and :code:`${HOME}/my_federation` as the path to the workspace directory.
- 
-     .. code-block:: console
- 
-         export WORKSPACE_TEMPLATE=keras_cnn_mnist
-         export WORKSPACE_PATH=${HOME}/my_federation
- 
- 3.	Decide a workspace template, which are end-to-end federated learning training demonstrations. The following is a sample of available templates:
- 
-  - :code:`keras_cnn_mnist`: a workspace with a simple `Keras <http://keras.io/>`__ CNN model that will download the `MNIST <http://yann.lecun.com/exdb/mnist/>`_ dataset and train in a federation.
-  - :code:`tf_2dunet`: a workspace with a simple `TensorFlow <http://tensorflow.org>`__ CNN model that will use the `BraTS <https://www.med.upenn.edu/sbia/brats2017/data.html>`_ dataset and train in a federation.
-  - :code:`tf_cnn_histology`: a workspace with a simple `TensorFlow <http://tensorflow.org>`__ CNN model that will download the `Colorectal Histology <https://zenodo.org/record/53169#.XGZemKwzbmG>`_ dataset and train in a federation.
-  - :code:`torch_cnn_histology`: a workspace with a simple `PyTorch <http://pytorch.org/>`__ CNN model that will download the `Colorectal Histology <https://zenodo.org/record/53169#.XGZemKwzbmG>`_ dataset and train in a federation.
-  - :code:`torch_cnn_mnist`: a workspace with a simple `PyTorch <http://pytorch.org>`__ CNN model that will download the `MNIST <http://yann.lecun.com/exdb/mnist/>`_ dataset and train in a federation.
- 
-   See the complete list of available templates.
- 
-     .. code-block:: console
- 
-        fx workspace create --prefix ${WORKSPACE_PATH}
- 
- 
- 4.  Create a workspace directory for the new federation project.
- 
-     .. code-block:: console
- 
-        fx workspace create --prefix ${WORKSPACE_PATH} --template ${WORKSPACE_TEMPLATE}
- 
- 
-     .. note::
- 
- 		You can use your own models by overwriting the Python scripts in the **src** subdirectory in the workspace directory.
- 
- 5.  Change to the workspace directory.
- 
-     .. code-block:: console
- 
-         cd ${WORKSPACE_PATH}
- 
- 6.  Install the workspace requirements:
- 
-     .. code-block:: console
- 
-         pip install -r requirements.txt
- 
- 
- 7.	Create an initial set of random model weights.
- 
-     .. note::
- 
-         While models can be trained from scratch, in many cases the federation performs fine-tuning of a previously trained model. For this reason, pre-trained weights for the model are stored in protobuf files on the aggregator node and passed to collaborator nodes during initialization.
- 
-         The protobuf file with the initial weights is found in **${WORKSPACE_TEMPLATE}_init.pbuf**.
- 
- 
-     .. code-block:: console
- 
- 		fx plan initialize
- 
- 
-     This command initializes the FL plan and auto populates the `fully qualified domain name (FQDN) <https://en.wikipedia.org/wiki/Fully_qualified_domain_name>`_ of the aggregator node. This FQDN is embedded within the FL plan so the collaborator nodes know the address of the externally accessible aggregator server to connect to.
- 
-     If you have connection issues with the auto populated FQDN in the FL plan, you can do **one of the following**:
- 
- 	- OPTION 1: override the auto populated FQDN value with the :code:`-a` flag.
- 
- 		.. code-block:: console
- 
- 			fx plan initialize -a aggregator-hostname.internal-domain.com
- 
- 	- OPTION 2: override the apparent FQDN of the system by setting an FQDN environment variable.
- 
- 		.. code-block:: console
- 
- 			export FQDN=x.x.x.x
- 
- 		and initializing the FL plan
- 
- 		.. code-block:: console
- 
- 			fx plan initialize
- 
- 
- .. note::
- 
-        Each workspace may have multiple FL plans and multiple collaborator lists associated with it. Therefore, :code:`fx plan initialize` has the following optional parameters.
- 
-        +-------------------------+---------------------------------------------------------+
-        | Optional Parameters     | Description                                             |
-        +=========================+=========================================================+
-        | -p, --plan_config PATH  | Federated Learning plan [default = plan/plan.yaml]      |
-        +-------------------------+---------------------------------------------------------+
-        | -c, --cols_config PATH  | Authorized collaborator list [default = plan/cols.yaml] |
-        +-------------------------+---------------------------------------------------------+
-        | -d, --data_config PATH  | The data set/shard configuration file                   |
-        +-------------------------+---------------------------------------------------------+
- 
- 
- 
- .. _configure_the_federation:
- 
- 
- STEP 2: Configure the Federation
- ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
- 
- The objectives in this step:
- 
-     - Ensure each node in the federation has a valid public key infrastructure (PKI) certificate. See :doc:`/source/utilities/pki` for details on available workflows.
-     - Distribute the workspace from the aggregator node to the other collaborator nodes.
- 
- 
- .. _install_certs_agg:
- 
- **On the Aggregator Node:**
- 
- Setting Up the Certificate Authority
- 
- 1. Change to the path of your workspace:
- 
-     .. code-block:: console
- 
-        cd WORKSPACE_PATH
- 
- 2. Set up the aggregator node as the `certificate authority <https://en.wikipedia.org/wiki/Certificate_authority>`_ for the federation.
- 
-  All certificates will be signed by the aggregator node. Follow the instructions and enter the information as prompted. The command will create a simple database file to keep track of all issued certificates.
- 
-     .. code-block:: console
- 
-        fx workspace certify
- 
- 3. Run the aggregator certificate creation command, replacing :code:`AFQDN` with the actual `fully qualified domain name (FQDN) <https://en.wikipedia.org/wiki/Fully_qualified_domain_name>`_ for the aggregator node.
- 
-     .. code-block:: console
- 
-        fx aggregator generate-cert-request --fqdn AFQDN
- 
-     .. note::
- 
-        On Linux\*\, you can discover the FQDN with this command:
- 
-            .. code-block:: console
- 
-               hostname --all-fqdns | awk '{print $1}'
- 
-    .. note::
- 
-       You can override the apparent FQDN of the system by setting an FQDN environment variable before creating the certificate.
- 
-         .. code-block:: console
- 
-             fx aggregator generate-cert-request export FQDN=x.x.x.x
- 
-       If you omit the :code:`--fdqn` parameter, then :code:`fx` will automatically use the FQDN of the current node assuming the node has been correctly set with a static address.
- 
-         .. code-block:: console
- 
-             fx aggregator generate-cert-request
- 
- 4. Run the aggregator certificate signing command, replacing :code:`AFQDN` with the actual `fully qualified domain name (FQDN) <https://en.wikipedia.org/wiki/Fully_qualified_domain_name>`_ for the aggregator node.
- 
-     .. code-block:: console
- 
-        fx aggregator certify --fqdn AFQDN
- 
- 
-    .. note::
- 
-       You can override the apparent FQDN of the system by setting an FQDN environment variable (:code:`export FQDN=x.x.x.x`) before signing the certificate.
- 
-         .. code-block:: console
- 
-            fx aggregator certify export FQDN=x.x.x.x
- 
- 5. This node now has a signed security certificate as the aggregator for this new federation. You should have the following files.
- 
-     +---------------------------+--------------------------------------------------+
-     | File Type                 | Filename                                         |
-     +===========================+==================================================+
-     | Certificate chain         | WORKSPACE.PATH/cert/cert_chain.crt               |
-     +---------------------------+--------------------------------------------------+
-     | Aggregator certificate    | WORKSPACE.PATH/cert/server/agg_{AFQDN}.crt       |
-     +---------------------------+--------------------------------------------------+
-     | Aggregator key            | WORKSPACE.PATH/cert/server/agg_{AFQDN}.key       |
-     +---------------------------+--------------------------------------------------+
- 
-     where **AFQDN** is the fully-qualified domain name of the aggregator node.
- 
- .. _workspace_export:
- 
- Exporting the Workspace
- 
- 
- 1. Export the workspace so that it can be imported to the collaborator nodes.
- 
-     .. code-block:: console
- 
-        fx workspace export
- 
-    The :code:`export` command will archive the current workspace (with a :code:`zip` file extension) and create a **requirements.txt** of the current Python\*\ packages in the virtual environment.
- 
- 2. The next step is to transfer this workspace archive to each collaborator node.
- 
- 
- .. _install_certs_colab:
- 
- **On the Collaborator Node**:
- 
- Importing the Workspace
- 
- 1. Copy the :ref:`workspace archive <workspace_export>` from the aggregator node to the collaborator nodes.
- 
- 2. Import the workspace archive.
- 
-     .. code-block:: console
- 
-        fx workspace import --archive WORKSPACE.zip
- 
-  where **WORKSPACE.zip** is the name of the workspace archive. This will unzip the workspace to the current directory and install the required Python packages within the current virtual environment.
- 
- 3. For each test machine you want to run as collaborator nodes, create a collaborator certificate request to be signed by the certificate authority.
- 
-  Replace :code:`COL_LABEL` with the label you assigned to the collaborator. This label does not have to be the FQDN; it can be any unique alphanumeric label.
- 
-     .. code-block:: console
- 
-        fx collaborator generate-cert-request -n {COL_LABEL}
- 
- 
-  The creation script will also ask you to specify the path to the data. For this example, enter the integer that represents which MNIST shard to use on this collaborator node. For the first collaborator node enter **1**. For the second collaborator node enter **2**.
- 
-  This will create the following files:
- 
-     +-----------------------------+--------------------------------------------------------+
-     | File Type                   | Filename                                               |
-     +=============================+========================================================+
-     | Collaborator CSR            | WORKSPACE.PATH/cert/client/col_{COL_LABEL}.csr         |
-     +-----------------------------+--------------------------------------------------------+
-     | Collaborator key            | WORKSPACE.PATH/cert/client/col_{COL_LABEL}.key         |
-     +-----------------------------+--------------------------------------------------------+
-     | Collaborator CSR Package    | WORKSPACE.PATH/col_{COL_LABEL}_to_agg_cert_request.zip |
-     +-----------------------------+--------------------------------------------------------+
- 
- 
- 4. On the aggregator node (i.e., the certificate authority in this example), sign the Collaborator CSR Package from the collaborator nodes.
- 
-     .. code-block:: console
- 
-        fx collaborator certify --request-pkg /PATH/TO/col_{COL_LABEL}_to_agg_cert_request.zip
- 
-    where :code:`/PATH/TO/col_{COL_LABEL}_to_agg_cert_request.zip` is the path to the Collaborator CSR Package containing the :code:`.csr` file from the collaborator node. The certificate authority will sign this certificate for use in the federation.
- 
-    The command packages the signed collaborator certificate, along with the **cert_chain.crt** file needed to verify certificate signatures, for transport back to the collaborator node:
- 
-     +---------------------------------+------------------------------------------------------------+
-     | File Type                       | Filename                                                   |
-     +=================================+============================================================+
-     | Certificate and Chain Package   | WORKSPACE.PATH/agg_to_col_{COL_LABEL}_signed_cert.zip      |
-     +---------------------------------+------------------------------------------------------------+
- 
- 5. On the collaborator node, import the signed certificate and certificate chain into your workspace.
- 
-     .. code-block:: console
- 
-        fx collaborator certify --import /PATH/TO/agg_to_col_{COL_LABEL}_signed_cert.zip
- 
- 
- 
- .. _running_the_federation.start_nodes:
- 
- 
- STEP 3: Start the Federation
- ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
- 
- **On the Aggregator Node:**
- 
- 1. Start the Aggregator.
- 
-     .. code-block:: console
- 
-        fx aggregator start
- 
-  Now, the Aggregator is running and waiting for Collaborators to connect.
- 
- .. _running_collaborators:
- 
- **On the Collaborator Nodes:**
- 
- 1. Open a new terminal, change the directory to the workspace, and activate the virtual environment.
- 
- 2. Run the Collaborator.
- 
-     .. code-block:: console
- 
-        fx collaborator start -n {COLLABORATOR_LABEL}
- 
-     where :code:`COLLABORATOR_LABEL` is the label for this Collaborator.
- 
-     .. note::
- 
-        Each workspace may have multiple FL plans and multiple collaborator lists associated with it.
-        Therefore, :code:`fx collaborator start` has the following optional parameters.
- 
-            +-------------------------+---------------------------------------------------------+
-            | Optional Parameters     | Description                                             |
-            +=========================+=========================================================+
-            | -p, --plan_config PATH  | Federated Learning plan [default = plan/plan.yaml]      |
-            +-------------------------+---------------------------------------------------------+
-            | -d, --data_config PATH  | The data set/shard configuration file                   |
-            +-------------------------+---------------------------------------------------------+
- 
- 3. Repeat the earlier steps for each collaborator node in the federation.
- 
-   When all of the Collaborators connect, the Aggregator starts training. You will see log messages describing the progress of the federated training.
- 
-   When the last round of training is completed, the Aggregator stores the final weights in the protobuf file that was specified in the YAML file, which in this example is located at **save/${WORKSPACE_TEMPLATE}_latest.pbuf**.
- 
- 
- 
- .. _running_the_federation_docker:
- 
- 
- Docker Approach
- ---------------
- 
- There are two ways you can run |productName| with Docker\*\.
- 
- - `Option 1: Deploy a Federation in a Docker Container`_
- - `Option 2: Deploy Your Workspace in a Docker Container`_
- 
- 
- .. _running_the_federation_docker_base_image:
- 
- Option 1: Deploy a Federation in a Docker Container
- ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
- 
- .. note::
-     You have to built an |productName| image. See :ref:`install_docker` for details.
- 
- 
- 1. Run the |productName| image.
- 
-     .. code-block:: console
- 
-        docker run -it --network host openfl
- 
- 
- You can now experiment with |productName| in the container. For example, you can test the project pipeline with the `"Hello Federation" bash script <https://github.com/intel/openfl/blob/develop/tests/github/test_hello_federation.sh>`_.
- 
- 
- .. _running_the_federation_docker_workspace:
- 
- Option 2: Deploy Your Workspace in a Docker Container
- ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
- 
- .. note::
-     You have to set up a TaskRunner and run :code:`fx plan initialize` in the workspace directory. See `STEP 1: Create a Workspace on the Aggregator`_ for details.
- 
- 
- 1. Build an image with the workspace you created.
- 
-     .. code-block:: console
- 
-        fx workspace dockerize
- 
- 
-     By default, the image is saved as **WORKSPACE_NAME_image.tar** in the workspace directory.
- 
- 2. The image can be distributed and run on other nodes without any environment preparation.
- 
-     .. parsed-literal::
- 
-         docker run -it --rm \\
-             --network host \\
-             -v user_data_folder:/home/user/workspace/data \\
-             ${WORKSPACE_IMAGE_NAME} \\
-             bash
- 
- 
-     .. note::
- 
-         The FL plan should be initialized with the FQDN of the node where the aggregator container will be running.
- 
- 3. Generate public key infrastructure (PKI) certificates for all collaborators and the aggregator. See :doc:`/source/utilities/pki` for details.
- 
- 4. `STEP 3: Start the Federation`_.
--- 0 ----
diff -crB --new-file ./openfl/docs/source/openfl/communication.rst ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/source/openfl/communication.rst
*** ./openfl/docs/source/openfl/communication.rst	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/source/openfl/communication.rst	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,40 ****
- .. # Copyright (C) 2020-2021 Intel Corporation
- .. # SPDX-License-Identifier: Apache-2.0
- 
- .. _director_communications:
- 
- ***************************************
- Director Service Communication Diagrams
- ***************************************
- 
- The following diagrams depict existing procedure calls to the Director service. Included are interactions with the Director's inner representations to better understand their signatures.
- 
- Director-Envoy Communication
- ============================
- 
- The following diagram depicts a typical process of establishing a Federation and registering an experiment.  
- 
- .. kroki:: director_envoy.mmd
-     :caption: Basic Scenario of Director-Envoy Communication
-     :align: center
-     :type: mermaid
- 
- Director Side Envoy Representation and Related Remote Procedure Calls
- =====================================================================
- 
- This diagram shows possible interactions with Envoy handles on the Director side.
- 
- .. kroki:: envoy_representation_and_RPCs.mmd
-     :caption: Communications Altering or Requesting Envoy-Related Information
-     :align: center
-     :type: mermaid
- 
- Director Side Experiment Representation and Related Remote Procedure Calls
- ==========================================================================
- 
- This diagram shows possible interactions with Experiment handles on the Director side.
- 
- .. kroki:: experiment_representation_and_RPCs.mmd
-     :caption: Communications Altering or Requesting Experiment-Related Information
-     :align: center
-     :type: mermaid
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/docs/source/openfl/components.rst ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/source/openfl/components.rst
*** ./openfl/docs/source/openfl/components.rst	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/source/openfl/components.rst	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,113 ****
- .. # Copyright (C) 2020-2021 Intel Corporation
- .. # SPDX-License-Identifier: Apache-2.0
- 
- .. _openfl_components:
- 
- *****************************
- Core Components
- *****************************
- 
- Open Federated Learning (|productName|) has the following components:
- 
-     - :ref:`openfl_short_lived_components`
-     - :ref:`openfl_ll_components`
- 
- 
- .. _openfl_short_lived_components:
- 
- Short-Lived Components
- ======================
- 
- These components are terminated when the experiment is finished.
- 	
-     - The *Aggregator* which receives model updates from *Collaborators* and combines them to form the global model.
-     - The *Collaborator* which uses local dataset to train a global model.
- 
- The *Aggregator* is framework-agnostic, as it operates tensors in OpenFL inner representation,
- while the *Collaborator* can use deep learning frameworks as computational backend, such as `TensorFlow* <https://www.tensorflow.org/>`_ or `PyTorch* <https://pytorch.org/>`_.
- 
- 
- Aggregator
- ----------
- 
- The Aggregator is a short-lived entity, which means that its lifespan is limited by the experiment execution time.
- It orchestrates Collaborators according to the FL plan, performs model aggregation at the end of each round,
- and acts as a parameter server for collaborators.
- 
- Model weight aggregation logic may be customized via :ref:`plugin mechanism <overriding_agg_fn>`.
- 
- The Aggregator is spawned by the :ref:`Director <openfl_ll_components_director>` when a new experiment is submitted.
- 
- 
- Collaborator
- ------------
- 
- The Collaborator is a short-lived entity that manages training the model on local data, which includes
- 
-     - executing assigned tasks,
-     - converting deep learning framework-specific tensor objects to |productName| inner representation, and
-     - exchanging model parameters with the Aggregator.
- 
- The Collaborator is created by the :ref:`Envoy <openfl_ll_components_envoy>` when a new experiment is submitted
- in the :ref:`Director-based workflow <director_workflow>`. The Collaborator should be started from CLI if a user follows the
- :ref:`Aggregator-based workflow <running_the_federation_aggregator_based>`
- 
- Every Collaborator is a unique service. The data loader is loaded with a local *shard descriptor* to perform tasks
- included in an FL experiment. At the end of the training task, weight tensors are extracted and sent to the central node
- and aggregated.
- 
- Converting tensor objects is handled by :ref:`framework adapter <framework_adapter>` plugins.
- Included in |productName| are framework adapters for PyTorch and TensorFlow 2.x.
- The list of framework adapters is extensible. User can contribute new framework adapters for deep learning frameworks
- they would like see supported in |productName|.
- 
- 
- .. _openfl_ll_components:
- 
- Long-Lived Components
- ======================
- 
- These components were introduced to support the :ref:`Director-based workflow <director_workflow>`.
- 	
-     - The *Director* is the central node of the federation. This component starts an *Aggregator* for each experiment, broadcasts experiment archive to connected collaborator nodes, and provides updates on the status.
-     - The *Envoy* runs on collaborator nodes and is always connected to the *Director*. When the *Director* starts an experiment, the *Envoy* starts the *Collaborator* to train the global model.
- 
- These components stay available to distribute several of experiments in the federation.
- 
- .. _openfl_ll_components_director:
- 
- Director
- --------
- 
- The Director is a long-lived entity and is the central node of the federation. It accepts connections from:
- 
-     - Frontend clients (data scientists using :ref:`interactive_python_api`)
-     - Envoys, if their Shard Descriptors are complient to the same data interface
- 
- The Director supports concurrent frontend connections.
- While the Director may take in several experiments, the experiments are executed in series.
- 
- When an experiment is reported, the Director starts an Aggregator and sends the experiment data to involved Envoys.
- While an experiment is running, the Director oversees the Aggregator and delivers updates on the status of
- the experiment, which includes trained model snapshots and metrics by request.
- 
- 
- .. _openfl_ll_components_envoy:
- 
- Envoy
- -----
- 
- The Envoy is a long-lived entity that runs on collaborator nodes connected to the Director. 
- 
- Every Envoy is matched to one `shard descriptor <https://github.com/intel/openfl/blob/develop/openfl/interface/interactive_api/shard_descriptor.py>`_
- in order to run. When the Director starts an experiment, the Envoy accepts the experiment workspace,
- prepares the environment, and starts a Collaborator.
- 
- The envoy is also responsible for sending heartbeat messages to the Director. These messages may also include information
- regarding collaborator machine resource utilization. Refer to :ref:`device monitor plugin <device_monitor_plugin>` for details.
- 
- 
- Static Diagram
- ==============
- 
- .. figure:: director_workflow.svg
--- 0 ----
diff -crB --new-file ./openfl/docs/source/openfl/director_envoy.mmd ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/source/openfl/director_envoy.mmd
*** ./openfl/docs/source/openfl/director_envoy.mmd	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/source/openfl/director_envoy.mmd	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,30 ****
- sequenceDiagram
-     participant D as Director
-     participant E as Envoy
-     rect rgb(0, 255, 0,.1)
-         Note over D,E: A Federation startup process
-         D->D: Starts
-         E->E: Starts and loads local Shard Descriptor
-         E-->>D: Connects using FQDN and certificate
-         E-->>+D: Communicates dataset info
-         D-->D: Ensures unified data interface
-         D-->>-E: Approves
-         D-->D: Keeps a list of connected Envoys
-         
-     end
-     Note over D,E: We consider a Federation set up
-     rect rgb(0, 0, 255,.05)
-         Note over D,E: An Experiment's start
-         D->D: Registers a model, FL tasks and an FL plan
-         D->D:Starts an Aggregator with a toy plan
-         Note left of D: An Envoy with dummy data is <br>started locally
-         opt Test run failed
-             D-->D: Notifies user that <br>the experiment is inconsistent
-             D-->D: The experiment ends
-         end
-         D->D: Starts an Aggregator
-         D-->>E: Sends the experiment archive <br>and the FL plan to envoys
-         E-->E: Starts a Collaborator
-         D-->D: Fills the model with the final weights <br>and returns to user
-     end
-     Note over D,E: The Experiment ended. <br> The Federation keeps existing.
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/docs/source/openfl/director_workflow.svg ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/source/openfl/director_workflow.svg
*** ./openfl/docs/source/openfl/director_workflow.svg	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/source/openfl/director_workflow.svg	1969-12-31 16:00:00.000000000 -0800
***************
*** 1 ****
- <svg width="1280" height="720" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" overflow="hidden"><defs><clipPath id="clip0"><rect x="0" y="0" width="1280" height="720"/></clipPath></defs><g clip-path="url(#clip0)"><rect x="0" y="0" width="1280" height="720" fill="#FFFFFF"/><rect x="363" y="226" width="553" height="469" fill="#5B9BD5" fill-opacity="0.2"/><text fill="#7F7F7F" font-family="Calibri,Calibri_MSFontService,sans-serif" font-weight="400" font-size="13" transform="translate(372.832 686)">OpenFL</text><path d="M402.5 262.5C402.5 255.873 407.873 250.5 414.5 250.5L532.5 250.5C539.127 250.5 544.5 255.873 544.5 262.5L544.5 310.5C544.5 317.127 539.127 322.5 532.5 322.5L414.5 322.5C407.873 322.5 402.5 317.127 402.5 310.5Z" stroke="#41719C" stroke-width="1.33333" stroke-miterlimit="8" fill="#5B9BD5" fill-rule="evenodd"/><text fill="#FFFFFF" font-family="Calibri,Calibri_MSFontService,sans-serif" font-weight="400" font-size="21" transform="translate(425.454 281)">Python API <tspan font-size="21" x="-2.19333" y="26">component</tspan></text><path d="M402.5 108.308C402.5 90.1889 417.189 75.5001 435.308 75.5001L511.692 75.5001C529.811 75.5001 544.5 90.1889 544.5 108.308L544.5 115.692C544.5 133.811 529.811 148.5 511.692 148.5L435.308 148.5C417.189 148.5 402.5 133.811 402.5 115.692Z" stroke="#507E32" stroke-width="1.33333" stroke-miterlimit="8" fill="#70AD47" fill-rule="evenodd"/><text fill="#FFFFFF" font-family="Calibri,Calibri_MSFontService,sans-serif" font-weight="400" font-size="19" transform="translate(429.324 106)">Experiment <tspan font-size="19" x="9.57333" y="23">Manager</tspan></text><path d="M442.5 57.0001C442.5 39.6031 456.379 25.5001 473.5 25.5001 490.621 25.5001 504.5 39.6031 504.5 57.0001 504.5 74.397 490.621 88.5001 473.5 88.5001 456.379 88.5001 442.5 74.397 442.5 57.0001Z" stroke="#507E32" stroke-width="1.33333" stroke-miterlimit="8" fill="#70AD47" fill-rule="evenodd"/><path d="M77.5001 459.859C77.5001 441.988 91.9876 427.5 109.859 427.5L186.141 427.5C204.012 427.5 218.5 441.988 218.5 459.859L218.5 467.141C218.5 485.012 204.012 499.5 186.141 499.5L109.859 499.5C91.9876 499.5 77.5001 485.012 77.5001 467.141Z" stroke="#507E32" stroke-width="1.33333" stroke-miterlimit="8" fill="#70AD47" fill-rule="evenodd"/><text fill="#FFFFFF" font-family="Calibri,Calibri_MSFontService,sans-serif" font-weight="400" font-size="19" transform="translate(116.438 458)">Director <tspan font-size="19" x="-3.30667" y="23">Manager</tspan></text><path d="M116.5 409C116.5 391.603 130.603 377.5 148 377.5 165.397 377.5 179.5 391.603 179.5 409 179.5 426.397 165.397 440.5 148 440.5 130.603 440.5 116.5 426.397 116.5 409Z" stroke="#507E32" stroke-width="1.33333" stroke-miterlimit="8" fill="#70AD47" fill-rule="evenodd"/><path d="M1062.5 461.309C1062.5 443.189 1077.19 428.5 1095.31 428.5L1170.69 428.5C1188.81 428.5 1203.5 443.189 1203.5 461.309L1203.5 468.692C1203.5 486.811 1188.81 501.5 1170.69 501.5L1095.31 501.5C1077.19 501.5 1062.5 486.811 1062.5 468.692Z" stroke="#507E32" stroke-width="1.33333" stroke-miterlimit="8" fill="#70AD47" fill-rule="evenodd"/><text fill="#FFFFFF" font-family="Calibri,Calibri_MSFontService,sans-serif" font-weight="400" font-size="19" transform="translate(1085.4 459)">Collaborator <tspan font-size="19" x="13.1267" y="23">Manager</tspan></text><path d="M1101.5 410.5C1101.5 393.379 1115.6 379.5 1133 379.5 1150.4 379.5 1164.5 393.379 1164.5 410.5 1164.5 427.621 1150.4 441.5 1133 441.5 1115.6 441.5 1101.5 427.621 1101.5 410.5Z" stroke="#507E32" stroke-width="1.33333" stroke-miterlimit="8" fill="#70AD47" fill-rule="evenodd"/><rect x="388" y="403" width="167" height="254" fill="#70AD47" fill-opacity="0.501961"/><text fill="#7F7F7F" font-family="Calibri,Calibri_MSFontService,sans-serif" font-weight="400" font-size="12" transform="translate(397.693 649)">Central node</text><path d="M400.5 440.5C400.5 433.873 405.873 428.5 412.5 428.5L529.5 428.5C536.127 428.5 541.5 433.873 541.5 440.5L541.5 488.5C541.5 495.127 536.127 500.5 529.5 500.5L412.5 500.5C405.873 500.5 400.5 495.127 400.5 488.5Z" stroke="#41719C" stroke-width="1.33333" stroke-miterlimit="8" fill="#5B9BD5" fill-rule="evenodd"/><text fill="#FFFFFF" font-family="Calibri,Calibri_MSFontService,sans-serif" font-weight="400" font-size="21" transform="translate(435.081 471)">Director</text><rect x="723" y="407" width="167" height="253" fill="#70AD47" fill-opacity="0.501961"/><text fill="#7F7F7F" font-family="Calibri,Calibri_MSFontService,sans-serif" font-weight="400" font-size="12" transform="translate(732.783 652)">Collaborator node</text><path d="M736.5 439.667C736.5 432.947 741.947 427.5 748.667 427.5L866.333 427.5C873.053 427.5 878.5 432.947 878.5 439.667L878.5 488.333C878.5 495.053 873.053 500.5 866.333 500.5L748.667 500.5C741.947 500.5 736.5 495.053 736.5 488.333Z" stroke="#41719C" stroke-width="1.33333" stroke-miterlimit="8" fill="#5B9BD5" fill-rule="evenodd"/><text fill="#FFFFFF" font-family="Calibri,Calibri_MSFontService,sans-serif" font-weight="400" font-size="21" transform="translate(781.363 470)">Envoy</text><path d="M400.5 576.5C400.5 569.873 405.873 564.5 412.5 564.5L529.5 564.5C536.127 564.5 541.5 569.873 541.5 576.5L541.5 624.5C541.5 631.127 536.127 636.5 529.5 636.5L412.5 636.5C405.873 636.5 400.5 631.127 400.5 624.5Z" stroke="#41719C" stroke-width="1.33333" stroke-miterlimit="8" fill="#5B9BD5" fill-rule="evenodd"/><text fill="#FFFFFF" font-family="Calibri,Calibri_MSFontService,sans-serif" font-weight="400" font-size="21" transform="translate(422.856 607)">Aggregator</text><path d="M736.5 576.5C736.5 569.873 741.873 564.5 748.5 564.5L866.5 564.5C873.127 564.5 878.5 569.873 878.5 576.5L878.5 624.5C878.5 631.127 873.127 636.5 866.5 636.5L748.5 636.5C741.873 636.5 736.5 631.127 736.5 624.5Z" stroke="#41719C" stroke-width="1.33333" stroke-miterlimit="8" fill="#5B9BD5" fill-rule="evenodd"/><text fill="#FFFFFF" font-family="Calibri,Calibri_MSFontService,sans-serif" font-weight="400" font-size="21" transform="translate(753.286 607)">Collaborator</text><path d="M0.333333-1.02799e-06 0.333628 95.462-0.333039 95.462-0.333333 1.02799e-06ZM4.00029 94.1286 0.000314961 102.129-3.99971 94.1286Z" fill="#70AD47" transform="matrix(-1 0 0 1 473.5 148.5)"/><rect x="385" y="163" width="183" height="48" fill="#FFFFFF"/><text fill="#7F7F7F" font-family="Calibri,Calibri_MSFontService,sans-serif" font-weight="400" font-size="16" transform="translate(398.235 183)">Provides FL plans, Tasks, <tspan font-size="16" x="8.10666" y="19">Models, Data Loaders</tspan></text><path d="M218.501 463.167 393.452 463.846 393.449 464.513 218.499 463.833ZM392.132 460.175 400.117 464.206 392.101 468.174Z" fill="#70AD47"/><rect x="240" y="419" width="116" height="88" fill="#FFFFFF"/><text fill="#7F7F7F" font-family="Calibri,Calibri_MSFontService,sans-serif" font-weight="400" font-size="16" transform="translate(265.803 439)">Launches.<tspan font-size="16" x="-12.8733" y="19">Sets up global </tspan><tspan font-size="16" x="-2.72668" y="38">Federation </tspan><tspan font-size="16" x="6.99332" y="58">settings</tspan></text><path d="M1062.5 465.173 885.164 463.882 885.169 463.215 1062.5 464.506ZM886.471 467.558 878.5 463.5 886.529 459.558Z" fill="#70AD47"/><rect x="921" y="419" width="131" height="88" fill="#FFFFFF"/><text fill="#7F7F7F" font-family="Calibri,Calibri_MSFontService,sans-serif" font-weight="400" font-size="16" transform="translate(954.221 439)">Launches.<tspan font-size="16" x="-12.4333" y="19">Provides local </tspan><tspan font-size="16" x="-12.18" y="38">dataset Shard </tspan><tspan font-size="16" x="-4.58667" y="58">Descriptors</tspan></text><path d="M471.833 549.5 471.833 557.654 471.167 557.654 471.167 549.5ZM475.5 556.321 471.5 564.321 467.5 556.321Z" fill="#5B9BD5"/><text fill="#7F7F7F" font-family="Calibri,Calibri_MSFontService,sans-serif" font-weight="400" font-size="13" transform="translate(410.583 524)">Creates an instance to <tspan font-size="13" x="-12.1667" y="16">maintain an FL experiment</tspan></text><path d="M471.5 499.5 471.5 512.274" stroke="#5B9BD5" stroke-width="0.666667" stroke-miterlimit="8" fill="none" fill-rule="evenodd"/><text fill="#7F7F7F" font-family="Calibri,Calibri_MSFontService,sans-serif" font-weight="400" font-size="13" transform="translate(747.029 527)">Creates an instance to <tspan font-size="13" x="-12.1667" y="16">maintain an FL experiment</tspan></text><path d="M0 0 0.000209974 11.1366" stroke="#5B9BD5" stroke-width="0.666667" stroke-miterlimit="8" fill="none" fill-rule="evenodd" transform="matrix(-1 0 0 1 807.5 500.5)"/><path d="M807.833 553.5 807.833 557.97 807.167 557.97 807.167 553.5ZM811.5 556.637 807.5 564.637 803.5 556.637Z" fill="#5B9BD5"/><text fill="#7F7F7F" font-family="Calibri,Calibri_MSFontService,sans-serif" font-weight="400" font-size="13" transform="translate(561.516 436)">Communicates dataset info, <tspan font-size="13" x="18.6666" y="16">Sends status updates</tspan><tspan font-size="13" x="25.5564" y="49">Approves, Sends FL </tspan><tspan font-size="13" x="43.8031" y="65">experiments</tspan><tspan font-size="13" x="2.12366" y="139">Sends locally tuned tensors </tspan><tspan font-size="13" x="21.5436" y="155">and training metrics</tspan><tspan font-size="13" x="18.4586" y="182">Sends tasks and initial </tspan><tspan font-size="13" x="57.5386" y="198">tensors</tspan></text><path d="M548.167 440.167 553.5 440.167 553.5 440.833 548.167 440.833ZM555.5 440.167 560.833 440.167 560.833 440.833 555.5 440.833ZM562.833 440.167 568.167 440.167 568.167 440.833 562.833 440.833ZM570.167 440.167 575.5 440.167 575.5 440.833 570.167 440.833ZM577.5 440.167 582.833 440.167 582.833 440.833 577.5 440.833ZM584.833 440.167 590.167 440.167 590.167 440.833 584.833 440.833ZM592.167 440.167 597.5 440.167 597.5 440.833 592.167 440.833ZM599.5 440.167 604.833 440.167 604.833 440.833 599.5 440.833ZM606.833 440.167 612.167 440.167 612.167 440.833 606.833 440.833ZM614.167 440.167 619.5 440.167 619.5 440.833 614.167 440.833ZM621.5 440.167 626.833 440.167 626.833 440.833 621.5 440.833ZM628.833 440.167 634.167 440.167 634.167 440.833 628.833 440.833ZM636.167 440.167 641.5 440.167 641.5 440.833 636.167 440.833ZM643.5 440.167 648.833 440.167 648.833 440.833 643.5 440.833ZM650.833 440.167 656.167 440.167 656.167 440.833 650.833 440.833ZM658.167 440.167 663.5 440.167 663.5 440.833 658.167 440.833ZM665.5 440.167 670.833 440.167 670.833 440.833 665.5 440.833ZM672.833 440.167 678.167 440.167 678.167 440.833 672.833 440.833ZM680.167 440.167 685.5 440.167 685.5 440.833 680.167 440.833ZM687.5 440.167 692.833 440.167 692.833 440.833 687.5 440.833ZM694.833 440.167 700.167 440.167 700.167 440.833 694.833 440.833ZM702.167 440.167 707.5 440.167 707.5 440.833 702.167 440.833ZM709.5 440.167 714.833 440.167 714.833 440.833 709.5 440.833ZM716.833 440.167 722.167 440.167 722.167 440.833 716.833 440.833ZM724.167 440.167 729.5 440.167 729.5 440.833 724.167 440.833ZM731.5 440.167 736.118 440.167 736.118 440.833 731.5 440.833ZM549.5 444.5 541.5 440.5 549.5 436.5Z" fill="#5B9BD5"/><path d="M6.6667-0.33333 12-0.333327 12 0.33334 6.6667 0.333337ZM14-0.333326 19.3334-0.333323 19.3334 0.333344 14 0.333341ZM21.3334-0.333322 26.6667-0.333319 26.6667 0.333348 21.3334 0.333345ZM28.6667-0.333318 34-0.333315 34 0.333352 28.6667 0.333349ZM36-0.333314 41.3334-0.333311 41.3334 0.333356 36 0.333353ZM43.3334-0.33331 48.6667-0.333307 48.6667 0.33336 43.3334 0.333357ZM50.6667-0.333306 56-0.333303 56 0.333364 50.6667 0.333361ZM58-0.333302 63.3334-0.333299 63.3334 0.333367 58 0.333365ZM65.3334-0.333298 70.6667-0.333295 70.6667 0.333371 65.3334 0.333369ZM72.6667-0.333294 78-0.333291 78 0.333375 72.6667 0.333373ZM80-0.33329 85.3334-0.333287 85.3334 0.333379 80 0.333376ZM87.3334-0.333286 92.6667-0.333283 92.6667 0.333383 87.3334 0.33338ZM94.6667-0.333282 100-0.333279 100 0.333387 94.6667 0.333384ZM102-0.333278 107.333-0.333275 107.333 0.333391 102 0.333388ZM109.333-0.333274 114.667-0.333271 114.667 0.333395 109.333 0.333392ZM116.667-0.33327 122-0.333268 122 0.333399 116.667 0.333396ZM124-0.333266 129.333-0.333264 129.333 0.333403 124 0.3334ZM131.333-0.333262 136.667-0.33326 136.667 0.333407 131.333 0.333404ZM138.667-0.333259 144-0.333256 144 0.333411 138.667 0.333408ZM146-0.333255 151.333-0.333252 151.333 0.333415 146 0.333412ZM153.333-0.333251 158.667-0.333248 158.667 0.333419 153.333 0.333416ZM160.667-0.333247 166-0.333244 166 0.333423 160.667 0.33342ZM168-0.333243 173.333-0.33324 173.333 0.333427 168 0.333424ZM175.333-0.333239 180.667-0.333236 180.667 0.333431 175.333 0.333428ZM182.667-0.333235 188-0.333232 188 0.333435 182.667 0.333432ZM190-0.333231 194.618-0.333228 194.618 0.333438 190 0.333436ZM8 4 0 0 8-4Z" fill="#5B9BD5" transform="matrix(-1 0 0 1 736.118 491.5)"/><path d="M548.167 581.167 553.5 581.167 553.5 581.833 548.167 581.833ZM555.5 581.167 560.833 581.167 560.833 581.833 555.5 581.833ZM562.833 581.167 568.167 581.167 568.167 581.833 562.833 581.833ZM570.167 581.167 575.5 581.167 575.5 581.833 570.167 581.833ZM577.5 581.167 582.833 581.167 582.833 581.833 577.5 581.833ZM584.833 581.167 590.167 581.167 590.167 581.833 584.833 581.833ZM592.167 581.167 597.5 581.167 597.5 581.833 592.167 581.833ZM599.5 581.167 604.833 581.167 604.833 581.833 599.5 581.833ZM606.833 581.167 612.167 581.167 612.167 581.833 606.833 581.833ZM614.167 581.167 619.5 581.167 619.5 581.833 614.167 581.833ZM621.5 581.167 626.833 581.167 626.833 581.833 621.5 581.833ZM628.833 581.167 634.167 581.167 634.167 581.833 628.833 581.833ZM636.167 581.167 641.5 581.167 641.5 581.833 636.167 581.833ZM643.5 581.167 648.833 581.167 648.833 581.833 643.5 581.833ZM650.833 581.167 656.167 581.167 656.167 581.833 650.833 581.833ZM658.167 581.167 663.5 581.167 663.5 581.833 658.167 581.833ZM665.5 581.167 670.833 581.167 670.833 581.833 665.5 581.833ZM672.833 581.167 678.167 581.167 678.167 581.833 672.833 581.833ZM680.167 581.167 685.5 581.167 685.5 581.833 680.167 581.833ZM687.5 581.167 692.833 581.167 692.833 581.833 687.5 581.833ZM694.833 581.167 700.167 581.167 700.167 581.833 694.833 581.833ZM702.167 581.167 707.5 581.167 707.5 581.833 702.167 581.833ZM709.5 581.167 714.833 581.167 714.833 581.833 709.5 581.833ZM716.833 581.167 722.167 581.167 722.167 581.833 716.833 581.833ZM724.167 581.167 729.5 581.167 729.5 581.833 724.167 581.833ZM731.5 581.167 736.118 581.167 736.118 581.833 731.5 581.833ZM549.5 585.5 541.5 581.5 549.5 577.5Z" fill="#5B9BD5"/><path d="M6.6667-0.33333 12-0.333327 12 0.33334 6.6667 0.333337ZM14-0.333326 19.3334-0.333323 19.3334 0.333344 14 0.333341ZM21.3334-0.333322 26.6667-0.333319 26.6667 0.333348 21.3334 0.333345ZM28.6667-0.333318 34-0.333315 34 0.333352 28.6667 0.333349ZM36-0.333314 41.3334-0.333311 41.3334 0.333356 36 0.333353ZM43.3334-0.33331 48.6667-0.333307 48.6667 0.33336 43.3334 0.333357ZM50.6667-0.333306 56-0.333303 56 0.333364 50.6667 0.333361ZM58-0.333302 63.3334-0.333299 63.3334 0.333367 58 0.333365ZM65.3334-0.333298 70.6667-0.333295 70.6667 0.333371 65.3334 0.333369ZM72.6667-0.333294 78-0.333291 78 0.333375 72.6667 0.333373ZM80-0.33329 85.3334-0.333287 85.3334 0.333379 80 0.333376ZM87.3334-0.333286 92.6667-0.333283 92.6667 0.333383 87.3334 0.33338ZM94.6667-0.333282 100-0.333279 100 0.333387 94.6667 0.333384ZM102-0.333278 107.333-0.333275 107.333 0.333391 102 0.333388ZM109.333-0.333274 114.667-0.333271 114.667 0.333395 109.333 0.333392ZM116.667-0.33327 122-0.333268 122 0.333399 116.667 0.333396ZM124-0.333266 129.333-0.333264 129.333 0.333403 124 0.3334ZM131.333-0.333262 136.667-0.33326 136.667 0.333407 131.333 0.333404ZM138.667-0.333259 144-0.333256 144 0.333411 138.667 0.333408ZM146-0.333255 151.333-0.333252 151.333 0.333415 146 0.333412ZM153.333-0.333251 158.667-0.333248 158.667 0.333419 153.333 0.333416ZM160.667-0.333247 166-0.333244 166 0.333423 160.667 0.33342ZM168-0.333243 173.333-0.33324 173.333 0.333427 168 0.333424ZM175.333-0.333239 180.667-0.333236 180.667 0.333431 175.333 0.333428ZM182.667-0.333235 188-0.333232 188 0.333435 182.667 0.333432ZM190-0.333231 194.618-0.333228 194.618 0.333438 190 0.333436ZM8 4 0 0 8-4Z" fill="#5B9BD5" transform="matrix(-1 0 0 1 736.118 624.5)"/><path d="M429.833 390.5 429.833 395.833 429.167 395.833 429.167 390.5ZM429.833 397.833 429.833 403.167 429.167 403.167 429.167 397.833ZM429.833 405.167 429.833 410.5 429.167 410.5 429.167 405.167ZM429.833 412.5 429.833 417.833 429.167 417.833 429.167 412.5ZM429.833 419.833 429.833 422.069 429.167 422.069 429.167 419.833ZM433.5 420.736 429.5 428.736 425.5 420.736Z" fill="#5B9BD5"/><path d="M0.333333-2.36129e-06 0.333371 5.33333-0.333296 5.33334-0.333333 2.36129e-06ZM0.333385 7.33333 0.333391 8.15391-0.333276 8.15391-0.333281 7.33334ZM4.00005 6.82055 0.000104987 14.8206-3.99995 6.82061Z" fill="#5B9BD5" transform="matrix(1 0 0 -1 516.5 337.321)"/><text fill="#7F7F7F" font-family="Calibri,Calibri_MSFontService,sans-serif" font-weight="400" font-size="13" transform="translate(396.932 365)">Registers FL <tspan font-size="13" x="-1.83331" y="16">experiments</tspan><tspan font-size="13" x="73.5058" y="-16">Sends info about </tspan><tspan font-size="13" x="77.1725" y="0">the Federation. </tspan><tspan font-size="13" x="75.4192" y="16">Returns training </tspan><tspan font-size="13" x="96.8392" y="32">artifacts</tspan></text><path d="M429.5 322.5 429.5 345.939" stroke="#5B9BD5" stroke-width="0.666667" stroke-miterlimit="8" stroke-dasharray="5.33333 2" fill="none" fill-rule="evenodd"/><path d="M516.5 407.5 516.5 429.298" stroke="#5B9BD5" stroke-width="0.666667" stroke-miterlimit="8" stroke-dasharray="5.33333 2" fill="none" fill-rule="evenodd"/></g></svg>
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/docs/source/openfl/envoy_representation_and_RPCs.mmd ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/source/openfl/envoy_representation_and_RPCs.mmd
*** ./openfl/docs/source/openfl/envoy_representation_and_RPCs.mmd	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/source/openfl/envoy_representation_and_RPCs.mmd	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,30 ****
- sequenceDiagram
-   participant ER as Envoy Representation
-   participant D as Director
-   participant E as Envoy
-   participant F as Frontend API
- 
-   E-)+D: Acknowledge Shard request
-   note over ER,D: Envoy registry is a dict-like object
-   D->>ER: Creates and puts to the Registry
-   activate ER
-   D->>-E: Approves
-   loop Healthcheck timeout
-     E-)+D: Sends status
-     D->>ER: Adds info or updates ER state
-     activate ER
-     D->>-E: Acknowledges
-   end
-   rect rgb(225, 255, 225)
-     Note over D: API requests may overlap <br>with the healthcheck loop
-     F-)+D: Requests Shard Registry
-     D->>ER: Gets required info
-     D->>-F: Replies with the Registry state
-   end
-   D-->E: Disconnect
-   D-->D: Waits for several Healthcheck timeouts
-   D->>ER: Removes from the Registry
-   deactivate ER
-   deactivate ER
-   Note over ER: Will not be included in the next <br>API Registry request
-             
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/docs/source/openfl/experiment_representation_and_RPCs.mmd ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/source/openfl/experiment_representation_and_RPCs.mmd
*** ./openfl/docs/source/openfl/experiment_representation_and_RPCs.mmd	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/source/openfl/experiment_representation_and_RPCs.mmd	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,59 ****
- sequenceDiagram
-   participant ER as Experiment Representation
-   participant D as Director
-   participant E as Envoy
-   participant F as Frontend API
- 
-   F->>+D: Set New Experiment
-   D->>+ER: Creates ER and puts in the registry
-   note over ER,D: Experiment registry is a queue-like object
-   D->>-F: Approves
- 
-   F->>+D: Get Registered experiments
-   D->>ER: Gets name and status
-   note over ER,D: Registry can also return <br>an experiment list by user id
-   D->>-F: Approves
- 
-   rect rgb(225, 255, 225)
-     note over ER,E: Envoys may start awaiting experiments <br>even if the queue is empty
-     E-)+D: Wait Experiment *STREAM*
-     note over ER,D: Assuming the Experiment is the next in the queue <br>and the Envoy is assigned for this Experiment
-     D->>ER: Gets experiment name (pop operation)
-     D->>-E: Wait Experiment Response
- 
-     E->>+D: Get Experiment Data
-     D->>ER: Gets experiment archive (by name)
-     D->>ER: Sets status to In Progress
-     D->>-E: Experiment Data
-   end
- 
-   rect rgb(255, 225, 225)
-   note over ER,E: The Experiment execution
-     D-->D: Starts an aggregator that orchestrates experiment
-     D->>ER: Removes experiment archive
-     D-->D: Finishes the experiment and releases involved Envoys
-     D->>+ER: Puts training artifacts
-     D->>ER: Sets status to Finished
-   end
- 
-   rect rgb(225, 225, 255)
-     note over ER,F: Restoring experiment on the Frontend <br>from the Director's experiment representation
-     F->>+D: Restore experiment by name
-     D->>ER: Gets required data
-     note over ER,D: The Registry may also return <br>the experiment by its identifier
-     D->>-F: Response with model structure and the plan
-   end
- 
- 
-   F->>+D: Requests training artifacts
-   D->>ER: Gets training artifacts
-   D->>-F: Respond
- 
-   F->>+D: Requests removing the Experiment entry
-   D->>ER: Removes Experiment from registry
- 
-   deactivate ER
-   deactivate ER
- 
-   D->>-F: Acknowledges
-   
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/docs/source/openfl/plugins.rst ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/source/openfl/plugins.rst
*** ./openfl/docs/source/openfl/plugins.rst	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/source/openfl/plugins.rst	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,101 ****
- .. # Copyright (C) 2020-2021 Intel Corporation
- .. # SPDX-License-Identifier: Apache-2.0
- 
- *****************
- Plugin Components
- *****************
- 
- Open Federated Learning (|productName|) is designed to be a flexible and extensible framework. Plugins are interchangeable parts of |productName| components. Different plugins support varying usage scenarios.
- A plugin may be **required** or **optional**. 
- 
- You can provide your implementations of |productName| plugins to achieve a desired behavior. Technically, a plugin is just a class that implements some interface. You may enable a plugin by putting its 
- import path and initialization parameters to the config file of a corresponding |productName| component or to the frontend Python API. See `openfl-tutorials <https://github.com/intel/openfl/tree/develop/openfl-tutorials>`_ for more details.
- 
- .. _framework_adapter:
- 
- Framework Adapter
- ######################
- 
- The Framework Adapter plugin enables |productName| support for Deep Learning frameworks usage in FL experiments. 
- It is a **required** plugin for the frontend API component and Envoy.
- All the framework-specific operations on model weights are isolated in this plugin so |productName| can be framework-agnostic.
- 
- The Framework adapter plugin interface has two required methods to load and extract tensors from a model and an optimizer:
- 
-     - :code:`get_tensor_dict`
-     - :code:`set_tensor_dict`
- 
- :code:`get_tensor_dict` method accepts a model and optionally an optimizer. It should return a dictionary :code:`{tensor_name : ndarray}` 
- that maps tensor names to tensors in the NumPy representation.
- 
-     .. code-block:: python
- 
-        @staticmethod
-        def get_tensor_dict(model, optimizer=None) -> dict:
- 
- :code:`set_tensor_dict` method accepts a tensor dictionary, a model, and optionally an optimizer. It loads weights from the tensor dictionary 
- to the model in place. Tensor names in the dictionary match corresponding names set in :code:`get_tensor_dict`.
- 
-     .. code-block:: python
- 
-        @staticmethod
-        def set_tensor_dict(model, tensor_dict, optimizer=None, device='cpu') -> None:
- 
- If your new framework model cannot be directly serialized with pickle-type libraries, you can optionally 
- implement the :code:`serialization_setup` method to prepare the model object for serialization.
- 
-     .. code-block:: python
- 
-         def serialization_setup():
- 
- 
- .. _serializer_plugin:
- 
- Experiment Serializer
- ######################
- 
- The Serializer plugin is used on the frontend Python API to serialize the Experiment components and then on Envoys to deserialize them.
- Currently, the default serializer plugin is based on pickling. It is a **required** plugin.
- 
- The serializer plugin must implement the :code:`serialize` method that creates a Python object representation on disk.
- 
-     .. code-block:: python
- 
-        @staticmethod
-        def serialize(object_, filename: str) -> None:
- 
- The plugin must also implement the :code:`restore_object` method that will load previously serialized object from disk.
- 
-     .. code-block:: python
- 
-        @staticmethod
-        def restore_object(filename: str):
- 
- 
- .. _device_monitor_plugin:
- 
- CUDA Device Monitor
- ######################
- 
- The CUDA Device Monitor plugin is an **optional** plugin for Envoys that can gather status information about GPU devices. 
- This information may be used by Envoys and included in a healthcheck message that is sent to the Director. 
- Therefore, you can query this Envoy Registry information from the Director to determine the status of CUDA devices.
- 
- CUDA Device Monitor plugin must implement the following interface:
- 
-     .. code-block:: python
- 
-        class CUDADeviceMonitor:
- 
-           def get_driver_version(self) -> str:
-              ...
- 
-           def get_device_memory_total(self, index: int) -> int:
-              ...
- 
-           def get_device_memory_utilized(self, index: int) -> int:
-              ...
- 
-           def get_device_utilization(self, index: int) -> str:
-              """It is just a general method that returns a string that may be shown to the frontend user."""
-              ...
--- 0 ----
diff -crB --new-file ./openfl/docs/source/openfl/static_diagram.svg ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/source/openfl/static_diagram.svg
*** ./openfl/docs/source/openfl/static_diagram.svg	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/source/openfl/static_diagram.svg	1969-12-31 16:00:00.000000000 -0800
***************
*** 1 ****
- <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" viewBox="0 0 3104 2546" style="background: #ffffff"><g id="v-3"  transform="matrix(1,0,0,1,0,0)"><g id="j_36"    transform="translate(20,2501)"><g id="v-667"><text  id="v-668" font-size="22px" y="0.8em" xml:space="preserve" font-weight="normal" text-anchor="start" fill="#aaaaaa" pointer-events="none" font-family="Open Sans" transform="matrix(1,0,0,1,0,0)"><tspan id="v-669"  dy="0em" x="0">Friday, 27 August 2021, 16:25 Moscow Standard Time</tspan></text></g></g><g id="j_35"    transform="translate(20,2455)"><g id="v-663"><text  id="v-664" font-size="36px" y="0.8em" xml:space="preserve" font-weight="normal" text-anchor="start" fill="#000000" pointer-events="none" font-family="Open Sans" transform="matrix(1,0,0,1,0,0)"><tspan id="v-665"  dy="0em" x="0">Container diagram for OpenFL</tspan></text></g></g><g id="j_13"    transform="translate(840,740)" style=""><g id="v-214"><rect  id="v-215" width="1390" height="1582" rx="0" ry="0" fill="#ffffff" stroke="#444444" stroke-width="2" stroke-dasharray="20,20" pointer-events="none"></rect><text  id="v-216" font-size="24px" y="1543" xml:space="preserve" font-weight="normal" fill="#444444" x="10" text-anchor="start" pointer-events="visible" font-family="Open Sans" transform="matrix(1,0,0,1,15,0)"><tspan id="v-218"  dy="0em" x="0">OpenFL</tspan></text><text  id="v-217" font-size="19px" y="1567" xml:space="preserve" font-weight="normal" fill="#444444" x="10" text-anchor="start" pointer-events="visible" font-family="Open Sans" transform="matrix(1,0,0,1,15,0)"><tspan id="v-219"  dy="0em" x="0">[Software System]</tspan></text></g></g><g id="j_22"    transform="translate(860,1300)" style=""><g id="v-342"><rect  id="v-343" width="490" height="929" rx="0" ry="0" fill="#ffffff" stroke="#cccccc" stroke-width="2" stroke-dasharray="5,5" pointer-events="none"></rect><text  id="v-344" font-size="24px" y="914" xml:space="preserve" font-weight="normal" fill="#cccccc" x="10" text-anchor="start" pointer-events="visible" font-family="Open Sans" transform="matrix(1,0,0,1,15,0)"><tspan id="v-346"  dy="0em" x="0">Central node</tspan></text><text  id="v-345" font-size="19px" y="914" display="none" xml:space="preserve" font-weight="normal" fill="#cccccc" x="10" text-anchor="start" pointer-events="visible" font-family="Open Sans" transform="matrix(1,0,0,1,15,0)"><tspan id="v-347"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g></g><g id="j_16"    transform="translate(1720,1300)" style=""><g id="v-253"><rect  id="v-254" width="490" height="929" rx="0" ry="0" fill="#ffffff" stroke="#cccccc" stroke-width="2" stroke-dasharray="5,5" pointer-events="none"></rect><text  id="v-255" font-size="24px" y="914" xml:space="preserve" font-weight="normal" fill="#cccccc" x="10" text-anchor="start" pointer-events="visible" font-family="Open Sans" transform="matrix(1,0,0,1,15,0)"><tspan id="v-257"  dy="0em" x="0">Collaborator node</tspan></text><text  id="v-256" font-size="19px" y="914" display="none" xml:space="preserve" font-weight="normal" fill="#cccccc" x="10" text-anchor="start" pointer-events="visible" font-family="Open Sans" transform="matrix(1,0,0,1,15,0)"><tspan id="v-258"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g></g><g id="j_14"    transform="translate(890,200)" style=""><g  id="v-223" style="opacity: 1;"><rect  x="0" y="160" width="400" height="240" rx="70" id="v-225" stroke="#073b6f" stroke-width="2" pointer-events="visiblePainted" fill="#08427b"></rect><circle  cx="200" cy="88.88888888888889" r="88.88888888888889" id="v-224" stroke="#073b6f" stroke-width="2" pointer-events="visiblePainted" fill="#08427b"></circle><line  x1="80" y1="266.6666666666667" x2="80" y2="400" style="stroke-width:2px" id="v-231" stroke="#073b6f"></line><line  x1="320" y1="266.6666666666667" x2="320" y2="400" style="stroke-width:2px" id="v-232" stroke="#073b6f"></line><text  id="v-226" font-size="34px" y="0.8em" xml:space="preserve" font-weight="bold" text-anchor="middle" pointer-events="visible" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,200,205)"><tspan id="v-233"  dy="0em" x="0">Data scientist</tspan></text><text  id="v-227" font-size="19px" y="0.8em" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,200,247.5)"><tspan id="v-234"  dy="0em" x="0">[Person]</tspan></text><text  id="v-228" font-size="24px" y="0.8em" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,200,295)"><tspan id="v-235"  dy="0em" x="0">A person or group of people</tspan><tspan id="v-236"  dy="1.2em" x="0">using OpenFL</tspan></text><text  id="v-229" font-weight="bold" text-anchor="middle" font-family="Open Sans" fill="#ffffff" font-size="24" transform="matrix(1,0,0,1,200,371.2)" display="none"></text><image  id="v-230"></image></g></g><g id="j_15"    transform="translate(1740,1320)" style="" ><g  id="v-240" style="opacity: 1;"><rect  id="v-241" rx="20" ry="20" stroke="#3c7fc0" stroke-width="2" pointer-events="visiblePainted" fill="#438dd5" width="450" height="300"></rect><text  id="v-242" font-size="34" y="0.8em" xml:space="preserve" font-weight="bold" text-anchor="middle" pointer-events="visible" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,225,60)"><tspan id="v-247"  dy="0em" x="0">Envoy</tspan></text><text  id="v-243" font-size="19" y="0.8em" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,225,102.5)"><tspan id="v-248"  dy="0em" x="0">[Container]</tspan></text><text  id="v-244" font-size="24" y="0.8em" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,225,150)"><tspan id="v-249"  dy="0em" x="0">A long-living entity that can adapt a</tspan><tspan id="v-250"  dy="1.2em" x="0">local data set and spawn</tspan><tspan id="v-251"  dy="1.2em" x="0">collaborators</tspan></text><text  id="v-245" font-weight="bold" text-anchor="middle" font-family="Open Sans" fill="#ffffff" font-size="24" transform="matrix(1,0,0,1,225,270)" y="0.8em" xml:space="preserve" display="none"><tspan id="v-259"  dy="0em" x="0">+</tspan></text><image  id="v-246"></image></g></g><g id="j_17"    transform="translate(2470,1265)" style=""><g  id="v-265" style="opacity: 1;"><rect  x="0" y="160" width="400" height="240" rx="70" id="v-267" stroke="#073b6f" stroke-width="2" pointer-events="visiblePainted" fill="#08427b"></rect><circle  cx="200" cy="88.88888888888889" r="88.88888888888889" id="v-266" stroke="#073b6f" stroke-width="2" pointer-events="visiblePainted" fill="#08427b"></circle><line  x1="80" y1="266.6666666666667" x2="80" y2="400" style="stroke-width:2px" id="v-273" stroke="#073b6f"></line><line  x1="320" y1="266.6666666666667" x2="320" y2="400" style="stroke-width:2px" id="v-274" stroke="#073b6f"></line><text  id="v-268" font-size="34px" y="0.8em" xml:space="preserve" font-weight="bold" text-anchor="middle" pointer-events="visible" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,200,205)"><tspan id="v-275"  dy="0em" x="0">Collaborator manager</tspan></text><text  id="v-269" font-size="19px" y="0.8em" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,200,247.5)"><tspan id="v-276"  dy="0em" x="0">[Person]</tspan></text><text  id="v-270" font-size="24px" y="0.8em" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,200,295)"><tspan id="v-277"  dy="0em" x="0">Data owner's representative</tspan><tspan id="v-278"  dy="1.2em" x="0">controlling Envoy</tspan></text><text  id="v-271" font-weight="bold" text-anchor="middle" font-family="Open Sans" fill="#ffffff" font-size="24" transform="matrix(1,0,0,1,200,371.2)" display="none"></text><image  id="v-272"></image></g></g><g id="j_18"    transform="translate(230,1270)" style=""><g  id="v-282" style="opacity: 1;"><rect  x="0" y="160" width="400" height="240" rx="70" id="v-284" stroke="#073b6f" stroke-width="2" pointer-events="visiblePainted" fill="#08427b"></rect><circle  cx="200" cy="88.88888888888889" r="88.88888888888889" id="v-283" stroke="#073b6f" stroke-width="2" pointer-events="visiblePainted" fill="#08427b"></circle><line  x1="80" y1="266.6666666666667" x2="80" y2="400" style="stroke-width:2px" id="v-290" stroke="#073b6f"></line><line  x1="320" y1="266.6666666666667" x2="320" y2="400" style="stroke-width:2px" id="v-291" stroke="#073b6f"></line><text  id="v-285" font-size="34px" y="0.8em" xml:space="preserve" font-weight="bold" text-anchor="middle" pointer-events="visible" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,200,246.9)"><tspan id="v-292"  dy="0em" x="0">Director manager</tspan></text><text  id="v-286" font-size="19px" y="0.8em" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,200,289.4)"><tspan id="v-293"  dy="0em" x="0">[Person]</tspan></text><text  id="v-287" font-size="24px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,200,313.1)"><tspan id="v-294"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text><text  id="v-288" font-weight="bold" text-anchor="middle" font-family="Open Sans" fill="#ffffff" font-size="24" transform="matrix(1,0,0,1,200,371.2)" display="none"></text><image  id="v-289"></image></g></g><g id="j_19"    transform="translate(1740,1855)" style="" ><g  id="v-298" style="opacity: 1;"><rect  id="v-299" rx="20" ry="20" stroke="#3c7fc0" stroke-width="2" pointer-events="visiblePainted" fill="#438dd5" width="450" height="300"></rect><text  id="v-300" font-size="34" y="0.8em" xml:space="preserve" font-weight="bold" text-anchor="middle" pointer-events="visible" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,225,75)"><tspan id="v-305"  dy="0em" x="0">Collaborator</tspan></text><text  id="v-301" font-size="19" y="0.8em" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,225,117.5)"><tspan id="v-306"  dy="0em" x="0">[Container]</tspan></text><text  id="v-302" font-size="24" y="0.8em" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,225,165)"><tspan id="v-307"  dy="0em" x="0">Actor executing tasks on local data</tspan><tspan id="v-308"  dy="1.2em" x="0">inside one experiment</tspan></text><text  id="v-303" font-weight="bold" text-anchor="middle" font-family="Open Sans" fill="#ffffff" font-size="24" transform="matrix(1,0,0,1,225,270)" y="0.8em" xml:space="preserve" display="none"><tspan id="v-309"  dy="0em" x="0">+</tspan></text><image  id="v-304"></image></g></g><g id="j_20"    transform="translate(880,760)" style="" ><g  id="v-315" style="opacity: 1;"><rect  id="v-316" rx="20" ry="20" stroke="#3c7fc0" stroke-width="2" pointer-events="visiblePainted" fill="#438dd5" width="450" height="300"></rect><text  id="v-317" font-size="34" y="0.8em" xml:space="preserve" font-weight="bold" text-anchor="middle" pointer-events="visible" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,225,75)"><tspan id="v-322"  dy="0em" x="0">Python API component</tspan></text><text  id="v-318" font-size="19" y="0.8em" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,225,117.5)"><tspan id="v-323"  dy="0em" x="0">[Container]</tspan></text><text  id="v-319" font-size="24" y="0.8em" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,225,165)"><tspan id="v-324"  dy="0em" x="0">A set of tools to setup register FL</tspan><tspan id="v-325"  dy="1.2em" x="0">Experiments</tspan></text><text  id="v-320" font-weight="bold" text-anchor="middle" font-family="Open Sans" fill="#ffffff" font-size="24" transform="matrix(1,0,0,1,225,270)" y="0.8em" xml:space="preserve" display="none"><tspan id="v-326"  dy="0em" x="0">+</tspan></text><image  id="v-321"></image></g></g><g id="j_21"    transform="translate(880,1320)" style="" ><g  id="v-330" style="opacity: 1;"><rect  id="v-331" rx="20" ry="20" stroke="#3c7fc0" stroke-width="2" pointer-events="visiblePainted" fill="#438dd5" width="450" height="300"></rect><text  id="v-332" font-size="34" y="0.8em" xml:space="preserve" font-weight="bold" text-anchor="middle" pointer-events="visible" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,225,75)"><tspan id="v-337"  dy="0em" x="0">Director</tspan></text><text  id="v-333" font-size="19" y="0.8em" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,225,117.5)"><tspan id="v-338"  dy="0em" x="0">[Container]</tspan></text><text  id="v-334" font-size="24" y="0.8em" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,225,165)"><tspan id="v-339"  dy="0em" x="0">A long-living entity that can spawn</tspan><tspan id="v-340"  dy="1.2em" x="0">aggregators</tspan></text><text  id="v-335" font-weight="bold" text-anchor="middle" font-family="Open Sans" fill="#ffffff" font-size="24" transform="matrix(1,0,0,1,225,270)" y="0.8em" display="none" xml:space="preserve"><tspan id="v-348"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text><image  id="v-336"></image></g></g><g id="j_23"    transform="translate(880,1855)" style="" ><g  id="v-352" style="opacity: 1;"><rect  id="v-353" rx="20" ry="20" stroke="#3c7fc0" stroke-width="2" pointer-events="visiblePainted" fill="#438dd5" width="450" height="300"></rect><text  id="v-354" font-size="34" y="0.8em" xml:space="preserve" font-weight="bold" text-anchor="middle" pointer-events="visible" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,225,75)"><tspan id="v-359"  dy="0em" x="0">Aggregator</tspan></text><text  id="v-355" font-size="19" y="0.8em" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,225,117.5)"><tspan id="v-360"  dy="0em" x="0">[Container]</tspan></text><text  id="v-356" font-size="24" y="0.8em" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,225,165)"><tspan id="v-361"  dy="0em" x="0">Model server and collaborator</tspan><tspan id="v-362"  dy="1.2em" x="0">orchestrator</tspan></text><text  id="v-357" font-weight="bold" text-anchor="middle" font-family="Open Sans" fill="#ffffff" font-size="24" transform="matrix(1,0,0,1,225,270)" y="0.8em" display="none" xml:space="preserve"><tspan id="v-363"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text><image  id="v-358"></image></g></g><g id="j_24"   ><path  stroke="#707070" id="v-386" stroke-width="2" stroke-dasharray="30 30" fill="none" d="M 630 1470 860 1470" style="opacity: 1;"></path><path  fill="black" stroke="black" transform="translate(630,1470) scale(1,1) rotate(0)"></path><path  fill="#707070" stroke="#707070" id="v-388" d="M 20 0 L 0 10 L 20 20 z" transform="translate(880,1480) scale(1,1) rotate(-180)" style="opacity: 1;"></path><path  id="v-387" fill="none" d="M 630 1470 860 1470"></path><title ></title><g ><g  id="v-371" label-idx="0" cursor="move" transform="translate(745, 1470)" style="opacity: 1;"><rect id="v-373" fill="#ffffff" rx="3" ry="3" stroke="#ffffff" stroke-width="20px" pointer-events="none" width="165.5" height="119" transform="matrix(1,0,0,1,-82.7,-59.5)"></rect><text id="v-372" font-size="24px" y="0.8em" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,-52.2)"><tspan id="v-374"  dy="0em" x="0">Launches. Sets</tspan><tspan id="v-375"  dy="1.2em" x="0">up global</tspan><tspan id="v-376"  dy="1.2em" x="0">Federation</tspan><tspan id="v-377"  dy="1.2em" x="0">settings</tspan></text></g><g  id="v-378" label-idx="1" cursor="move" transform="translate(745, 1539.6)" style="opacity: 1;"><rect id="v-380" fill="#ffffff" rx="3" ry="3" pointer-events="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-379" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,0)"><tspan id="v-381"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g><g  id="v-382" label-idx="2" cursor="move" transform="translate(745, 1563.6)" style="opacity: 1;"><rect id="v-384" fill="#ffffff" rx="3" ry="3" pointer-events="none"  display="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-383" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal"  transform="matrix(1,0,0,1,0,0)"><tspan id="v-385"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g></g><g  display="none"></g><g  id="v-390" display="none"><g  id="v-368"><path  end="source" d="M 26 0 L 0 13 L 26 26 z"></path></g><g  id="v-369"><path  end="target" d="M 26 0 L 0 13 L 26 26 z"></path></g></g><g  id="v-389" display="none"><g  id="v-367" transform="translate(670, 1470) "><g  event="remove"><circle r="11"></circle><path transform="scale(.8) translate(-16, -16)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"></path><title>Remove link.</title></g><g  event="link:options"><circle r="11" transform="translate(25)"></circle><path fill="white" transform="scale(.55) translate(29, -16)" d="M31.229,17.736c0.064-0.571,0.104-1.148,0.104-1.736s-0.04-1.166-0.104-1.737l-4.377-1.557c-0.218-0.716-0.504-1.401-0.851-2.05l1.993-4.192c-0.725-0.91-1.549-1.734-2.458-2.459l-4.193,1.994c-0.647-0.347-1.334-0.632-2.049-0.849l-1.558-4.378C17.165,0.708,16.588,0.667,16,0.667s-1.166,0.041-1.737,0.105L12.707,5.15c-0.716,0.217-1.401,0.502-2.05,0.849L6.464,4.005C5.554,4.73,4.73,5.554,4.005,6.464l1.994,4.192c-0.347,0.648-0.632,1.334-0.849,2.05l-4.378,1.557C0.708,14.834,0.667,15.412,0.667,16s0.041,1.165,0.105,1.736l4.378,1.558c0.217,0.715,0.502,1.401,0.849,2.049l-1.994,4.193c0.725,0.909,1.549,1.733,2.459,2.458l4.192-1.993c0.648,0.347,1.334,0.633,2.05,0.851l1.557,4.377c0.571,0.064,1.148,0.104,1.737,0.104c0.588,0,1.165-0.04,1.736-0.104l1.558-4.377c0.715-0.218,1.399-0.504,2.049-0.851l4.193,1.993c0.909-0.725,1.733-1.549,2.458-2.458l-1.993-4.193c0.347-0.647,0.633-1.334,0.851-2.049L31.229,17.736zM16,20.871c-2.69,0-4.872-2.182-4.872-4.871c0-2.69,2.182-4.872,4.872-4.872c2.689,0,4.871,2.182,4.871,4.872C20.871,18.689,18.689,20.871,16,20.871z"></path><title>Link options.</title></g></g></g></g><g id="j_25"   ><path  stroke="#707070" id="v-413" stroke-width="2" stroke-dasharray="30 30" fill="none" d="M 2470 1466 2210 1468" style="opacity: 1;"></path><path  fill="black" stroke="black" transform="translate(2470,1466) scale(1,1) rotate(-180.4092559814453)"></path><path  fill="#707070" stroke="#707070" id="v-415" d="M 20 0 L 0 10 L 20 20 z" transform="translate(2189.928584200193,1458.0002707109588) scale(1,1) rotate(-0.40924862027168274)" style="opacity: 1;"></path><path  id="v-414" fill="none" d="M 2470 1466 2210 1468"></path><title ></title><g ><g  id="v-398" label-idx="0" cursor="move" transform="translate(2340, 1467)" style="opacity: 1;"><rect id="v-400" fill="#ffffff" rx="3" ry="3" stroke="#ffffff" stroke-width="20px" pointer-events="none" width="194.34375" height="119" transform="matrix(1,0,0,1,-97.2,-59.5)"></rect><text id="v-399" font-size="24px" y="0.8em" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,-52.2)"><tspan id="v-401"  dy="0em" x="0">Launches.</tspan><tspan id="v-402"  dy="1.2em" x="0">Provides local</tspan><tspan id="v-403"  dy="1.2em" x="0">dataset</tspan><tspan id="v-404"  dy="1.2em" x="0">ShardDescriptors</tspan></text></g><g  id="v-405" label-idx="1" cursor="move" transform="translate(2340, 1536.6)" style="opacity: 1;"><rect id="v-407" fill="#ffffff" rx="3" ry="3" pointer-events="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-406" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,0)"><tspan id="v-408"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g><g  id="v-409" label-idx="2" cursor="move" transform="translate(2340, 1560.6)" style="opacity: 1;"><rect id="v-411" fill="#ffffff" rx="3" ry="3" pointer-events="none"  display="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-410" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal"  transform="matrix(1,0,0,1,0,0)"><tspan id="v-412"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g></g><g  display="none"></g><g  id="v-417" display="none"><g  id="v-395"><path  end="source" d="M 26 0 L 0 13 L 26 26 z"></path></g><g  id="v-396"><path  end="target" d="M 26 0 L 0 13 L 26 26 z"></path></g></g><g  id="v-416" display="none"><g  id="v-394" transform="translate(2430.001220703125, 1466.3076171875) "><g  event="remove"><circle r="11"></circle><path transform="scale(.8) translate(-16, -16)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"></path><title>Remove link.</title></g><g  event="link:options"><circle r="11" transform="translate(25)"></circle><path fill="white" transform="scale(.55) translate(29, -16)" d="M31.229,17.736c0.064-0.571,0.104-1.148,0.104-1.736s-0.04-1.166-0.104-1.737l-4.377-1.557c-0.218-0.716-0.504-1.401-0.851-2.05l1.993-4.192c-0.725-0.91-1.549-1.734-2.458-2.459l-4.193,1.994c-0.647-0.347-1.334-0.632-2.049-0.849l-1.558-4.378C17.165,0.708,16.588,0.667,16,0.667s-1.166,0.041-1.737,0.105L12.707,5.15c-0.716,0.217-1.401,0.502-2.05,0.849L6.464,4.005C5.554,4.73,4.73,5.554,4.005,6.464l1.994,4.192c-0.347,0.648-0.632,1.334-0.849,2.05l-4.378,1.557C0.708,14.834,0.667,15.412,0.667,16s0.041,1.165,0.105,1.736l4.378,1.558c0.217,0.715,0.502,1.401,0.849,2.049l-1.994,4.193c0.725,0.909,1.549,1.733,2.459,2.458l4.192-1.993c0.648,0.347,1.334,0.633,2.05,0.851l1.557,4.377c0.571,0.064,1.148,0.104,1.737,0.104c0.588,0,1.165-0.04,1.736-0.104l1.558-4.377c0.715-0.218,1.399-0.504,2.049-0.851l4.193,1.993c0.909-0.725,1.733-1.549,2.458-2.458l-1.993-4.193c0.347-0.647,0.633-1.334,0.851-2.049L31.229,17.736zM16,20.871c-2.69,0-4.872-2.182-4.872-4.871c0-2.69,2.182-4.872,4.872-4.872c2.689,0,4.871,2.182,4.871,4.872C20.871,18.689,18.689,20.871,16,20.871z"></path><title>Link options.</title></g></g></g></g><g id="j_26"   ><path  stroke="#707070" id="v-441" stroke-width="2" stroke-dasharray="30 30" fill="none" d="M 1740 1971 1545 1941 S 1535 1940 1525 1941 L 1350 1968" style="opacity: 1;"></path><path  fill="black" stroke="black" transform="translate(1740,1971) scale(1,1) rotate(-171.40090942382812)"></path><path  fill="#707070" stroke="#707070" id="v-443" d="M 20 0 L 0 10 L 20 20 z" transform="translate(1328.5047894829493,1961.1123693136124) scale(1,1) rotate(-8.599088668823242)" style="opacity: 1;"></path><path  id="v-442" fill="none" d="M 1740 1971 1545 1941 S 1535 1940 1525 1941 L 1350 1968"></path><title ></title><g ><g  id="v-426" label-idx="0" cursor="move" transform="translate(1545.0970458984375, 1941.014892578125)" style="opacity: 1;"><rect id="v-428" fill="#ffffff" rx="3" ry="3" stroke="#ffffff" stroke-width="20px" pointer-events="none" width="156.1875" height="119" transform="matrix(1,0,0,1,-78.1,-59.5)"></rect><text id="v-427" font-size="24px" y="0.8em" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,-52.2)"><tspan id="v-429"  dy="0em" x="0">Sends locally</tspan><tspan id="v-430"  dy="1.2em" x="0">tuned tensors</tspan><tspan id="v-431"  dy="1.2em" x="0">and training</tspan><tspan id="v-432"  dy="1.2em" x="0">metrics</tspan></text></g><g  id="v-433" label-idx="1" cursor="move" transform="translate(1545.0970458984375, 2010.614892578125)" style="opacity: 1;"><rect id="v-435" fill="#ffffff" rx="3" ry="3" pointer-events="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-434" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,0)"><tspan id="v-436"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g><g  id="v-437" label-idx="2" cursor="move" transform="translate(1545.0970458984375, 2034.614892578125)" style="opacity: 1;"><rect id="v-439" fill="#ffffff" rx="3" ry="3" pointer-events="none"  display="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-438" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal"  transform="matrix(1,0,0,1,0,0)"><tspan id="v-440"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g></g><g  display="none"><g  transform="translate(1535, 1940)" id="v-422"><circle  idx="0" r="10"></circle><path  idx="0" d="M16,5.333c-7.732,0-14,4.701-14,10.5c0,1.982,0.741,3.833,2.016,5.414L2,25.667l5.613-1.441c2.339,1.317,5.237,2.107,8.387,2.107c7.732,0,14-4.701,14-10.5C30,10.034,23.732,5.333,16,5.333z" transform="translate(5, -33)"></path><path  idx="0" transform="scale(.8) translate(9.5, -37)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"><title>Remove vertex.</title></path></g></g><g  id="v-445" display="none"><g  id="v-423"><path  end="source" d="M 26 0 L 0 13 L 26 26 z"></path></g><g  id="v-424"><path  end="target" d="M 26 0 L 0 13 L 26 26 z"></path></g></g><g  id="v-444" display="none"><g  id="v-421" transform="translate(1700.465087890625, 1964.917724609375) "><g  event="remove"><circle r="11"></circle><path transform="scale(.8) translate(-16, -16)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"></path><title>Remove link.</title></g><g  event="link:options"><circle r="11" transform="translate(25)"></circle><path fill="white" transform="scale(.55) translate(29, -16)" d="M31.229,17.736c0.064-0.571,0.104-1.148,0.104-1.736s-0.04-1.166-0.104-1.737l-4.377-1.557c-0.218-0.716-0.504-1.401-0.851-2.05l1.993-4.192c-0.725-0.91-1.549-1.734-2.458-2.459l-4.193,1.994c-0.647-0.347-1.334-0.632-2.049-0.849l-1.558-4.378C17.165,0.708,16.588,0.667,16,0.667s-1.166,0.041-1.737,0.105L12.707,5.15c-0.716,0.217-1.401,0.502-2.05,0.849L6.464,4.005C5.554,4.73,4.73,5.554,4.005,6.464l1.994,4.192c-0.347,0.648-0.632,1.334-0.849,2.05l-4.378,1.557C0.708,14.834,0.667,15.412,0.667,16s0.041,1.165,0.105,1.736l4.378,1.558c0.217,0.715,0.502,1.401,0.849,2.049l-1.994,4.193c0.725,0.909,1.549,1.733,2.459,2.458l4.192-1.993c0.648,0.347,1.334,0.633,2.05,0.851l1.557,4.377c0.571,0.064,1.148,0.104,1.737,0.104c0.588,0,1.165-0.04,1.736-0.104l1.558-4.377c0.715-0.218,1.399-0.504,2.049-0.851l4.193,1.993c0.909-0.725,1.733-1.549,2.458-2.458l-1.993-4.193c0.347-0.647,0.633-1.334,0.851-2.049L31.229,17.736zM16,20.871c-2.69,0-4.872-2.182-4.872-4.871c0-2.69,2.182-4.872,4.872-4.872c2.689,0,4.871,2.182,4.871,4.872C20.871,18.689,18.689,20.871,16,20.871z"></path><title>Link options.</title></g></g></g></g><g id="j_27"   ><path  stroke="#707070" id="v-467" stroke-width="2" stroke-dasharray="30 30" fill="none" d="M 1096 600 1100 740" style="opacity: 1;"></path><path  fill="black" stroke="black" transform="translate(1096,600) scale(1,1) rotate(88.21008300781253)"></path><path  fill="#707070" stroke="#707070" id="v-469" d="M 20 0 L 0 10 L 20 20 z" transform="translate(1091.0048486091628,760.3123508866711) scale(1,1) rotate(-91.78990936279297)" style="opacity: 1;"></path><path  id="v-468" fill="none" d="M 1096 600 1100 740"></path><title ></title><g ><g  id="v-453" label-idx="0" cursor="move" transform="translate(1098, 670)" style="opacity: 1;"><rect id="v-455" fill="#ffffff" rx="3" ry="3" stroke="#ffffff" stroke-width="20px" pointer-events="none" width="199.65625" height="90.203125" transform="matrix(1,0,0,1,-99.8,-45.1)"></rect><text id="v-454" font-size="24px" y="0.8em" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,-37.8)"><tspan id="v-456"  dy="0em" x="0">Provides FL Plans,</tspan><tspan id="v-457"  dy="1.2em" x="0">Tasks, Models,</tspan><tspan id="v-458"  dy="1.2em" x="0">DataLoaders</tspan></text></g><g  id="v-459" label-idx="1" cursor="move" transform="translate(1098, 727.6)" style="opacity: 1;"><rect id="v-461" fill="#ffffff" rx="3" ry="3" pointer-events="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-460" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,0)"><tspan id="v-462"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g><g  id="v-463" label-idx="2" cursor="move" transform="translate(1098, 751.6)" style="opacity: 1;"><rect id="v-465" fill="#ffffff" rx="3" ry="3" pointer-events="none"  display="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-464" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal"  transform="matrix(1,0,0,1,0,0)"><tspan id="v-466"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g></g><g  display="none"></g><g  id="v-471" display="none"><g  id="v-450"><path  end="source" d="M 26 0 L 0 13 L 26 26 z"></path></g><g  id="v-451"><path  end="target" d="M 26 0 L 0 13 L 26 26 z"></path></g></g><g  id="v-470" display="none"><g  id="v-449" transform="translate(1097.142333984375, 639.9837036132812) "><g  event="remove"><circle r="11"></circle><path transform="scale(.8) translate(-16, -16)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"></path><title>Remove link.</title></g><g  event="link:options"><circle r="11" transform="translate(25)"></circle><path fill="white" transform="scale(.55) translate(29, -16)" d="M31.229,17.736c0.064-0.571,0.104-1.148,0.104-1.736s-0.04-1.166-0.104-1.737l-4.377-1.557c-0.218-0.716-0.504-1.401-0.851-2.05l1.993-4.192c-0.725-0.91-1.549-1.734-2.458-2.459l-4.193,1.994c-0.647-0.347-1.334-0.632-2.049-0.849l-1.558-4.378C17.165,0.708,16.588,0.667,16,0.667s-1.166,0.041-1.737,0.105L12.707,5.15c-0.716,0.217-1.401,0.502-2.05,0.849L6.464,4.005C5.554,4.73,4.73,5.554,4.005,6.464l1.994,4.192c-0.347,0.648-0.632,1.334-0.849,2.05l-4.378,1.557C0.708,14.834,0.667,15.412,0.667,16s0.041,1.165,0.105,1.736l4.378,1.558c0.217,0.715,0.502,1.401,0.849,2.049l-1.994,4.193c0.725,0.909,1.549,1.733,2.459,2.458l4.192-1.993c0.648,0.347,1.334,0.633,2.05,0.851l1.557,4.377c0.571,0.064,1.148,0.104,1.737,0.104c0.588,0,1.165-0.04,1.736-0.104l1.558-4.377c0.715-0.218,1.399-0.504,2.049-0.851l4.193,1.993c0.909-0.725,1.733-1.549,2.458-2.458l-1.993-4.193c0.347-0.647,0.633-1.334,0.851-2.049L31.229,17.736zM16,20.871c-2.69,0-4.872-2.182-4.872-4.871c0-2.69,2.182-4.872,4.872-4.872c2.689,0,4.871,2.182,4.871,4.872C20.871,18.689,18.689,20.871,16,20.871z"></path><title>Link options.</title></g></g></g></g><g id="j_28"   ><path  stroke="#707070" id="v-493" stroke-width="2" stroke-dasharray="30 30" fill="none" d="M 1330 2047 1555 2088 S 1565 2090 1575 2088 L 1720 2057" style="opacity: 1;"></path><path  fill="black" stroke="black" transform="translate(1330,2047) scale(1,1) rotate(10.36920166015625)"></path><path  fill="#707070" stroke="#707070" id="v-495" d="M 20 0 L 0 10 L 20 20 z" transform="translate(1742.0685808356088,2062.783760202619) scale(1,1) rotate(-191.9381561279297)" style="opacity: 1;"></path><path  id="v-494" fill="none" d="M 1330 2047 1555 2088 S 1565 2090 1575 2088 L 1720 2057"></path><title ></title><g ><g  id="v-480" label-idx="0" cursor="move" transform="translate(1525.3284912109375, 2082.59326171875)" style="opacity: 1;"><rect id="v-482" fill="#ffffff" rx="3" ry="3" stroke="#ffffff" stroke-width="20px" pointer-events="none" width="180.0625" height="61.40625" transform="matrix(1,0,0,1,-90,-30.7)"></rect><text id="v-481" font-size="24px" y="0.8em" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,-23.4)"><tspan id="v-483"  dy="0em" x="0">Sends tasks and</tspan><tspan id="v-484"  dy="1.2em" x="0">initial tensors</tspan></text></g><g  id="v-485" label-idx="1" cursor="move" transform="translate(1525.3284912109375, 2125.79326171875)" style="opacity: 1;"><rect id="v-487" fill="#ffffff" rx="3" ry="3" pointer-events="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-486" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,0)"><tspan id="v-488"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g><g  id="v-489" label-idx="2" cursor="move" transform="translate(1525.3284912109375, 2149.79326171875)" style="opacity: 1;"><rect id="v-491" fill="#ffffff" rx="3" ry="3" pointer-events="none"  display="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-490" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal"  transform="matrix(1,0,0,1,0,0)"><tspan id="v-492"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g></g><g  display="none"><g  transform="translate(1565, 2090)" id="v-476"><circle  idx="0" r="10"></circle><path  idx="0" d="M16,5.333c-7.732,0-14,4.701-14,10.5c0,1.982,0.741,3.833,2.016,5.414L2,25.667l5.613-1.441c2.339,1.317,5.237,2.107,8.387,2.107c7.732,0,14-4.701,14-10.5C30,10.034,23.732,5.333,16,5.333z" transform="translate(5, -33)"></path><path  idx="0" transform="scale(.8) translate(9.5, -37)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"><title>Remove vertex.</title></path></g></g><g  id="v-497" display="none"><g  id="v-477"><path  end="source" d="M 26 0 L 0 13 L 26 26 z"></path></g><g  id="v-478"><path  end="target" d="M 26 0 L 0 13 L 26 26 z"></path></g></g><g  id="v-496" display="none"><g  id="v-475" transform="translate(1369.35205078125, 2054.1708984375) "><g  event="remove"><circle r="11"></circle><path transform="scale(.8) translate(-16, -16)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"></path><title>Remove link.</title></g><g  event="link:options"><circle r="11" transform="translate(25)"></circle><path fill="white" transform="scale(.55) translate(29, -16)" d="M31.229,17.736c0.064-0.571,0.104-1.148,0.104-1.736s-0.04-1.166-0.104-1.737l-4.377-1.557c-0.218-0.716-0.504-1.401-0.851-2.05l1.993-4.192c-0.725-0.91-1.549-1.734-2.458-2.459l-4.193,1.994c-0.647-0.347-1.334-0.632-2.049-0.849l-1.558-4.378C17.165,0.708,16.588,0.667,16,0.667s-1.166,0.041-1.737,0.105L12.707,5.15c-0.716,0.217-1.401,0.502-2.05,0.849L6.464,4.005C5.554,4.73,4.73,5.554,4.005,6.464l1.994,4.192c-0.347,0.648-0.632,1.334-0.849,2.05l-4.378,1.557C0.708,14.834,0.667,15.412,0.667,16s0.041,1.165,0.105,1.736l4.378,1.558c0.217,0.715,0.502,1.401,0.849,2.049l-1.994,4.193c0.725,0.909,1.549,1.733,2.459,2.458l4.192-1.993c0.648,0.347,1.334,0.633,2.05,0.851l1.557,4.377c0.571,0.064,1.148,0.104,1.737,0.104c0.588,0,1.165-0.04,1.736-0.104l1.558-4.377c0.715-0.218,1.399-0.504,2.049-0.851l4.193,1.993c0.909-0.725,1.733-1.549,2.458-2.458l-1.993-4.193c0.347-0.647,0.633-1.334,0.851-2.049L31.229,17.736zM16,20.871c-2.69,0-4.872-2.182-4.872-4.871c0-2.69,2.182-4.872,4.872-4.872c2.689,0,4.871,2.182,4.871,4.872C20.871,18.689,18.689,20.871,16,20.871z"></path><title>Link options.</title></g></g></g></g><g id="j_29"   ><path  stroke="#707070" id="v-519" stroke-width="2" stroke-dasharray="30 30" fill="none" d="M 1330 1500 1540 1529 S 1550 1530 1560 1529 L 1720 1506" style="opacity: 1;"></path><path  fill="black" stroke="black" transform="translate(1330,1500) scale(1,1) rotate(7.765167236328139)"></path><path  fill="#707070" stroke="#707070" id="v-521" d="M 20 0 L 0 10 L 20 20 z" transform="translate(1741.4069390794684,1512.9004776234322) scale(1,1) rotate(-188.08787536621094)" style="opacity: 1;"></path><path  id="v-520" fill="none" d="M 1330 1500 1540 1529 S 1550 1530 1560 1529 L 1720 1506"></path><title ></title><g ><g  id="v-506" label-idx="0" cursor="move" transform="translate(1524.98193359375, 1526.926025390625)" style="opacity: 1;"><rect id="v-508" fill="#ffffff" rx="3" ry="3" stroke="#ffffff" stroke-width="20px" pointer-events="none" width="185.4375" height="61.40625" transform="matrix(1,0,0,1,-92.7,-30.7)"></rect><text id="v-507" font-size="24px" y="0.8em" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,-23.4)"><tspan id="v-509"  dy="0em" x="0">Approves, Sends</tspan><tspan id="v-510"  dy="1.2em" x="0">FL experiments</tspan></text></g><g  id="v-511" label-idx="1" cursor="move" transform="translate(1524.98193359375, 1570.126025390625)" style="opacity: 1;"><rect id="v-513" fill="#ffffff" rx="3" ry="3" pointer-events="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-512" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,0)"><tspan id="v-514"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g><g  id="v-515" label-idx="2" cursor="move" transform="translate(1524.98193359375, 1594.126025390625)" style="opacity: 1;"><rect id="v-517" fill="#ffffff" rx="3" ry="3" pointer-events="none"  display="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-516" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal"  transform="matrix(1,0,0,1,0,0)"><tspan id="v-518"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g></g><g  display="none"><g  transform="translate(1550, 1530)" id="v-502"><circle  idx="0" r="10"></circle><path  idx="0" d="M16,5.333c-7.732,0-14,4.701-14,10.5c0,1.982,0.741,3.833,2.016,5.414L2,25.667l5.613-1.441c2.339,1.317,5.237,2.107,8.387,2.107c7.732,0,14-4.701,14-10.5C30,10.034,23.732,5.333,16,5.333z" transform="translate(5, -33)"></path><path  idx="0" transform="scale(.8) translate(9.5, -37)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"><title>Remove vertex.</title></path></g></g><g  id="v-523" display="none"><g  id="v-503"><path  end="source" d="M 26 0 L 0 13 L 26 26 z"></path></g><g  id="v-504"><path  end="target" d="M 26 0 L 0 13 L 26 26 z"></path></g></g><g  id="v-522" display="none"><g  id="v-501" transform="translate(1369.6240234375, 1505.471923828125) "><g  event="remove"><circle r="11"></circle><path transform="scale(.8) translate(-16, -16)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"></path><title>Remove link.</title></g><g  event="link:options"><circle r="11" transform="translate(25)"></circle><path fill="white" transform="scale(.55) translate(29, -16)" d="M31.229,17.736c0.064-0.571,0.104-1.148,0.104-1.736s-0.04-1.166-0.104-1.737l-4.377-1.557c-0.218-0.716-0.504-1.401-0.851-2.05l1.993-4.192c-0.725-0.91-1.549-1.734-2.458-2.459l-4.193,1.994c-0.647-0.347-1.334-0.632-2.049-0.849l-1.558-4.378C17.165,0.708,16.588,0.667,16,0.667s-1.166,0.041-1.737,0.105L12.707,5.15c-0.716,0.217-1.401,0.502-2.05,0.849L6.464,4.005C5.554,4.73,4.73,5.554,4.005,6.464l1.994,4.192c-0.347,0.648-0.632,1.334-0.849,2.05l-4.378,1.557C0.708,14.834,0.667,15.412,0.667,16s0.041,1.165,0.105,1.736l4.378,1.558c0.217,0.715,0.502,1.401,0.849,2.049l-1.994,4.193c0.725,0.909,1.549,1.733,2.459,2.458l4.192-1.993c0.648,0.347,1.334,0.633,2.05,0.851l1.557,4.377c0.571,0.064,1.148,0.104,1.737,0.104c0.588,0,1.165-0.04,1.736-0.104l1.558-4.377c0.715-0.218,1.399-0.504,2.049-0.851l4.193,1.993c0.909-0.725,1.733-1.549,2.458-2.458l-1.993-4.193c0.347-0.647,0.633-1.334,0.851-2.049L31.229,17.736zM16,20.871c-2.69,0-4.872-2.182-4.872-4.871c0-2.69,2.182-4.872,4.872-4.872c2.689,0,4.871,2.182,4.871,4.872C20.871,18.689,18.689,20.871,16,20.871z"></path><title>Link options.</title></g></g></g></g><g id="j_30"   ><path  stroke="#707070" id="v-547" stroke-width="2" stroke-dasharray="30 30" fill="none" d="M 1740 1413 1540 1362 S 1530 1360 1520 1363 L 1349 1407" style="opacity: 1;"></path><path  fill="black" stroke="black" transform="translate(1740,1413) scale(1,1) rotate(-165.83543395996094)"></path><path  fill="#707070" stroke="#707070" id="v-549" d="M 20 0 L 0 10 L 20 20 z" transform="translate(1327.4836591093501,1402.3217559621125) scale(1,1) rotate(-14.57421588897705)" style="opacity: 1;"></path><path  id="v-548" fill="none" d="M 1740 1413 1540 1362 S 1530 1360 1520 1363 L 1349 1407"></path><title ></title><g ><g  id="v-532" label-idx="0" cursor="move" transform="translate(1544.66943359375, 1363.190673828125)" style="opacity: 1;"><rect id="v-534" fill="#ffffff" rx="3" ry="3" stroke="#ffffff" stroke-width="20px" pointer-events="none" width="167.9375" height="119" transform="matrix(1,0,0,1,-84,-59.5)"></rect><text id="v-533" font-size="24px" y="0.8em" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,-52.2)"><tspan id="v-535"  dy="0em" x="0">Communicates</tspan><tspan id="v-536"  dy="1.2em" x="0">dataset info,</tspan><tspan id="v-537"  dy="1.2em" x="0">Sends status</tspan><tspan id="v-538"  dy="1.2em" x="0">updates</tspan></text></g><g  id="v-539" label-idx="1" cursor="move" transform="translate(1544.66943359375, 1432.790673828125)" style="opacity: 1;"><rect id="v-541" fill="#ffffff" rx="3" ry="3" pointer-events="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-540" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,0)"><tspan id="v-542"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g><g  id="v-543" label-idx="2" cursor="move" transform="translate(1544.66943359375, 1456.790673828125)" style="opacity: 1;"><rect id="v-545" fill="#ffffff" rx="3" ry="3" pointer-events="none"  display="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-544" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal"  transform="matrix(1,0,0,1,0,0)"><tspan id="v-546"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g></g><g  display="none"><g  transform="translate(1530, 1360)" id="v-528"><circle  idx="0" r="10"></circle><path  idx="0" d="M16,5.333c-7.732,0-14,4.701-14,10.5c0,1.982,0.741,3.833,2.016,5.414L2,25.667l5.613-1.441c2.339,1.317,5.237,2.107,8.387,2.107c7.732,0,14-4.701,14-10.5C30,10.034,23.732,5.333,16,5.333z" transform="translate(5, -33)"></path><path  idx="0" transform="scale(.8) translate(9.5, -37)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"><title>Remove vertex.</title></path></g></g><g  id="v-551" display="none"><g  id="v-529"><path  end="source" d="M 26 0 L 0 13 L 26 26 z"></path></g><g  id="v-530"><path  end="target" d="M 26 0 L 0 13 L 26 26 z"></path></g></g><g  id="v-550" display="none"><g  id="v-527" transform="translate(1701.2403564453125, 1403.1163330078125) "><g  event="remove"><circle r="11"></circle><path transform="scale(.8) translate(-16, -16)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"></path><title>Remove link.</title></g><g  event="link:options"><circle r="11" transform="translate(25)"></circle><path fill="white" transform="scale(.55) translate(29, -16)" d="M31.229,17.736c0.064-0.571,0.104-1.148,0.104-1.736s-0.04-1.166-0.104-1.737l-4.377-1.557c-0.218-0.716-0.504-1.401-0.851-2.05l1.993-4.192c-0.725-0.91-1.549-1.734-2.458-2.459l-4.193,1.994c-0.647-0.347-1.334-0.632-2.049-0.849l-1.558-4.378C17.165,0.708,16.588,0.667,16,0.667s-1.166,0.041-1.737,0.105L12.707,5.15c-0.716,0.217-1.401,0.502-2.05,0.849L6.464,4.005C5.554,4.73,4.73,5.554,4.005,6.464l1.994,4.192c-0.347,0.648-0.632,1.334-0.849,2.05l-4.378,1.557C0.708,14.834,0.667,15.412,0.667,16s0.041,1.165,0.105,1.736l4.378,1.558c0.217,0.715,0.502,1.401,0.849,2.049l-1.994,4.193c0.725,0.909,1.549,1.733,2.459,2.458l4.192-1.993c0.648,0.347,1.334,0.633,2.05,0.851l1.557,4.377c0.571,0.064,1.148,0.104,1.737,0.104c0.588,0,1.165-0.04,1.736-0.104l1.558-4.377c0.715-0.218,1.399-0.504,2.049-0.851l4.193,1.993c0.909-0.725,1.733-1.549,2.458-2.458l-1.993-4.193c0.347-0.647,0.633-1.334,0.851-2.049L31.229,17.736zM16,20.871c-2.69,0-4.872-2.182-4.872-4.871c0-2.69,2.182-4.872,4.872-4.872c2.689,0,4.871,2.182,4.871,4.872C20.871,18.689,18.689,20.871,16,20.871z"></path><title>Link options.</title></g></g></g></g><g id="j_31"   ><path  stroke="#707070" id="v-574" stroke-width="2" stroke-dasharray="30 30" fill="none" d="M 1965 1620 1965 1835" style="opacity: 1;"></path><path  fill="black" stroke="black" transform="translate(1965,1620) scale(1,1) rotate(-270)"></path><path  fill="#707070" stroke="#707070" id="v-576" d="M 20 0 L 0 10 L 20 20 z" transform="translate(1955,1855) scale(1,1) rotate(-90)" style="opacity: 1;"></path><path  id="v-575" fill="none" d="M 1965 1620 1965 1835"></path><title ></title><g ><g  id="v-559" label-idx="0" cursor="move" transform="translate(1965, 1727.5)" style="opacity: 1;"><rect id="v-561" fill="#ffffff" rx="3" ry="3" stroke="#ffffff" stroke-width="20px" pointer-events="none" width="164.46875" height="119" transform="matrix(1,0,0,1,-82.2,-59.5)"></rect><text id="v-560" font-size="24px" y="0.8em" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,-52.2)"><tspan id="v-562"  dy="0em" x="0">Creates an</tspan><tspan id="v-563"  dy="1.2em" x="0">instance to</tspan><tspan id="v-564"  dy="1.2em" x="0">maintain an FL</tspan><tspan id="v-565"  dy="1.2em" x="0">experiment</tspan></text></g><g  id="v-566" label-idx="1" cursor="move" transform="translate(1965, 1797.1)" style="opacity: 1;"><rect id="v-568" fill="#ffffff" rx="3" ry="3" pointer-events="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-567" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,0)"><tspan id="v-569"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g><g  id="v-570" label-idx="2" cursor="move" transform="translate(1965, 1821.1)" style="opacity: 1;"><rect id="v-572" fill="#ffffff" rx="3" ry="3" pointer-events="none"  display="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-571" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal"  transform="matrix(1,0,0,1,0,0)"><tspan id="v-573"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g></g><g  display="none"></g><g  id="v-578" display="none"><g  id="v-556"><path  end="source" d="M 26 0 L 0 13 L 26 26 z"></path></g><g  id="v-557"><path  end="target" d="M 26 0 L 0 13 L 26 26 z"></path></g></g><g  id="v-577" display="none"><g  id="v-555" transform="translate(1965, 1660) "><g  event="remove"><circle r="11"></circle><path transform="scale(.8) translate(-16, -16)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"></path><title>Remove link.</title></g><g  event="link:options"><circle r="11" transform="translate(25)"></circle><path fill="white" transform="scale(.55) translate(29, -16)" d="M31.229,17.736c0.064-0.571,0.104-1.148,0.104-1.736s-0.04-1.166-0.104-1.737l-4.377-1.557c-0.218-0.716-0.504-1.401-0.851-2.05l1.993-4.192c-0.725-0.91-1.549-1.734-2.458-2.459l-4.193,1.994c-0.647-0.347-1.334-0.632-2.049-0.849l-1.558-4.378C17.165,0.708,16.588,0.667,16,0.667s-1.166,0.041-1.737,0.105L12.707,5.15c-0.716,0.217-1.401,0.502-2.05,0.849L6.464,4.005C5.554,4.73,4.73,5.554,4.005,6.464l1.994,4.192c-0.347,0.648-0.632,1.334-0.849,2.05l-4.378,1.557C0.708,14.834,0.667,15.412,0.667,16s0.041,1.165,0.105,1.736l4.378,1.558c0.217,0.715,0.502,1.401,0.849,2.049l-1.994,4.193c0.725,0.909,1.549,1.733,2.459,2.458l4.192-1.993c0.648,0.347,1.334,0.633,2.05,0.851l1.557,4.377c0.571,0.064,1.148,0.104,1.737,0.104c0.588,0,1.165-0.04,1.736-0.104l1.558-4.377c0.715-0.218,1.399-0.504,2.049-0.851l4.193,1.993c0.909-0.725,1.733-1.549,2.458-2.458l-1.993-4.193c0.347-0.647,0.633-1.334,0.851-2.049L31.229,17.736zM16,20.871c-2.69,0-4.872-2.182-4.872-4.871c0-2.69,2.182-4.872,4.872-4.872c2.689,0,4.871,2.182,4.871,4.872C20.871,18.689,18.689,20.871,16,20.871z"></path><title>Link options.</title></g></g></g></g><g id="j_32"   ><path  stroke="#707070" id="v-601" stroke-width="2" stroke-dasharray="30 30" fill="none" d="M 1105 1620 1105 1835" style="opacity: 1;"></path><path  fill="black" stroke="black" transform="translate(1105,1620) scale(1,1) rotate(-270)"></path><path  fill="#707070" stroke="#707070" id="v-603" d="M 20 0 L 0 10 L 20 20 z" transform="translate(1095,1855) scale(1,1) rotate(-90)" style="opacity: 1;"></path><path  id="v-602" fill="none" d="M 1105 1620 1105 1835"></path><title ></title><g ><g  id="v-586" label-idx="0" cursor="move" transform="translate(1105, 1727.5)" style="opacity: 1;"><rect id="v-588" fill="#ffffff" rx="3" ry="3" stroke="#ffffff" stroke-width="20px" pointer-events="none" width="164.46875" height="119" transform="matrix(1,0,0,1,-82.2,-59.5)"></rect><text id="v-587" font-size="24px" y="0.8em" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,-52.2)"><tspan id="v-589"  dy="0em" x="0">Creates an</tspan><tspan id="v-590"  dy="1.2em" x="0">instance to</tspan><tspan id="v-591"  dy="1.2em" x="0">maintain an FL</tspan><tspan id="v-592"  dy="1.2em" x="0">experiment</tspan></text></g><g  id="v-593" label-idx="1" cursor="move" transform="translate(1105, 1797.1)" style="opacity: 1;"><rect id="v-595" fill="#ffffff" rx="3" ry="3" pointer-events="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-594" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,0)"><tspan id="v-596"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g><g  id="v-597" label-idx="2" cursor="move" transform="translate(1105, 1821.1)" style="opacity: 1;"><rect id="v-599" fill="#ffffff" rx="3" ry="3" pointer-events="none"  display="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-598" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal"  transform="matrix(1,0,0,1,0,0)"><tspan id="v-600"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g></g><g  display="none"></g><g  id="v-605" display="none"><g  id="v-583"><path  end="source" d="M 26 0 L 0 13 L 26 26 z"></path></g><g  id="v-584"><path  end="target" d="M 26 0 L 0 13 L 26 26 z"></path></g></g><g  id="v-604" display="none"><g  id="v-582" transform="translate(1105, 1660) "><g  event="remove"><circle r="11"></circle><path transform="scale(.8) translate(-16, -16)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"></path><title>Remove link.</title></g><g  event="link:options"><circle r="11" transform="translate(25)"></circle><path fill="white" transform="scale(.55) translate(29, -16)" d="M31.229,17.736c0.064-0.571,0.104-1.148,0.104-1.736s-0.04-1.166-0.104-1.737l-4.377-1.557c-0.218-0.716-0.504-1.401-0.851-2.05l1.993-4.192c-0.725-0.91-1.549-1.734-2.458-2.459l-4.193,1.994c-0.647-0.347-1.334-0.632-2.049-0.849l-1.558-4.378C17.165,0.708,16.588,0.667,16,0.667s-1.166,0.041-1.737,0.105L12.707,5.15c-0.716,0.217-1.401,0.502-2.05,0.849L6.464,4.005C5.554,4.73,4.73,5.554,4.005,6.464l1.994,4.192c-0.347,0.648-0.632,1.334-0.849,2.05l-4.378,1.557C0.708,14.834,0.667,15.412,0.667,16s0.041,1.165,0.105,1.736l4.378,1.558c0.217,0.715,0.502,1.401,0.849,2.049l-1.994,4.193c0.725,0.909,1.549,1.733,2.459,2.458l4.192-1.993c0.648,0.347,1.334,0.633,2.05,0.851l1.557,4.377c0.571,0.064,1.148,0.104,1.737,0.104c0.588,0,1.165-0.04,1.736-0.104l1.558-4.377c0.715-0.218,1.399-0.504,2.049-0.851l4.193,1.993c0.909-0.725,1.733-1.549,2.458-2.458l-1.993-4.193c0.347-0.647,0.633-1.334,0.851-2.049L31.229,17.736zM16,20.871c-2.69,0-4.872-2.182-4.872-4.871c0-2.69,2.182-4.872,4.872-4.872c2.689,0,4.871,2.182,4.871,4.872C20.871,18.689,18.689,20.871,16,20.871z"></path><title>Link options.</title></g></g></g></g><g id="j_33"   ><path  stroke="#707070" id="v-631" stroke-width="2" stroke-dasharray="30 30" fill="none" d="M 1163 1320 1211 1194 S 1215 1185 1211 1176 L 1172 1079" style="opacity: 1;"></path><path  fill="black" stroke="black" transform="translate(1163,1320) scale(1,1) rotate(-68.93405151367188)"></path><path  fill="#707070" stroke="#707070" id="v-633" d="M 20 0 L 0 10 L 20 20 z" transform="translate(1174.284724466815,1056.286115138385) scale(1,1) rotate(68.1985778808594)" style="opacity: 1;"></path><path  id="v-632" fill="none" d="M 1163 1320 1211 1194 S 1215 1185 1211 1176 L 1172 1079"></path><title ></title><g ><g  id="v-614" label-idx="0" cursor="move" transform="translate(1208.896728515625, 1199.5211181640625)" style="opacity: 1;"><rect id="v-616" fill="#ffffff" rx="3" ry="3" stroke="#ffffff" stroke-width="20px" pointer-events="none" width="180.0625" height="176.59375" transform="matrix(1,0,0,1,-90,-88.3)"></rect><text id="v-615" font-size="24px" y="0.8em" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,-81)"><tspan id="v-617"  dy="0em" x="0">Sends</tspan><tspan id="v-618"  dy="1.2em" x="0">information</tspan><tspan id="v-619"  dy="1.2em" x="0">about the</tspan><tspan id="v-620"  dy="1.2em" x="0">Federation.</tspan><tspan id="v-621"  dy="1.2em" x="0">Returns training</tspan><tspan id="v-622"  dy="1.2em" x="0">artifacts.</tspan></text></g><g  id="v-623" label-idx="1" cursor="move" transform="translate(1208.896728515625, 1293.1211181640624)" style="opacity: 1;"><rect id="v-625" fill="#ffffff" rx="3" ry="3" pointer-events="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-624" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,0)"><tspan id="v-626"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g><g  id="v-627" label-idx="2" cursor="move" transform="translate(1208.896728515625, 1317.1211181640624)" style="opacity: 1;"><rect id="v-629" fill="#ffffff" rx="3" ry="3" pointer-events="none"  display="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-628" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal"  transform="matrix(1,0,0,1,0,0)"><tspan id="v-630"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g></g><g  display="none"><g  transform="translate(1215, 1185)" id="v-610"><circle  idx="0" r="10"></circle><path  idx="0" d="M16,5.333c-7.732,0-14,4.701-14,10.5c0,1.982,0.741,3.833,2.016,5.414L2,25.667l5.613-1.441c2.339,1.317,5.237,2.107,8.387,2.107c7.732,0,14-4.701,14-10.5C30,10.034,23.732,5.333,16,5.333z" transform="translate(5, -33)"></path><path  idx="0" transform="scale(.8) translate(9.5, -37)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"><title>Remove vertex.</title></path></g></g><g  id="v-635" display="none"><g  id="v-611"><path  end="source" d="M 26 0 L 0 13 L 26 26 z"></path></g><g  id="v-612"><path  end="target" d="M 26 0 L 0 13 L 26 26 z"></path></g></g><g  id="v-634" display="none"><g  id="v-609" transform="translate(1177.2398681640625, 1282.6204833984375) "><g  event="remove"><circle r="11"></circle><path transform="scale(.8) translate(-16, -16)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"></path><title>Remove link.</title></g><g  event="link:options"><circle r="11" transform="translate(25)"></circle><path fill="white" transform="scale(.55) translate(29, -16)" d="M31.229,17.736c0.064-0.571,0.104-1.148,0.104-1.736s-0.04-1.166-0.104-1.737l-4.377-1.557c-0.218-0.716-0.504-1.401-0.851-2.05l1.993-4.192c-0.725-0.91-1.549-1.734-2.458-2.459l-4.193,1.994c-0.647-0.347-1.334-0.632-2.049-0.849l-1.558-4.378C17.165,0.708,16.588,0.667,16,0.667s-1.166,0.041-1.737,0.105L12.707,5.15c-0.716,0.217-1.401,0.502-2.05,0.849L6.464,4.005C5.554,4.73,4.73,5.554,4.005,6.464l1.994,4.192c-0.347,0.648-0.632,1.334-0.849,2.05l-4.378,1.557C0.708,14.834,0.667,15.412,0.667,16s0.041,1.165,0.105,1.736l4.378,1.558c0.217,0.715,0.502,1.401,0.849,2.049l-1.994,4.193c0.725,0.909,1.549,1.733,2.459,2.458l4.192-1.993c0.648,0.347,1.334,0.633,2.05,0.851l1.557,4.377c0.571,0.064,1.148,0.104,1.737,0.104c0.588,0,1.165-0.04,1.736-0.104l1.558-4.377c0.715-0.218,1.399-0.504,2.049-0.851l4.193,1.993c0.909-0.725,1.733-1.549,2.458-2.458l-1.993-4.193c0.347-0.647,0.633-1.334,0.851-2.049L31.229,17.736zM16,20.871c-2.69,0-4.872-2.182-4.872-4.871c0-2.69,2.182-4.872,4.872-4.872c2.689,0,4.871,2.182,4.871,4.872C20.871,18.689,18.689,20.871,16,20.871z"></path><title>Link options.</title></g></g></g></g><g id="j_34"   ><path  stroke="#707070" id="v-657" stroke-width="2" stroke-dasharray="30 30" fill="none" d="M 1043 1060 999 1166 S 995 1175 998 1184 L 1042 1301" style="opacity: 1;"></path><path  fill="black" stroke="black" transform="translate(1043,1060) scale(1,1) rotate(-247.34477233886722)"></path><path  fill="#707070" stroke="#707070" id="v-659" d="M 20 0 L 0 10 L 20 20 z" transform="translate(1039.628751669837,1323.4899973110653) scale(1,1) rotate(-110.426025390625)" style="opacity: 1;"></path><path  id="v-658" fill="none" d="M 1043 1060 999 1166 S 995 1175 998 1184 L 1042 1301"></path><title ></title><g ><g  id="v-644" label-idx="0" cursor="move" transform="translate(997.0918579101562, 1180.0296630859375)" style="opacity: 1;"><rect id="v-646" fill="#ffffff" rx="3" ry="3" stroke="#ffffff" stroke-width="20px" pointer-events="none" width="140.5" height="61.40625" transform="matrix(1,0,0,1,-70.2,-30.7)"></rect><text id="v-645" font-size="24px" y="0.8em" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,-23.4)"><tspan id="v-647"  dy="0em" x="0">Registers FL</tspan><tspan id="v-648"  dy="1.2em" x="0">experiments</tspan></text></g><g  id="v-649" label-idx="1" cursor="move" transform="translate(997.0918579101562, 1223.2296630859375)" style="opacity: 1;"><rect id="v-651" fill="#ffffff" rx="3" ry="3" pointer-events="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-650" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,0)"><tspan id="v-652"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g><g  id="v-653" label-idx="2" cursor="move" transform="translate(997.0918579101562, 1247.2296630859375)" style="opacity: 1;"><rect id="v-655" fill="#ffffff" rx="3" ry="3" pointer-events="none"  display="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-654" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal"  transform="matrix(1,0,0,1,0,0)"><tspan id="v-656"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g></g><g  display="none"><g  transform="translate(995, 1175)" id="v-640"><circle  idx="0" r="10"></circle><path  idx="0" d="M16,5.333c-7.732,0-14,4.701-14,10.5c0,1.982,0.741,3.833,2.016,5.414L2,25.667l5.613-1.441c2.339,1.317,5.237,2.107,8.387,2.107c7.732,0,14-4.701,14-10.5C30,10.034,23.732,5.333,16,5.333z" transform="translate(5, -33)"></path><path  idx="0" transform="scale(.8) translate(9.5, -37)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"><title>Remove vertex.</title></path></g></g><g  id="v-661" display="none"><g  id="v-641"><path  end="source" d="M 26 0 L 0 13 L 26 26 z"></path></g><g  id="v-642"><path  end="target" d="M 26 0 L 0 13 L 26 26 z"></path></g></g><g  id="v-660" display="none"><g  id="v-639" transform="translate(1027.6649169921875, 1096.943603515625) "><g  event="remove"><circle r="11"></circle><path transform="scale(.8) translate(-16, -16)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"></path><title>Remove link.</title></g><g  event="link:options"><circle r="11" transform="translate(25)"></circle><path fill="white" transform="scale(.55) translate(29, -16)" d="M31.229,17.736c0.064-0.571,0.104-1.148,0.104-1.736s-0.04-1.166-0.104-1.737l-4.377-1.557c-0.218-0.716-0.504-1.401-0.851-2.05l1.993-4.192c-0.725-0.91-1.549-1.734-2.458-2.459l-4.193,1.994c-0.647-0.347-1.334-0.632-2.049-0.849l-1.558-4.378C17.165,0.708,16.588,0.667,16,0.667s-1.166,0.041-1.737,0.105L12.707,5.15c-0.716,0.217-1.401,0.502-2.05,0.849L6.464,4.005C5.554,4.73,4.73,5.554,4.005,6.464l1.994,4.192c-0.347,0.648-0.632,1.334-0.849,2.05l-4.378,1.557C0.708,14.834,0.667,15.412,0.667,16s0.041,1.165,0.105,1.736l4.378,1.558c0.217,0.715,0.502,1.401,0.849,2.049l-1.994,4.193c0.725,0.909,1.549,1.733,2.459,2.458l4.192-1.993c0.648,0.347,1.334,0.633,2.05,0.851l1.557,4.377c0.571,0.064,1.148,0.104,1.737,0.104c0.588,0,1.165-0.04,1.736-0.104l1.558-4.377c0.715-0.218,1.399-0.504,2.049-0.851l4.193,1.993c0.909-0.725,1.733-1.549,2.458-2.458l-1.993-4.193c0.347-0.647,0.633-1.334,0.851-2.049L31.229,17.736zM16,20.871c-2.69,0-4.872-2.182-4.872-4.871c0-2.69,2.182-4.872,4.872-4.872c2.689,0,4.871,2.182,4.871,4.872C20.871,18.689,18.689,20.871,16,20.871z"></path><title>Link options.</title></g></g></g></g></g><defs id="v-4"></defs></svg>
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/docs/source/utilities/pki.rst ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/source/utilities/pki.rst
*** ./openfl/docs/source/utilities/pki.rst	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/source/utilities/pki.rst	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,108 ****
- .. # Copyright (C) 2020-2021 Intel Corporation
- .. # SPDX-License-Identifier: Apache-2.0
- 
- *******************************************************
- |productName| Public Key Infrastructure (PKI) Solutions
- *******************************************************
- 
- .. _pki_overview:
- 
- Overview
- ========
- 
- Transport Layer Security (`TLS <https://en.wikipedia.org/wiki/Transport_Layer_Security>`_) encryption is used for network connections in federated learning. Therefore, security keys and certificates will need to be created for the aggregator and collaborators to negotiate the connection securely. 
- 
- If you have trusted workspaces and connections, you can start your experiment with the :code:`disable_tls` option.
- 
- 
- Otherwise, you can certify nodes with your own PKI solution or use the PKI solution workflows provided by |productName|. 
- 
-     - :ref:`semi_automatic_certification`
-     - :ref:`manual_certification`
- 
- .. note::
- 
-     The |productName| PKI solution is based on `step-ca <https://github.com/smallstep/certificates>`_ as a server and `step <https://github.com/smallstep/cli>`_ as a client utilities. They are downloaded during the workspace setup.
- 
- .. note::
- 
-    Different certificates can be created for each project workspace.
- 
- .. _install_certs:
- 
- .. kroki:: ../../mermaid/CSR_signing.mmd
-     :caption: Manual certificate generation and signing
-     :align: center
-     :type: mermaid
- 
- .. kroki:: ../../mermaid/pki_scheme.mmd
-     :caption: Step-ca certificate generation and signing
-     :align: center
-     :type: mermaid
- 
- .. _semi_automatic_certification:
- 
- Semi-Automatic PKI Workflow
- ===========================
- 
- The |productName| PKI pipeline involves creating a local certificate authority (CA) on a \HTTPS \ server that listens for signing requests. Certificates from each client are signed by the CA via a token. The token must be copied to clients in a secure manner. 
- 
- 1. Create the CA.
- 
-       .. code-block:: console
- 
-          fx pki install -p </path/to/ca/dir> --ca-url <host:port>
- 
-       | where
-       | :code:`-p` defines the path to the directory that contains CA files, and
-       | :code:`--ca-url` defines the host and port that the CA server will listen, if not specified, :code:`--ca-url` will be "localhost:9123"
- 
-       When executing this command, you will be prompted for a password and password confirmation. The password will encrypt some CA files.
-       This command will also download `step-ca <https://github.com/smallstep/certificates>`_ and `step <https://github.com/smallstep/cli>`_ binaries.
- 
- 2. Run the CA server.
- 
-       .. code-block:: console
- 
-          fx pki run -p </path/to/ca/dir>
- 
-       | where
-       | :code:`-p` defines the path to the directory that contains CA files.
- 
- 3. Create a token for client.
- 
-       .. code-block:: console
- 
-          fx pki get-token -n <subject> --ca-path </path/to/ca/dir> --ca-url <host:port>
- 
-       | where
-       | :code:`-n` defines the subject name, FQDN for director, collaborator name for envoy, or API name for the API-layer node.
-       | :code:`--ca-path` defines the path to the directory that contains CA files.
-       | :code:`--ca-url` defines the host and port that the CA server will listen, if not specified, :code:`--ca-url` will be "localhost:9123"
- 
-       Run this command from the CA directory on the CA server. The output is a token which contains a JWT (JSON web token) from the CA server and the CA root certificate concatenated together. This JWT is valid for 24 hours.
- 
- 4. Copy the token to the clients (director or envoy) via a secure channel, and certify the token.
- 
-       .. code-block:: console
- 
-          cd <path/to/subject/folder>
-          fx pki certify -n <subject> -t <generated token for subject>
- 
-       | where
-       | :code:`-n` defines the subject name, FQDN for director, collaborator name for envoy, or API name for the API-layer node.
-       | :code:`-t` defines the output token from the previous command.
- 
-       With this command, the client connects to the CA server over \HTTPS\, which is provided by the root certificate which was copied together with the JWT. The CA server authenticates the client via the JWT, and the client authenticates the server via the root certificate.
- 
- The signed certificate and private key are stored on each node in the federation. The signed certificate is valid for one year. You should certify all nodes that will participate in the federation director, which includes all envoys and API-layer nodes.
-    
- 
- 
- .. _manual_certification:
- 
- 
- Manual PKI Workflow 
- ===================
- 
- This solution is embedded into the aggregator-based workflow. See :ref:`Configure the Federation <configure_the_federation>` for details.
--- 0 ----
diff -crB --new-file ./openfl/docs/source/utilities/splitters_data.rst ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/source/utilities/splitters_data.rst
*** ./openfl/docs/source/utilities/splitters_data.rst	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/source/utilities/splitters_data.rst	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,54 ****
- .. # Copyright (C) 2020-2021 Intel Corporation
- .. # SPDX-License-Identifier: Apache-2.0
- 
- .. _data_splitting:
- 
- *****************
- Dataset Splitters
- *****************
- 
- 
- |productName| allows you to specify custom data splits **for simulation runs on a single dataset**.
- 
- You may apply data splitters differently depending on the |productName| workflow that you follow. 
- 
- 
- OPTION 1: Use **Native Python API** (Aggregator-Based Workflow) Functions to Split the Data
- ===========================================================================================
- 
- Predefined |productName| data splitters functions are as follows:
- 
- - ``openfl.utilities.data_splitters.EqualNumPyDataSplitter`` (default)
- - ``openfl.utilities.data_splitters.RandomNumPyDataSplitter``
- - ``openfl.component.aggregation_functions.LogNormalNumPyDataSplitter``, which assumes the ``data`` argument as ``np.ndarray`` of integers (labels)
- - ``openfl.component.aggregation_functions.DirichletNumPyDataSplitter``, which assumes the ``data`` argument as ``np.ndarray`` of integers (labels)
- 
- Alternatively, you can create an `implementation <https://github.com/intel/openfl/blob/develop/openfl/utilities/data_splitters/numpy.py>`_ of :class:`openfl.plugins.data_splitters.NumPyDataSplitter` and pass it to the :code:`FederatedDataset` function as either ``train_splitter`` or ``valid_splitter`` keyword argument.
- 
- 
- OPTION 2: Use Dataset Splitters in your Shard Descriptor
- ========================================================
- 
- Apply one of previously mentioned splitting function on your data to perform a simulation. 
- 
- ``NumPyDataSplitter`` requires a single ``split`` function. The :code:`split` function returns a list of indices which represents the collaborator-wise indices groups.
- 
- This function receives ``data`` - NumPy array required to build the subsets of data indices. It could be the whole dataset, or labels only, or anything else.
- 
- 
- .. code-block:: python
- 
-     X_train, y_train = ... # train set
-     X_valid, y_valid = ... # valid set
-     train_splitter = RandomNumPyDataSplitter()
-     valid_splitter = RandomNumPyDataSplitter()
-     # collaborator_count value is passed to DataLoader constructor
-     # shard_num can be evaluated from data_path
-     train_idx = train_splitter.split(y_train, collaborator_count)[shard_num]
-     valid_idx = valid_splitter.split(y_valid, collaborator_count)[shard_num]
-     X_train_shard = X_train[train_idx]
-     X_valid_shard = X_valid[valid_idx]
- 
- .. note::
-     By default, the data is shuffled and split equally. See an `example <https://github.com/intel/openfl/blob/develop/openfl/utilities/data_splitters/numpy.py>`_ of :class:`openfl.utilities.data_splitters.EqualNumPyDataSplitter` for details.
-     
--- 0 ----
diff -crB --new-file ./openfl/docs/source/utilities/utilities.rst ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/source/utilities/utilities.rst
*** ./openfl/docs/source/utilities/utilities.rst	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/source/utilities/utilities.rst	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,21 ****
- .. # Copyright (C) 2020-2021 Intel Corporation
- .. # SPDX-License-Identifier: Apache-2.0
- 
- *************************************************
- Open Federated Learning (|productName|) Utilities
- *************************************************
- 
- The following are utilities available in Open Federated Learning (|productName|).
- 
- :doc:`pki`
-     Use the Public Key Infrastructure (PKI) solution workflows to certify the nodes in your federation.
-     
- :doc:`splitters_data`
-     Split your data to run your federation from a single dataset.
- 
- .. toctree::
-    :maxdepth: 1
-    :hidden:
- 
-    pki
-    splitters_data
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/docs/source/workflow/running_the_federation.notebook.rst ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/source/workflow/running_the_federation.notebook.rst
*** ./openfl/docs/source/workflow/running_the_federation.notebook.rst	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/source/workflow/running_the_federation.notebook.rst	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,219 ****
- .. # Copyright (C) 2020-2021 Intel Corporation
- .. # SPDX-License-Identifier: Apache-2.0
- 
- .. _running_notebook:
- 
- **********************************
- Aggregator-Based Workflow Tutorial
- **********************************
- 
- You will start a Jupyter\* \  lab server and receive a URL you can use to access the tutorials. Jupyter notebooks are provided for PyTorch\* \  and TensorFlow\* \  that simulate a federation on a local machine.
- 
- .. note::
- 
- 	Follow the procedure to become familiar with the APIs used in aggregator-based workflow and conventions such as *FL Plans*, *Aggregators*, and *Collaborators*. 
- 	
- 
- Start the Tutorials
- ===================
- 
- 1. Start a Python\* \  3.8 (>=3.6, <3.9) virtual environment and confirm |productName| is available.
- 
-     .. code-block:: python
- 
- 		fx
-     
-     You should see a list of available commands
- 
- 2. Start a Jupyter server. This returns a URL to access available tutorials.
- 
- 	.. code-block:: python
- 
- 		fx tutorial start
- 
- 3. Open the URL (including the token) in your browser.
- 
- 4. Choose a tutorial from which to start. Each tutorial is a demonstration of a simulated federated learning. The following are examples of available tutorials:
- 
-  - :code:`Federated Keras MNIST Tutorial`: workspace with a simple `Keras <http://keras.io/>`_ CNN model that will download the `MNIST <http://yann.lecun.com/exdb/mnist/>`_ dataset and train in a federation.
-  - :code:`Federated Pytorch MNIST Tutorial`: workspace with a simple `PyTorch <https://pytorch.org/>`_ CNN model that will download the `MNIST <http://yann.lecun.com/exdb/mnist/>`_ dataset and train in a federation.
-  - :code:`Federated PyTorch UNET Tutorial`: workspace with a UNET `PyTorch <https://pytorch.org/>`_ model that will download the `Hyper-Kvasir <https://datasets.simula.no/hyper-kvasir/>`_ dataset and train in a federation.
-  - :code:`Federated PyTorch TinyImageNet`: workspace with a MobileNet-V2 `PyTorch <https://pytorch.org/>`_ model that will download the `Tiny-ImageNet <https://www.kaggle.com/c/tiny-imagenet/>`_ dataset and train in a federation.
- 
- 
- Familiarize with the API Concepts in an Aggregator-Based Worklow
- ================================================================
- 
- Step 1: Enable the |productName| Python API
- -------------------------------------------
- 
- Add the following lines to your Python script.
- 
-     .. code-block:: python
- 
-      import openfl.native as fx
-      from openfl.federated import FederatedModel, FederatedDataSet
- 
- This loads the |productName| package and import wrappers that adapt your existing data and models to a (simulated) federated context.
- 
- Step 2: Set Up the Experiment
- -----------------------------
- 
- For a basic experiment, run the following command.
- 
-     .. code-block:: python
- 
-      fx.init()
- 	 
- 	 
- This creates a workspace directory containing default FL plan values for your experiments, and sets up a an experiment with two collaborators (the collaborators are creatively named **one** and **two**).
- 
- For an experiment with more collaborators, run the following command.
- 
-     .. code-block:: python
- 
-      collaborator_list = [str(i) for i in range(NUM_COLLABORATORS)]
-      fx.init('keras_cnn_mnist', col_names=collaborator_list)
- 
- 
- .. note::
- 
- 	The following are template recommendations for training models:
- 	
- 	- For Keras models, run :code:`fx.init('keras_cnn_mnist')` to start with the *keras_cnn_mnist* template.
- 	- For PyTorch models, run :code:`fx.init('torch_cnn_mnist')` to start with the *torch_cnn_mnist* template.
- 	
- 
- Step 3: Customize the Federated Learning Plan (FL Plan)
- -------------------------------------------------------
- 
- For this example, the experiment is set up with the *keras_cnn_mnist* template.	
- 
-    .. code-block:: python
- 
- 		fx.init('keras_cnn_mnist')
- 	 
- 
- See the FL plan values that can be set with the :code:`fx.get_plan()` command.
- 
-     .. code-block:: python
- 
-      print(fx.get_plan())
- 
-      {
-        "aggregator.settings.best_state_path": "save/keras_cnn_mnist_best.pbuf",
-        "aggregator.settings.init_state_path": "save/keras_cnn_mnist_init.pbuf",
-        "aggregator.settings.last_state_path": "save/keras_cnn_mnist_last.pbuf",
-        "aggregator.settings.rounds_to_train": 10,
-        "aggregator.template": "openfl.component.Aggregator",
-        ...
-      }
- 
- Based on this plan values, the experiment will run for 10 rounds. You can customize the experiment to run for 20 rounds either at runtime or ahead of time.
- 
- Set the value at **runtime** with the :code:`override-config` parameter of :code:`fx.run_experiment`.
- 
-     .. code-block:: python
- 
-      #set values at experiment runtime
-      fx.run_experiment(experiment_collaborators, override_config={"aggregator.settings.rounds_to_train": 20})
- 
- 
- Set the value **ahead of time** with :code:`fx.update_plan()`.
- 
-     .. code-block:: python
- 
-      #Set values ahead of time with fx.update_plan() 
-      fx.update_plan({"aggregator.settings.rounds_to_train": 20})
- 
- 
- Step 4: Wrap the Data and Model
- -------------------------------
- 
- Use the :code:`FederatedDataSet` function to wrap in-memory numpy datasets and split the data into N mutually-exclusive chunks for each collaborator participating in the experiment.
- 
-     .. code-block:: python
- 
-      fl_data = FederatedDataSet(train_images, train_labels, valid_images, valid_labels, batch_size=32, num_classes=classes)
- 
- Similarly, the :code:`FederatedModel` function takes as an argument your model definition. For the first example, you can wrap a Keras model in a function that outputs the compiled model.
- 
- **Example 1:**
- 
-     .. code-block:: python
- 
-      def build_model(feature_shape,classes):
-          #Defines the MNIST model
-          model = Sequential()
-          model.add(Dense(64, input_shape=feature_shape, activation='relu'))
-          model.add(Dense(64, activation='relu'))
-          model.add(Dense(classes, activation='softmax'))
-          
-          model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])
-          return model 
- 
-      fl_model = FederatedModel(build_model, data_loader=fl_data)
- 
- For the second example with a PyTorch model, the :code:`FederatedModel` function takes the following parameters: 
- 
- - The class that defines the network definition and associated forward function
- - The lambda optimizer method that can be set to a newly instantiated network
- - The loss function
- 
- **Example 2:**
- 
-     .. code-block:: python
- 
-      class Net(nn.Module):
-          def __init__(self):
-              super(Net, self).__init__()
-              self.conv1 = nn.Conv2d(1, 16, 3)
-              self.pool = nn.MaxPool2d(2, 2)
-              self.conv2 = nn.Conv2d(16, 32, 3)
-              self.fc1 = nn.Linear(32 * 5 * 5, 32)
-              self.fc2 = nn.Linear(32, 84)
-              self.fc3 = nn.Linear(84, 10)
- 
-          def forward(self, x):
-              x = self.pool(F.relu(self.conv1(x)))
-              x = self.pool(F.relu(self.conv2(x)))
-              x = x.view(x.size(0),-1)
-              x = F.relu(self.fc1(x))
-              x = F.relu(self.fc2(x))
-              x = self.fc3(x)
-              return F.log_softmax(x, dim=1)
-     
-      optimizer = lambda x: optim.Adam(x, lr=1e-4)
-      
-      def cross_entropy(output, target):
-          """Binary cross-entropy metric
-          """
-          return F.binary_cross_entropy_with_logits(input=output,target=target)
- 
-      fl_model = FederatedModel(build_model=Net, optimizer=optimizer, loss_fn=cross_entropy, data_loader=fl_data)
- 
- 
- Step 5: Define the Collaborators
- --------------------------------
- 
- Define the collaborators taking part in the experiment. The example below uses the collaborator list, created earlier with the the :code:`fx.init()` command.
- 
-     .. code-block:: python
- 
-      experiment_collaborators = {col_name:col_model for col_name, col_model \
-                                       in zip(collaborator_list, fl_model.setup(len(collaborator_list)))}
- 
- This command creates a model for each collaborator with their data shard.
- 
- .. note::
- 
- 	In production deployments of |productName|, each collaborator will have the data on premise. Splitting data into shards is not necessary.
- 
- Step 6: Run the Experiment
- --------------------------
- 
- Run the experiment for five rounds and return the final model once completed.
- 
-     .. code-block:: python
- 
-      final_fl_model = fx.run_experiment(experiment_collaborators, override_config={"aggregator.settings.rounds_to_train": 5})
--- 0 ----
diff -crB --new-file ./openfl/docs/source/workflow/running_the_federation.singularity.rst ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/source/workflow/running_the_federation.singularity.rst
*** ./openfl/docs/source/workflow/running_the_federation.singularity.rst	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/source/workflow/running_the_federation.singularity.rst	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,10 ****
- .. # Copyright (C) 2020-2021 Intel Corporation
- .. # SPDX-License-Identifier: Apache-2.0
- 
- .. _running_the_federation_singularity:
- 
- Running on Singularity
- ######################
- 
- TODO
- 
--- 0 ----
diff -crB --new-file ./openfl/docs/source/workflow/running_the_federation.tutorial.rst ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/source/workflow/running_the_federation.tutorial.rst
*** ./openfl/docs/source/workflow/running_the_federation.tutorial.rst	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/source/workflow/running_the_federation.tutorial.rst	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,21 ****
- .. # Copyright (C) 2020-2021 Intel Corporation
- .. # SPDX-License-Identifier: Apache-2.0
- 
- .. _running_tutorial:
- 
- *************************************************
- Open Federated Learning (|productName|) Tutorials
- *************************************************
- 
- These tutorials use the Jupyter\* \  Lab server to help you become familiar with the APIs used in Open Federated Learning (|productName|).
- 
- :ref:`running_notebook`
-     Use this tutorial to familiarize with the APIs of the short-lived components (*Aggregator* and *Collaborator*).
-     
- 
- .. toctree::
-    :maxdepth: 2
-    :hidden:
- 
-    running_the_federation.notebook
-       
--- 0 ----
diff -crB --new-file ./openfl/docs/structurizer_dsl/README.md ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/structurizer_dsl/README.md
*** ./openfl/docs/structurizer_dsl/README.md	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/structurizer_dsl/README.md	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,14 ****
- 0. Structurizr DSL (diagram syntax) reference: <br>
- https://github.com/structurizr/dsl/blob/master/docs/language-reference.md# <br>
- 
- 1. Working with Structurizr CLI: <br>
- Article: 
- https://dev.to/simonbrown/getting-started-with-the-structurizr-cli-10c2 <br>
- Git:
- https://github.com/structurizr/cli/blob/master/docs/export.md <br>
- 
- 2. Using Structurizer CLI with Docker: <br>
- https://github.com/aidmax/structurizr-cli-docker <br>
- 
- 3. Rendering C4 models with Structurizr locally: <br>
- https://dev.to/simonbrown/getting-started-with-structurizr-lite-27d0 <br>
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/docs/structurizer_dsl/structurizr-1-Containers.svg ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/structurizer_dsl/structurizr-1-Containers.svg
*** ./openfl/docs/structurizer_dsl/structurizr-1-Containers.svg	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/structurizer_dsl/structurizr-1-Containers.svg	1969-12-31 16:00:00.000000000 -0800
***************
*** 1 ****
- <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" viewBox="0 0 3104 2546" style="background: #ffffff"><g id="v-3"  transform="matrix(1,0,0,1,0,0)"><g id="j_36"    transform="translate(20,2501)"><g id="v-667"><text  id="v-668" font-size="22px" y="0.8em" xml:space="preserve" font-weight="normal" text-anchor="start" fill="#aaaaaa" pointer-events="none" font-family="Open Sans" transform="matrix(1,0,0,1,0,0)"><tspan id="v-669"  dy="0em" x="0">Friday, 27 August 2021, 16:25 Moscow Standard Time</tspan></text></g></g><g id="j_35"    transform="translate(20,2455)"><g id="v-663"><text  id="v-664" font-size="36px" y="0.8em" xml:space="preserve" font-weight="normal" text-anchor="start" fill="#000000" pointer-events="none" font-family="Open Sans" transform="matrix(1,0,0,1,0,0)"><tspan id="v-665"  dy="0em" x="0">Container diagram for OpenFL</tspan></text></g></g><g id="j_13"    transform="translate(840,740)" style=""><g id="v-214"><rect  id="v-215" width="1390" height="1582" rx="0" ry="0" fill="#ffffff" stroke="#444444" stroke-width="2" stroke-dasharray="20,20" pointer-events="none"></rect><text  id="v-216" font-size="24px" y="1543" xml:space="preserve" font-weight="normal" fill="#444444" x="10" text-anchor="start" pointer-events="visible" font-family="Open Sans" transform="matrix(1,0,0,1,15,0)"><tspan id="v-218"  dy="0em" x="0">OpenFL</tspan></text><text  id="v-217" font-size="19px" y="1567" xml:space="preserve" font-weight="normal" fill="#444444" x="10" text-anchor="start" pointer-events="visible" font-family="Open Sans" transform="matrix(1,0,0,1,15,0)"><tspan id="v-219"  dy="0em" x="0">[Software System]</tspan></text></g></g><g id="j_22"    transform="translate(860,1300)" style=""><g id="v-342"><rect  id="v-343" width="490" height="929" rx="0" ry="0" fill="#ffffff" stroke="#cccccc" stroke-width="2" stroke-dasharray="5,5" pointer-events="none"></rect><text  id="v-344" font-size="24px" y="914" xml:space="preserve" font-weight="normal" fill="#cccccc" x="10" text-anchor="start" pointer-events="visible" font-family="Open Sans" transform="matrix(1,0,0,1,15,0)"><tspan id="v-346"  dy="0em" x="0">Central node</tspan></text><text  id="v-345" font-size="19px" y="914" display="none" xml:space="preserve" font-weight="normal" fill="#cccccc" x="10" text-anchor="start" pointer-events="visible" font-family="Open Sans" transform="matrix(1,0,0,1,15,0)"><tspan id="v-347"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g></g><g id="j_16"    transform="translate(1720,1300)" style=""><g id="v-253"><rect  id="v-254" width="490" height="929" rx="0" ry="0" fill="#ffffff" stroke="#cccccc" stroke-width="2" stroke-dasharray="5,5" pointer-events="none"></rect><text  id="v-255" font-size="24px" y="914" xml:space="preserve" font-weight="normal" fill="#cccccc" x="10" text-anchor="start" pointer-events="visible" font-family="Open Sans" transform="matrix(1,0,0,1,15,0)"><tspan id="v-257"  dy="0em" x="0">Collaborator node</tspan></text><text  id="v-256" font-size="19px" y="914" display="none" xml:space="preserve" font-weight="normal" fill="#cccccc" x="10" text-anchor="start" pointer-events="visible" font-family="Open Sans" transform="matrix(1,0,0,1,15,0)"><tspan id="v-258"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g></g><g id="j_14"    transform="translate(890,200)" style=""><g  id="v-223" style="opacity: 1;"><rect  x="0" y="160" width="400" height="240" rx="70" id="v-225" stroke="#073b6f" stroke-width="2" pointer-events="visiblePainted" fill="#08427b"></rect><circle  cx="200" cy="88.88888888888889" r="88.88888888888889" id="v-224" stroke="#073b6f" stroke-width="2" pointer-events="visiblePainted" fill="#08427b"></circle><line  x1="80" y1="266.6666666666667" x2="80" y2="400" style="stroke-width:2px" id="v-231" stroke="#073b6f"></line><line  x1="320" y1="266.6666666666667" x2="320" y2="400" style="stroke-width:2px" id="v-232" stroke="#073b6f"></line><text  id="v-226" font-size="34px" y="0.8em" xml:space="preserve" font-weight="bold" text-anchor="middle" pointer-events="visible" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,200,205)"><tspan id="v-233"  dy="0em" x="0">Data scientist</tspan></text><text  id="v-227" font-size="19px" y="0.8em" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,200,247.5)"><tspan id="v-234"  dy="0em" x="0">[Person]</tspan></text><text  id="v-228" font-size="24px" y="0.8em" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,200,295)"><tspan id="v-235"  dy="0em" x="0">A person or group of people</tspan><tspan id="v-236"  dy="1.2em" x="0">using OpenFL</tspan></text><text  id="v-229" font-weight="bold" text-anchor="middle" font-family="Open Sans" fill="#ffffff" font-size="24" transform="matrix(1,0,0,1,200,371.2)" display="none"></text><image  id="v-230"></image></g></g><g id="j_15"    transform="translate(1740,1320)" style="" ><g  id="v-240" style="opacity: 1;"><rect  id="v-241" rx="20" ry="20" stroke="#3c7fc0" stroke-width="2" pointer-events="visiblePainted" fill="#438dd5" width="450" height="300"></rect><text  id="v-242" font-size="34" y="0.8em" xml:space="preserve" font-weight="bold" text-anchor="middle" pointer-events="visible" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,225,60)"><tspan id="v-247"  dy="0em" x="0">Envoy</tspan></text><text  id="v-243" font-size="19" y="0.8em" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,225,102.5)"><tspan id="v-248"  dy="0em" x="0">[Container]</tspan></text><text  id="v-244" font-size="24" y="0.8em" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,225,150)"><tspan id="v-249"  dy="0em" x="0">A long-living entity that can adapt a</tspan><tspan id="v-250"  dy="1.2em" x="0">local data set and spawn</tspan><tspan id="v-251"  dy="1.2em" x="0">collaborators</tspan></text><text  id="v-245" font-weight="bold" text-anchor="middle" font-family="Open Sans" fill="#ffffff" font-size="24" transform="matrix(1,0,0,1,225,270)" y="0.8em" xml:space="preserve" display="none"><tspan id="v-259"  dy="0em" x="0">+</tspan></text><image  id="v-246"></image></g></g><g id="j_17"    transform="translate(2470,1265)" style=""><g  id="v-265" style="opacity: 1;"><rect  x="0" y="160" width="400" height="240" rx="70" id="v-267" stroke="#073b6f" stroke-width="2" pointer-events="visiblePainted" fill="#08427b"></rect><circle  cx="200" cy="88.88888888888889" r="88.88888888888889" id="v-266" stroke="#073b6f" stroke-width="2" pointer-events="visiblePainted" fill="#08427b"></circle><line  x1="80" y1="266.6666666666667" x2="80" y2="400" style="stroke-width:2px" id="v-273" stroke="#073b6f"></line><line  x1="320" y1="266.6666666666667" x2="320" y2="400" style="stroke-width:2px" id="v-274" stroke="#073b6f"></line><text  id="v-268" font-size="34px" y="0.8em" xml:space="preserve" font-weight="bold" text-anchor="middle" pointer-events="visible" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,200,205)"><tspan id="v-275"  dy="0em" x="0">Collaborator manager</tspan></text><text  id="v-269" font-size="19px" y="0.8em" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,200,247.5)"><tspan id="v-276"  dy="0em" x="0">[Person]</tspan></text><text  id="v-270" font-size="24px" y="0.8em" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,200,295)"><tspan id="v-277"  dy="0em" x="0">Data owner's representative</tspan><tspan id="v-278"  dy="1.2em" x="0">controlling Envoy</tspan></text><text  id="v-271" font-weight="bold" text-anchor="middle" font-family="Open Sans" fill="#ffffff" font-size="24" transform="matrix(1,0,0,1,200,371.2)" display="none"></text><image  id="v-272"></image></g></g><g id="j_18"    transform="translate(230,1270)" style=""><g  id="v-282" style="opacity: 1;"><rect  x="0" y="160" width="400" height="240" rx="70" id="v-284" stroke="#073b6f" stroke-width="2" pointer-events="visiblePainted" fill="#08427b"></rect><circle  cx="200" cy="88.88888888888889" r="88.88888888888889" id="v-283" stroke="#073b6f" stroke-width="2" pointer-events="visiblePainted" fill="#08427b"></circle><line  x1="80" y1="266.6666666666667" x2="80" y2="400" style="stroke-width:2px" id="v-290" stroke="#073b6f"></line><line  x1="320" y1="266.6666666666667" x2="320" y2="400" style="stroke-width:2px" id="v-291" stroke="#073b6f"></line><text  id="v-285" font-size="34px" y="0.8em" xml:space="preserve" font-weight="bold" text-anchor="middle" pointer-events="visible" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,200,246.9)"><tspan id="v-292"  dy="0em" x="0">Director manager</tspan></text><text  id="v-286" font-size="19px" y="0.8em" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,200,289.4)"><tspan id="v-293"  dy="0em" x="0">[Person]</tspan></text><text  id="v-287" font-size="24px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,200,313.1)"><tspan id="v-294"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text><text  id="v-288" font-weight="bold" text-anchor="middle" font-family="Open Sans" fill="#ffffff" font-size="24" transform="matrix(1,0,0,1,200,371.2)" display="none"></text><image  id="v-289"></image></g></g><g id="j_19"    transform="translate(1740,1855)" style="" ><g  id="v-298" style="opacity: 1;"><rect  id="v-299" rx="20" ry="20" stroke="#3c7fc0" stroke-width="2" pointer-events="visiblePainted" fill="#438dd5" width="450" height="300"></rect><text  id="v-300" font-size="34" y="0.8em" xml:space="preserve" font-weight="bold" text-anchor="middle" pointer-events="visible" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,225,75)"><tspan id="v-305"  dy="0em" x="0">Collaborator</tspan></text><text  id="v-301" font-size="19" y="0.8em" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,225,117.5)"><tspan id="v-306"  dy="0em" x="0">[Container]</tspan></text><text  id="v-302" font-size="24" y="0.8em" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,225,165)"><tspan id="v-307"  dy="0em" x="0">Actor executing tasks on local data</tspan><tspan id="v-308"  dy="1.2em" x="0">inside one experiment</tspan></text><text  id="v-303" font-weight="bold" text-anchor="middle" font-family="Open Sans" fill="#ffffff" font-size="24" transform="matrix(1,0,0,1,225,270)" y="0.8em" xml:space="preserve" display="none"><tspan id="v-309"  dy="0em" x="0">+</tspan></text><image  id="v-304"></image></g></g><g id="j_20"    transform="translate(880,760)" style="" ><g  id="v-315" style="opacity: 1;"><rect  id="v-316" rx="20" ry="20" stroke="#3c7fc0" stroke-width="2" pointer-events="visiblePainted" fill="#438dd5" width="450" height="300"></rect><text  id="v-317" font-size="34" y="0.8em" xml:space="preserve" font-weight="bold" text-anchor="middle" pointer-events="visible" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,225,75)"><tspan id="v-322"  dy="0em" x="0">Python API component</tspan></text><text  id="v-318" font-size="19" y="0.8em" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,225,117.5)"><tspan id="v-323"  dy="0em" x="0">[Container]</tspan></text><text  id="v-319" font-size="24" y="0.8em" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,225,165)"><tspan id="v-324"  dy="0em" x="0">A set of tools to setup register FL</tspan><tspan id="v-325"  dy="1.2em" x="0">Experiments</tspan></text><text  id="v-320" font-weight="bold" text-anchor="middle" font-family="Open Sans" fill="#ffffff" font-size="24" transform="matrix(1,0,0,1,225,270)" y="0.8em" xml:space="preserve" display="none"><tspan id="v-326"  dy="0em" x="0">+</tspan></text><image  id="v-321"></image></g></g><g id="j_21"    transform="translate(880,1320)" style="" ><g  id="v-330" style="opacity: 1;"><rect  id="v-331" rx="20" ry="20" stroke="#3c7fc0" stroke-width="2" pointer-events="visiblePainted" fill="#438dd5" width="450" height="300"></rect><text  id="v-332" font-size="34" y="0.8em" xml:space="preserve" font-weight="bold" text-anchor="middle" pointer-events="visible" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,225,75)"><tspan id="v-337"  dy="0em" x="0">Director</tspan></text><text  id="v-333" font-size="19" y="0.8em" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,225,117.5)"><tspan id="v-338"  dy="0em" x="0">[Container]</tspan></text><text  id="v-334" font-size="24" y="0.8em" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,225,165)"><tspan id="v-339"  dy="0em" x="0">A long-living entity that can spawn</tspan><tspan id="v-340"  dy="1.2em" x="0">aggregators</tspan></text><text  id="v-335" font-weight="bold" text-anchor="middle" font-family="Open Sans" fill="#ffffff" font-size="24" transform="matrix(1,0,0,1,225,270)" y="0.8em" display="none" xml:space="preserve"><tspan id="v-348"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text><image  id="v-336"></image></g></g><g id="j_23"    transform="translate(880,1855)" style="" ><g  id="v-352" style="opacity: 1;"><rect  id="v-353" rx="20" ry="20" stroke="#3c7fc0" stroke-width="2" pointer-events="visiblePainted" fill="#438dd5" width="450" height="300"></rect><text  id="v-354" font-size="34" y="0.8em" xml:space="preserve" font-weight="bold" text-anchor="middle" pointer-events="visible" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,225,75)"><tspan id="v-359"  dy="0em" x="0">Aggregator</tspan></text><text  id="v-355" font-size="19" y="0.8em" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,225,117.5)"><tspan id="v-360"  dy="0em" x="0">[Container]</tspan></text><text  id="v-356" font-size="24" y="0.8em" xml:space="preserve" text-anchor="middle" font-family="Open Sans" fill="#ffffff" transform="matrix(1,0,0,1,225,165)"><tspan id="v-361"  dy="0em" x="0">Model server and collaborator</tspan><tspan id="v-362"  dy="1.2em" x="0">orchestrator</tspan></text><text  id="v-357" font-weight="bold" text-anchor="middle" font-family="Open Sans" fill="#ffffff" font-size="24" transform="matrix(1,0,0,1,225,270)" y="0.8em" display="none" xml:space="preserve"><tspan id="v-363"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text><image  id="v-358"></image></g></g><g id="j_24"   ><path  stroke="#707070" id="v-386" stroke-width="2" stroke-dasharray="30 30" fill="none" d="M 630 1470 860 1470" style="opacity: 1;"></path><path  fill="black" stroke="black" transform="translate(630,1470) scale(1,1) rotate(0)"></path><path  fill="#707070" stroke="#707070" id="v-388" d="M 20 0 L 0 10 L 20 20 z" transform="translate(880,1480) scale(1,1) rotate(-180)" style="opacity: 1;"></path><path  id="v-387" fill="none" d="M 630 1470 860 1470"></path><title ></title><g ><g  id="v-371" label-idx="0" cursor="move" transform="translate(745, 1470)" style="opacity: 1;"><rect id="v-373" fill="#ffffff" rx="3" ry="3" stroke="#ffffff" stroke-width="20px" pointer-events="none" width="165.5" height="119" transform="matrix(1,0,0,1,-82.7,-59.5)"></rect><text id="v-372" font-size="24px" y="0.8em" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,-52.2)"><tspan id="v-374"  dy="0em" x="0">Launches. Sets</tspan><tspan id="v-375"  dy="1.2em" x="0">up global</tspan><tspan id="v-376"  dy="1.2em" x="0">Federation</tspan><tspan id="v-377"  dy="1.2em" x="0">settings</tspan></text></g><g  id="v-378" label-idx="1" cursor="move" transform="translate(745, 1539.6)" style="opacity: 1;"><rect id="v-380" fill="#ffffff" rx="3" ry="3" pointer-events="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-379" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,0)"><tspan id="v-381"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g><g  id="v-382" label-idx="2" cursor="move" transform="translate(745, 1563.6)" style="opacity: 1;"><rect id="v-384" fill="#ffffff" rx="3" ry="3" pointer-events="none"  display="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-383" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal"  transform="matrix(1,0,0,1,0,0)"><tspan id="v-385"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g></g><g  display="none"></g><g  id="v-390" display="none"><g  id="v-368"><path  end="source" d="M 26 0 L 0 13 L 26 26 z"></path></g><g  id="v-369"><path  end="target" d="M 26 0 L 0 13 L 26 26 z"></path></g></g><g  id="v-389" display="none"><g  id="v-367" transform="translate(670, 1470) "><g  event="remove"><circle r="11"></circle><path transform="scale(.8) translate(-16, -16)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"></path><title>Remove link.</title></g><g  event="link:options"><circle r="11" transform="translate(25)"></circle><path fill="white" transform="scale(.55) translate(29, -16)" d="M31.229,17.736c0.064-0.571,0.104-1.148,0.104-1.736s-0.04-1.166-0.104-1.737l-4.377-1.557c-0.218-0.716-0.504-1.401-0.851-2.05l1.993-4.192c-0.725-0.91-1.549-1.734-2.458-2.459l-4.193,1.994c-0.647-0.347-1.334-0.632-2.049-0.849l-1.558-4.378C17.165,0.708,16.588,0.667,16,0.667s-1.166,0.041-1.737,0.105L12.707,5.15c-0.716,0.217-1.401,0.502-2.05,0.849L6.464,4.005C5.554,4.73,4.73,5.554,4.005,6.464l1.994,4.192c-0.347,0.648-0.632,1.334-0.849,2.05l-4.378,1.557C0.708,14.834,0.667,15.412,0.667,16s0.041,1.165,0.105,1.736l4.378,1.558c0.217,0.715,0.502,1.401,0.849,2.049l-1.994,4.193c0.725,0.909,1.549,1.733,2.459,2.458l4.192-1.993c0.648,0.347,1.334,0.633,2.05,0.851l1.557,4.377c0.571,0.064,1.148,0.104,1.737,0.104c0.588,0,1.165-0.04,1.736-0.104l1.558-4.377c0.715-0.218,1.399-0.504,2.049-0.851l4.193,1.993c0.909-0.725,1.733-1.549,2.458-2.458l-1.993-4.193c0.347-0.647,0.633-1.334,0.851-2.049L31.229,17.736zM16,20.871c-2.69,0-4.872-2.182-4.872-4.871c0-2.69,2.182-4.872,4.872-4.872c2.689,0,4.871,2.182,4.871,4.872C20.871,18.689,18.689,20.871,16,20.871z"></path><title>Link options.</title></g></g></g></g><g id="j_25"   ><path  stroke="#707070" id="v-413" stroke-width="2" stroke-dasharray="30 30" fill="none" d="M 2470 1466 2210 1468" style="opacity: 1;"></path><path  fill="black" stroke="black" transform="translate(2470,1466) scale(1,1) rotate(-180.4092559814453)"></path><path  fill="#707070" stroke="#707070" id="v-415" d="M 20 0 L 0 10 L 20 20 z" transform="translate(2189.928584200193,1458.0002707109588) scale(1,1) rotate(-0.40924862027168274)" style="opacity: 1;"></path><path  id="v-414" fill="none" d="M 2470 1466 2210 1468"></path><title ></title><g ><g  id="v-398" label-idx="0" cursor="move" transform="translate(2340, 1467)" style="opacity: 1;"><rect id="v-400" fill="#ffffff" rx="3" ry="3" stroke="#ffffff" stroke-width="20px" pointer-events="none" width="194.34375" height="119" transform="matrix(1,0,0,1,-97.2,-59.5)"></rect><text id="v-399" font-size="24px" y="0.8em" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,-52.2)"><tspan id="v-401"  dy="0em" x="0">Launches.</tspan><tspan id="v-402"  dy="1.2em" x="0">Provides local</tspan><tspan id="v-403"  dy="1.2em" x="0">dataset</tspan><tspan id="v-404"  dy="1.2em" x="0">ShardDescriptors</tspan></text></g><g  id="v-405" label-idx="1" cursor="move" transform="translate(2340, 1536.6)" style="opacity: 1;"><rect id="v-407" fill="#ffffff" rx="3" ry="3" pointer-events="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-406" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,0)"><tspan id="v-408"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g><g  id="v-409" label-idx="2" cursor="move" transform="translate(2340, 1560.6)" style="opacity: 1;"><rect id="v-411" fill="#ffffff" rx="3" ry="3" pointer-events="none"  display="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-410" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal"  transform="matrix(1,0,0,1,0,0)"><tspan id="v-412"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g></g><g  display="none"></g><g  id="v-417" display="none"><g  id="v-395"><path  end="source" d="M 26 0 L 0 13 L 26 26 z"></path></g><g  id="v-396"><path  end="target" d="M 26 0 L 0 13 L 26 26 z"></path></g></g><g  id="v-416" display="none"><g  id="v-394" transform="translate(2430.001220703125, 1466.3076171875) "><g  event="remove"><circle r="11"></circle><path transform="scale(.8) translate(-16, -16)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"></path><title>Remove link.</title></g><g  event="link:options"><circle r="11" transform="translate(25)"></circle><path fill="white" transform="scale(.55) translate(29, -16)" d="M31.229,17.736c0.064-0.571,0.104-1.148,0.104-1.736s-0.04-1.166-0.104-1.737l-4.377-1.557c-0.218-0.716-0.504-1.401-0.851-2.05l1.993-4.192c-0.725-0.91-1.549-1.734-2.458-2.459l-4.193,1.994c-0.647-0.347-1.334-0.632-2.049-0.849l-1.558-4.378C17.165,0.708,16.588,0.667,16,0.667s-1.166,0.041-1.737,0.105L12.707,5.15c-0.716,0.217-1.401,0.502-2.05,0.849L6.464,4.005C5.554,4.73,4.73,5.554,4.005,6.464l1.994,4.192c-0.347,0.648-0.632,1.334-0.849,2.05l-4.378,1.557C0.708,14.834,0.667,15.412,0.667,16s0.041,1.165,0.105,1.736l4.378,1.558c0.217,0.715,0.502,1.401,0.849,2.049l-1.994,4.193c0.725,0.909,1.549,1.733,2.459,2.458l4.192-1.993c0.648,0.347,1.334,0.633,2.05,0.851l1.557,4.377c0.571,0.064,1.148,0.104,1.737,0.104c0.588,0,1.165-0.04,1.736-0.104l1.558-4.377c0.715-0.218,1.399-0.504,2.049-0.851l4.193,1.993c0.909-0.725,1.733-1.549,2.458-2.458l-1.993-4.193c0.347-0.647,0.633-1.334,0.851-2.049L31.229,17.736zM16,20.871c-2.69,0-4.872-2.182-4.872-4.871c0-2.69,2.182-4.872,4.872-4.872c2.689,0,4.871,2.182,4.871,4.872C20.871,18.689,18.689,20.871,16,20.871z"></path><title>Link options.</title></g></g></g></g><g id="j_26"   ><path  stroke="#707070" id="v-441" stroke-width="2" stroke-dasharray="30 30" fill="none" d="M 1740 1971 1545 1941 S 1535 1940 1525 1941 L 1350 1968" style="opacity: 1;"></path><path  fill="black" stroke="black" transform="translate(1740,1971) scale(1,1) rotate(-171.40090942382812)"></path><path  fill="#707070" stroke="#707070" id="v-443" d="M 20 0 L 0 10 L 20 20 z" transform="translate(1328.5047894829493,1961.1123693136124) scale(1,1) rotate(-8.599088668823242)" style="opacity: 1;"></path><path  id="v-442" fill="none" d="M 1740 1971 1545 1941 S 1535 1940 1525 1941 L 1350 1968"></path><title ></title><g ><g  id="v-426" label-idx="0" cursor="move" transform="translate(1545.0970458984375, 1941.014892578125)" style="opacity: 1;"><rect id="v-428" fill="#ffffff" rx="3" ry="3" stroke="#ffffff" stroke-width="20px" pointer-events="none" width="156.1875" height="119" transform="matrix(1,0,0,1,-78.1,-59.5)"></rect><text id="v-427" font-size="24px" y="0.8em" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,-52.2)"><tspan id="v-429"  dy="0em" x="0">Sends locally</tspan><tspan id="v-430"  dy="1.2em" x="0">tuned tensors</tspan><tspan id="v-431"  dy="1.2em" x="0">and training</tspan><tspan id="v-432"  dy="1.2em" x="0">metrics</tspan></text></g><g  id="v-433" label-idx="1" cursor="move" transform="translate(1545.0970458984375, 2010.614892578125)" style="opacity: 1;"><rect id="v-435" fill="#ffffff" rx="3" ry="3" pointer-events="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-434" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,0)"><tspan id="v-436"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g><g  id="v-437" label-idx="2" cursor="move" transform="translate(1545.0970458984375, 2034.614892578125)" style="opacity: 1;"><rect id="v-439" fill="#ffffff" rx="3" ry="3" pointer-events="none"  display="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-438" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal"  transform="matrix(1,0,0,1,0,0)"><tspan id="v-440"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g></g><g  display="none"><g  transform="translate(1535, 1940)" id="v-422"><circle  idx="0" r="10"></circle><path  idx="0" d="M16,5.333c-7.732,0-14,4.701-14,10.5c0,1.982,0.741,3.833,2.016,5.414L2,25.667l5.613-1.441c2.339,1.317,5.237,2.107,8.387,2.107c7.732,0,14-4.701,14-10.5C30,10.034,23.732,5.333,16,5.333z" transform="translate(5, -33)"></path><path  idx="0" transform="scale(.8) translate(9.5, -37)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"><title>Remove vertex.</title></path></g></g><g  id="v-445" display="none"><g  id="v-423"><path  end="source" d="M 26 0 L 0 13 L 26 26 z"></path></g><g  id="v-424"><path  end="target" d="M 26 0 L 0 13 L 26 26 z"></path></g></g><g  id="v-444" display="none"><g  id="v-421" transform="translate(1700.465087890625, 1964.917724609375) "><g  event="remove"><circle r="11"></circle><path transform="scale(.8) translate(-16, -16)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"></path><title>Remove link.</title></g><g  event="link:options"><circle r="11" transform="translate(25)"></circle><path fill="white" transform="scale(.55) translate(29, -16)" d="M31.229,17.736c0.064-0.571,0.104-1.148,0.104-1.736s-0.04-1.166-0.104-1.737l-4.377-1.557c-0.218-0.716-0.504-1.401-0.851-2.05l1.993-4.192c-0.725-0.91-1.549-1.734-2.458-2.459l-4.193,1.994c-0.647-0.347-1.334-0.632-2.049-0.849l-1.558-4.378C17.165,0.708,16.588,0.667,16,0.667s-1.166,0.041-1.737,0.105L12.707,5.15c-0.716,0.217-1.401,0.502-2.05,0.849L6.464,4.005C5.554,4.73,4.73,5.554,4.005,6.464l1.994,4.192c-0.347,0.648-0.632,1.334-0.849,2.05l-4.378,1.557C0.708,14.834,0.667,15.412,0.667,16s0.041,1.165,0.105,1.736l4.378,1.558c0.217,0.715,0.502,1.401,0.849,2.049l-1.994,4.193c0.725,0.909,1.549,1.733,2.459,2.458l4.192-1.993c0.648,0.347,1.334,0.633,2.05,0.851l1.557,4.377c0.571,0.064,1.148,0.104,1.737,0.104c0.588,0,1.165-0.04,1.736-0.104l1.558-4.377c0.715-0.218,1.399-0.504,2.049-0.851l4.193,1.993c0.909-0.725,1.733-1.549,2.458-2.458l-1.993-4.193c0.347-0.647,0.633-1.334,0.851-2.049L31.229,17.736zM16,20.871c-2.69,0-4.872-2.182-4.872-4.871c0-2.69,2.182-4.872,4.872-4.872c2.689,0,4.871,2.182,4.871,4.872C20.871,18.689,18.689,20.871,16,20.871z"></path><title>Link options.</title></g></g></g></g><g id="j_27"   ><path  stroke="#707070" id="v-467" stroke-width="2" stroke-dasharray="30 30" fill="none" d="M 1096 600 1100 740" style="opacity: 1;"></path><path  fill="black" stroke="black" transform="translate(1096,600) scale(1,1) rotate(88.21008300781253)"></path><path  fill="#707070" stroke="#707070" id="v-469" d="M 20 0 L 0 10 L 20 20 z" transform="translate(1091.0048486091628,760.3123508866711) scale(1,1) rotate(-91.78990936279297)" style="opacity: 1;"></path><path  id="v-468" fill="none" d="M 1096 600 1100 740"></path><title ></title><g ><g  id="v-453" label-idx="0" cursor="move" transform="translate(1098, 670)" style="opacity: 1;"><rect id="v-455" fill="#ffffff" rx="3" ry="3" stroke="#ffffff" stroke-width="20px" pointer-events="none" width="199.65625" height="90.203125" transform="matrix(1,0,0,1,-99.8,-45.1)"></rect><text id="v-454" font-size="24px" y="0.8em" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,-37.8)"><tspan id="v-456"  dy="0em" x="0">Provides FL Plans,</tspan><tspan id="v-457"  dy="1.2em" x="0">Tasks, Models,</tspan><tspan id="v-458"  dy="1.2em" x="0">DataLoaders</tspan></text></g><g  id="v-459" label-idx="1" cursor="move" transform="translate(1098, 727.6)" style="opacity: 1;"><rect id="v-461" fill="#ffffff" rx="3" ry="3" pointer-events="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-460" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,0)"><tspan id="v-462"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g><g  id="v-463" label-idx="2" cursor="move" transform="translate(1098, 751.6)" style="opacity: 1;"><rect id="v-465" fill="#ffffff" rx="3" ry="3" pointer-events="none"  display="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-464" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal"  transform="matrix(1,0,0,1,0,0)"><tspan id="v-466"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g></g><g  display="none"></g><g  id="v-471" display="none"><g  id="v-450"><path  end="source" d="M 26 0 L 0 13 L 26 26 z"></path></g><g  id="v-451"><path  end="target" d="M 26 0 L 0 13 L 26 26 z"></path></g></g><g  id="v-470" display="none"><g  id="v-449" transform="translate(1097.142333984375, 639.9837036132812) "><g  event="remove"><circle r="11"></circle><path transform="scale(.8) translate(-16, -16)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"></path><title>Remove link.</title></g><g  event="link:options"><circle r="11" transform="translate(25)"></circle><path fill="white" transform="scale(.55) translate(29, -16)" d="M31.229,17.736c0.064-0.571,0.104-1.148,0.104-1.736s-0.04-1.166-0.104-1.737l-4.377-1.557c-0.218-0.716-0.504-1.401-0.851-2.05l1.993-4.192c-0.725-0.91-1.549-1.734-2.458-2.459l-4.193,1.994c-0.647-0.347-1.334-0.632-2.049-0.849l-1.558-4.378C17.165,0.708,16.588,0.667,16,0.667s-1.166,0.041-1.737,0.105L12.707,5.15c-0.716,0.217-1.401,0.502-2.05,0.849L6.464,4.005C5.554,4.73,4.73,5.554,4.005,6.464l1.994,4.192c-0.347,0.648-0.632,1.334-0.849,2.05l-4.378,1.557C0.708,14.834,0.667,15.412,0.667,16s0.041,1.165,0.105,1.736l4.378,1.558c0.217,0.715,0.502,1.401,0.849,2.049l-1.994,4.193c0.725,0.909,1.549,1.733,2.459,2.458l4.192-1.993c0.648,0.347,1.334,0.633,2.05,0.851l1.557,4.377c0.571,0.064,1.148,0.104,1.737,0.104c0.588,0,1.165-0.04,1.736-0.104l1.558-4.377c0.715-0.218,1.399-0.504,2.049-0.851l4.193,1.993c0.909-0.725,1.733-1.549,2.458-2.458l-1.993-4.193c0.347-0.647,0.633-1.334,0.851-2.049L31.229,17.736zM16,20.871c-2.69,0-4.872-2.182-4.872-4.871c0-2.69,2.182-4.872,4.872-4.872c2.689,0,4.871,2.182,4.871,4.872C20.871,18.689,18.689,20.871,16,20.871z"></path><title>Link options.</title></g></g></g></g><g id="j_28"   ><path  stroke="#707070" id="v-493" stroke-width="2" stroke-dasharray="30 30" fill="none" d="M 1330 2047 1555 2088 S 1565 2090 1575 2088 L 1720 2057" style="opacity: 1;"></path><path  fill="black" stroke="black" transform="translate(1330,2047) scale(1,1) rotate(10.36920166015625)"></path><path  fill="#707070" stroke="#707070" id="v-495" d="M 20 0 L 0 10 L 20 20 z" transform="translate(1742.0685808356088,2062.783760202619) scale(1,1) rotate(-191.9381561279297)" style="opacity: 1;"></path><path  id="v-494" fill="none" d="M 1330 2047 1555 2088 S 1565 2090 1575 2088 L 1720 2057"></path><title ></title><g ><g  id="v-480" label-idx="0" cursor="move" transform="translate(1525.3284912109375, 2082.59326171875)" style="opacity: 1;"><rect id="v-482" fill="#ffffff" rx="3" ry="3" stroke="#ffffff" stroke-width="20px" pointer-events="none" width="180.0625" height="61.40625" transform="matrix(1,0,0,1,-90,-30.7)"></rect><text id="v-481" font-size="24px" y="0.8em" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,-23.4)"><tspan id="v-483"  dy="0em" x="0">Sends tasks and</tspan><tspan id="v-484"  dy="1.2em" x="0">initial tensors</tspan></text></g><g  id="v-485" label-idx="1" cursor="move" transform="translate(1525.3284912109375, 2125.79326171875)" style="opacity: 1;"><rect id="v-487" fill="#ffffff" rx="3" ry="3" pointer-events="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-486" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,0)"><tspan id="v-488"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g><g  id="v-489" label-idx="2" cursor="move" transform="translate(1525.3284912109375, 2149.79326171875)" style="opacity: 1;"><rect id="v-491" fill="#ffffff" rx="3" ry="3" pointer-events="none"  display="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-490" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal"  transform="matrix(1,0,0,1,0,0)"><tspan id="v-492"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g></g><g  display="none"><g  transform="translate(1565, 2090)" id="v-476"><circle  idx="0" r="10"></circle><path  idx="0" d="M16,5.333c-7.732,0-14,4.701-14,10.5c0,1.982,0.741,3.833,2.016,5.414L2,25.667l5.613-1.441c2.339,1.317,5.237,2.107,8.387,2.107c7.732,0,14-4.701,14-10.5C30,10.034,23.732,5.333,16,5.333z" transform="translate(5, -33)"></path><path  idx="0" transform="scale(.8) translate(9.5, -37)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"><title>Remove vertex.</title></path></g></g><g  id="v-497" display="none"><g  id="v-477"><path  end="source" d="M 26 0 L 0 13 L 26 26 z"></path></g><g  id="v-478"><path  end="target" d="M 26 0 L 0 13 L 26 26 z"></path></g></g><g  id="v-496" display="none"><g  id="v-475" transform="translate(1369.35205078125, 2054.1708984375) "><g  event="remove"><circle r="11"></circle><path transform="scale(.8) translate(-16, -16)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"></path><title>Remove link.</title></g><g  event="link:options"><circle r="11" transform="translate(25)"></circle><path fill="white" transform="scale(.55) translate(29, -16)" d="M31.229,17.736c0.064-0.571,0.104-1.148,0.104-1.736s-0.04-1.166-0.104-1.737l-4.377-1.557c-0.218-0.716-0.504-1.401-0.851-2.05l1.993-4.192c-0.725-0.91-1.549-1.734-2.458-2.459l-4.193,1.994c-0.647-0.347-1.334-0.632-2.049-0.849l-1.558-4.378C17.165,0.708,16.588,0.667,16,0.667s-1.166,0.041-1.737,0.105L12.707,5.15c-0.716,0.217-1.401,0.502-2.05,0.849L6.464,4.005C5.554,4.73,4.73,5.554,4.005,6.464l1.994,4.192c-0.347,0.648-0.632,1.334-0.849,2.05l-4.378,1.557C0.708,14.834,0.667,15.412,0.667,16s0.041,1.165,0.105,1.736l4.378,1.558c0.217,0.715,0.502,1.401,0.849,2.049l-1.994,4.193c0.725,0.909,1.549,1.733,2.459,2.458l4.192-1.993c0.648,0.347,1.334,0.633,2.05,0.851l1.557,4.377c0.571,0.064,1.148,0.104,1.737,0.104c0.588,0,1.165-0.04,1.736-0.104l1.558-4.377c0.715-0.218,1.399-0.504,2.049-0.851l4.193,1.993c0.909-0.725,1.733-1.549,2.458-2.458l-1.993-4.193c0.347-0.647,0.633-1.334,0.851-2.049L31.229,17.736zM16,20.871c-2.69,0-4.872-2.182-4.872-4.871c0-2.69,2.182-4.872,4.872-4.872c2.689,0,4.871,2.182,4.871,4.872C20.871,18.689,18.689,20.871,16,20.871z"></path><title>Link options.</title></g></g></g></g><g id="j_29"   ><path  stroke="#707070" id="v-519" stroke-width="2" stroke-dasharray="30 30" fill="none" d="M 1330 1500 1540 1529 S 1550 1530 1560 1529 L 1720 1506" style="opacity: 1;"></path><path  fill="black" stroke="black" transform="translate(1330,1500) scale(1,1) rotate(7.765167236328139)"></path><path  fill="#707070" stroke="#707070" id="v-521" d="M 20 0 L 0 10 L 20 20 z" transform="translate(1741.4069390794684,1512.9004776234322) scale(1,1) rotate(-188.08787536621094)" style="opacity: 1;"></path><path  id="v-520" fill="none" d="M 1330 1500 1540 1529 S 1550 1530 1560 1529 L 1720 1506"></path><title ></title><g ><g  id="v-506" label-idx="0" cursor="move" transform="translate(1524.98193359375, 1526.926025390625)" style="opacity: 1;"><rect id="v-508" fill="#ffffff" rx="3" ry="3" stroke="#ffffff" stroke-width="20px" pointer-events="none" width="185.4375" height="61.40625" transform="matrix(1,0,0,1,-92.7,-30.7)"></rect><text id="v-507" font-size="24px" y="0.8em" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,-23.4)"><tspan id="v-509"  dy="0em" x="0">Approves, Sends</tspan><tspan id="v-510"  dy="1.2em" x="0">FL experiments</tspan></text></g><g  id="v-511" label-idx="1" cursor="move" transform="translate(1524.98193359375, 1570.126025390625)" style="opacity: 1;"><rect id="v-513" fill="#ffffff" rx="3" ry="3" pointer-events="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-512" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,0)"><tspan id="v-514"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g><g  id="v-515" label-idx="2" cursor="move" transform="translate(1524.98193359375, 1594.126025390625)" style="opacity: 1;"><rect id="v-517" fill="#ffffff" rx="3" ry="3" pointer-events="none"  display="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-516" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal"  transform="matrix(1,0,0,1,0,0)"><tspan id="v-518"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g></g><g  display="none"><g  transform="translate(1550, 1530)" id="v-502"><circle  idx="0" r="10"></circle><path  idx="0" d="M16,5.333c-7.732,0-14,4.701-14,10.5c0,1.982,0.741,3.833,2.016,5.414L2,25.667l5.613-1.441c2.339,1.317,5.237,2.107,8.387,2.107c7.732,0,14-4.701,14-10.5C30,10.034,23.732,5.333,16,5.333z" transform="translate(5, -33)"></path><path  idx="0" transform="scale(.8) translate(9.5, -37)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"><title>Remove vertex.</title></path></g></g><g  id="v-523" display="none"><g  id="v-503"><path  end="source" d="M 26 0 L 0 13 L 26 26 z"></path></g><g  id="v-504"><path  end="target" d="M 26 0 L 0 13 L 26 26 z"></path></g></g><g  id="v-522" display="none"><g  id="v-501" transform="translate(1369.6240234375, 1505.471923828125) "><g  event="remove"><circle r="11"></circle><path transform="scale(.8) translate(-16, -16)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"></path><title>Remove link.</title></g><g  event="link:options"><circle r="11" transform="translate(25)"></circle><path fill="white" transform="scale(.55) translate(29, -16)" d="M31.229,17.736c0.064-0.571,0.104-1.148,0.104-1.736s-0.04-1.166-0.104-1.737l-4.377-1.557c-0.218-0.716-0.504-1.401-0.851-2.05l1.993-4.192c-0.725-0.91-1.549-1.734-2.458-2.459l-4.193,1.994c-0.647-0.347-1.334-0.632-2.049-0.849l-1.558-4.378C17.165,0.708,16.588,0.667,16,0.667s-1.166,0.041-1.737,0.105L12.707,5.15c-0.716,0.217-1.401,0.502-2.05,0.849L6.464,4.005C5.554,4.73,4.73,5.554,4.005,6.464l1.994,4.192c-0.347,0.648-0.632,1.334-0.849,2.05l-4.378,1.557C0.708,14.834,0.667,15.412,0.667,16s0.041,1.165,0.105,1.736l4.378,1.558c0.217,0.715,0.502,1.401,0.849,2.049l-1.994,4.193c0.725,0.909,1.549,1.733,2.459,2.458l4.192-1.993c0.648,0.347,1.334,0.633,2.05,0.851l1.557,4.377c0.571,0.064,1.148,0.104,1.737,0.104c0.588,0,1.165-0.04,1.736-0.104l1.558-4.377c0.715-0.218,1.399-0.504,2.049-0.851l4.193,1.993c0.909-0.725,1.733-1.549,2.458-2.458l-1.993-4.193c0.347-0.647,0.633-1.334,0.851-2.049L31.229,17.736zM16,20.871c-2.69,0-4.872-2.182-4.872-4.871c0-2.69,2.182-4.872,4.872-4.872c2.689,0,4.871,2.182,4.871,4.872C20.871,18.689,18.689,20.871,16,20.871z"></path><title>Link options.</title></g></g></g></g><g id="j_30"   ><path  stroke="#707070" id="v-547" stroke-width="2" stroke-dasharray="30 30" fill="none" d="M 1740 1413 1540 1362 S 1530 1360 1520 1363 L 1349 1407" style="opacity: 1;"></path><path  fill="black" stroke="black" transform="translate(1740,1413) scale(1,1) rotate(-165.83543395996094)"></path><path  fill="#707070" stroke="#707070" id="v-549" d="M 20 0 L 0 10 L 20 20 z" transform="translate(1327.4836591093501,1402.3217559621125) scale(1,1) rotate(-14.57421588897705)" style="opacity: 1;"></path><path  id="v-548" fill="none" d="M 1740 1413 1540 1362 S 1530 1360 1520 1363 L 1349 1407"></path><title ></title><g ><g  id="v-532" label-idx="0" cursor="move" transform="translate(1544.66943359375, 1363.190673828125)" style="opacity: 1;"><rect id="v-534" fill="#ffffff" rx="3" ry="3" stroke="#ffffff" stroke-width="20px" pointer-events="none" width="167.9375" height="119" transform="matrix(1,0,0,1,-84,-59.5)"></rect><text id="v-533" font-size="24px" y="0.8em" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,-52.2)"><tspan id="v-535"  dy="0em" x="0">Communicates</tspan><tspan id="v-536"  dy="1.2em" x="0">dataset info,</tspan><tspan id="v-537"  dy="1.2em" x="0">Sends status</tspan><tspan id="v-538"  dy="1.2em" x="0">updates</tspan></text></g><g  id="v-539" label-idx="1" cursor="move" transform="translate(1544.66943359375, 1432.790673828125)" style="opacity: 1;"><rect id="v-541" fill="#ffffff" rx="3" ry="3" pointer-events="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-540" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,0)"><tspan id="v-542"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g><g  id="v-543" label-idx="2" cursor="move" transform="translate(1544.66943359375, 1456.790673828125)" style="opacity: 1;"><rect id="v-545" fill="#ffffff" rx="3" ry="3" pointer-events="none"  display="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-544" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal"  transform="matrix(1,0,0,1,0,0)"><tspan id="v-546"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g></g><g  display="none"><g  transform="translate(1530, 1360)" id="v-528"><circle  idx="0" r="10"></circle><path  idx="0" d="M16,5.333c-7.732,0-14,4.701-14,10.5c0,1.982,0.741,3.833,2.016,5.414L2,25.667l5.613-1.441c2.339,1.317,5.237,2.107,8.387,2.107c7.732,0,14-4.701,14-10.5C30,10.034,23.732,5.333,16,5.333z" transform="translate(5, -33)"></path><path  idx="0" transform="scale(.8) translate(9.5, -37)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"><title>Remove vertex.</title></path></g></g><g  id="v-551" display="none"><g  id="v-529"><path  end="source" d="M 26 0 L 0 13 L 26 26 z"></path></g><g  id="v-530"><path  end="target" d="M 26 0 L 0 13 L 26 26 z"></path></g></g><g  id="v-550" display="none"><g  id="v-527" transform="translate(1701.2403564453125, 1403.1163330078125) "><g  event="remove"><circle r="11"></circle><path transform="scale(.8) translate(-16, -16)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"></path><title>Remove link.</title></g><g  event="link:options"><circle r="11" transform="translate(25)"></circle><path fill="white" transform="scale(.55) translate(29, -16)" d="M31.229,17.736c0.064-0.571,0.104-1.148,0.104-1.736s-0.04-1.166-0.104-1.737l-4.377-1.557c-0.218-0.716-0.504-1.401-0.851-2.05l1.993-4.192c-0.725-0.91-1.549-1.734-2.458-2.459l-4.193,1.994c-0.647-0.347-1.334-0.632-2.049-0.849l-1.558-4.378C17.165,0.708,16.588,0.667,16,0.667s-1.166,0.041-1.737,0.105L12.707,5.15c-0.716,0.217-1.401,0.502-2.05,0.849L6.464,4.005C5.554,4.73,4.73,5.554,4.005,6.464l1.994,4.192c-0.347,0.648-0.632,1.334-0.849,2.05l-4.378,1.557C0.708,14.834,0.667,15.412,0.667,16s0.041,1.165,0.105,1.736l4.378,1.558c0.217,0.715,0.502,1.401,0.849,2.049l-1.994,4.193c0.725,0.909,1.549,1.733,2.459,2.458l4.192-1.993c0.648,0.347,1.334,0.633,2.05,0.851l1.557,4.377c0.571,0.064,1.148,0.104,1.737,0.104c0.588,0,1.165-0.04,1.736-0.104l1.558-4.377c0.715-0.218,1.399-0.504,2.049-0.851l4.193,1.993c0.909-0.725,1.733-1.549,2.458-2.458l-1.993-4.193c0.347-0.647,0.633-1.334,0.851-2.049L31.229,17.736zM16,20.871c-2.69,0-4.872-2.182-4.872-4.871c0-2.69,2.182-4.872,4.872-4.872c2.689,0,4.871,2.182,4.871,4.872C20.871,18.689,18.689,20.871,16,20.871z"></path><title>Link options.</title></g></g></g></g><g id="j_31"   ><path  stroke="#707070" id="v-574" stroke-width="2" stroke-dasharray="30 30" fill="none" d="M 1965 1620 1965 1835" style="opacity: 1;"></path><path  fill="black" stroke="black" transform="translate(1965,1620) scale(1,1) rotate(-270)"></path><path  fill="#707070" stroke="#707070" id="v-576" d="M 20 0 L 0 10 L 20 20 z" transform="translate(1955,1855) scale(1,1) rotate(-90)" style="opacity: 1;"></path><path  id="v-575" fill="none" d="M 1965 1620 1965 1835"></path><title ></title><g ><g  id="v-559" label-idx="0" cursor="move" transform="translate(1965, 1727.5)" style="opacity: 1;"><rect id="v-561" fill="#ffffff" rx="3" ry="3" stroke="#ffffff" stroke-width="20px" pointer-events="none" width="164.46875" height="119" transform="matrix(1,0,0,1,-82.2,-59.5)"></rect><text id="v-560" font-size="24px" y="0.8em" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,-52.2)"><tspan id="v-562"  dy="0em" x="0">Creates an</tspan><tspan id="v-563"  dy="1.2em" x="0">instance to</tspan><tspan id="v-564"  dy="1.2em" x="0">maintain an FL</tspan><tspan id="v-565"  dy="1.2em" x="0">experiment</tspan></text></g><g  id="v-566" label-idx="1" cursor="move" transform="translate(1965, 1797.1)" style="opacity: 1;"><rect id="v-568" fill="#ffffff" rx="3" ry="3" pointer-events="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-567" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,0)"><tspan id="v-569"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g><g  id="v-570" label-idx="2" cursor="move" transform="translate(1965, 1821.1)" style="opacity: 1;"><rect id="v-572" fill="#ffffff" rx="3" ry="3" pointer-events="none"  display="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-571" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal"  transform="matrix(1,0,0,1,0,0)"><tspan id="v-573"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g></g><g  display="none"></g><g  id="v-578" display="none"><g  id="v-556"><path  end="source" d="M 26 0 L 0 13 L 26 26 z"></path></g><g  id="v-557"><path  end="target" d="M 26 0 L 0 13 L 26 26 z"></path></g></g><g  id="v-577" display="none"><g  id="v-555" transform="translate(1965, 1660) "><g  event="remove"><circle r="11"></circle><path transform="scale(.8) translate(-16, -16)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"></path><title>Remove link.</title></g><g  event="link:options"><circle r="11" transform="translate(25)"></circle><path fill="white" transform="scale(.55) translate(29, -16)" d="M31.229,17.736c0.064-0.571,0.104-1.148,0.104-1.736s-0.04-1.166-0.104-1.737l-4.377-1.557c-0.218-0.716-0.504-1.401-0.851-2.05l1.993-4.192c-0.725-0.91-1.549-1.734-2.458-2.459l-4.193,1.994c-0.647-0.347-1.334-0.632-2.049-0.849l-1.558-4.378C17.165,0.708,16.588,0.667,16,0.667s-1.166,0.041-1.737,0.105L12.707,5.15c-0.716,0.217-1.401,0.502-2.05,0.849L6.464,4.005C5.554,4.73,4.73,5.554,4.005,6.464l1.994,4.192c-0.347,0.648-0.632,1.334-0.849,2.05l-4.378,1.557C0.708,14.834,0.667,15.412,0.667,16s0.041,1.165,0.105,1.736l4.378,1.558c0.217,0.715,0.502,1.401,0.849,2.049l-1.994,4.193c0.725,0.909,1.549,1.733,2.459,2.458l4.192-1.993c0.648,0.347,1.334,0.633,2.05,0.851l1.557,4.377c0.571,0.064,1.148,0.104,1.737,0.104c0.588,0,1.165-0.04,1.736-0.104l1.558-4.377c0.715-0.218,1.399-0.504,2.049-0.851l4.193,1.993c0.909-0.725,1.733-1.549,2.458-2.458l-1.993-4.193c0.347-0.647,0.633-1.334,0.851-2.049L31.229,17.736zM16,20.871c-2.69,0-4.872-2.182-4.872-4.871c0-2.69,2.182-4.872,4.872-4.872c2.689,0,4.871,2.182,4.871,4.872C20.871,18.689,18.689,20.871,16,20.871z"></path><title>Link options.</title></g></g></g></g><g id="j_32"   ><path  stroke="#707070" id="v-601" stroke-width="2" stroke-dasharray="30 30" fill="none" d="M 1105 1620 1105 1835" style="opacity: 1;"></path><path  fill="black" stroke="black" transform="translate(1105,1620) scale(1,1) rotate(-270)"></path><path  fill="#707070" stroke="#707070" id="v-603" d="M 20 0 L 0 10 L 20 20 z" transform="translate(1095,1855) scale(1,1) rotate(-90)" style="opacity: 1;"></path><path  id="v-602" fill="none" d="M 1105 1620 1105 1835"></path><title ></title><g ><g  id="v-586" label-idx="0" cursor="move" transform="translate(1105, 1727.5)" style="opacity: 1;"><rect id="v-588" fill="#ffffff" rx="3" ry="3" stroke="#ffffff" stroke-width="20px" pointer-events="none" width="164.46875" height="119" transform="matrix(1,0,0,1,-82.2,-59.5)"></rect><text id="v-587" font-size="24px" y="0.8em" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,-52.2)"><tspan id="v-589"  dy="0em" x="0">Creates an</tspan><tspan id="v-590"  dy="1.2em" x="0">instance to</tspan><tspan id="v-591"  dy="1.2em" x="0">maintain an FL</tspan><tspan id="v-592"  dy="1.2em" x="0">experiment</tspan></text></g><g  id="v-593" label-idx="1" cursor="move" transform="translate(1105, 1797.1)" style="opacity: 1;"><rect id="v-595" fill="#ffffff" rx="3" ry="3" pointer-events="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-594" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,0)"><tspan id="v-596"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g><g  id="v-597" label-idx="2" cursor="move" transform="translate(1105, 1821.1)" style="opacity: 1;"><rect id="v-599" fill="#ffffff" rx="3" ry="3" pointer-events="none"  display="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-598" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal"  transform="matrix(1,0,0,1,0,0)"><tspan id="v-600"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g></g><g  display="none"></g><g  id="v-605" display="none"><g  id="v-583"><path  end="source" d="M 26 0 L 0 13 L 26 26 z"></path></g><g  id="v-584"><path  end="target" d="M 26 0 L 0 13 L 26 26 z"></path></g></g><g  id="v-604" display="none"><g  id="v-582" transform="translate(1105, 1660) "><g  event="remove"><circle r="11"></circle><path transform="scale(.8) translate(-16, -16)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"></path><title>Remove link.</title></g><g  event="link:options"><circle r="11" transform="translate(25)"></circle><path fill="white" transform="scale(.55) translate(29, -16)" d="M31.229,17.736c0.064-0.571,0.104-1.148,0.104-1.736s-0.04-1.166-0.104-1.737l-4.377-1.557c-0.218-0.716-0.504-1.401-0.851-2.05l1.993-4.192c-0.725-0.91-1.549-1.734-2.458-2.459l-4.193,1.994c-0.647-0.347-1.334-0.632-2.049-0.849l-1.558-4.378C17.165,0.708,16.588,0.667,16,0.667s-1.166,0.041-1.737,0.105L12.707,5.15c-0.716,0.217-1.401,0.502-2.05,0.849L6.464,4.005C5.554,4.73,4.73,5.554,4.005,6.464l1.994,4.192c-0.347,0.648-0.632,1.334-0.849,2.05l-4.378,1.557C0.708,14.834,0.667,15.412,0.667,16s0.041,1.165,0.105,1.736l4.378,1.558c0.217,0.715,0.502,1.401,0.849,2.049l-1.994,4.193c0.725,0.909,1.549,1.733,2.459,2.458l4.192-1.993c0.648,0.347,1.334,0.633,2.05,0.851l1.557,4.377c0.571,0.064,1.148,0.104,1.737,0.104c0.588,0,1.165-0.04,1.736-0.104l1.558-4.377c0.715-0.218,1.399-0.504,2.049-0.851l4.193,1.993c0.909-0.725,1.733-1.549,2.458-2.458l-1.993-4.193c0.347-0.647,0.633-1.334,0.851-2.049L31.229,17.736zM16,20.871c-2.69,0-4.872-2.182-4.872-4.871c0-2.69,2.182-4.872,4.872-4.872c2.689,0,4.871,2.182,4.871,4.872C20.871,18.689,18.689,20.871,16,20.871z"></path><title>Link options.</title></g></g></g></g><g id="j_33"   ><path  stroke="#707070" id="v-631" stroke-width="2" stroke-dasharray="30 30" fill="none" d="M 1163 1320 1211 1194 S 1215 1185 1211 1176 L 1172 1079" style="opacity: 1;"></path><path  fill="black" stroke="black" transform="translate(1163,1320) scale(1,1) rotate(-68.93405151367188)"></path><path  fill="#707070" stroke="#707070" id="v-633" d="M 20 0 L 0 10 L 20 20 z" transform="translate(1174.284724466815,1056.286115138385) scale(1,1) rotate(68.1985778808594)" style="opacity: 1;"></path><path  id="v-632" fill="none" d="M 1163 1320 1211 1194 S 1215 1185 1211 1176 L 1172 1079"></path><title ></title><g ><g  id="v-614" label-idx="0" cursor="move" transform="translate(1208.896728515625, 1199.5211181640625)" style="opacity: 1;"><rect id="v-616" fill="#ffffff" rx="3" ry="3" stroke="#ffffff" stroke-width="20px" pointer-events="none" width="180.0625" height="176.59375" transform="matrix(1,0,0,1,-90,-88.3)"></rect><text id="v-615" font-size="24px" y="0.8em" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,-81)"><tspan id="v-617"  dy="0em" x="0">Sends</tspan><tspan id="v-618"  dy="1.2em" x="0">information</tspan><tspan id="v-619"  dy="1.2em" x="0">about the</tspan><tspan id="v-620"  dy="1.2em" x="0">Federation.</tspan><tspan id="v-621"  dy="1.2em" x="0">Returns training</tspan><tspan id="v-622"  dy="1.2em" x="0">artifacts.</tspan></text></g><g  id="v-623" label-idx="1" cursor="move" transform="translate(1208.896728515625, 1293.1211181640624)" style="opacity: 1;"><rect id="v-625" fill="#ffffff" rx="3" ry="3" pointer-events="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-624" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,0)"><tspan id="v-626"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g><g  id="v-627" label-idx="2" cursor="move" transform="translate(1208.896728515625, 1317.1211181640624)" style="opacity: 1;"><rect id="v-629" fill="#ffffff" rx="3" ry="3" pointer-events="none"  display="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-628" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal"  transform="matrix(1,0,0,1,0,0)"><tspan id="v-630"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g></g><g  display="none"><g  transform="translate(1215, 1185)" id="v-610"><circle  idx="0" r="10"></circle><path  idx="0" d="M16,5.333c-7.732,0-14,4.701-14,10.5c0,1.982,0.741,3.833,2.016,5.414L2,25.667l5.613-1.441c2.339,1.317,5.237,2.107,8.387,2.107c7.732,0,14-4.701,14-10.5C30,10.034,23.732,5.333,16,5.333z" transform="translate(5, -33)"></path><path  idx="0" transform="scale(.8) translate(9.5, -37)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"><title>Remove vertex.</title></path></g></g><g  id="v-635" display="none"><g  id="v-611"><path  end="source" d="M 26 0 L 0 13 L 26 26 z"></path></g><g  id="v-612"><path  end="target" d="M 26 0 L 0 13 L 26 26 z"></path></g></g><g  id="v-634" display="none"><g  id="v-609" transform="translate(1177.2398681640625, 1282.6204833984375) "><g  event="remove"><circle r="11"></circle><path transform="scale(.8) translate(-16, -16)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"></path><title>Remove link.</title></g><g  event="link:options"><circle r="11" transform="translate(25)"></circle><path fill="white" transform="scale(.55) translate(29, -16)" d="M31.229,17.736c0.064-0.571,0.104-1.148,0.104-1.736s-0.04-1.166-0.104-1.737l-4.377-1.557c-0.218-0.716-0.504-1.401-0.851-2.05l1.993-4.192c-0.725-0.91-1.549-1.734-2.458-2.459l-4.193,1.994c-0.647-0.347-1.334-0.632-2.049-0.849l-1.558-4.378C17.165,0.708,16.588,0.667,16,0.667s-1.166,0.041-1.737,0.105L12.707,5.15c-0.716,0.217-1.401,0.502-2.05,0.849L6.464,4.005C5.554,4.73,4.73,5.554,4.005,6.464l1.994,4.192c-0.347,0.648-0.632,1.334-0.849,2.05l-4.378,1.557C0.708,14.834,0.667,15.412,0.667,16s0.041,1.165,0.105,1.736l4.378,1.558c0.217,0.715,0.502,1.401,0.849,2.049l-1.994,4.193c0.725,0.909,1.549,1.733,2.459,2.458l4.192-1.993c0.648,0.347,1.334,0.633,2.05,0.851l1.557,4.377c0.571,0.064,1.148,0.104,1.737,0.104c0.588,0,1.165-0.04,1.736-0.104l1.558-4.377c0.715-0.218,1.399-0.504,2.049-0.851l4.193,1.993c0.909-0.725,1.733-1.549,2.458-2.458l-1.993-4.193c0.347-0.647,0.633-1.334,0.851-2.049L31.229,17.736zM16,20.871c-2.69,0-4.872-2.182-4.872-4.871c0-2.69,2.182-4.872,4.872-4.872c2.689,0,4.871,2.182,4.871,4.872C20.871,18.689,18.689,20.871,16,20.871z"></path><title>Link options.</title></g></g></g></g><g id="j_34"   ><path  stroke="#707070" id="v-657" stroke-width="2" stroke-dasharray="30 30" fill="none" d="M 1043 1060 999 1166 S 995 1175 998 1184 L 1042 1301" style="opacity: 1;"></path><path  fill="black" stroke="black" transform="translate(1043,1060) scale(1,1) rotate(-247.34477233886722)"></path><path  fill="#707070" stroke="#707070" id="v-659" d="M 20 0 L 0 10 L 20 20 z" transform="translate(1039.628751669837,1323.4899973110653) scale(1,1) rotate(-110.426025390625)" style="opacity: 1;"></path><path  id="v-658" fill="none" d="M 1043 1060 999 1166 S 995 1175 998 1184 L 1042 1301"></path><title ></title><g ><g  id="v-644" label-idx="0" cursor="move" transform="translate(997.0918579101562, 1180.0296630859375)" style="opacity: 1;"><rect id="v-646" fill="#ffffff" rx="3" ry="3" stroke="#ffffff" stroke-width="20px" pointer-events="none" width="140.5" height="61.40625" transform="matrix(1,0,0,1,-70.2,-30.7)"></rect><text id="v-645" font-size="24px" y="0.8em" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,-23.4)"><tspan id="v-647"  dy="0em" x="0">Registers FL</tspan><tspan id="v-648"  dy="1.2em" x="0">experiments</tspan></text></g><g  id="v-649" label-idx="1" cursor="move" transform="translate(997.0918579101562, 1223.2296630859375)" style="opacity: 1;"><rect id="v-651" fill="#ffffff" rx="3" ry="3" pointer-events="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-650" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal" transform="matrix(1,0,0,1,0,0)"><tspan id="v-652"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g><g  id="v-653" label-idx="2" cursor="move" transform="translate(997.0918579101562, 1247.2296630859375)" style="opacity: 1;"><rect id="v-655" fill="#ffffff" rx="3" ry="3" pointer-events="none"  display="none" width="0" height="0" transform="matrix(1,0,0,1,0,0)"></rect><text id="v-654" font-size="19px" y="0.8em" display="none" xml:space="preserve" text-anchor="middle" pointer-events="none" fill="#707070" font-family="Open Sans" font-weight="normal"  transform="matrix(1,0,0,1,0,0)"><tspan id="v-656"  dy="0em" x="0" style="fill-opacity: 0; stroke-opacity: 0;">-</tspan></text></g></g><g  display="none"><g  transform="translate(995, 1175)" id="v-640"><circle  idx="0" r="10"></circle><path  idx="0" d="M16,5.333c-7.732,0-14,4.701-14,10.5c0,1.982,0.741,3.833,2.016,5.414L2,25.667l5.613-1.441c2.339,1.317,5.237,2.107,8.387,2.107c7.732,0,14-4.701,14-10.5C30,10.034,23.732,5.333,16,5.333z" transform="translate(5, -33)"></path><path  idx="0" transform="scale(.8) translate(9.5, -37)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"><title>Remove vertex.</title></path></g></g><g  id="v-661" display="none"><g  id="v-641"><path  end="source" d="M 26 0 L 0 13 L 26 26 z"></path></g><g  id="v-642"><path  end="target" d="M 26 0 L 0 13 L 26 26 z"></path></g></g><g  id="v-660" display="none"><g  id="v-639" transform="translate(1027.6649169921875, 1096.943603515625) "><g  event="remove"><circle r="11"></circle><path transform="scale(.8) translate(-16, -16)" d="M24.778,21.419 19.276,15.917 24.777,10.415 21.949,7.585 16.447,13.087 10.945,7.585 8.117,10.415 13.618,15.917 8.116,21.419 10.946,24.248 16.447,18.746 21.948,24.248z"></path><title>Remove link.</title></g><g  event="link:options"><circle r="11" transform="translate(25)"></circle><path fill="white" transform="scale(.55) translate(29, -16)" d="M31.229,17.736c0.064-0.571,0.104-1.148,0.104-1.736s-0.04-1.166-0.104-1.737l-4.377-1.557c-0.218-0.716-0.504-1.401-0.851-2.05l1.993-4.192c-0.725-0.91-1.549-1.734-2.458-2.459l-4.193,1.994c-0.647-0.347-1.334-0.632-2.049-0.849l-1.558-4.378C17.165,0.708,16.588,0.667,16,0.667s-1.166,0.041-1.737,0.105L12.707,5.15c-0.716,0.217-1.401,0.502-2.05,0.849L6.464,4.005C5.554,4.73,4.73,5.554,4.005,6.464l1.994,4.192c-0.347,0.648-0.632,1.334-0.849,2.05l-4.378,1.557C0.708,14.834,0.667,15.412,0.667,16s0.041,1.165,0.105,1.736l4.378,1.558c0.217,0.715,0.502,1.401,0.849,2.049l-1.994,4.193c0.725,0.909,1.549,1.733,2.459,2.458l4.192-1.993c0.648,0.347,1.334,0.633,2.05,0.851l1.557,4.377c0.571,0.064,1.148,0.104,1.737,0.104c0.588,0,1.165-0.04,1.736-0.104l1.558-4.377c0.715-0.218,1.399-0.504,2.049-0.851l4.193,1.993c0.909-0.725,1.733-1.549,2.458-2.458l-1.993-4.193c0.347-0.647,0.633-1.334,0.851-2.049L31.229,17.736zM16,20.871c-2.69,0-4.872-2.182-4.872-4.871c0-2.69,2.182-4.872,4.872-4.872c2.689,0,4.871,2.182,4.871,4.872C20.871,18.689,18.689,20.871,16,20.871z"></path><title>Link options.</title></g></g></g></g></g><defs id="v-4"></defs></svg>
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/docs/structurizer_dsl/workspace.dsl ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/structurizer_dsl/workspace.dsl
*** ./openfl/docs/structurizer_dsl/workspace.dsl	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/structurizer_dsl/workspace.dsl	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,97 ****
- 
- workspace "OpenFL" "An open framework for Federated Learning." {
-     model {
-         group "Control" {
-             user = person "Data scientist" "A person or group of people using OpenFL"
-             shardOwner = person "Collaborator manager" "Data owner's representative controlling Envoy"
-             centralManager = person "Director manager" 
-             governor = softwareSystem "Governor" "CCF-based system for corporate clients"
-         }
-         openfl = softwareSystem "OpenFL" "An open framework for Federated Learning" {
-             apiLayer = container "Python API component" "A set of tools to setup and register FL Experiments" {
-                 federationInterface = component "Federaion Interface"
-                 experimentInterface = component "Experiment Interface"
-                 # TaskInterface = component ""
-             }
- 
-             group "Central node" {
-                 director = container "Director" "A long-living entity that can spawn aggregators"
-                 aggregator = container "Aggregator" "Model server and collaborator orchestrator"{
-                     assigner = component "Task Assigner" "Decides the policy for which collaborators should run FL tasks"
-                     grpcServer = component "gRPC Server"
-                 }
-             }
-             group "Collaborator node" {
-                 envoy = container "Envoy" "A long-living entity that can adapt a local dataset and spawn collaborators" {
-                     shardDescriptor = component "Shard Descriptor" "Data manager's interface aimed to unify data access" {
-                         tags "Interface"
-                     }
-                 }
-                 collaborator = container "Collaborator" "Actor executing tasks on local data inside one experiment" {
-                     pluginManager = component "Plugin Manager"
-                     taskRunner = component "Task Runner"
-                     tensorDB = component "Tensor Data Base"
-                     tensorCodec = component "TensorCodec"
-                     grpcClient = component "gRPC Client"
-                     frameworkAdapter = component "Framework Adapter"
-                 }
-             }
-         }
-         config = element "Config file"
- 
-         # relationships between people and software systems
-         user -> openfl "Controls Fedarations. Provides FL plans, tasks, models, data"
-         governor -> openfl "Controls Fedarations"
- 
-         # relationships to/from containers
-         user -> apiLayer "Provides FL Plans, Tasks, Models, DataLoaders"
-         shardOwner -> envoy "Launches. Provides local dataset ShardDescriptors"
-         centralManager -> director "Launches. Sets up global Federation settings"
-         apiLayer -> director "Registers FL experiments"
-         director -> apiLayer "Sends information about the Federation. Returns training artifacts."
-         director -> aggregator "Creates an instance to maintain an FL experiment"
-         envoy -> collaborator "Creates an instance to maintain an FL experiment"
-         envoy -> director "Communicates dataset info, Sends status updates"
-         director -> envoy "Approves, Sends FL experiments"
-         aggregator -> collaborator "Sends tasks and initial tensors"
-         collaborator -> aggregator "Sends locally tuned tensors and training metrics"
- 
- 
-         # relationships to/from components
-         envoy -> taskRunner "Provides tasks' defenitions"
-         grpcClient -> taskRunner "Invokes some tasks for the round"
-         aggregator -> grpcClient "Communicates"
-     }
- 
-     views
-         theme default
- 
-         systemcontext openfl "SystemContext" {
-             include *
-             autoLayout
-             
-         }
- 
-         container openfl "Containers" {
-             include *
-             # include config
-             # autoLayout
-         }
- 
-         component collaborator "Collaborator" {
-             include *
-             autoLayout
-         }
- 
-         component apiLayer "API" {
-             include *
-             autoLayout
-         }
- 
-         component envoy "Envoy" {
-             include *
-             autoLayout
-         }
- 
- }
- 
--- 0 ----
diff -crB --new-file ./openfl/docs/structurizer_dsl/workspace.json ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/structurizer_dsl/workspace.json
*** ./openfl/docs/structurizer_dsl/workspace.json	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/structurizer_dsl/workspace.json	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,509 ****
- {
-   "id" : 1,
-   "name" : "OpenFL",
-   "description" : "An open framework for Federated Learning.",
-   "revision" : 0,
-   "lastModifiedDate" : "2021-08-27T13:28:56Z",
-   "lastModifiedAgent" : "structurizr-web/2475",
-   "properties" : {
-     "structurizr.dsl" : "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"
-   },
-   "configuration" : { },
-   "model" : {
-     "people" : [ {
-       "id" : "2",
-       "tags" : "Element,Person",
-       "name" : "Collaborator manager",
-       "description" : "Data owner's representative controlling Envoy",
-       "relationships" : [ {
-         "id" : "26",
-         "tags" : "Relationship",
-         "sourceId" : "2",
-         "destinationId" : "13",
-         "description" : "Launches. Provides local dataset ShardDescriptors"
-       }, {
-         "id" : "27",
-         "tags" : "Relationship",
-         "sourceId" : "2",
-         "destinationId" : "5",
-         "description" : "Launches. Provides local dataset ShardDescriptors"
-       } ],
-       "group" : "Control",
-       "location" : "Unspecified"
-     }, {
-       "id" : "1",
-       "tags" : "Element,Person",
-       "name" : "Data scientist",
-       "description" : "A person or group of people using OpenFL",
-       "relationships" : [ {
-         "id" : "25",
-         "tags" : "Relationship",
-         "sourceId" : "1",
-         "destinationId" : "6",
-         "description" : "Provides FL Plans, Tasks, Models, DataLoaders"
-       }, {
-         "id" : "23",
-         "tags" : "Relationship",
-         "sourceId" : "1",
-         "destinationId" : "5",
-         "description" : "Controls Fedarations. Provides FL plans, tasks, models, data"
-       } ],
-       "group" : "Control",
-       "location" : "Unspecified"
-     }, {
-       "id" : "3",
-       "tags" : "Element,Person",
-       "name" : "Director manager",
-       "relationships" : [ {
-         "id" : "29",
-         "tags" : "Relationship",
-         "sourceId" : "3",
-         "destinationId" : "5",
-         "description" : "Launches. Sets up global Federation settings"
-       }, {
-         "id" : "28",
-         "tags" : "Relationship",
-         "sourceId" : "3",
-         "destinationId" : "9",
-         "description" : "Launches. Sets up global Federation settings"
-       } ],
-       "group" : "Control",
-       "location" : "Unspecified"
-     } ],
-     "softwareSystems" : [ {
-       "id" : "4",
-       "tags" : "Element,Software System",
-       "name" : "Governor",
-       "description" : "CCF-based system for corporate clients",
-       "relationships" : [ {
-         "id" : "24",
-         "tags" : "Relationship",
-         "sourceId" : "4",
-         "destinationId" : "5",
-         "description" : "Controls Fedarations"
-       } ],
-       "group" : "Control",
-       "location" : "Unspecified"
-     }, {
-       "id" : "5",
-       "tags" : "Element,Software System",
-       "name" : "OpenFL",
-       "description" : "An open framework for Federated Learning",
-       "location" : "Unspecified",
-       "containers" : [ {
-         "id" : "10",
-         "tags" : "Element,Container",
-         "name" : "Aggregator",
-         "description" : "Model server and collaborator orchestrator",
-         "relationships" : [ {
-           "id" : "40",
-           "tags" : "Relationship",
-           "sourceId" : "10",
-           "destinationId" : "20",
-           "description" : "Communicates"
-         }, {
-           "id" : "36",
-           "tags" : "Relationship",
-           "sourceId" : "10",
-           "destinationId" : "15",
-           "description" : "Sends tasks and initial tensors"
-         } ],
-         "group" : "Central node",
-         "components" : [ {
-           "id" : "11",
-           "tags" : "Element,Component",
-           "name" : "Task Assigner",
-           "description" : "Decides the policy for which collaborators should run FL tasks",
-           "size" : 0
-         }, {
-           "id" : "12",
-           "tags" : "Element,Component",
-           "name" : "gRPC Server",
-           "size" : 0
-         } ]
-       }, {
-         "id" : "15",
-         "tags" : "Element,Container",
-         "name" : "Collaborator",
-         "description" : "Actor executing tasks on local data inside one experiment",
-         "relationships" : [ {
-           "id" : "37",
-           "tags" : "Relationship",
-           "sourceId" : "15",
-           "destinationId" : "10",
-           "description" : "Sends locally tuned tensors and training metrics"
-         } ],
-         "group" : "Collaborator node",
-         "components" : [ {
-           "id" : "16",
-           "tags" : "Element,Component",
-           "name" : "Plugin Manager",
-           "size" : 0
-         }, {
-           "id" : "21",
-           "tags" : "Element,Component",
-           "name" : "Framework Adapter",
-           "size" : 0
-         }, {
-           "id" : "18",
-           "tags" : "Element,Component",
-           "name" : "Tensor Data Base",
-           "size" : 0
-         }, {
-           "id" : "20",
-           "tags" : "Element,Component",
-           "name" : "gRPC Client",
-           "relationships" : [ {
-             "id" : "39",
-             "tags" : "Relationship",
-             "sourceId" : "20",
-             "destinationId" : "17",
-             "description" : "Invokes some tasks for the round"
-           } ],
-           "size" : 0
-         }, {
-           "id" : "19",
-           "tags" : "Element,Component",
-           "name" : "TensorCodec",
-           "size" : 0
-         }, {
-           "id" : "17",
-           "tags" : "Element,Component",
-           "name" : "Task Runner",
-           "size" : 0
-         } ]
-       }, {
-         "id" : "6",
-         "tags" : "Element,Container",
-         "name" : "Python API component",
-         "description" : "A set of tools to setup register FL Experiments",
-         "relationships" : [ {
-           "id" : "30",
-           "tags" : "Relationship",
-           "sourceId" : "6",
-           "destinationId" : "9",
-           "description" : "Registers FL experiments"
-         } ],
-         "components" : [ {
-           "id" : "8",
-           "tags" : "Element,Component",
-           "name" : "Experiment Interface",
-           "size" : 0
-         }, {
-           "id" : "7",
-           "tags" : "Element,Component",
-           "name" : "Federaion Interface",
-           "size" : 0
-         } ]
-       }, {
-         "id" : "13",
-         "tags" : "Element,Container",
-         "name" : "Envoy",
-         "description" : "A long-living entity that can adapt a local data set and spawn collaborators",
-         "relationships" : [ {
-           "id" : "34",
-           "tags" : "Relationship",
-           "sourceId" : "13",
-           "destinationId" : "9",
-           "description" : "Communicates dataset info, Sends status updates"
-         }, {
-           "id" : "38",
-           "tags" : "Relationship",
-           "sourceId" : "13",
-           "destinationId" : "17",
-           "description" : "Provides tasks' defenitions"
-         }, {
-           "id" : "33",
-           "tags" : "Relationship",
-           "sourceId" : "13",
-           "destinationId" : "15",
-           "description" : "Creates an instance to maintain an FL experiment"
-         } ],
-         "group" : "Collaborator node",
-         "components" : [ {
-           "id" : "14",
-           "tags" : "Element,Component,Interface",
-           "name" : "Shard Descriptor",
-           "description" : "Data manager's interface aimed to unify data access",
-           "size" : 0
-         } ]
-       }, {
-         "id" : "9",
-         "tags" : "Element,Container",
-         "name" : "Director",
-         "description" : "A long-living entity that can spawn aggregators",
-         "relationships" : [ {
-           "id" : "31",
-           "tags" : "Relationship",
-           "sourceId" : "9",
-           "destinationId" : "6",
-           "description" : "Sends information about the Federation. Returns training artifacts."
-         }, {
-           "id" : "35",
-           "tags" : "Relationship",
-           "sourceId" : "9",
-           "destinationId" : "13",
-           "description" : "Approves, Sends FL experiments"
-         }, {
-           "id" : "32",
-           "tags" : "Relationship",
-           "sourceId" : "9",
-           "destinationId" : "10",
-           "description" : "Creates an instance to maintain an FL experiment"
-         } ],
-         "group" : "Central node"
-       } ]
-     } ],
-     "customElements" : [ {
-       "id" : "22",
-       "tags" : "Element",
-       "name" : "Config file"
-     } ]
-   },
-   "documentation" : { },
-   "views" : {
-     "systemContextViews" : [ {
-       "softwareSystemId" : "5",
-       "key" : "SystemContext",
-       "paperSize" : "A4_Landscape",
-       "dimensions" : {
-         "width" : 3358,
-         "height" : 1454
-       },
-       "automaticLayout" : {
-         "implementation" : "Graphviz",
-         "rankDirection" : "TopBottom",
-         "rankSeparation" : 300,
-         "nodeSeparation" : 300,
-         "edgeSeparation" : 0,
-         "vertices" : false
-       },
-       "enterpriseBoundaryVisible" : true,
-       "elements" : [ {
-         "id" : "1",
-         "x" : 2604,
-         "y" : 277
-       }, {
-         "id" : "2",
-         "x" : 1854,
-         "y" : 277
-       }, {
-         "id" : "3",
-         "x" : 1104,
-         "y" : 277
-       }, {
-         "id" : "4",
-         "x" : 354,
-         "y" : 277
-       }, {
-         "id" : "5",
-         "x" : 1479,
-         "y" : 877
-       } ],
-       "relationships" : [ {
-         "id" : "29"
-       }, {
-         "id" : "27"
-       }, {
-         "id" : "24",
-         "vertices" : [ {
-           "x" : 954,
-           "y" : 681
-         } ]
-       }, {
-         "id" : "23",
-         "vertices" : [ {
-           "x" : 2454,
-           "y" : 681
-         } ]
-       } ]
-     } ],
-     "containerViews" : [ {
-       "softwareSystemId" : "5",
-       "key" : "Containers",
-       "dimensions" : {
-         "width" : 3104,
-         "height" : 2546
-       },
-       "externalSoftwareSystemBoundariesVisible" : true,
-       "elements" : [ {
-         "id" : "1",
-         "x" : 890,
-         "y" : 200
-       }, {
-         "id" : "13",
-         "x" : 1740,
-         "y" : 1320
-       }, {
-         "id" : "2",
-         "x" : 2470,
-         "y" : 1265
-       }, {
-         "id" : "3",
-         "x" : 230,
-         "y" : 1270
-       }, {
-         "id" : "15",
-         "x" : 1740,
-         "y" : 1855
-       }, {
-         "id" : "6",
-         "x" : 880,
-         "y" : 760
-       }, {
-         "id" : "9",
-         "x" : 880,
-         "y" : 1320
-       }, {
-         "id" : "10",
-         "x" : 880,
-         "y" : 1855
-       } ],
-       "relationships" : [ {
-         "id" : "28"
-       }, {
-         "id" : "26"
-       }, {
-         "id" : "37",
-         "vertices" : [ {
-           "x" : 1535,
-           "y" : 1940
-         } ]
-       }, {
-         "id" : "25"
-       }, {
-         "id" : "36",
-         "vertices" : [ {
-           "x" : 1565,
-           "y" : 2090
-         } ]
-       }, {
-         "id" : "35",
-         "vertices" : [ {
-           "x" : 1550,
-           "y" : 1530
-         } ]
-       }, {
-         "id" : "34",
-         "vertices" : [ {
-           "x" : 1530,
-           "y" : 1360
-         } ]
-       }, {
-         "id" : "33"
-       }, {
-         "id" : "32"
-       }, {
-         "id" : "31",
-         "vertices" : [ {
-           "x" : 1215,
-           "y" : 1185
-         } ]
-       }, {
-         "id" : "30",
-         "vertices" : [ {
-           "x" : 995,
-           "y" : 1175
-         } ]
-       } ]
-     } ],
-     "componentViews" : [ {
-       "key" : "Collaborator",
-       "automaticLayout" : {
-         "implementation" : "Graphviz",
-         "rankDirection" : "TopBottom",
-         "rankSeparation" : 300,
-         "nodeSeparation" : 300,
-         "edgeSeparation" : 0,
-         "vertices" : false
-       },
-       "containerId" : "15",
-       "externalContainerBoundariesVisible" : true,
-       "elements" : [ {
-         "id" : "13",
-         "x" : 0,
-         "y" : 0
-       }, {
-         "id" : "16",
-         "x" : 0,
-         "y" : 0
-       }, {
-         "id" : "17",
-         "x" : 0,
-         "y" : 0
-       }, {
-         "id" : "18",
-         "x" : 0,
-         "y" : 0
-       }, {
-         "id" : "19",
-         "x" : 0,
-         "y" : 0
-       }, {
-         "id" : "20",
-         "x" : 0,
-         "y" : 0
-       }, {
-         "id" : "21",
-         "x" : 0,
-         "y" : 0
-       }, {
-         "id" : "10",
-         "x" : 0,
-         "y" : 0
-       } ],
-       "relationships" : [ {
-         "id" : "40"
-       }, {
-         "id" : "38"
-       }, {
-         "id" : "39"
-       } ]
-     }, {
-       "key" : "API",
-       "automaticLayout" : {
-         "implementation" : "Graphviz",
-         "rankDirection" : "TopBottom",
-         "rankSeparation" : 300,
-         "nodeSeparation" : 300,
-         "edgeSeparation" : 0,
-         "vertices" : false
-       },
-       "containerId" : "6",
-       "externalContainerBoundariesVisible" : true,
-       "elements" : [ {
-         "id" : "7",
-         "x" : 0,
-         "y" : 0
-       }, {
-         "id" : "8",
-         "x" : 0,
-         "y" : 0
-       } ]
-     }, {
-       "key" : "Envoy",
-       "automaticLayout" : {
-         "implementation" : "Graphviz",
-         "rankDirection" : "TopBottom",
-         "rankSeparation" : 300,
-         "nodeSeparation" : 300,
-         "edgeSeparation" : 0,
-         "vertices" : false
-       },
-       "containerId" : "13",
-       "externalContainerBoundariesVisible" : true,
-       "elements" : [ {
-         "id" : "14",
-         "x" : 0,
-         "y" : 0
-       } ]
-     } ],
-     "configuration" : {
-       "branding" : { },
-       "styles" : { },
-       "themes" : [ "https://static.structurizr.com/themes/default/theme.json" ],
-       "terminology" : { },
-       "lastSavedView" : "Containers"
-     }
-   }
- }
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/docs/supported_aggregation_algorithms.rst ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/supported_aggregation_algorithms.rst
*** ./openfl/docs/supported_aggregation_algorithms.rst	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/supported_aggregation_algorithms.rst	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,49 ****
- .. # Copyright (C) 2020-2021 Intel Corporation
- .. # SPDX-License-Identifier: Apache-2.0
- 
- *********************************
- Supported aggregation algorithms
- *********************************
- ===========
- FedAvg
- ===========
- Default aggregation algorithm in OpenFL.
- Multiplies local model weights with relative data size and averages this multiplication result.
- 
- =========
- FedProx
- =========
- Paper: https://arxiv.org/abs/1812.06127
- 
- FedProx in OpenFL is implemented as a custom optimizer for PyTorch/TensorFlow. In order to use FedProx, do the following:
- 
- 1. PyTorch:
- 
-   - replace your optimizer with SGD-based :class:`openfl.utilities.optimizers.torch.FedProxOptimizer` 
-     or Adam-based :class:`openfl.utilities.optimizers.torch.FedProxAdam`.
-     Also, you should save model weights for the next round via calling `.set_old_weights()` method of the optimizer
-     before the training epoch.
- 
- 2. TensorFlow:
- 
-   - replace your optimizer with SGD-based :py:class:`openfl.utilities.optimizers.keras.FedProxOptimizer`.
- 
- For more details, see :code:`openfl-tutorials/Federated_FedProx_*_MNIST_Tutorial.ipynb` where * is the framework name.
- 
- =========
- FedOpt
- =========
- Paper: https://arxiv.org/abs/2003.00295
- 
- FedOpt in OpenFL: :ref:`adaptive_aggregation_functions`
- 
- ==========
- FedCurv 
- ==========
- Paper: https://arxiv.org/abs/1910.07796
- 
- Requires PyTorch >= 1.9.0. Other frameworks are not supported yet.
- 
- Use :py:class:`openfl.utilities.fedcurv.torch.FedCurv` to override train function using :code:`.get_penalty()`, :code:`.on_train_begin()`, and :code:`.on_train_end()` methods.
- In addition, you should override default :code:`AggregationFunction` of the train task with :class:`openfl.component.aggregation_functions.FedCurvWeightedAverage`.
- See :code:`PyTorch_Histology_FedCurv` tutorial in :code:`openfl-tutorials/interactive_api` directory for more details.
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/docs/troubleshooting.rst ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/troubleshooting.rst
*** ./openfl/docs/troubleshooting.rst	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/troubleshooting.rst	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,30 ****
- .. # Copyright (C) 2020-2021 Intel Corporation
- .. # SPDX-License-Identifier: Apache-2.0
- 
- .. _troubleshooting:
- 
- *******************************************************
- |productName| Troubleshooting
- *******************************************************
- 
- The following is a list of commonly reported issues in Open Federated Learning (|productName|). If you don't see your issue reported here, please submit a `Github issue
- <https://github.com/intel/openfl/issues>`_ or contact us directly on `Slack <https://join.slack.com/t/openfl/shared_invite/zt-ovzbohvn-T5fApk05~YS_iZhjJ5yaTw>`_.
- 
- 1. I see the error :code:`Cannot import name TensorFlowDataLoader from openfl.federated`
- 
-    |productName| currently uses conditional imports to attempt to be framework agnostic. If your task runner is derived from `KerasTaskRunner` or `TensorflowTaskRunner`, this error could come up if TensorFlow\*\  was not installed in your collaborator's virtual environment. If running on multi-node experiment, we recommend using the :code:`fx workspace export` and :code:`fx workspace import` commands, as this will ensure consistent modules between aggregator and collaborators.
- 
- 2. **None of the collaborators can connect to my aggregator node**
- 
-    There are a few reasons that this can happen, but the most common is the aggregator node's FQDN (Fully qualified domain name) was incorrectly specified in the plan. By default, :code:`fx plan initialize` will attempt to resolve the FQDN for you (this should look something like :code:`hostname.domain.com`), but this can sometimes parse an incorrect domain name. 
-    
-    If you face this issue, look at :code:`agg_addr` in **plan/plan.yaml** and verify that you can access this address externally. If the address is externally accessible and you are running |productName| in an enterprise environment, verify that the aggregator's listening port is not blocked. In such cases, :code:`agg_port` should be manually specified in the FL plan and then redistributed to all participants. 
- 
- 3. **After starting the collaborator, I see the error** :code:`Handshake failed with fatal error SSL_ERROR_SSL`
- 
-    This error likely results from a bad certificate presented by the collaborator. Steps for regenerating the collaborator certificate can be found :ref:`here <install_certs_colab>`.
- 
- 4. **I am seeing some other error while running the experiment. Is there more verbose logging available so I can investigate this on my own?**
- 
-    Yes! You can turn on verbose logging with :code:`fx -l DEBUG collaborator start` or :code:`fx -l DEBUG aggregator start`. This will give verbose information related to gRPC, bidirectional tensor transfer, and compression related information.  
- 
--- 0 ----
diff -crB --new-file ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/EGG-INFO/PKG-INFO ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/EGG-INFO/PKG-INFO
*** ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/EGG-INFO/PKG-INFO	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/EGG-INFO/PKG-INFO	2022-07-14 19:50:30.221821780 -0700
***************
*** 0 ****
--- 1,210 ----
+ Metadata-Version: 2.1
+ Name: grpcio-tools
+ Version: 1.34.1
+ Summary: Protobuf code generator for gRPC
+ Home-page: https://grpc.io
+ Author: The gRPC Authors
+ Author-email: grpc-io@googlegroups.com
+ License: Apache License 2.0
+ Platform: UNKNOWN
+ Classifier: Development Status :: 5 - Production/Stable
+ Classifier: Programming Language :: Python
+ Classifier: Programming Language :: Python :: 2
+ Classifier: Programming Language :: Python :: 2.7
+ Classifier: Programming Language :: Python :: 3
+ Classifier: Programming Language :: Python :: 3.4
+ Classifier: Programming Language :: Python :: 3.5
+ Classifier: Programming Language :: Python :: 3.6
+ Classifier: License :: OSI Approved :: Apache Software License
+ Requires-Dist: protobuf (<4.0dev,>=3.5.0.post1)
+ Requires-Dist: grpcio (>=1.34.1)
+ Requires-Dist: setuptools
+ 
+ gRPC Python Tools
+ =================
+ 
+ Package for gRPC Python tools.
+ 
+ Supported Python Versions
+ -------------------------
+ Python >= 3.5
+ 
+ Deprecated Python Versions
+ --------------------------
+ Python == 2.7. Python 2.7 support will be removed on January 1, 2020.
+ 
+ Installation
+ ------------
+ 
+ The gRPC Python tools package is available for Linux, Mac OS X, and Windows
+ running Python 2.7.
+ 
+ Installing From PyPI
+ ~~~~~~~~~~~~~~~~~~~~
+ 
+ If you are installing locally...
+ 
+ ::
+ 
+   $ pip install grpcio-tools
+ 
+ Else system wide (on Ubuntu)...
+ 
+ ::
+ 
+   $ sudo pip install grpcio-tools
+ 
+ If you're on Windows make sure that you installed the :code:`pip.exe` component
+ when you installed Python (if not go back and install it!) then invoke:
+ 
+ ::
+ 
+   $ pip.exe install grpcio-tools
+ 
+ Windows users may need to invoke :code:`pip.exe` from a command line ran as
+ administrator.
+ 
+ n.b. On Windows and on Mac OS X one *must* have a recent release of :code:`pip`
+ to retrieve the proper wheel from PyPI. Be sure to upgrade to the latest
+ version!
+ 
+ You might also need to install Cython to handle installation via the source
+ distribution if gRPC Python's system coverage with wheels does not happen to
+ include your system.
+ 
+ Installing From Source
+ ~~~~~~~~~~~~~~~~~~~~~~
+ 
+ Building from source requires that you have the Python headers (usually a
+ package named :code:`python-dev`) and Cython installed. It further requires a
+ GCC-like compiler to go smoothly; you can probably get it to work without
+ GCC-like stuff, but you may end up having a bad time.
+ 
+ ::
+ 
+   $ export REPO_ROOT=grpc  # REPO_ROOT can be any directory of your choice
+   $ git clone -b RELEASE_TAG_HERE https://github.com/grpc/grpc $REPO_ROOT
+   $ cd $REPO_ROOT
+   $ git submodule update --init
+ 
+   $ cd tools/distrib/python/grpcio_tools
+   $ python ../make_grpcio_tools.py
+ 
+   # For the next command do `sudo pip install` if you get permission-denied errors
+   $ GRPC_PYTHON_BUILD_WITH_CYTHON=1 pip install .
+ 
+ You cannot currently install Python from source on Windows. Things might work
+ out for you in MSYS2 (follow the Linux instructions), but it isn't officially
+ supported at the moment.
+ 
+ Troubleshooting
+ ~~~~~~~~~~~~~~~
+ 
+ Help, I ...
+ 
+ * **... see a** :code:`pkg_resources.VersionConflict` **when I try to install
+   grpc**
+ 
+   This is likely because :code:`pip` doesn't own the offending dependency,
+   which in turn is likely because your operating system's package manager owns
+   it. You'll need to force the installation of the dependency:
+ 
+   :code:`pip install --ignore-installed $OFFENDING_DEPENDENCY`
+ 
+   For example, if you get an error like the following:
+ 
+   ::
+ 
+     Traceback (most recent call last):
+     File "<string>", line 17, in <module>
+      ...
+     File "/usr/lib/python2.7/dist-packages/pkg_resources.py", line 509, in find
+       raise VersionConflict(dist, req)
+     pkg_resources.VersionConflict: (six 1.8.0 (/usr/lib/python2.7/dist-packages), Requirement.parse('six>=1.10'))
+ 
+   You can fix it by doing:
+ 
+   ::
+ 
+     sudo pip install --ignore-installed six
+ 
+ * **... see compiler errors on some platforms when either installing from source or from the source distribution**
+ 
+   If you see
+ 
+   ::
+ 
+     /tmp/pip-build-U8pSsr/cython/Cython/Plex/Scanners.c:4:20: fatal error: Python.h: No such file or directory
+     #include "Python.h"
+                     ^
+     compilation terminated.
+ 
+   You can fix it by installing `python-dev` package. i.e
+ 
+   ::
+ 
+     sudo apt-get install python-dev
+ 
+   If you see something similar to:
+ 
+   ::
+ 
+     third_party/protobuf/src/google/protobuf/stubs/mathlimits.h:173:31: note: in expansion of macro 'SIGNED_INT_MAX'
+     static const Type kPosMax = SIGNED_INT_MAX(Type); \\
+                                ^
+ 
+   And your toolchain is GCC (at the time of this writing, up through at least
+   GCC 6.0), this is probably a bug where GCC chokes on constant expressions
+   when the :code:`-fwrapv` flag is specified. You should consider setting your
+   environment with :code:`CFLAGS=-fno-wrapv` or using clang (:code:`CC=clang`).
+ 
+ Usage
+ -----
+ 
+ Given protobuf include directories :code:`$INCLUDE`, an output directory
+ :code:`$OUTPUT`, and proto files :code:`$PROTO_FILES`, invoke as:
+ 
+ ::
+ 
+   $ python -m grpc.tools.protoc -I$INCLUDE --python_out=$OUTPUT --grpc_python_out=$OUTPUT $PROTO_FILES
+ 
+ To use as a build step in distutils-based projects, you may use the provided
+ command class in your :code:`setup.py`:
+ 
+ ::
+ 
+   setuptools.setup(
+     # ...
+     cmdclass={
+       'build_proto_modules': grpc.tools.command.BuildPackageProtos,
+     }
+     # ...
+   )
+ 
+ Invocation of the command will walk the project tree and transpile every
+ :code:`.proto` file into a :code:`_pb2.py` file in the same directory.
+ 
+ Note that this particular approach requires :code:`grpcio-tools` to be
+ installed on the machine before the setup script is invoked (i.e. no
+ combination of :code:`setup_requires` or :code:`install_requires` will provide
+ access to :code:`grpc.tools.command.BuildPackageProtos` if it isn't already
+ installed). One way to work around this can be found in our
+ :code:`grpcio-health-checking`
+ `package <https://pypi.python.org/pypi/grpcio-health-checking>`_:
+ 
+ ::
+ 
+   class BuildPackageProtos(setuptools.Command):
+     """Command to generate project *_pb2.py modules from proto files."""
+     # ...
+     def run(self):
+       from grpc.tools import command
+       command.build_package_protos(self.distribution.package_dir[''])
+ 
+ Now including :code:`grpcio-tools` in :code:`setup_requires` will provide the
+ command on-setup as desired.
+ 
+ For more information on command classes, consult :code:`distutils` and
+ :code:`setuptools` documentation.
+ 
+ 
diff -crB --new-file ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/EGG-INFO/RECORD ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/EGG-INFO/RECORD
*** ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/EGG-INFO/RECORD	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/EGG-INFO/RECORD	2022-07-14 19:50:30.221821780 -0700
***************
*** 0 ****
--- 1,20 ----
+ grpc_tools/__init__.py,sha256=SxD-ymrdM7hKoDGjCDjcA3TSaFadaSZ9kDtinr0Droo,577
+ grpc_tools/_protoc_compiler.cpython-38-x86_64-linux-gnu.so,sha256=xNQso8XSYhekT-kzfEqX1AzGpGdJuGlZJLohO2mZTK8,7650632
+ grpc_tools/command.py,sha256=5Sz4Ausq0U8o4lKZviq-NeH8eis5TRnn49ADMBTfB5s,2539
+ grpc_tools/protoc.py,sha256=HuriAgf5IoA6SWlRGEPbjXwd9CqIZ7ijp_8w9VA97lg,7124
+ grpc_tools/_proto/google/protobuf/any.proto,sha256=zGJoj1FidXq0ZfBLwcFgJVOw16eq5WTpYzGhkXZTMIQ,5878
+ grpc_tools/_proto/google/protobuf/api.proto,sha256=3AEDegckEOX3zQjFL7ZBWs1nB7Wazi37Tfh4puAW-bg,7734
+ grpc_tools/_proto/google/protobuf/descriptor.proto,sha256=sg53JSOpkaGcwPVzZ5Bzm3dSwkL3NtWs5DlJvs1NXKE,37986
+ grpc_tools/_proto/google/protobuf/duration.proto,sha256=F_8ubVQmP5mSOp1DoeArIPLLvR4q0j9b9WeTlyxAf0A,4888
+ grpc_tools/_proto/google/protobuf/empty.proto,sha256=sY4M1E4NBUICwUA8SDJxgPOZXQjq0qbU0BLAVRp6NWM,2422
+ grpc_tools/_proto/google/protobuf/field_mask.proto,sha256=psf0O50x84YmmlSxefBLfIYkElYBTrxpBZiDorlVbl8,8192
+ grpc_tools/_proto/google/protobuf/source_context.proto,sha256=ZKwgTUcnBUe96VKhx6IC0K8MlVKSoh9RPvJp9vigx40,2352
+ grpc_tools/_proto/google/protobuf/struct.proto,sha256=Ey53TIKzyzOKH_WRlQy-Cuzq9tw9hERYY5CmhQ630Q4,3780
+ grpc_tools/_proto/google/protobuf/timestamp.proto,sha256=esvXq4TBXrzUqzyO0rbpYDuZlbVHQ6fTvWERdmTy5Ps,6200
+ grpc_tools/_proto/google/protobuf/type.proto,sha256=pl21Lh9lRm3JoFmrNNDJVHM8-Uc86n_lOseo7Io4FAc,6129
+ grpc_tools/_proto/google/protobuf/wrappers.proto,sha256=UUoA6sjKpnmiJZeo9ZQsLoxiD4fGZJVv6kg6zVnnvZM,4035
+ grpc_tools/_proto/google/protobuf/compiler/plugin.proto,sha256=lwQeDQQXA5vawEYWjSdh_3v3Zieqj58eFVcAnlPgmpo,8486
+ grpcio_tools-1.34.1.dist-info/METADATA,sha256=cC7sbx3e-IWHiAcMpCawihkw97ee3PynhDs5PQkcOdI,6376
+ grpcio_tools-1.34.1.dist-info/WHEEL,sha256=KUZSkuQMxyAdWwk8_y9mjEqh6Qo2Th8Id2c_HBQK9jE,111
+ grpcio_tools-1.34.1.dist-info/top_level.txt,sha256=87-PeMJ9gHMiRlUPAx2Yi7Bk14I34SOlTpgZsxhhz-c,11
+ grpcio_tools-1.34.1.dist-info/RECORD,,
diff -crB --new-file ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/EGG-INFO/requires.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/EGG-INFO/requires.txt
*** ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/EGG-INFO/requires.txt	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/EGG-INFO/requires.txt	2022-07-14 19:50:30.621821777 -0700
***************
*** 0 ****
--- 1,3 ----
+ protobuf<4.0dev,>=3.5.0.post1
+ grpcio>=1.34.1
+ setuptools
diff -crB --new-file ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/EGG-INFO/top_level.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/EGG-INFO/top_level.txt
*** ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/EGG-INFO/top_level.txt	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/EGG-INFO/top_level.txt	2022-07-14 19:50:30.221821780 -0700
***************
*** 0 ****
--- 1 ----
+ grpc_tools
diff -crB --new-file ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/EGG-INFO/WHEEL ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/EGG-INFO/WHEEL
*** ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/EGG-INFO/WHEEL	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/EGG-INFO/WHEEL	2022-07-14 19:50:30.221821780 -0700
***************
*** 0 ****
--- 1,5 ----
+ Wheel-Version: 1.0
+ Generator: bdist_wheel (0.34.2)
+ Root-Is-Purelib: false
+ Tag: cp38-cp38-manylinux2014_x86_64
+ 
diff -crB --new-file ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/command.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/command.py
*** ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/command.py	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/command.py	2022-07-14 19:50:30.221821780 -0700
***************
*** 0 ****
--- 1,70 ----
+ # Copyright 2016 gRPC authors.
+ #
+ # Licensed under the Apache License, Version 2.0 (the "License");
+ # you may not use this file except in compliance with the License.
+ # You may obtain a copy of the License at
+ #
+ #     http://www.apache.org/licenses/LICENSE-2.0
+ #
+ # Unless required by applicable law or agreed to in writing, software
+ # distributed under the License is distributed on an "AS IS" BASIS,
+ # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ # See the License for the specific language governing permissions and
+ # limitations under the License.
+ 
+ import os
+ import pkg_resources
+ import sys
+ 
+ import setuptools
+ 
+ from grpc_tools import protoc
+ 
+ 
+ def build_package_protos(package_root, strict_mode=False):
+     proto_files = []
+     inclusion_root = os.path.abspath(package_root)
+     for root, _, files in os.walk(inclusion_root):
+         for filename in files:
+             if filename.endswith('.proto'):
+                 proto_files.append(os.path.abspath(os.path.join(root,
+                                                                 filename)))
+ 
+     well_known_protos_include = pkg_resources.resource_filename(
+         'grpc_tools', '_proto')
+ 
+     for proto_file in proto_files:
+         command = [
+             'grpc_tools.protoc',
+             '--proto_path={}'.format(inclusion_root),
+             '--proto_path={}'.format(well_known_protos_include),
+             '--python_out={}'.format(inclusion_root),
+             '--grpc_python_out={}'.format(inclusion_root),
+         ] + [proto_file]
+         if protoc.main(command) != 0:
+             if strict_mode:
+                 raise Exception('error: {} failed'.format(command))
+             else:
+                 sys.stderr.write('warning: {} failed'.format(command))
+ 
+ 
+ class BuildPackageProtos(setuptools.Command):
+     """Command to generate project *_pb2.py modules from proto files."""
+ 
+     description = 'build grpc protobuf modules'
+     user_options = [('strict-mode', 's',
+                      'exit with non-zero value if the proto compiling fails.')]
+ 
+     def initialize_options(self):
+         self.strict_mode = False
+ 
+     def finalize_options(self):
+         pass
+ 
+     def run(self):
+         # due to limitations of the proto generator, we require that only *one*
+         # directory is provided as an 'include' directory. We assume it's the '' key
+         # to `self.distribution.package_dir` (and get a key error if it's not
+         # there).
+         build_package_protos(self.distribution.package_dir[''],
+                              self.strict_mode)
diff -crB --new-file ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/__init__.py
*** ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/__init__.py	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/__init__.py	2022-07-14 19:50:30.157821781 -0700
***************
*** 0 ****
--- 1,13 ----
+ # Copyright 2016 gRPC authors.
+ #
+ # Licensed under the Apache License, Version 2.0 (the "License");
+ # you may not use this file except in compliance with the License.
+ # You may obtain a copy of the License at
+ #
+ #     http://www.apache.org/licenses/LICENSE-2.0
+ #
+ # Unless required by applicable law or agreed to in writing, software
+ # distributed under the License is distributed on an "AS IS" BASIS,
+ # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ # See the License for the specific language governing permissions and
+ # limitations under the License.
diff -crB --new-file ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/any.proto ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/any.proto
*** ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/any.proto	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/any.proto	2022-07-14 19:50:30.221821780 -0700
***************
*** 0 ****
--- 1,155 ----
+ // Protocol Buffers - Google's data interchange format
+ // Copyright 2008 Google Inc.  All rights reserved.
+ // https://developers.google.com/protocol-buffers/
+ //
+ // Redistribution and use in source and binary forms, with or without
+ // modification, are permitted provided that the following conditions are
+ // met:
+ //
+ //     * Redistributions of source code must retain the above copyright
+ // notice, this list of conditions and the following disclaimer.
+ //     * Redistributions in binary form must reproduce the above
+ // copyright notice, this list of conditions and the following disclaimer
+ // in the documentation and/or other materials provided with the
+ // distribution.
+ //     * Neither the name of Google Inc. nor the names of its
+ // contributors may be used to endorse or promote products derived from
+ // this software without specific prior written permission.
+ //
+ // THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ // "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ // LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ // A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ // OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ // SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ // LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ // DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ // THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ // (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ // OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ 
+ syntax = "proto3";
+ 
+ package google.protobuf;
+ 
+ option csharp_namespace = "Google.Protobuf.WellKnownTypes";
+ option go_package = "github.com/golang/protobuf/ptypes/any";
+ option java_package = "com.google.protobuf";
+ option java_outer_classname = "AnyProto";
+ option java_multiple_files = true;
+ option objc_class_prefix = "GPB";
+ 
+ // `Any` contains an arbitrary serialized protocol buffer message along with a
+ // URL that describes the type of the serialized message.
+ //
+ // Protobuf library provides support to pack/unpack Any values in the form
+ // of utility functions or additional generated methods of the Any type.
+ //
+ // Example 1: Pack and unpack a message in C++.
+ //
+ //     Foo foo = ...;
+ //     Any any;
+ //     any.PackFrom(foo);
+ //     ...
+ //     if (any.UnpackTo(&foo)) {
+ //       ...
+ //     }
+ //
+ // Example 2: Pack and unpack a message in Java.
+ //
+ //     Foo foo = ...;
+ //     Any any = Any.pack(foo);
+ //     ...
+ //     if (any.is(Foo.class)) {
+ //       foo = any.unpack(Foo.class);
+ //     }
+ //
+ //  Example 3: Pack and unpack a message in Python.
+ //
+ //     foo = Foo(...)
+ //     any = Any()
+ //     any.Pack(foo)
+ //     ...
+ //     if any.Is(Foo.DESCRIPTOR):
+ //       any.Unpack(foo)
+ //       ...
+ //
+ //  Example 4: Pack and unpack a message in Go
+ //
+ //      foo := &pb.Foo{...}
+ //      any, err := ptypes.MarshalAny(foo)
+ //      ...
+ //      foo := &pb.Foo{}
+ //      if err := ptypes.UnmarshalAny(any, foo); err != nil {
+ //        ...
+ //      }
+ //
+ // The pack methods provided by protobuf library will by default use
+ // 'type.googleapis.com/full.type.name' as the type URL and the unpack
+ // methods only use the fully qualified type name after the last '/'
+ // in the type URL, for example "foo.bar.com/x/y.z" will yield type
+ // name "y.z".
+ //
+ //
+ // JSON
+ // ====
+ // The JSON representation of an `Any` value uses the regular
+ // representation of the deserialized, embedded message, with an
+ // additional field `@type` which contains the type URL. Example:
+ //
+ //     package google.profile;
+ //     message Person {
+ //       string first_name = 1;
+ //       string last_name = 2;
+ //     }
+ //
+ //     {
+ //       "@type": "type.googleapis.com/google.profile.Person",
+ //       "firstName": <string>,
+ //       "lastName": <string>
+ //     }
+ //
+ // If the embedded message type is well-known and has a custom JSON
+ // representation, that representation will be embedded adding a field
+ // `value` which holds the custom JSON in addition to the `@type`
+ // field. Example (for message [google.protobuf.Duration][]):
+ //
+ //     {
+ //       "@type": "type.googleapis.com/google.protobuf.Duration",
+ //       "value": "1.212s"
+ //     }
+ //
+ message Any {
+   // A URL/resource name that uniquely identifies the type of the serialized
+   // protocol buffer message. This string must contain at least
+   // one "/" character. The last segment of the URL's path must represent
+   // the fully qualified name of the type (as in
+   // `path/google.protobuf.Duration`). The name should be in a canonical form
+   // (e.g., leading "." is not accepted).
+   //
+   // In practice, teams usually precompile into the binary all types that they
+   // expect it to use in the context of Any. However, for URLs which use the
+   // scheme `http`, `https`, or no scheme, one can optionally set up a type
+   // server that maps type URLs to message definitions as follows:
+   //
+   // * If no scheme is provided, `https` is assumed.
+   // * An HTTP GET on the URL must yield a [google.protobuf.Type][]
+   //   value in binary format, or produce an error.
+   // * Applications are allowed to cache lookup results based on the
+   //   URL, or have them precompiled into a binary to avoid any
+   //   lookup. Therefore, binary compatibility needs to be preserved
+   //   on changes to types. (Use versioned type names to manage
+   //   breaking changes.)
+   //
+   // Note: this functionality is not currently available in the official
+   // protobuf release, and it is not used for type URLs beginning with
+   // type.googleapis.com.
+   //
+   // Schemes other than `http`, `https` (or the empty scheme) might be
+   // used with implementation specific semantics.
+   //
+   string type_url = 1;
+ 
+   // Must be a valid serialized protocol buffer of the above specified type.
+   bytes value = 2;
+ }
diff -crB --new-file ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/api.proto ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/api.proto
*** ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/api.proto	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/api.proto	2022-07-14 19:50:30.221821780 -0700
***************
*** 0 ****
--- 1,210 ----
+ // Protocol Buffers - Google's data interchange format
+ // Copyright 2008 Google Inc.  All rights reserved.
+ // https://developers.google.com/protocol-buffers/
+ //
+ // Redistribution and use in source and binary forms, with or without
+ // modification, are permitted provided that the following conditions are
+ // met:
+ //
+ //     * Redistributions of source code must retain the above copyright
+ // notice, this list of conditions and the following disclaimer.
+ //     * Redistributions in binary form must reproduce the above
+ // copyright notice, this list of conditions and the following disclaimer
+ // in the documentation and/or other materials provided with the
+ // distribution.
+ //     * Neither the name of Google Inc. nor the names of its
+ // contributors may be used to endorse or promote products derived from
+ // this software without specific prior written permission.
+ //
+ // THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ // "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ // LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ // A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ // OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ // SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ // LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ // DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ // THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ // (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ // OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ 
+ syntax = "proto3";
+ 
+ package google.protobuf;
+ 
+ import "google/protobuf/source_context.proto";
+ import "google/protobuf/type.proto";
+ 
+ option csharp_namespace = "Google.Protobuf.WellKnownTypes";
+ option java_package = "com.google.protobuf";
+ option java_outer_classname = "ApiProto";
+ option java_multiple_files = true;
+ option objc_class_prefix = "GPB";
+ option go_package = "google.golang.org/genproto/protobuf/api;api";
+ 
+ // Api is a light-weight descriptor for an API Interface.
+ //
+ // Interfaces are also described as "protocol buffer services" in some contexts,
+ // such as by the "service" keyword in a .proto file, but they are different
+ // from API Services, which represent a concrete implementation of an interface
+ // as opposed to simply a description of methods and bindings. They are also
+ // sometimes simply referred to as "APIs" in other contexts, such as the name of
+ // this message itself. See https://cloud.google.com/apis/design/glossary for
+ // detailed terminology.
+ message Api {
+ 
+   // The fully qualified name of this interface, including package name
+   // followed by the interface's simple name.
+   string name = 1;
+ 
+   // The methods of this interface, in unspecified order.
+   repeated Method methods = 2;
+ 
+   // Any metadata attached to the interface.
+   repeated Option options = 3;
+ 
+   // A version string for this interface. If specified, must have the form
+   // `major-version.minor-version`, as in `1.10`. If the minor version is
+   // omitted, it defaults to zero. If the entire version field is empty, the
+   // major version is derived from the package name, as outlined below. If the
+   // field is not empty, the version in the package name will be verified to be
+   // consistent with what is provided here.
+   //
+   // The versioning schema uses [semantic
+   // versioning](http://semver.org) where the major version number
+   // indicates a breaking change and the minor version an additive,
+   // non-breaking change. Both version numbers are signals to users
+   // what to expect from different versions, and should be carefully
+   // chosen based on the product plan.
+   //
+   // The major version is also reflected in the package name of the
+   // interface, which must end in `v<major-version>`, as in
+   // `google.feature.v1`. For major versions 0 and 1, the suffix can
+   // be omitted. Zero major versions must only be used for
+   // experimental, non-GA interfaces.
+   //
+   //
+   string version = 4;
+ 
+   // Source context for the protocol buffer service represented by this
+   // message.
+   SourceContext source_context = 5;
+ 
+   // Included interfaces. See [Mixin][].
+   repeated Mixin mixins = 6;
+ 
+   // The source syntax of the service.
+   Syntax syntax = 7;
+ }
+ 
+ // Method represents a method of an API interface.
+ message Method {
+ 
+   // The simple name of this method.
+   string name = 1;
+ 
+   // A URL of the input message type.
+   string request_type_url = 2;
+ 
+   // If true, the request is streamed.
+   bool request_streaming = 3;
+ 
+   // The URL of the output message type.
+   string response_type_url = 4;
+ 
+   // If true, the response is streamed.
+   bool response_streaming = 5;
+ 
+   // Any metadata attached to the method.
+   repeated Option options = 6;
+ 
+   // The source syntax of this method.
+   Syntax syntax = 7;
+ }
+ 
+ // Declares an API Interface to be included in this interface. The including
+ // interface must redeclare all the methods from the included interface, but
+ // documentation and options are inherited as follows:
+ //
+ // - If after comment and whitespace stripping, the documentation
+ //   string of the redeclared method is empty, it will be inherited
+ //   from the original method.
+ //
+ // - Each annotation belonging to the service config (http,
+ //   visibility) which is not set in the redeclared method will be
+ //   inherited.
+ //
+ // - If an http annotation is inherited, the path pattern will be
+ //   modified as follows. Any version prefix will be replaced by the
+ //   version of the including interface plus the [root][] path if
+ //   specified.
+ //
+ // Example of a simple mixin:
+ //
+ //     package google.acl.v1;
+ //     service AccessControl {
+ //       // Get the underlying ACL object.
+ //       rpc GetAcl(GetAclRequest) returns (Acl) {
+ //         option (google.api.http).get = "/v1/{resource=**}:getAcl";
+ //       }
+ //     }
+ //
+ //     package google.storage.v2;
+ //     service Storage {
+ //       rpc GetAcl(GetAclRequest) returns (Acl);
+ //
+ //       // Get a data record.
+ //       rpc GetData(GetDataRequest) returns (Data) {
+ //         option (google.api.http).get = "/v2/{resource=**}";
+ //       }
+ //     }
+ //
+ // Example of a mixin configuration:
+ //
+ //     apis:
+ //     - name: google.storage.v2.Storage
+ //       mixins:
+ //       - name: google.acl.v1.AccessControl
+ //
+ // The mixin construct implies that all methods in `AccessControl` are
+ // also declared with same name and request/response types in
+ // `Storage`. A documentation generator or annotation processor will
+ // see the effective `Storage.GetAcl` method after inherting
+ // documentation and annotations as follows:
+ //
+ //     service Storage {
+ //       // Get the underlying ACL object.
+ //       rpc GetAcl(GetAclRequest) returns (Acl) {
+ //         option (google.api.http).get = "/v2/{resource=**}:getAcl";
+ //       }
+ //       ...
+ //     }
+ //
+ // Note how the version in the path pattern changed from `v1` to `v2`.
+ //
+ // If the `root` field in the mixin is specified, it should be a
+ // relative path under which inherited HTTP paths are placed. Example:
+ //
+ //     apis:
+ //     - name: google.storage.v2.Storage
+ //       mixins:
+ //       - name: google.acl.v1.AccessControl
+ //         root: acls
+ //
+ // This implies the following inherited HTTP annotation:
+ //
+ //     service Storage {
+ //       // Get the underlying ACL object.
+ //       rpc GetAcl(GetAclRequest) returns (Acl) {
+ //         option (google.api.http).get = "/v2/acls/{resource=**}:getAcl";
+ //       }
+ //       ...
+ //     }
+ message Mixin {
+   // The fully qualified name of the interface which is included.
+   string name = 1;
+ 
+   // If non-empty specifies a path under which inherited HTTP paths
+   // are rooted.
+   string root = 2;
+ }
diff -crB --new-file ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/compiler/plugin.proto ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/compiler/plugin.proto
*** ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/compiler/plugin.proto	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/compiler/plugin.proto	2022-07-14 19:50:30.221821780 -0700
***************
*** 0 ****
--- 1,178 ----
+ // Protocol Buffers - Google's data interchange format
+ // Copyright 2008 Google Inc.  All rights reserved.
+ // https://developers.google.com/protocol-buffers/
+ //
+ // Redistribution and use in source and binary forms, with or without
+ // modification, are permitted provided that the following conditions are
+ // met:
+ //
+ //     * Redistributions of source code must retain the above copyright
+ // notice, this list of conditions and the following disclaimer.
+ //     * Redistributions in binary form must reproduce the above
+ // copyright notice, this list of conditions and the following disclaimer
+ // in the documentation and/or other materials provided with the
+ // distribution.
+ //     * Neither the name of Google Inc. nor the names of its
+ // contributors may be used to endorse or promote products derived from
+ // this software without specific prior written permission.
+ //
+ // THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ // "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ // LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ // A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ // OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ // SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ // LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ // DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ // THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ // (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ // OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ 
+ // Author: kenton@google.com (Kenton Varda)
+ //
+ // WARNING:  The plugin interface is currently EXPERIMENTAL and is subject to
+ //   change.
+ //
+ // protoc (aka the Protocol Compiler) can be extended via plugins.  A plugin is
+ // just a program that reads a CodeGeneratorRequest from stdin and writes a
+ // CodeGeneratorResponse to stdout.
+ //
+ // Plugins written using C++ can use google/protobuf/compiler/plugin.h instead
+ // of dealing with the raw protocol defined here.
+ //
+ // A plugin executable needs only to be placed somewhere in the path.  The
+ // plugin should be named "protoc-gen-$NAME", and will then be used when the
+ // flag "--${NAME}_out" is passed to protoc.
+ 
+ syntax = "proto2";
+ 
+ package google.protobuf.compiler;
+ option java_package = "com.google.protobuf.compiler";
+ option java_outer_classname = "PluginProtos";
+ 
+ option go_package = "github.com/golang/protobuf/protoc-gen-go/plugin;plugin_go";
+ 
+ import "google/protobuf/descriptor.proto";
+ 
+ // The version number of protocol compiler.
+ message Version {
+   optional int32 major = 1;
+   optional int32 minor = 2;
+   optional int32 patch = 3;
+   // A suffix for alpha, beta or rc release, e.g., "alpha-1", "rc2". It should
+   // be empty for mainline stable releases.
+   optional string suffix = 4;
+ }
+ 
+ // An encoded CodeGeneratorRequest is written to the plugin's stdin.
+ message CodeGeneratorRequest {
+   // The .proto files that were explicitly listed on the command-line.  The
+   // code generator should generate code only for these files.  Each file's
+   // descriptor will be included in proto_file, below.
+   repeated string file_to_generate = 1;
+ 
+   // The generator parameter passed on the command-line.
+   optional string parameter = 2;
+ 
+   // FileDescriptorProtos for all files in files_to_generate and everything
+   // they import.  The files will appear in topological order, so each file
+   // appears before any file that imports it.
+   //
+   // protoc guarantees that all proto_files will be written after
+   // the fields above, even though this is not technically guaranteed by the
+   // protobuf wire format.  This theoretically could allow a plugin to stream
+   // in the FileDescriptorProtos and handle them one by one rather than read
+   // the entire set into memory at once.  However, as of this writing, this
+   // is not similarly optimized on protoc's end -- it will store all fields in
+   // memory at once before sending them to the plugin.
+   //
+   // Type names of fields and extensions in the FileDescriptorProto are always
+   // fully qualified.
+   repeated FileDescriptorProto proto_file = 15;
+ 
+   // The version number of protocol compiler.
+   optional Version compiler_version = 3;
+ 
+ }
+ 
+ // The plugin writes an encoded CodeGeneratorResponse to stdout.
+ message CodeGeneratorResponse {
+   // Error message.  If non-empty, code generation failed.  The plugin process
+   // should exit with status code zero even if it reports an error in this way.
+   //
+   // This should be used to indicate errors in .proto files which prevent the
+   // code generator from generating correct code.  Errors which indicate a
+   // problem in protoc itself -- such as the input CodeGeneratorRequest being
+   // unparseable -- should be reported by writing a message to stderr and
+   // exiting with a non-zero status code.
+   optional string error = 1;
+ 
+   // A bitmask of supported features that the code generator supports.
+   // This is a bitwise "or" of values from the Feature enum.
+   optional uint64 supported_features = 2;
+ 
+   // Sync with code_generator.h.
+   enum Feature {
+     FEATURE_NONE = 0;
+     FEATURE_PROTO3_OPTIONAL = 1;
+   }
+ 
+   // Represents a single generated file.
+   message File {
+     // The file name, relative to the output directory.  The name must not
+     // contain "." or ".." components and must be relative, not be absolute (so,
+     // the file cannot lie outside the output directory).  "/" must be used as
+     // the path separator, not "\".
+     //
+     // If the name is omitted, the content will be appended to the previous
+     // file.  This allows the generator to break large files into small chunks,
+     // and allows the generated text to be streamed back to protoc so that large
+     // files need not reside completely in memory at one time.  Note that as of
+     // this writing protoc does not optimize for this -- it will read the entire
+     // CodeGeneratorResponse before writing files to disk.
+     optional string name = 1;
+ 
+     // If non-empty, indicates that the named file should already exist, and the
+     // content here is to be inserted into that file at a defined insertion
+     // point.  This feature allows a code generator to extend the output
+     // produced by another code generator.  The original generator may provide
+     // insertion points by placing special annotations in the file that look
+     // like:
+     //   @@protoc_insertion_point(NAME)
+     // The annotation can have arbitrary text before and after it on the line,
+     // which allows it to be placed in a comment.  NAME should be replaced with
+     // an identifier naming the point -- this is what other generators will use
+     // as the insertion_point.  Code inserted at this point will be placed
+     // immediately above the line containing the insertion point (thus multiple
+     // insertions to the same point will come out in the order they were added).
+     // The double-@ is intended to make it unlikely that the generated code
+     // could contain things that look like insertion points by accident.
+     //
+     // For example, the C++ code generator places the following line in the
+     // .pb.h files that it generates:
+     //   // @@protoc_insertion_point(namespace_scope)
+     // This line appears within the scope of the file's package namespace, but
+     // outside of any particular class.  Another plugin can then specify the
+     // insertion_point "namespace_scope" to generate additional classes or
+     // other declarations that should be placed in this scope.
+     //
+     // Note that if the line containing the insertion point begins with
+     // whitespace, the same whitespace will be added to every line of the
+     // inserted text.  This is useful for languages like Python, where
+     // indentation matters.  In these languages, the insertion point comment
+     // should be indented the same amount as any inserted code will need to be
+     // in order to work correctly in that context.
+     //
+     // The code generator that generates the initial file and the one which
+     // inserts into it must both run as part of a single invocation of protoc.
+     // Code generators are executed in the order in which they appear on the
+     // command line.
+     //
+     // If |insertion_point| is present, |name| must also be present.
+     optional string insertion_point = 2;
+ 
+     // The file contents.
+     optional string content = 15;
+   }
+   repeated File file = 15;
+ }
diff -crB --new-file ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/descriptor.proto ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/descriptor.proto
*** ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/descriptor.proto	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/descriptor.proto	2022-07-14 19:50:30.221821780 -0700
***************
*** 0 ****
--- 1,909 ----
+ // Protocol Buffers - Google's data interchange format
+ // Copyright 2008 Google Inc.  All rights reserved.
+ // https://developers.google.com/protocol-buffers/
+ //
+ // Redistribution and use in source and binary forms, with or without
+ // modification, are permitted provided that the following conditions are
+ // met:
+ //
+ //     * Redistributions of source code must retain the above copyright
+ // notice, this list of conditions and the following disclaimer.
+ //     * Redistributions in binary form must reproduce the above
+ // copyright notice, this list of conditions and the following disclaimer
+ // in the documentation and/or other materials provided with the
+ // distribution.
+ //     * Neither the name of Google Inc. nor the names of its
+ // contributors may be used to endorse or promote products derived from
+ // this software without specific prior written permission.
+ //
+ // THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ // "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ // LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ // A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ // OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ // SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ // LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ // DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ // THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ // (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ // OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ 
+ // Author: kenton@google.com (Kenton Varda)
+ //  Based on original Protocol Buffers design by
+ //  Sanjay Ghemawat, Jeff Dean, and others.
+ //
+ // The messages in this file describe the definitions found in .proto files.
+ // A valid .proto file can be translated directly to a FileDescriptorProto
+ // without any other information (e.g. without reading its imports).
+ 
+ 
+ syntax = "proto2";
+ 
+ package google.protobuf;
+ 
+ option go_package = "github.com/golang/protobuf/protoc-gen-go/descriptor;descriptor";
+ option java_package = "com.google.protobuf";
+ option java_outer_classname = "DescriptorProtos";
+ option csharp_namespace = "Google.Protobuf.Reflection";
+ option objc_class_prefix = "GPB";
+ option cc_enable_arenas = true;
+ 
+ // descriptor.proto must be optimized for speed because reflection-based
+ // algorithms don't work during bootstrapping.
+ option optimize_for = SPEED;
+ 
+ // The protocol compiler can output a FileDescriptorSet containing the .proto
+ // files it parses.
+ message FileDescriptorSet {
+   repeated FileDescriptorProto file = 1;
+ }
+ 
+ // Describes a complete .proto file.
+ message FileDescriptorProto {
+   optional string name = 1;     // file name, relative to root of source tree
+   optional string package = 2;  // e.g. "foo", "foo.bar", etc.
+ 
+   // Names of files imported by this file.
+   repeated string dependency = 3;
+   // Indexes of the public imported files in the dependency list above.
+   repeated int32 public_dependency = 10;
+   // Indexes of the weak imported files in the dependency list.
+   // For Google-internal migration only. Do not use.
+   repeated int32 weak_dependency = 11;
+ 
+   // All top-level definitions in this file.
+   repeated DescriptorProto message_type = 4;
+   repeated EnumDescriptorProto enum_type = 5;
+   repeated ServiceDescriptorProto service = 6;
+   repeated FieldDescriptorProto extension = 7;
+ 
+   optional FileOptions options = 8;
+ 
+   // This field contains optional information about the original source code.
+   // You may safely remove this entire field without harming runtime
+   // functionality of the descriptors -- the information is needed only by
+   // development tools.
+   optional SourceCodeInfo source_code_info = 9;
+ 
+   // The syntax of the proto file.
+   // The supported values are "proto2" and "proto3".
+   optional string syntax = 12;
+ }
+ 
+ // Describes a message type.
+ message DescriptorProto {
+   optional string name = 1;
+ 
+   repeated FieldDescriptorProto field = 2;
+   repeated FieldDescriptorProto extension = 6;
+ 
+   repeated DescriptorProto nested_type = 3;
+   repeated EnumDescriptorProto enum_type = 4;
+ 
+   message ExtensionRange {
+     optional int32 start = 1;  // Inclusive.
+     optional int32 end = 2;    // Exclusive.
+ 
+     optional ExtensionRangeOptions options = 3;
+   }
+   repeated ExtensionRange extension_range = 5;
+ 
+   repeated OneofDescriptorProto oneof_decl = 8;
+ 
+   optional MessageOptions options = 7;
+ 
+   // Range of reserved tag numbers. Reserved tag numbers may not be used by
+   // fields or extension ranges in the same message. Reserved ranges may
+   // not overlap.
+   message ReservedRange {
+     optional int32 start = 1;  // Inclusive.
+     optional int32 end = 2;    // Exclusive.
+   }
+   repeated ReservedRange reserved_range = 9;
+   // Reserved field names, which may not be used by fields in the same message.
+   // A given name may only be reserved once.
+   repeated string reserved_name = 10;
+ }
+ 
+ message ExtensionRangeOptions {
+   // The parser stores options it doesn't recognize here. See above.
+   repeated UninterpretedOption uninterpreted_option = 999;
+ 
+ 
+   // Clients can define custom options in extensions of this message. See above.
+   extensions 1000 to max;
+ }
+ 
+ // Describes a field within a message.
+ message FieldDescriptorProto {
+   enum Type {
+     // 0 is reserved for errors.
+     // Order is weird for historical reasons.
+     TYPE_DOUBLE = 1;
+     TYPE_FLOAT = 2;
+     // Not ZigZag encoded.  Negative numbers take 10 bytes.  Use TYPE_SINT64 if
+     // negative values are likely.
+     TYPE_INT64 = 3;
+     TYPE_UINT64 = 4;
+     // Not ZigZag encoded.  Negative numbers take 10 bytes.  Use TYPE_SINT32 if
+     // negative values are likely.
+     TYPE_INT32 = 5;
+     TYPE_FIXED64 = 6;
+     TYPE_FIXED32 = 7;
+     TYPE_BOOL = 8;
+     TYPE_STRING = 9;
+     // Tag-delimited aggregate.
+     // Group type is deprecated and not supported in proto3. However, Proto3
+     // implementations should still be able to parse the group wire format and
+     // treat group fields as unknown fields.
+     TYPE_GROUP = 10;
+     TYPE_MESSAGE = 11;  // Length-delimited aggregate.
+ 
+     // New in version 2.
+     TYPE_BYTES = 12;
+     TYPE_UINT32 = 13;
+     TYPE_ENUM = 14;
+     TYPE_SFIXED32 = 15;
+     TYPE_SFIXED64 = 16;
+     TYPE_SINT32 = 17;  // Uses ZigZag encoding.
+     TYPE_SINT64 = 18;  // Uses ZigZag encoding.
+   }
+ 
+   enum Label {
+     // 0 is reserved for errors
+     LABEL_OPTIONAL = 1;
+     LABEL_REQUIRED = 2;
+     LABEL_REPEATED = 3;
+   }
+ 
+   optional string name = 1;
+   optional int32 number = 3;
+   optional Label label = 4;
+ 
+   // If type_name is set, this need not be set.  If both this and type_name
+   // are set, this must be one of TYPE_ENUM, TYPE_MESSAGE or TYPE_GROUP.
+   optional Type type = 5;
+ 
+   // For message and enum types, this is the name of the type.  If the name
+   // starts with a '.', it is fully-qualified.  Otherwise, C++-like scoping
+   // rules are used to find the type (i.e. first the nested types within this
+   // message are searched, then within the parent, on up to the root
+   // namespace).
+   optional string type_name = 6;
+ 
+   // For extensions, this is the name of the type being extended.  It is
+   // resolved in the same manner as type_name.
+   optional string extendee = 2;
+ 
+   // For numeric types, contains the original text representation of the value.
+   // For booleans, "true" or "false".
+   // For strings, contains the default text contents (not escaped in any way).
+   // For bytes, contains the C escaped value.  All bytes >= 128 are escaped.
+   // TODO(kenton):  Base-64 encode?
+   optional string default_value = 7;
+ 
+   // If set, gives the index of a oneof in the containing type's oneof_decl
+   // list.  This field is a member of that oneof.
+   optional int32 oneof_index = 9;
+ 
+   // JSON name of this field. The value is set by protocol compiler. If the
+   // user has set a "json_name" option on this field, that option's value
+   // will be used. Otherwise, it's deduced from the field's name by converting
+   // it to camelCase.
+   optional string json_name = 10;
+ 
+   optional FieldOptions options = 8;
+ 
+   // If true, this is a proto3 "optional". When a proto3 field is optional, it
+   // tracks presence regardless of field type.
+   //
+   // When proto3_optional is true, this field must be belong to a oneof to
+   // signal to old proto3 clients that presence is tracked for this field. This
+   // oneof is known as a "synthetic" oneof, and this field must be its sole
+   // member (each proto3 optional field gets its own synthetic oneof). Synthetic
+   // oneofs exist in the descriptor only, and do not generate any API. Synthetic
+   // oneofs must be ordered after all "real" oneofs.
+   //
+   // For message fields, proto3_optional doesn't create any semantic change,
+   // since non-repeated message fields always track presence. However it still
+   // indicates the semantic detail of whether the user wrote "optional" or not.
+   // This can be useful for round-tripping the .proto file. For consistency we
+   // give message fields a synthetic oneof also, even though it is not required
+   // to track presence. This is especially important because the parser can't
+   // tell if a field is a message or an enum, so it must always create a
+   // synthetic oneof.
+   //
+   // Proto2 optional fields do not set this flag, because they already indicate
+   // optional with `LABEL_OPTIONAL`.
+   optional bool proto3_optional = 17;
+ }
+ 
+ // Describes a oneof.
+ message OneofDescriptorProto {
+   optional string name = 1;
+   optional OneofOptions options = 2;
+ }
+ 
+ // Describes an enum type.
+ message EnumDescriptorProto {
+   optional string name = 1;
+ 
+   repeated EnumValueDescriptorProto value = 2;
+ 
+   optional EnumOptions options = 3;
+ 
+   // Range of reserved numeric values. Reserved values may not be used by
+   // entries in the same enum. Reserved ranges may not overlap.
+   //
+   // Note that this is distinct from DescriptorProto.ReservedRange in that it
+   // is inclusive such that it can appropriately represent the entire int32
+   // domain.
+   message EnumReservedRange {
+     optional int32 start = 1;  // Inclusive.
+     optional int32 end = 2;    // Inclusive.
+   }
+ 
+   // Range of reserved numeric values. Reserved numeric values may not be used
+   // by enum values in the same enum declaration. Reserved ranges may not
+   // overlap.
+   repeated EnumReservedRange reserved_range = 4;
+ 
+   // Reserved enum value names, which may not be reused. A given name may only
+   // be reserved once.
+   repeated string reserved_name = 5;
+ }
+ 
+ // Describes a value within an enum.
+ message EnumValueDescriptorProto {
+   optional string name = 1;
+   optional int32 number = 2;
+ 
+   optional EnumValueOptions options = 3;
+ }
+ 
+ // Describes a service.
+ message ServiceDescriptorProto {
+   optional string name = 1;
+   repeated MethodDescriptorProto method = 2;
+ 
+   optional ServiceOptions options = 3;
+ }
+ 
+ // Describes a method of a service.
+ message MethodDescriptorProto {
+   optional string name = 1;
+ 
+   // Input and output type names.  These are resolved in the same way as
+   // FieldDescriptorProto.type_name, but must refer to a message type.
+   optional string input_type = 2;
+   optional string output_type = 3;
+ 
+   optional MethodOptions options = 4;
+ 
+   // Identifies if client streams multiple client messages
+   optional bool client_streaming = 5 [default = false];
+   // Identifies if server streams multiple server messages
+   optional bool server_streaming = 6 [default = false];
+ }
+ 
+ 
+ // ===================================================================
+ // Options
+ 
+ // Each of the definitions above may have "options" attached.  These are
+ // just annotations which may cause code to be generated slightly differently
+ // or may contain hints for code that manipulates protocol messages.
+ //
+ // Clients may define custom options as extensions of the *Options messages.
+ // These extensions may not yet be known at parsing time, so the parser cannot
+ // store the values in them.  Instead it stores them in a field in the *Options
+ // message called uninterpreted_option. This field must have the same name
+ // across all *Options messages. We then use this field to populate the
+ // extensions when we build a descriptor, at which point all protos have been
+ // parsed and so all extensions are known.
+ //
+ // Extension numbers for custom options may be chosen as follows:
+ // * For options which will only be used within a single application or
+ //   organization, or for experimental options, use field numbers 50000
+ //   through 99999.  It is up to you to ensure that you do not use the
+ //   same number for multiple options.
+ // * For options which will be published and used publicly by multiple
+ //   independent entities, e-mail protobuf-global-extension-registry@google.com
+ //   to reserve extension numbers. Simply provide your project name (e.g.
+ //   Objective-C plugin) and your project website (if available) -- there's no
+ //   need to explain how you intend to use them. Usually you only need one
+ //   extension number. You can declare multiple options with only one extension
+ //   number by putting them in a sub-message. See the Custom Options section of
+ //   the docs for examples:
+ //   https://developers.google.com/protocol-buffers/docs/proto#options
+ //   If this turns out to be popular, a web service will be set up
+ //   to automatically assign option numbers.
+ 
+ message FileOptions {
+ 
+   // Sets the Java package where classes generated from this .proto will be
+   // placed.  By default, the proto package is used, but this is often
+   // inappropriate because proto packages do not normally start with backwards
+   // domain names.
+   optional string java_package = 1;
+ 
+ 
+   // If set, all the classes from the .proto file are wrapped in a single
+   // outer class with the given name.  This applies to both Proto1
+   // (equivalent to the old "--one_java_file" option) and Proto2 (where
+   // a .proto always translates to a single class, but you may want to
+   // explicitly choose the class name).
+   optional string java_outer_classname = 8;
+ 
+   // If set true, then the Java code generator will generate a separate .java
+   // file for each top-level message, enum, and service defined in the .proto
+   // file.  Thus, these types will *not* be nested inside the outer class
+   // named by java_outer_classname.  However, the outer class will still be
+   // generated to contain the file's getDescriptor() method as well as any
+   // top-level extensions defined in the file.
+   optional bool java_multiple_files = 10 [default = false];
+ 
+   // This option does nothing.
+   optional bool java_generate_equals_and_hash = 20 [deprecated=true];
+ 
+   // If set true, then the Java2 code generator will generate code that
+   // throws an exception whenever an attempt is made to assign a non-UTF-8
+   // byte sequence to a string field.
+   // Message reflection will do the same.
+   // However, an extension field still accepts non-UTF-8 byte sequences.
+   // This option has no effect on when used with the lite runtime.
+   optional bool java_string_check_utf8 = 27 [default = false];
+ 
+ 
+   // Generated classes can be optimized for speed or code size.
+   enum OptimizeMode {
+     SPEED = 1;         // Generate complete code for parsing, serialization,
+                        // etc.
+     CODE_SIZE = 2;     // Use ReflectionOps to implement these methods.
+     LITE_RUNTIME = 3;  // Generate code using MessageLite and the lite runtime.
+   }
+   optional OptimizeMode optimize_for = 9 [default = SPEED];
+ 
+   // Sets the Go package where structs generated from this .proto will be
+   // placed. If omitted, the Go package will be derived from the following:
+   //   - The basename of the package import path, if provided.
+   //   - Otherwise, the package statement in the .proto file, if present.
+   //   - Otherwise, the basename of the .proto file, without extension.
+   optional string go_package = 11;
+ 
+ 
+ 
+ 
+   // Should generic services be generated in each language?  "Generic" services
+   // are not specific to any particular RPC system.  They are generated by the
+   // main code generators in each language (without additional plugins).
+   // Generic services were the only kind of service generation supported by
+   // early versions of google.protobuf.
+   //
+   // Generic services are now considered deprecated in favor of using plugins
+   // that generate code specific to your particular RPC system.  Therefore,
+   // these default to false.  Old code which depends on generic services should
+   // explicitly set them to true.
+   optional bool cc_generic_services = 16 [default = false];
+   optional bool java_generic_services = 17 [default = false];
+   optional bool py_generic_services = 18 [default = false];
+   optional bool php_generic_services = 42 [default = false];
+ 
+   // Is this file deprecated?
+   // Depending on the target platform, this can emit Deprecated annotations
+   // for everything in the file, or it will be completely ignored; in the very
+   // least, this is a formalization for deprecating files.
+   optional bool deprecated = 23 [default = false];
+ 
+   // Enables the use of arenas for the proto messages in this file. This applies
+   // only to generated classes for C++.
+   optional bool cc_enable_arenas = 31 [default = true];
+ 
+ 
+   // Sets the objective c class prefix which is prepended to all objective c
+   // generated classes from this .proto. There is no default.
+   optional string objc_class_prefix = 36;
+ 
+   // Namespace for generated classes; defaults to the package.
+   optional string csharp_namespace = 37;
+ 
+   // By default Swift generators will take the proto package and CamelCase it
+   // replacing '.' with underscore and use that to prefix the types/symbols
+   // defined. When this options is provided, they will use this value instead
+   // to prefix the types/symbols defined.
+   optional string swift_prefix = 39;
+ 
+   // Sets the php class prefix which is prepended to all php generated classes
+   // from this .proto. Default is empty.
+   optional string php_class_prefix = 40;
+ 
+   // Use this option to change the namespace of php generated classes. Default
+   // is empty. When this option is empty, the package name will be used for
+   // determining the namespace.
+   optional string php_namespace = 41;
+ 
+   // Use this option to change the namespace of php generated metadata classes.
+   // Default is empty. When this option is empty, the proto file name will be
+   // used for determining the namespace.
+   optional string php_metadata_namespace = 44;
+ 
+   // Use this option to change the package of ruby generated classes. Default
+   // is empty. When this option is not set, the package name will be used for
+   // determining the ruby package.
+   optional string ruby_package = 45;
+ 
+ 
+   // The parser stores options it doesn't recognize here.
+   // See the documentation for the "Options" section above.
+   repeated UninterpretedOption uninterpreted_option = 999;
+ 
+   // Clients can define custom options in extensions of this message.
+   // See the documentation for the "Options" section above.
+   extensions 1000 to max;
+ 
+   reserved 38;
+ }
+ 
+ message MessageOptions {
+   // Set true to use the old proto1 MessageSet wire format for extensions.
+   // This is provided for backwards-compatibility with the MessageSet wire
+   // format.  You should not use this for any other reason:  It's less
+   // efficient, has fewer features, and is more complicated.
+   //
+   // The message must be defined exactly as follows:
+   //   message Foo {
+   //     option message_set_wire_format = true;
+   //     extensions 4 to max;
+   //   }
+   // Note that the message cannot have any defined fields; MessageSets only
+   // have extensions.
+   //
+   // All extensions of your type must be singular messages; e.g. they cannot
+   // be int32s, enums, or repeated messages.
+   //
+   // Because this is an option, the above two restrictions are not enforced by
+   // the protocol compiler.
+   optional bool message_set_wire_format = 1 [default = false];
+ 
+   // Disables the generation of the standard "descriptor()" accessor, which can
+   // conflict with a field of the same name.  This is meant to make migration
+   // from proto1 easier; new code should avoid fields named "descriptor".
+   optional bool no_standard_descriptor_accessor = 2 [default = false];
+ 
+   // Is this message deprecated?
+   // Depending on the target platform, this can emit Deprecated annotations
+   // for the message, or it will be completely ignored; in the very least,
+   // this is a formalization for deprecating messages.
+   optional bool deprecated = 3 [default = false];
+ 
+   // Whether the message is an automatically generated map entry type for the
+   // maps field.
+   //
+   // For maps fields:
+   //     map<KeyType, ValueType> map_field = 1;
+   // The parsed descriptor looks like:
+   //     message MapFieldEntry {
+   //         option map_entry = true;
+   //         optional KeyType key = 1;
+   //         optional ValueType value = 2;
+   //     }
+   //     repeated MapFieldEntry map_field = 1;
+   //
+   // Implementations may choose not to generate the map_entry=true message, but
+   // use a native map in the target language to hold the keys and values.
+   // The reflection APIs in such implementations still need to work as
+   // if the field is a repeated message field.
+   //
+   // NOTE: Do not set the option in .proto files. Always use the maps syntax
+   // instead. The option should only be implicitly set by the proto compiler
+   // parser.
+   optional bool map_entry = 7;
+ 
+   reserved 8;  // javalite_serializable
+   reserved 9;  // javanano_as_lite
+ 
+ 
+   // The parser stores options it doesn't recognize here. See above.
+   repeated UninterpretedOption uninterpreted_option = 999;
+ 
+   // Clients can define custom options in extensions of this message. See above.
+   extensions 1000 to max;
+ }
+ 
+ message FieldOptions {
+   // The ctype option instructs the C++ code generator to use a different
+   // representation of the field than it normally would.  See the specific
+   // options below.  This option is not yet implemented in the open source
+   // release -- sorry, we'll try to include it in a future version!
+   optional CType ctype = 1 [default = STRING];
+   enum CType {
+     // Default mode.
+     STRING = 0;
+ 
+     CORD = 1;
+ 
+     STRING_PIECE = 2;
+   }
+   // The packed option can be enabled for repeated primitive fields to enable
+   // a more efficient representation on the wire. Rather than repeatedly
+   // writing the tag and type for each element, the entire array is encoded as
+   // a single length-delimited blob. In proto3, only explicit setting it to
+   // false will avoid using packed encoding.
+   optional bool packed = 2;
+ 
+   // The jstype option determines the JavaScript type used for values of the
+   // field.  The option is permitted only for 64 bit integral and fixed types
+   // (int64, uint64, sint64, fixed64, sfixed64).  A field with jstype JS_STRING
+   // is represented as JavaScript string, which avoids loss of precision that
+   // can happen when a large value is converted to a floating point JavaScript.
+   // Specifying JS_NUMBER for the jstype causes the generated JavaScript code to
+   // use the JavaScript "number" type.  The behavior of the default option
+   // JS_NORMAL is implementation dependent.
+   //
+   // This option is an enum to permit additional types to be added, e.g.
+   // goog.math.Integer.
+   optional JSType jstype = 6 [default = JS_NORMAL];
+   enum JSType {
+     // Use the default type.
+     JS_NORMAL = 0;
+ 
+     // Use JavaScript strings.
+     JS_STRING = 1;
+ 
+     // Use JavaScript numbers.
+     JS_NUMBER = 2;
+   }
+ 
+   // Should this field be parsed lazily?  Lazy applies only to message-type
+   // fields.  It means that when the outer message is initially parsed, the
+   // inner message's contents will not be parsed but instead stored in encoded
+   // form.  The inner message will actually be parsed when it is first accessed.
+   //
+   // This is only a hint.  Implementations are free to choose whether to use
+   // eager or lazy parsing regardless of the value of this option.  However,
+   // setting this option true suggests that the protocol author believes that
+   // using lazy parsing on this field is worth the additional bookkeeping
+   // overhead typically needed to implement it.
+   //
+   // This option does not affect the public interface of any generated code;
+   // all method signatures remain the same.  Furthermore, thread-safety of the
+   // interface is not affected by this option; const methods remain safe to
+   // call from multiple threads concurrently, while non-const methods continue
+   // to require exclusive access.
+   //
+   //
+   // Note that implementations may choose not to check required fields within
+   // a lazy sub-message.  That is, calling IsInitialized() on the outer message
+   // may return true even if the inner message has missing required fields.
+   // This is necessary because otherwise the inner message would have to be
+   // parsed in order to perform the check, defeating the purpose of lazy
+   // parsing.  An implementation which chooses not to check required fields
+   // must be consistent about it.  That is, for any particular sub-message, the
+   // implementation must either *always* check its required fields, or *never*
+   // check its required fields, regardless of whether or not the message has
+   // been parsed.
+   optional bool lazy = 5 [default = false];
+ 
+   // Is this field deprecated?
+   // Depending on the target platform, this can emit Deprecated annotations
+   // for accessors, or it will be completely ignored; in the very least, this
+   // is a formalization for deprecating fields.
+   optional bool deprecated = 3 [default = false];
+ 
+   // For Google-internal migration only. Do not use.
+   optional bool weak = 10 [default = false];
+ 
+ 
+   // The parser stores options it doesn't recognize here. See above.
+   repeated UninterpretedOption uninterpreted_option = 999;
+ 
+   // Clients can define custom options in extensions of this message. See above.
+   extensions 1000 to max;
+ 
+   reserved 4;  // removed jtype
+ }
+ 
+ message OneofOptions {
+   // The parser stores options it doesn't recognize here. See above.
+   repeated UninterpretedOption uninterpreted_option = 999;
+ 
+   // Clients can define custom options in extensions of this message. See above.
+   extensions 1000 to max;
+ }
+ 
+ message EnumOptions {
+ 
+   // Set this option to true to allow mapping different tag names to the same
+   // value.
+   optional bool allow_alias = 2;
+ 
+   // Is this enum deprecated?
+   // Depending on the target platform, this can emit Deprecated annotations
+   // for the enum, or it will be completely ignored; in the very least, this
+   // is a formalization for deprecating enums.
+   optional bool deprecated = 3 [default = false];
+ 
+   reserved 5;  // javanano_as_lite
+ 
+   // The parser stores options it doesn't recognize here. See above.
+   repeated UninterpretedOption uninterpreted_option = 999;
+ 
+   // Clients can define custom options in extensions of this message. See above.
+   extensions 1000 to max;
+ }
+ 
+ message EnumValueOptions {
+   // Is this enum value deprecated?
+   // Depending on the target platform, this can emit Deprecated annotations
+   // for the enum value, or it will be completely ignored; in the very least,
+   // this is a formalization for deprecating enum values.
+   optional bool deprecated = 1 [default = false];
+ 
+   // The parser stores options it doesn't recognize here. See above.
+   repeated UninterpretedOption uninterpreted_option = 999;
+ 
+   // Clients can define custom options in extensions of this message. See above.
+   extensions 1000 to max;
+ }
+ 
+ message ServiceOptions {
+ 
+   // Note:  Field numbers 1 through 32 are reserved for Google's internal RPC
+   //   framework.  We apologize for hoarding these numbers to ourselves, but
+   //   we were already using them long before we decided to release Protocol
+   //   Buffers.
+ 
+   // Is this service deprecated?
+   // Depending on the target platform, this can emit Deprecated annotations
+   // for the service, or it will be completely ignored; in the very least,
+   // this is a formalization for deprecating services.
+   optional bool deprecated = 33 [default = false];
+ 
+   // The parser stores options it doesn't recognize here. See above.
+   repeated UninterpretedOption uninterpreted_option = 999;
+ 
+   // Clients can define custom options in extensions of this message. See above.
+   extensions 1000 to max;
+ }
+ 
+ message MethodOptions {
+ 
+   // Note:  Field numbers 1 through 32 are reserved for Google's internal RPC
+   //   framework.  We apologize for hoarding these numbers to ourselves, but
+   //   we were already using them long before we decided to release Protocol
+   //   Buffers.
+ 
+   // Is this method deprecated?
+   // Depending on the target platform, this can emit Deprecated annotations
+   // for the method, or it will be completely ignored; in the very least,
+   // this is a formalization for deprecating methods.
+   optional bool deprecated = 33 [default = false];
+ 
+   // Is this method side-effect-free (or safe in HTTP parlance), or idempotent,
+   // or neither? HTTP based RPC implementation may choose GET verb for safe
+   // methods, and PUT verb for idempotent methods instead of the default POST.
+   enum IdempotencyLevel {
+     IDEMPOTENCY_UNKNOWN = 0;
+     NO_SIDE_EFFECTS = 1;  // implies idempotent
+     IDEMPOTENT = 2;       // idempotent, but may have side effects
+   }
+   optional IdempotencyLevel idempotency_level = 34
+       [default = IDEMPOTENCY_UNKNOWN];
+ 
+   // The parser stores options it doesn't recognize here. See above.
+   repeated UninterpretedOption uninterpreted_option = 999;
+ 
+   // Clients can define custom options in extensions of this message. See above.
+   extensions 1000 to max;
+ }
+ 
+ 
+ // A message representing a option the parser does not recognize. This only
+ // appears in options protos created by the compiler::Parser class.
+ // DescriptorPool resolves these when building Descriptor objects. Therefore,
+ // options protos in descriptor objects (e.g. returned by Descriptor::options(),
+ // or produced by Descriptor::CopyTo()) will never have UninterpretedOptions
+ // in them.
+ message UninterpretedOption {
+   // The name of the uninterpreted option.  Each string represents a segment in
+   // a dot-separated name.  is_extension is true iff a segment represents an
+   // extension (denoted with parentheses in options specs in .proto files).
+   // E.g.,{ ["foo", false], ["bar.baz", true], ["qux", false] } represents
+   // "foo.(bar.baz).qux".
+   message NamePart {
+     required string name_part = 1;
+     required bool is_extension = 2;
+   }
+   repeated NamePart name = 2;
+ 
+   // The value of the uninterpreted option, in whatever type the tokenizer
+   // identified it as during parsing. Exactly one of these should be set.
+   optional string identifier_value = 3;
+   optional uint64 positive_int_value = 4;
+   optional int64 negative_int_value = 5;
+   optional double double_value = 6;
+   optional bytes string_value = 7;
+   optional string aggregate_value = 8;
+ }
+ 
+ // ===================================================================
+ // Optional source code info
+ 
+ // Encapsulates information about the original source file from which a
+ // FileDescriptorProto was generated.
+ message SourceCodeInfo {
+   // A Location identifies a piece of source code in a .proto file which
+   // corresponds to a particular definition.  This information is intended
+   // to be useful to IDEs, code indexers, documentation generators, and similar
+   // tools.
+   //
+   // For example, say we have a file like:
+   //   message Foo {
+   //     optional string foo = 1;
+   //   }
+   // Let's look at just the field definition:
+   //   optional string foo = 1;
+   //   ^       ^^     ^^  ^  ^^^
+   //   a       bc     de  f  ghi
+   // We have the following locations:
+   //   span   path               represents
+   //   [a,i)  [ 4, 0, 2, 0 ]     The whole field definition.
+   //   [a,b)  [ 4, 0, 2, 0, 4 ]  The label (optional).
+   //   [c,d)  [ 4, 0, 2, 0, 5 ]  The type (string).
+   //   [e,f)  [ 4, 0, 2, 0, 1 ]  The name (foo).
+   //   [g,h)  [ 4, 0, 2, 0, 3 ]  The number (1).
+   //
+   // Notes:
+   // - A location may refer to a repeated field itself (i.e. not to any
+   //   particular index within it).  This is used whenever a set of elements are
+   //   logically enclosed in a single code segment.  For example, an entire
+   //   extend block (possibly containing multiple extension definitions) will
+   //   have an outer location whose path refers to the "extensions" repeated
+   //   field without an index.
+   // - Multiple locations may have the same path.  This happens when a single
+   //   logical declaration is spread out across multiple places.  The most
+   //   obvious example is the "extend" block again -- there may be multiple
+   //   extend blocks in the same scope, each of which will have the same path.
+   // - A location's span is not always a subset of its parent's span.  For
+   //   example, the "extendee" of an extension declaration appears at the
+   //   beginning of the "extend" block and is shared by all extensions within
+   //   the block.
+   // - Just because a location's span is a subset of some other location's span
+   //   does not mean that it is a descendant.  For example, a "group" defines
+   //   both a type and a field in a single declaration.  Thus, the locations
+   //   corresponding to the type and field and their components will overlap.
+   // - Code which tries to interpret locations should probably be designed to
+   //   ignore those that it doesn't understand, as more types of locations could
+   //   be recorded in the future.
+   repeated Location location = 1;
+   message Location {
+     // Identifies which part of the FileDescriptorProto was defined at this
+     // location.
+     //
+     // Each element is a field number or an index.  They form a path from
+     // the root FileDescriptorProto to the place where the definition.  For
+     // example, this path:
+     //   [ 4, 3, 2, 7, 1 ]
+     // refers to:
+     //   file.message_type(3)  // 4, 3
+     //       .field(7)         // 2, 7
+     //       .name()           // 1
+     // This is because FileDescriptorProto.message_type has field number 4:
+     //   repeated DescriptorProto message_type = 4;
+     // and DescriptorProto.field has field number 2:
+     //   repeated FieldDescriptorProto field = 2;
+     // and FieldDescriptorProto.name has field number 1:
+     //   optional string name = 1;
+     //
+     // Thus, the above path gives the location of a field name.  If we removed
+     // the last element:
+     //   [ 4, 3, 2, 7 ]
+     // this path refers to the whole field declaration (from the beginning
+     // of the label to the terminating semicolon).
+     repeated int32 path = 1 [packed = true];
+ 
+     // Always has exactly three or four elements: start line, start column,
+     // end line (optional, otherwise assumed same as start line), end column.
+     // These are packed into a single field for efficiency.  Note that line
+     // and column numbers are zero-based -- typically you will want to add
+     // 1 to each before displaying to a user.
+     repeated int32 span = 2 [packed = true];
+ 
+     // If this SourceCodeInfo represents a complete declaration, these are any
+     // comments appearing before and after the declaration which appear to be
+     // attached to the declaration.
+     //
+     // A series of line comments appearing on consecutive lines, with no other
+     // tokens appearing on those lines, will be treated as a single comment.
+     //
+     // leading_detached_comments will keep paragraphs of comments that appear
+     // before (but not connected to) the current element. Each paragraph,
+     // separated by empty lines, will be one comment element in the repeated
+     // field.
+     //
+     // Only the comment content is provided; comment markers (e.g. //) are
+     // stripped out.  For block comments, leading whitespace and an asterisk
+     // will be stripped from the beginning of each line other than the first.
+     // Newlines are included in the output.
+     //
+     // Examples:
+     //
+     //   optional int32 foo = 1;  // Comment attached to foo.
+     //   // Comment attached to bar.
+     //   optional int32 bar = 2;
+     //
+     //   optional string baz = 3;
+     //   // Comment attached to baz.
+     //   // Another line attached to baz.
+     //
+     //   // Comment attached to qux.
+     //   //
+     //   // Another line attached to qux.
+     //   optional double qux = 4;
+     //
+     //   // Detached comment for corge. This is not leading or trailing comments
+     //   // to qux or corge because there are blank lines separating it from
+     //   // both.
+     //
+     //   // Detached comment for corge paragraph 2.
+     //
+     //   optional string corge = 5;
+     //   /* Block comment attached
+     //    * to corge.  Leading asterisks
+     //    * will be removed. */
+     //   /* Block comment attached to
+     //    * grault. */
+     //   optional int32 grault = 6;
+     //
+     //   // ignored detached comments.
+     optional string leading_comments = 3;
+     optional string trailing_comments = 4;
+     repeated string leading_detached_comments = 6;
+   }
+ }
+ 
+ // Describes the relationship between generated code and its original source
+ // file. A GeneratedCodeInfo message is associated with only one generated
+ // source file, but may contain references to different source .proto files.
+ message GeneratedCodeInfo {
+   // An Annotation connects some span of text in generated code to an element
+   // of its generating .proto file.
+   repeated Annotation annotation = 1;
+   message Annotation {
+     // Identifies the element in the original source .proto file. This field
+     // is formatted the same as SourceCodeInfo.Location.path.
+     repeated int32 path = 1 [packed = true];
+ 
+     // Identifies the filesystem path to the original source .proto.
+     optional string source_file = 2;
+ 
+     // Identifies the starting offset in bytes in the generated code
+     // that relates to the identified object.
+     optional int32 begin = 3;
+ 
+     // Identifies the ending offset in bytes in the generated code that
+     // relates to the identified offset. The end offset should be one past
+     // the last relevant byte (so the length of the text = end - begin).
+     optional int32 end = 4;
+   }
+ }
diff -crB --new-file ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/duration.proto ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/duration.proto
*** ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/duration.proto	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/duration.proto	2022-07-14 19:50:30.221821780 -0700
***************
*** 0 ****
--- 1,116 ----
+ // Protocol Buffers - Google's data interchange format
+ // Copyright 2008 Google Inc.  All rights reserved.
+ // https://developers.google.com/protocol-buffers/
+ //
+ // Redistribution and use in source and binary forms, with or without
+ // modification, are permitted provided that the following conditions are
+ // met:
+ //
+ //     * Redistributions of source code must retain the above copyright
+ // notice, this list of conditions and the following disclaimer.
+ //     * Redistributions in binary form must reproduce the above
+ // copyright notice, this list of conditions and the following disclaimer
+ // in the documentation and/or other materials provided with the
+ // distribution.
+ //     * Neither the name of Google Inc. nor the names of its
+ // contributors may be used to endorse or promote products derived from
+ // this software without specific prior written permission.
+ //
+ // THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ // "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ // LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ // A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ // OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ // SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ // LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ // DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ // THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ // (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ // OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ 
+ syntax = "proto3";
+ 
+ package google.protobuf;
+ 
+ option csharp_namespace = "Google.Protobuf.WellKnownTypes";
+ option cc_enable_arenas = true;
+ option go_package = "github.com/golang/protobuf/ptypes/duration";
+ option java_package = "com.google.protobuf";
+ option java_outer_classname = "DurationProto";
+ option java_multiple_files = true;
+ option objc_class_prefix = "GPB";
+ 
+ // A Duration represents a signed, fixed-length span of time represented
+ // as a count of seconds and fractions of seconds at nanosecond
+ // resolution. It is independent of any calendar and concepts like "day"
+ // or "month". It is related to Timestamp in that the difference between
+ // two Timestamp values is a Duration and it can be added or subtracted
+ // from a Timestamp. Range is approximately +-10,000 years.
+ //
+ // # Examples
+ //
+ // Example 1: Compute Duration from two Timestamps in pseudo code.
+ //
+ //     Timestamp start = ...;
+ //     Timestamp end = ...;
+ //     Duration duration = ...;
+ //
+ //     duration.seconds = end.seconds - start.seconds;
+ //     duration.nanos = end.nanos - start.nanos;
+ //
+ //     if (duration.seconds < 0 && duration.nanos > 0) {
+ //       duration.seconds += 1;
+ //       duration.nanos -= 1000000000;
+ //     } else if (duration.seconds > 0 && duration.nanos < 0) {
+ //       duration.seconds -= 1;
+ //       duration.nanos += 1000000000;
+ //     }
+ //
+ // Example 2: Compute Timestamp from Timestamp + Duration in pseudo code.
+ //
+ //     Timestamp start = ...;
+ //     Duration duration = ...;
+ //     Timestamp end = ...;
+ //
+ //     end.seconds = start.seconds + duration.seconds;
+ //     end.nanos = start.nanos + duration.nanos;
+ //
+ //     if (end.nanos < 0) {
+ //       end.seconds -= 1;
+ //       end.nanos += 1000000000;
+ //     } else if (end.nanos >= 1000000000) {
+ //       end.seconds += 1;
+ //       end.nanos -= 1000000000;
+ //     }
+ //
+ // Example 3: Compute Duration from datetime.timedelta in Python.
+ //
+ //     td = datetime.timedelta(days=3, minutes=10)
+ //     duration = Duration()
+ //     duration.FromTimedelta(td)
+ //
+ // # JSON Mapping
+ //
+ // In JSON format, the Duration type is encoded as a string rather than an
+ // object, where the string ends in the suffix "s" (indicating seconds) and
+ // is preceded by the number of seconds, with nanoseconds expressed as
+ // fractional seconds. For example, 3 seconds with 0 nanoseconds should be
+ // encoded in JSON format as "3s", while 3 seconds and 1 nanosecond should
+ // be expressed in JSON format as "3.000000001s", and 3 seconds and 1
+ // microsecond should be expressed in JSON format as "3.000001s".
+ //
+ //
+ message Duration {
+   // Signed seconds of the span of time. Must be from -315,576,000,000
+   // to +315,576,000,000 inclusive. Note: these bounds are computed from:
+   // 60 sec/min * 60 min/hr * 24 hr/day * 365.25 days/year * 10000 years
+   int64 seconds = 1;
+ 
+   // Signed fractions of a second at nanosecond resolution of the span
+   // of time. Durations less than one second are represented with a 0
+   // `seconds` field and a positive or negative `nanos` field. For durations
+   // of one second or more, a non-zero value for the `nanos` field must be
+   // of the same sign as the `seconds` field. Must be from -999,999,999
+   // to +999,999,999 inclusive.
+   int32 nanos = 2;
+ }
diff -crB --new-file ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/empty.proto ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/empty.proto
*** ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/empty.proto	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/empty.proto	2022-07-14 19:50:30.221821780 -0700
***************
*** 0 ****
--- 1,52 ----
+ // Protocol Buffers - Google's data interchange format
+ // Copyright 2008 Google Inc.  All rights reserved.
+ // https://developers.google.com/protocol-buffers/
+ //
+ // Redistribution and use in source and binary forms, with or without
+ // modification, are permitted provided that the following conditions are
+ // met:
+ //
+ //     * Redistributions of source code must retain the above copyright
+ // notice, this list of conditions and the following disclaimer.
+ //     * Redistributions in binary form must reproduce the above
+ // copyright notice, this list of conditions and the following disclaimer
+ // in the documentation and/or other materials provided with the
+ // distribution.
+ //     * Neither the name of Google Inc. nor the names of its
+ // contributors may be used to endorse or promote products derived from
+ // this software without specific prior written permission.
+ //
+ // THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ // "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ // LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ // A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ // OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ // SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ // LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ // DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ // THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ // (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ // OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ 
+ syntax = "proto3";
+ 
+ package google.protobuf;
+ 
+ option csharp_namespace = "Google.Protobuf.WellKnownTypes";
+ option go_package = "github.com/golang/protobuf/ptypes/empty";
+ option java_package = "com.google.protobuf";
+ option java_outer_classname = "EmptyProto";
+ option java_multiple_files = true;
+ option objc_class_prefix = "GPB";
+ option cc_enable_arenas = true;
+ 
+ // A generic empty message that you can re-use to avoid defining duplicated
+ // empty messages in your APIs. A typical example is to use it as the request
+ // or the response type of an API method. For instance:
+ //
+ //     service Foo {
+ //       rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty);
+ //     }
+ //
+ // The JSON representation for `Empty` is empty JSON object `{}`.
+ message Empty {}
diff -crB --new-file ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/field_mask.proto ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/field_mask.proto
*** ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/field_mask.proto	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/field_mask.proto	2022-07-14 19:50:30.221821780 -0700
***************
*** 0 ****
--- 1,245 ----
+ // Protocol Buffers - Google's data interchange format
+ // Copyright 2008 Google Inc.  All rights reserved.
+ // https://developers.google.com/protocol-buffers/
+ //
+ // Redistribution and use in source and binary forms, with or without
+ // modification, are permitted provided that the following conditions are
+ // met:
+ //
+ //     * Redistributions of source code must retain the above copyright
+ // notice, this list of conditions and the following disclaimer.
+ //     * Redistributions in binary form must reproduce the above
+ // copyright notice, this list of conditions and the following disclaimer
+ // in the documentation and/or other materials provided with the
+ // distribution.
+ //     * Neither the name of Google Inc. nor the names of its
+ // contributors may be used to endorse or promote products derived from
+ // this software without specific prior written permission.
+ //
+ // THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ // "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ // LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ // A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ // OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ // SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ // LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ // DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ // THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ // (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ // OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ 
+ syntax = "proto3";
+ 
+ package google.protobuf;
+ 
+ option csharp_namespace = "Google.Protobuf.WellKnownTypes";
+ option java_package = "com.google.protobuf";
+ option java_outer_classname = "FieldMaskProto";
+ option java_multiple_files = true;
+ option objc_class_prefix = "GPB";
+ option go_package = "google.golang.org/genproto/protobuf/field_mask;field_mask";
+ option cc_enable_arenas = true;
+ 
+ // `FieldMask` represents a set of symbolic field paths, for example:
+ //
+ //     paths: "f.a"
+ //     paths: "f.b.d"
+ //
+ // Here `f` represents a field in some root message, `a` and `b`
+ // fields in the message found in `f`, and `d` a field found in the
+ // message in `f.b`.
+ //
+ // Field masks are used to specify a subset of fields that should be
+ // returned by a get operation or modified by an update operation.
+ // Field masks also have a custom JSON encoding (see below).
+ //
+ // # Field Masks in Projections
+ //
+ // When used in the context of a projection, a response message or
+ // sub-message is filtered by the API to only contain those fields as
+ // specified in the mask. For example, if the mask in the previous
+ // example is applied to a response message as follows:
+ //
+ //     f {
+ //       a : 22
+ //       b {
+ //         d : 1
+ //         x : 2
+ //       }
+ //       y : 13
+ //     }
+ //     z: 8
+ //
+ // The result will not contain specific values for fields x,y and z
+ // (their value will be set to the default, and omitted in proto text
+ // output):
+ //
+ //
+ //     f {
+ //       a : 22
+ //       b {
+ //         d : 1
+ //       }
+ //     }
+ //
+ // A repeated field is not allowed except at the last position of a
+ // paths string.
+ //
+ // If a FieldMask object is not present in a get operation, the
+ // operation applies to all fields (as if a FieldMask of all fields
+ // had been specified).
+ //
+ // Note that a field mask does not necessarily apply to the
+ // top-level response message. In case of a REST get operation, the
+ // field mask applies directly to the response, but in case of a REST
+ // list operation, the mask instead applies to each individual message
+ // in the returned resource list. In case of a REST custom method,
+ // other definitions may be used. Where the mask applies will be
+ // clearly documented together with its declaration in the API.  In
+ // any case, the effect on the returned resource/resources is required
+ // behavior for APIs.
+ //
+ // # Field Masks in Update Operations
+ //
+ // A field mask in update operations specifies which fields of the
+ // targeted resource are going to be updated. The API is required
+ // to only change the values of the fields as specified in the mask
+ // and leave the others untouched. If a resource is passed in to
+ // describe the updated values, the API ignores the values of all
+ // fields not covered by the mask.
+ //
+ // If a repeated field is specified for an update operation, new values will
+ // be appended to the existing repeated field in the target resource. Note that
+ // a repeated field is only allowed in the last position of a `paths` string.
+ //
+ // If a sub-message is specified in the last position of the field mask for an
+ // update operation, then new value will be merged into the existing sub-message
+ // in the target resource.
+ //
+ // For example, given the target message:
+ //
+ //     f {
+ //       b {
+ //         d: 1
+ //         x: 2
+ //       }
+ //       c: [1]
+ //     }
+ //
+ // And an update message:
+ //
+ //     f {
+ //       b {
+ //         d: 10
+ //       }
+ //       c: [2]
+ //     }
+ //
+ // then if the field mask is:
+ //
+ //  paths: ["f.b", "f.c"]
+ //
+ // then the result will be:
+ //
+ //     f {
+ //       b {
+ //         d: 10
+ //         x: 2
+ //       }
+ //       c: [1, 2]
+ //     }
+ //
+ // An implementation may provide options to override this default behavior for
+ // repeated and message fields.
+ //
+ // In order to reset a field's value to the default, the field must
+ // be in the mask and set to the default value in the provided resource.
+ // Hence, in order to reset all fields of a resource, provide a default
+ // instance of the resource and set all fields in the mask, or do
+ // not provide a mask as described below.
+ //
+ // If a field mask is not present on update, the operation applies to
+ // all fields (as if a field mask of all fields has been specified).
+ // Note that in the presence of schema evolution, this may mean that
+ // fields the client does not know and has therefore not filled into
+ // the request will be reset to their default. If this is unwanted
+ // behavior, a specific service may require a client to always specify
+ // a field mask, producing an error if not.
+ //
+ // As with get operations, the location of the resource which
+ // describes the updated values in the request message depends on the
+ // operation kind. In any case, the effect of the field mask is
+ // required to be honored by the API.
+ //
+ // ## Considerations for HTTP REST
+ //
+ // The HTTP kind of an update operation which uses a field mask must
+ // be set to PATCH instead of PUT in order to satisfy HTTP semantics
+ // (PUT must only be used for full updates).
+ //
+ // # JSON Encoding of Field Masks
+ //
+ // In JSON, a field mask is encoded as a single string where paths are
+ // separated by a comma. Fields name in each path are converted
+ // to/from lower-camel naming conventions.
+ //
+ // As an example, consider the following message declarations:
+ //
+ //     message Profile {
+ //       User user = 1;
+ //       Photo photo = 2;
+ //     }
+ //     message User {
+ //       string display_name = 1;
+ //       string address = 2;
+ //     }
+ //
+ // In proto a field mask for `Profile` may look as such:
+ //
+ //     mask {
+ //       paths: "user.display_name"
+ //       paths: "photo"
+ //     }
+ //
+ // In JSON, the same mask is represented as below:
+ //
+ //     {
+ //       mask: "user.displayName,photo"
+ //     }
+ //
+ // # Field Masks and Oneof Fields
+ //
+ // Field masks treat fields in oneofs just as regular fields. Consider the
+ // following message:
+ //
+ //     message SampleMessage {
+ //       oneof test_oneof {
+ //         string name = 4;
+ //         SubMessage sub_message = 9;
+ //       }
+ //     }
+ //
+ // The field mask can be:
+ //
+ //     mask {
+ //       paths: "name"
+ //     }
+ //
+ // Or:
+ //
+ //     mask {
+ //       paths: "sub_message"
+ //     }
+ //
+ // Note that oneof type names ("test_oneof" in this case) cannot be used in
+ // paths.
+ //
+ // ## Field Mask Verification
+ //
+ // The implementation of any API method which has a FieldMask type field in the
+ // request should verify the included field paths, and return an
+ // `INVALID_ARGUMENT` error if any path is unmappable.
+ message FieldMask {
+   // The set of field mask paths.
+   repeated string paths = 1;
+ }
diff -crB --new-file ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/source_context.proto ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/source_context.proto
*** ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/source_context.proto	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/source_context.proto	2022-07-14 19:50:30.221821780 -0700
***************
*** 0 ****
--- 1,48 ----
+ // Protocol Buffers - Google's data interchange format
+ // Copyright 2008 Google Inc.  All rights reserved.
+ // https://developers.google.com/protocol-buffers/
+ //
+ // Redistribution and use in source and binary forms, with or without
+ // modification, are permitted provided that the following conditions are
+ // met:
+ //
+ //     * Redistributions of source code must retain the above copyright
+ // notice, this list of conditions and the following disclaimer.
+ //     * Redistributions in binary form must reproduce the above
+ // copyright notice, this list of conditions and the following disclaimer
+ // in the documentation and/or other materials provided with the
+ // distribution.
+ //     * Neither the name of Google Inc. nor the names of its
+ // contributors may be used to endorse or promote products derived from
+ // this software without specific prior written permission.
+ //
+ // THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ // "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ // LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ // A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ // OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ // SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ // LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ // DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ // THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ // (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ // OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ 
+ syntax = "proto3";
+ 
+ package google.protobuf;
+ 
+ option csharp_namespace = "Google.Protobuf.WellKnownTypes";
+ option java_package = "com.google.protobuf";
+ option java_outer_classname = "SourceContextProto";
+ option java_multiple_files = true;
+ option objc_class_prefix = "GPB";
+ option go_package = "google.golang.org/genproto/protobuf/source_context;source_context";
+ 
+ // `SourceContext` represents information about the source of a
+ // protobuf element, like the file in which it is defined.
+ message SourceContext {
+   // The path-qualified name of the .proto file that contained the associated
+   // protobuf element.  For example: `"google/protobuf/source_context.proto"`.
+   string file_name = 1;
+ }
diff -crB --new-file ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/struct.proto ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/struct.proto
*** ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/struct.proto	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/struct.proto	2022-07-14 19:50:30.221821780 -0700
***************
*** 0 ****
--- 1,95 ----
+ // Protocol Buffers - Google's data interchange format
+ // Copyright 2008 Google Inc.  All rights reserved.
+ // https://developers.google.com/protocol-buffers/
+ //
+ // Redistribution and use in source and binary forms, with or without
+ // modification, are permitted provided that the following conditions are
+ // met:
+ //
+ //     * Redistributions of source code must retain the above copyright
+ // notice, this list of conditions and the following disclaimer.
+ //     * Redistributions in binary form must reproduce the above
+ // copyright notice, this list of conditions and the following disclaimer
+ // in the documentation and/or other materials provided with the
+ // distribution.
+ //     * Neither the name of Google Inc. nor the names of its
+ // contributors may be used to endorse or promote products derived from
+ // this software without specific prior written permission.
+ //
+ // THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ // "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ // LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ // A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ // OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ // SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ // LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ // DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ // THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ // (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ // OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ 
+ syntax = "proto3";
+ 
+ package google.protobuf;
+ 
+ option csharp_namespace = "Google.Protobuf.WellKnownTypes";
+ option cc_enable_arenas = true;
+ option go_package = "github.com/golang/protobuf/ptypes/struct;structpb";
+ option java_package = "com.google.protobuf";
+ option java_outer_classname = "StructProto";
+ option java_multiple_files = true;
+ option objc_class_prefix = "GPB";
+ 
+ // `Struct` represents a structured data value, consisting of fields
+ // which map to dynamically typed values. In some languages, `Struct`
+ // might be supported by a native representation. For example, in
+ // scripting languages like JS a struct is represented as an
+ // object. The details of that representation are described together
+ // with the proto support for the language.
+ //
+ // The JSON representation for `Struct` is JSON object.
+ message Struct {
+   // Unordered map of dynamically typed values.
+   map<string, Value> fields = 1;
+ }
+ 
+ // `Value` represents a dynamically typed value which can be either
+ // null, a number, a string, a boolean, a recursive struct value, or a
+ // list of values. A producer of value is expected to set one of that
+ // variants, absence of any variant indicates an error.
+ //
+ // The JSON representation for `Value` is JSON value.
+ message Value {
+   // The kind of value.
+   oneof kind {
+     // Represents a null value.
+     NullValue null_value = 1;
+     // Represents a double value.
+     double number_value = 2;
+     // Represents a string value.
+     string string_value = 3;
+     // Represents a boolean value.
+     bool bool_value = 4;
+     // Represents a structured value.
+     Struct struct_value = 5;
+     // Represents a repeated `Value`.
+     ListValue list_value = 6;
+   }
+ }
+ 
+ // `NullValue` is a singleton enumeration to represent the null value for the
+ // `Value` type union.
+ //
+ //  The JSON representation for `NullValue` is JSON `null`.
+ enum NullValue {
+   // Null value.
+   NULL_VALUE = 0;
+ }
+ 
+ // `ListValue` is a wrapper around a repeated field of values.
+ //
+ // The JSON representation for `ListValue` is JSON array.
+ message ListValue {
+   // Repeated field of dynamically typed values.
+   repeated Value values = 1;
+ }
diff -crB --new-file ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/timestamp.proto ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/timestamp.proto
*** ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/timestamp.proto	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/timestamp.proto	2022-07-14 19:50:30.221821780 -0700
***************
*** 0 ****
--- 1,138 ----
+ // Protocol Buffers - Google's data interchange format
+ // Copyright 2008 Google Inc.  All rights reserved.
+ // https://developers.google.com/protocol-buffers/
+ //
+ // Redistribution and use in source and binary forms, with or without
+ // modification, are permitted provided that the following conditions are
+ // met:
+ //
+ //     * Redistributions of source code must retain the above copyright
+ // notice, this list of conditions and the following disclaimer.
+ //     * Redistributions in binary form must reproduce the above
+ // copyright notice, this list of conditions and the following disclaimer
+ // in the documentation and/or other materials provided with the
+ // distribution.
+ //     * Neither the name of Google Inc. nor the names of its
+ // contributors may be used to endorse or promote products derived from
+ // this software without specific prior written permission.
+ //
+ // THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ // "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ // LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ // A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ // OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ // SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ // LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ // DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ // THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ // (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ // OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ 
+ syntax = "proto3";
+ 
+ package google.protobuf;
+ 
+ option csharp_namespace = "Google.Protobuf.WellKnownTypes";
+ option cc_enable_arenas = true;
+ option go_package = "github.com/golang/protobuf/ptypes/timestamp";
+ option java_package = "com.google.protobuf";
+ option java_outer_classname = "TimestampProto";
+ option java_multiple_files = true;
+ option objc_class_prefix = "GPB";
+ 
+ // A Timestamp represents a point in time independent of any time zone or local
+ // calendar, encoded as a count of seconds and fractions of seconds at
+ // nanosecond resolution. The count is relative to an epoch at UTC midnight on
+ // January 1, 1970, in the proleptic Gregorian calendar which extends the
+ // Gregorian calendar backwards to year one.
+ //
+ // All minutes are 60 seconds long. Leap seconds are "smeared" so that no leap
+ // second table is needed for interpretation, using a [24-hour linear
+ // smear](https://developers.google.com/time/smear).
+ //
+ // The range is from 0001-01-01T00:00:00Z to 9999-12-31T23:59:59.999999999Z. By
+ // restricting to that range, we ensure that we can convert to and from [RFC
+ // 3339](https://www.ietf.org/rfc/rfc3339.txt) date strings.
+ //
+ // # Examples
+ //
+ // Example 1: Compute Timestamp from POSIX `time()`.
+ //
+ //     Timestamp timestamp;
+ //     timestamp.set_seconds(time(NULL));
+ //     timestamp.set_nanos(0);
+ //
+ // Example 2: Compute Timestamp from POSIX `gettimeofday()`.
+ //
+ //     struct timeval tv;
+ //     gettimeofday(&tv, NULL);
+ //
+ //     Timestamp timestamp;
+ //     timestamp.set_seconds(tv.tv_sec);
+ //     timestamp.set_nanos(tv.tv_usec * 1000);
+ //
+ // Example 3: Compute Timestamp from Win32 `GetSystemTimeAsFileTime()`.
+ //
+ //     FILETIME ft;
+ //     GetSystemTimeAsFileTime(&ft);
+ //     UINT64 ticks = (((UINT64)ft.dwHighDateTime) << 32) | ft.dwLowDateTime;
+ //
+ //     // A Windows tick is 100 nanoseconds. Windows epoch 1601-01-01T00:00:00Z
+ //     // is 11644473600 seconds before Unix epoch 1970-01-01T00:00:00Z.
+ //     Timestamp timestamp;
+ //     timestamp.set_seconds((INT64) ((ticks / 10000000) - 11644473600LL));
+ //     timestamp.set_nanos((INT32) ((ticks % 10000000) * 100));
+ //
+ // Example 4: Compute Timestamp from Java `System.currentTimeMillis()`.
+ //
+ //     long millis = System.currentTimeMillis();
+ //
+ //     Timestamp timestamp = Timestamp.newBuilder().setSeconds(millis / 1000)
+ //         .setNanos((int) ((millis % 1000) * 1000000)).build();
+ //
+ //
+ // Example 5: Compute Timestamp from current time in Python.
+ //
+ //     timestamp = Timestamp()
+ //     timestamp.GetCurrentTime()
+ //
+ // # JSON Mapping
+ //
+ // In JSON format, the Timestamp type is encoded as a string in the
+ // [RFC 3339](https://www.ietf.org/rfc/rfc3339.txt) format. That is, the
+ // format is "{year}-{month}-{day}T{hour}:{min}:{sec}[.{frac_sec}]Z"
+ // where {year} is always expressed using four digits while {month}, {day},
+ // {hour}, {min}, and {sec} are zero-padded to two digits each. The fractional
+ // seconds, which can go up to 9 digits (i.e. up to 1 nanosecond resolution),
+ // are optional. The "Z" suffix indicates the timezone ("UTC"); the timezone
+ // is required. A proto3 JSON serializer should always use UTC (as indicated by
+ // "Z") when printing the Timestamp type and a proto3 JSON parser should be
+ // able to accept both UTC and other timezones (as indicated by an offset).
+ //
+ // For example, "2017-01-15T01:30:15.01Z" encodes 15.01 seconds past
+ // 01:30 UTC on January 15, 2017.
+ //
+ // In JavaScript, one can convert a Date object to this format using the
+ // standard
+ // [toISOString()](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Date/toISOString)
+ // method. In Python, a standard `datetime.datetime` object can be converted
+ // to this format using
+ // [`strftime`](https://docs.python.org/2/library/time.html#time.strftime) with
+ // the time format spec '%Y-%m-%dT%H:%M:%S.%fZ'. Likewise, in Java, one can use
+ // the Joda Time's [`ISODateTimeFormat.dateTime()`](
+ // http://www.joda.org/joda-time/apidocs/org/joda/time/format/ISODateTimeFormat.html#dateTime%2D%2D
+ // ) to obtain a formatter capable of generating timestamps in this format.
+ //
+ //
+ message Timestamp {
+   // Represents seconds of UTC time since Unix epoch
+   // 1970-01-01T00:00:00Z. Must be from 0001-01-01T00:00:00Z to
+   // 9999-12-31T23:59:59Z inclusive.
+   int64 seconds = 1;
+ 
+   // Non-negative fractions of a second at nanosecond resolution. Negative
+   // second values with fractions must still have non-negative nanos values
+   // that count forward in time. Must be from 0 to 999,999,999
+   // inclusive.
+   int32 nanos = 2;
+ }
diff -crB --new-file ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/type.proto ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/type.proto
*** ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/type.proto	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/type.proto	2022-07-14 19:50:30.221821780 -0700
***************
*** 0 ****
--- 1,187 ----
+ // Protocol Buffers - Google's data interchange format
+ // Copyright 2008 Google Inc.  All rights reserved.
+ // https://developers.google.com/protocol-buffers/
+ //
+ // Redistribution and use in source and binary forms, with or without
+ // modification, are permitted provided that the following conditions are
+ // met:
+ //
+ //     * Redistributions of source code must retain the above copyright
+ // notice, this list of conditions and the following disclaimer.
+ //     * Redistributions in binary form must reproduce the above
+ // copyright notice, this list of conditions and the following disclaimer
+ // in the documentation and/or other materials provided with the
+ // distribution.
+ //     * Neither the name of Google Inc. nor the names of its
+ // contributors may be used to endorse or promote products derived from
+ // this software without specific prior written permission.
+ //
+ // THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ // "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ // LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ // A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ // OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ // SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ // LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ // DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ // THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ // (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ // OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ 
+ syntax = "proto3";
+ 
+ package google.protobuf;
+ 
+ import "google/protobuf/any.proto";
+ import "google/protobuf/source_context.proto";
+ 
+ option csharp_namespace = "Google.Protobuf.WellKnownTypes";
+ option cc_enable_arenas = true;
+ option java_package = "com.google.protobuf";
+ option java_outer_classname = "TypeProto";
+ option java_multiple_files = true;
+ option objc_class_prefix = "GPB";
+ option go_package = "google.golang.org/genproto/protobuf/ptype;ptype";
+ 
+ // A protocol buffer message type.
+ message Type {
+   // The fully qualified message name.
+   string name = 1;
+   // The list of fields.
+   repeated Field fields = 2;
+   // The list of types appearing in `oneof` definitions in this type.
+   repeated string oneofs = 3;
+   // The protocol buffer options.
+   repeated Option options = 4;
+   // The source context.
+   SourceContext source_context = 5;
+   // The source syntax.
+   Syntax syntax = 6;
+ }
+ 
+ // A single field of a message type.
+ message Field {
+   // Basic field types.
+   enum Kind {
+     // Field type unknown.
+     TYPE_UNKNOWN = 0;
+     // Field type double.
+     TYPE_DOUBLE = 1;
+     // Field type float.
+     TYPE_FLOAT = 2;
+     // Field type int64.
+     TYPE_INT64 = 3;
+     // Field type uint64.
+     TYPE_UINT64 = 4;
+     // Field type int32.
+     TYPE_INT32 = 5;
+     // Field type fixed64.
+     TYPE_FIXED64 = 6;
+     // Field type fixed32.
+     TYPE_FIXED32 = 7;
+     // Field type bool.
+     TYPE_BOOL = 8;
+     // Field type string.
+     TYPE_STRING = 9;
+     // Field type group. Proto2 syntax only, and deprecated.
+     TYPE_GROUP = 10;
+     // Field type message.
+     TYPE_MESSAGE = 11;
+     // Field type bytes.
+     TYPE_BYTES = 12;
+     // Field type uint32.
+     TYPE_UINT32 = 13;
+     // Field type enum.
+     TYPE_ENUM = 14;
+     // Field type sfixed32.
+     TYPE_SFIXED32 = 15;
+     // Field type sfixed64.
+     TYPE_SFIXED64 = 16;
+     // Field type sint32.
+     TYPE_SINT32 = 17;
+     // Field type sint64.
+     TYPE_SINT64 = 18;
+   }
+ 
+   // Whether a field is optional, required, or repeated.
+   enum Cardinality {
+     // For fields with unknown cardinality.
+     CARDINALITY_UNKNOWN = 0;
+     // For optional fields.
+     CARDINALITY_OPTIONAL = 1;
+     // For required fields. Proto2 syntax only.
+     CARDINALITY_REQUIRED = 2;
+     // For repeated fields.
+     CARDINALITY_REPEATED = 3;
+   };
+ 
+   // The field type.
+   Kind kind = 1;
+   // The field cardinality.
+   Cardinality cardinality = 2;
+   // The field number.
+   int32 number = 3;
+   // The field name.
+   string name = 4;
+   // The field type URL, without the scheme, for message or enumeration
+   // types. Example: `"type.googleapis.com/google.protobuf.Timestamp"`.
+   string type_url = 6;
+   // The index of the field type in `Type.oneofs`, for message or enumeration
+   // types. The first type has index 1; zero means the type is not in the list.
+   int32 oneof_index = 7;
+   // Whether to use alternative packed wire representation.
+   bool packed = 8;
+   // The protocol buffer options.
+   repeated Option options = 9;
+   // The field JSON name.
+   string json_name = 10;
+   // The string value of the default value of this field. Proto2 syntax only.
+   string default_value = 11;
+ }
+ 
+ // Enum type definition.
+ message Enum {
+   // Enum type name.
+   string name = 1;
+   // Enum value definitions.
+   repeated EnumValue enumvalue = 2;
+   // Protocol buffer options.
+   repeated Option options = 3;
+   // The source context.
+   SourceContext source_context = 4;
+   // The source syntax.
+   Syntax syntax = 5;
+ }
+ 
+ // Enum value definition.
+ message EnumValue {
+   // Enum value name.
+   string name = 1;
+   // Enum value number.
+   int32 number = 2;
+   // Protocol buffer options.
+   repeated Option options = 3;
+ }
+ 
+ // A protocol buffer option, which can be attached to a message, field,
+ // enumeration, etc.
+ message Option {
+   // The option's name. For protobuf built-in options (options defined in
+   // descriptor.proto), this is the short name. For example, `"map_entry"`.
+   // For custom options, it should be the fully-qualified name. For example,
+   // `"google.api.http"`.
+   string name = 1;
+   // The option's value packed in an Any message. If the value is a primitive,
+   // the corresponding wrapper type defined in google/protobuf/wrappers.proto
+   // should be used. If the value is an enum, it should be stored as an int32
+   // value using the google.protobuf.Int32Value type.
+   Any value = 2;
+ }
+ 
+ // The syntax in which a protocol buffer element is defined.
+ enum Syntax {
+   // Syntax `proto2`.
+   SYNTAX_PROTO2 = 0;
+   // Syntax `proto3`.
+   SYNTAX_PROTO3 = 1;
+ }
diff -crB --new-file ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/wrappers.proto ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/wrappers.proto
*** ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/wrappers.proto	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_proto/google/protobuf/wrappers.proto	2022-07-14 19:50:30.221821780 -0700
***************
*** 0 ****
--- 1,123 ----
+ // Protocol Buffers - Google's data interchange format
+ // Copyright 2008 Google Inc.  All rights reserved.
+ // https://developers.google.com/protocol-buffers/
+ //
+ // Redistribution and use in source and binary forms, with or without
+ // modification, are permitted provided that the following conditions are
+ // met:
+ //
+ //     * Redistributions of source code must retain the above copyright
+ // notice, this list of conditions and the following disclaimer.
+ //     * Redistributions in binary form must reproduce the above
+ // copyright notice, this list of conditions and the following disclaimer
+ // in the documentation and/or other materials provided with the
+ // distribution.
+ //     * Neither the name of Google Inc. nor the names of its
+ // contributors may be used to endorse or promote products derived from
+ // this software without specific prior written permission.
+ //
+ // THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ // "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ // LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ // A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ // OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ // SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ // LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ // DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ // THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ // (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ // OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ 
+ // Wrappers for primitive (non-message) types. These types are useful
+ // for embedding primitives in the `google.protobuf.Any` type and for places
+ // where we need to distinguish between the absence of a primitive
+ // typed field and its default value.
+ //
+ // These wrappers have no meaningful use within repeated fields as they lack
+ // the ability to detect presence on individual elements.
+ // These wrappers have no meaningful use within a map or a oneof since
+ // individual entries of a map or fields of a oneof can already detect presence.
+ 
+ syntax = "proto3";
+ 
+ package google.protobuf;
+ 
+ option csharp_namespace = "Google.Protobuf.WellKnownTypes";
+ option cc_enable_arenas = true;
+ option go_package = "github.com/golang/protobuf/ptypes/wrappers";
+ option java_package = "com.google.protobuf";
+ option java_outer_classname = "WrappersProto";
+ option java_multiple_files = true;
+ option objc_class_prefix = "GPB";
+ 
+ // Wrapper message for `double`.
+ //
+ // The JSON representation for `DoubleValue` is JSON number.
+ message DoubleValue {
+   // The double value.
+   double value = 1;
+ }
+ 
+ // Wrapper message for `float`.
+ //
+ // The JSON representation for `FloatValue` is JSON number.
+ message FloatValue {
+   // The float value.
+   float value = 1;
+ }
+ 
+ // Wrapper message for `int64`.
+ //
+ // The JSON representation for `Int64Value` is JSON string.
+ message Int64Value {
+   // The int64 value.
+   int64 value = 1;
+ }
+ 
+ // Wrapper message for `uint64`.
+ //
+ // The JSON representation for `UInt64Value` is JSON string.
+ message UInt64Value {
+   // The uint64 value.
+   uint64 value = 1;
+ }
+ 
+ // Wrapper message for `int32`.
+ //
+ // The JSON representation for `Int32Value` is JSON number.
+ message Int32Value {
+   // The int32 value.
+   int32 value = 1;
+ }
+ 
+ // Wrapper message for `uint32`.
+ //
+ // The JSON representation for `UInt32Value` is JSON number.
+ message UInt32Value {
+   // The uint32 value.
+   uint32 value = 1;
+ }
+ 
+ // Wrapper message for `bool`.
+ //
+ // The JSON representation for `BoolValue` is JSON `true` and `false`.
+ message BoolValue {
+   // The bool value.
+   bool value = 1;
+ }
+ 
+ // Wrapper message for `string`.
+ //
+ // The JSON representation for `StringValue` is JSON string.
+ message StringValue {
+   // The string value.
+   string value = 1;
+ }
+ 
+ // Wrapper message for `bytes`.
+ //
+ // The JSON representation for `BytesValue` is JSON string.
+ message BytesValue {
+   // The bytes value.
+   bytes value = 1;
+ }
Binary files ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_protoc_compiler.cpython-38-x86_64-linux-gnu.so and ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/_protoc_compiler.cpython-38-x86_64-linux-gnu.so differ
diff -crB --new-file ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/protoc.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/protoc.py
*** ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/protoc.py	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/protoc.py	2022-07-14 19:50:30.221821780 -0700
***************
*** 0 ****
--- 1,173 ----
+ #!/usr/bin/env python
+ 
+ # Copyright 2016 gRPC authors.
+ #
+ # Licensed under the Apache License, Version 2.0 (the "License");
+ # you may not use this file except in compliance with the License.
+ # You may obtain a copy of the License at
+ #
+ #     http://www.apache.org/licenses/LICENSE-2.0
+ #
+ # Unless required by applicable law or agreed to in writing, software
+ # distributed under the License is distributed on an "AS IS" BASIS,
+ # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ # See the License for the specific language governing permissions and
+ # limitations under the License.
+ 
+ import pkg_resources
+ import sys
+ 
+ import os
+ 
+ from grpc_tools import _protoc_compiler
+ 
+ _PROTO_MODULE_SUFFIX = "_pb2"
+ _SERVICE_MODULE_SUFFIX = "_pb2_grpc"
+ 
+ _DISABLE_DYNAMIC_STUBS = "GRPC_PYTHON_DISABLE_DYNAMIC_STUBS"
+ 
+ 
+ def main(command_arguments):
+     """Run the protocol buffer compiler with the given command-line arguments.
+ 
+   Args:
+     command_arguments: a list of strings representing command line arguments to
+         `protoc`.
+   """
+     command_arguments = [argument.encode() for argument in command_arguments]
+     return _protoc_compiler.run_main(command_arguments)
+ 
+ 
+ # NOTE(rbellevi): importlib.abc is not supported on 3.4.
+ if sys.version_info >= (3, 5, 0):
+     import contextlib
+     import importlib
+     import importlib.machinery
+     import threading
+ 
+     _FINDERS_INSTALLED = False
+     _FINDERS_INSTALLED_LOCK = threading.Lock()
+ 
+     def _maybe_install_proto_finders():
+         global _FINDERS_INSTALLED
+         with _FINDERS_INSTALLED_LOCK:
+             if not _FINDERS_INSTALLED:
+                 sys.meta_path.extend([
+                     ProtoFinder(_PROTO_MODULE_SUFFIX,
+                                 _protoc_compiler.get_protos),
+                     ProtoFinder(_SERVICE_MODULE_SUFFIX,
+                                 _protoc_compiler.get_services)
+                 ])
+                 sys.path.append(
+                     pkg_resources.resource_filename('grpc_tools', '_proto'))
+                 _FINDERS_INSTALLED = True
+ 
+     def _module_name_to_proto_file(suffix, module_name):
+         components = module_name.split(".")
+         proto_name = components[-1][:-1 * len(suffix)]
+         # NOTE(rbellevi): The Protobuf library expects this path to use
+         # forward slashes on every platform.
+         return "/".join(components[:-1] + [proto_name + ".proto"])
+ 
+     def _proto_file_to_module_name(suffix, proto_file):
+         components = proto_file.split(os.path.sep)
+         proto_base_name = os.path.splitext(components[-1])[0]
+         return ".".join(components[:-1] + [proto_base_name + suffix])
+ 
+     def _protos(protobuf_path):
+         """Returns a gRPC module generated from the indicated proto file."""
+         _maybe_install_proto_finders()
+         module_name = _proto_file_to_module_name(_PROTO_MODULE_SUFFIX,
+                                                  protobuf_path)
+         module = importlib.import_module(module_name)
+         return module
+ 
+     def _services(protobuf_path):
+         """Returns a module generated from the indicated proto file."""
+         _maybe_install_proto_finders()
+         _protos(protobuf_path)
+         module_name = _proto_file_to_module_name(_SERVICE_MODULE_SUFFIX,
+                                                  protobuf_path)
+         module = importlib.import_module(module_name)
+         return module
+ 
+     def _protos_and_services(protobuf_path):
+         """Returns two modules, corresponding to _pb2.py and _pb2_grpc.py files."""
+         return (_protos(protobuf_path), _services(protobuf_path))
+ 
+     _proto_code_cache = {}
+     _proto_code_cache_lock = threading.RLock()
+ 
+     class ProtoLoader(importlib.abc.Loader):
+ 
+         def __init__(self, suffix, codegen_fn, module_name, protobuf_path,
+                      proto_root):
+             self._suffix = suffix
+             self._codegen_fn = codegen_fn
+             self._module_name = module_name
+             self._protobuf_path = protobuf_path
+             self._proto_root = proto_root
+ 
+         def create_module(self, spec):
+             return None
+ 
+         def _generated_file_to_module_name(self, filepath):
+             components = filepath.split(os.path.sep)
+             return ".".join(components[:-1] +
+                             [os.path.splitext(components[-1])[0]])
+ 
+         def exec_module(self, module):
+             assert module.__name__ == self._module_name
+             code = None
+             with _proto_code_cache_lock:
+                 if self._module_name in _proto_code_cache:
+                     code = _proto_code_cache[self._module_name]
+                     exec(code, module.__dict__)
+                 else:
+                     files = self._codegen_fn(
+                         self._protobuf_path.encode('ascii'),
+                         [path.encode('ascii') for path in sys.path])
+                     # NOTE: The files are returned in topological order of dependencies. Each
+                     # entry is guaranteed to depend only on the modules preceding it in the
+                     # list and the last entry is guaranteed to be our requested module. We
+                     # cache the code from the first invocation at module-scope so that we
+                     # don't have to regenerate code that has already been generated by protoc.
+                     for f in files[:-1]:
+                         module_name = self._generated_file_to_module_name(
+                             f[0].decode('ascii'))
+                         if module_name not in sys.modules:
+                             if module_name not in _proto_code_cache:
+                                 _proto_code_cache[module_name] = f[1]
+                             importlib.import_module(module_name)
+                     exec(files[-1][1], module.__dict__)
+ 
+     class ProtoFinder(importlib.abc.MetaPathFinder):
+ 
+         def __init__(self, suffix, codegen_fn):
+             self._suffix = suffix
+             self._codegen_fn = codegen_fn
+ 
+         def find_spec(self, fullname, path, target=None):
+             if not fullname.endswith(self._suffix):
+                 return None
+             filepath = _module_name_to_proto_file(self._suffix, fullname)
+             for search_path in sys.path:
+                 try:
+                     prospective_path = os.path.join(search_path, filepath)
+                     os.stat(prospective_path)
+                 except (FileNotFoundError, NotADirectoryError, OSError):
+                     continue
+                 else:
+                     return importlib.machinery.ModuleSpec(
+                         fullname,
+                         ProtoLoader(self._suffix, self._codegen_fn, fullname,
+                                     filepath, search_path))
+ 
+     # NOTE(rbellevi): We provide an environment variable that enables users to completely
+     # disable this behavior if it is not desired, e.g. for performance reasons.
+     if not os.getenv(_DISABLE_DYNAMIC_STUBS):
+         _maybe_install_proto_finders()
+ 
+ if __name__ == '__main__':
+     proto_include = pkg_resources.resource_filename('grpc_tools', '_proto')
+     sys.exit(main(sys.argv + ['-I{}'.format(proto_include)]))
Binary files ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/__pycache__/command.cpython-38.pyc and ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/__pycache__/command.cpython-38.pyc differ
Binary files ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/__pycache__/__init__.cpython-38.pyc and ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/__pycache__/__init__.cpython-38.pyc differ
Binary files ./openfl/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/__pycache__/protoc.cpython-38.pyc and ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools-1.34.1-py3.8-linux-x86_64.egg/grpc_tools/__pycache__/protoc.cpython-38.pyc differ
diff -crB --new-file ./openfl/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/any_pb2_grpc.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/any_pb2_grpc.py
*** ./openfl/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/any_pb2_grpc.py	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/any_pb2_grpc.py	2022-10-28 12:05:37.344709854 -0700
***************
*** 0 ****
--- 1,4 ----
+ # Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
+ """Client and server classes corresponding to protobuf-defined services."""
+ import grpc
+ 
diff -crB --new-file ./openfl/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/api_pb2_grpc.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/api_pb2_grpc.py
*** ./openfl/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/api_pb2_grpc.py	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/api_pb2_grpc.py	2022-10-28 12:05:37.352709853 -0700
***************
*** 0 ****
--- 1,4 ----
+ # Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
+ """Client and server classes corresponding to protobuf-defined services."""
+ import grpc
+ 
diff -crB --new-file ./openfl/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/compiler/plugin_pb2_grpc.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/compiler/plugin_pb2_grpc.py
*** ./openfl/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/compiler/plugin_pb2_grpc.py	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/compiler/plugin_pb2_grpc.py	2022-10-28 12:05:37.352709853 -0700
***************
*** 0 ****
--- 1,4 ----
+ # Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
+ """Client and server classes corresponding to protobuf-defined services."""
+ import grpc
+ 
diff -crB --new-file ./openfl/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/descriptor_pb2_grpc.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/descriptor_pb2_grpc.py
*** ./openfl/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/descriptor_pb2_grpc.py	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/descriptor_pb2_grpc.py	2022-10-28 12:05:37.348709853 -0700
***************
*** 0 ****
--- 1,4 ----
+ # Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
+ """Client and server classes corresponding to protobuf-defined services."""
+ import grpc
+ 
diff -crB --new-file ./openfl/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/duration_pb2_grpc.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/duration_pb2_grpc.py
*** ./openfl/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/duration_pb2_grpc.py	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/duration_pb2_grpc.py	2022-10-28 12:05:37.348709853 -0700
***************
*** 0 ****
--- 1,4 ----
+ # Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
+ """Client and server classes corresponding to protobuf-defined services."""
+ import grpc
+ 
diff -crB --new-file ./openfl/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/empty_pb2_grpc.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/empty_pb2_grpc.py
*** ./openfl/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/empty_pb2_grpc.py	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/empty_pb2_grpc.py	2022-10-28 12:05:37.348709853 -0700
***************
*** 0 ****
--- 1,4 ----
+ # Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
+ """Client and server classes corresponding to protobuf-defined services."""
+ import grpc
+ 
diff -crB --new-file ./openfl/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/field_mask_pb2_grpc.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/field_mask_pb2_grpc.py
*** ./openfl/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/field_mask_pb2_grpc.py	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/field_mask_pb2_grpc.py	2022-10-28 12:05:37.348709853 -0700
***************
*** 0 ****
--- 1,4 ----
+ # Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
+ """Client and server classes corresponding to protobuf-defined services."""
+ import grpc
+ 
diff -crB --new-file ./openfl/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/source_context_pb2_grpc.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/source_context_pb2_grpc.py
*** ./openfl/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/source_context_pb2_grpc.py	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/source_context_pb2_grpc.py	2022-10-28 12:05:37.340709854 -0700
***************
*** 0 ****
--- 1,4 ----
+ # Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
+ """Client and server classes corresponding to protobuf-defined services."""
+ import grpc
+ 
diff -crB --new-file ./openfl/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/struct_pb2_grpc.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/struct_pb2_grpc.py
*** ./openfl/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/struct_pb2_grpc.py	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/struct_pb2_grpc.py	2022-10-28 12:05:37.344709854 -0700
***************
*** 0 ****
--- 1,4 ----
+ # Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
+ """Client and server classes corresponding to protobuf-defined services."""
+ import grpc
+ 
diff -crB --new-file ./openfl/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/timestamp_pb2_grpc.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/timestamp_pb2_grpc.py
*** ./openfl/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/timestamp_pb2_grpc.py	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/timestamp_pb2_grpc.py	2022-10-28 12:05:37.348709853 -0700
***************
*** 0 ****
--- 1,4 ----
+ # Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
+ """Client and server classes corresponding to protobuf-defined services."""
+ import grpc
+ 
diff -crB --new-file ./openfl/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/type_pb2_grpc.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/type_pb2_grpc.py
*** ./openfl/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/type_pb2_grpc.py	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/type_pb2_grpc.py	2022-10-28 12:05:37.344709854 -0700
***************
*** 0 ****
--- 1,4 ----
+ # Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
+ """Client and server classes corresponding to protobuf-defined services."""
+ import grpc
+ 
diff -crB --new-file ./openfl/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/wrappers_pb2_grpc.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/wrappers_pb2_grpc.py
*** ./openfl/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/wrappers_pb2_grpc.py	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/grpcio_tools_1.34.1_py3.8_linux_x86_64.egg/grpc_tools/_proto/google/protobuf/wrappers_pb2_grpc.py	2022-10-28 12:05:37.348709853 -0700
***************
*** 0 ****
--- 1,4 ----
+ # Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
+ """Client and server classes corresponding to protobuf-defined services."""
+ import grpc
+ 
diff -crB --new-file ./openfl/.eggs/README.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/README.txt
*** ./openfl/.eggs/README.txt	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.eggs/README.txt	2022-07-14 19:50:28.581821793 -0700
***************
*** 0 ****
--- 1,6 ----
+ This directory contains eggs that were downloaded by setuptools to build, test, and run plug-ins.
+ 
+ This directory caches those eggs to prevent repeated downloads.
+ 
+ However, it is safe to delete this directory.
+ 
diff -crB --new-file ./openfl/.git/config ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/config
*** ./openfl/.git/config	2022-11-18 11:06:29.691187478 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/config	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,11 ****
- [core]
- 	repositoryformatversion = 0
- 	filemode = true
- 	bare = false
- 	logallrefupdates = true
- [remote "origin"]
- 	url = https://github.com/intel/openfl.git
- 	fetch = +refs/heads/*:refs/remotes/origin/*
- [branch "develop"]
- 	remote = origin
- 	merge = refs/heads/develop
--- 0 ----
diff -crB --new-file ./openfl/.git/description ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/description
*** ./openfl/.git/description	2022-11-18 11:06:24.339187741 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/description	1969-12-31 16:00:00.000000000 -0800
***************
*** 1 ****
- Unnamed repository; edit this file 'description' to name the repository.
--- 0 ----
diff -crB --new-file ./openfl/.git/HEAD ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/HEAD
*** ./openfl/.git/HEAD	2022-11-18 11:08:33.047181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/HEAD	1969-12-31 16:00:00.000000000 -0800
***************
*** 1 ****
- c2e8c0d512ec4f3346176edd042ace31405a366b
--- 0 ----
diff -crB --new-file ./openfl/.git/hooks/applypatch-msg.sample ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/hooks/applypatch-msg.sample
*** ./openfl/.git/hooks/applypatch-msg.sample	2022-11-18 11:06:24.339187741 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/hooks/applypatch-msg.sample	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,15 ****
- #!/bin/sh
- #
- # An example hook script to check the commit log message taken by
- # applypatch from an e-mail message.
- #
- # The hook should exit with non-zero status after issuing an
- # appropriate message if it wants to stop the commit.  The hook is
- # allowed to edit the commit message file.
- #
- # To enable this hook, rename this file to "applypatch-msg".
- 
- . git-sh-setup
- commitmsg="$(git rev-parse --git-path hooks/commit-msg)"
- test -x "$commitmsg" && exec "$commitmsg" ${1+"$@"}
- :
--- 0 ----
diff -crB --new-file ./openfl/.git/hooks/commit-msg.sample ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/hooks/commit-msg.sample
*** ./openfl/.git/hooks/commit-msg.sample	2022-11-18 11:06:24.339187741 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/hooks/commit-msg.sample	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,24 ****
- #!/bin/sh
- #
- # An example hook script to check the commit log message.
- # Called by "git commit" with one argument, the name of the file
- # that has the commit message.  The hook should exit with non-zero
- # status after issuing an appropriate message if it wants to stop the
- # commit.  The hook is allowed to edit the commit message file.
- #
- # To enable this hook, rename this file to "commit-msg".
- 
- # Uncomment the below to add a Signed-off-by line to the message.
- # Doing this in a hook is a bad idea in general, but the prepare-commit-msg
- # hook is more suited to it.
- #
- # SOB=$(git var GIT_AUTHOR_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
- # grep -qs "^$SOB" "$1" || echo "$SOB" >> "$1"
- 
- # This example catches duplicate Signed-off-by lines.
- 
- test "" = "$(grep '^Signed-off-by: ' "$1" |
- 	 sort | uniq -c | sed -e '/^[ 	]*1[ 	]/d')" || {
- 	echo >&2 Duplicate Signed-off-by lines.
- 	exit 1
- }
--- 0 ----
diff -crB --new-file ./openfl/.git/hooks/fsmonitor-watchman.sample ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/hooks/fsmonitor-watchman.sample
*** ./openfl/.git/hooks/fsmonitor-watchman.sample	2022-11-18 11:06:24.339187741 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/hooks/fsmonitor-watchman.sample	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,109 ****
- #!/usr/bin/perl
- 
- use strict;
- use warnings;
- use IPC::Open2;
- 
- # An example hook script to integrate Watchman
- # (https://facebook.github.io/watchman/) with git to speed up detecting
- # new and modified files.
- #
- # The hook is passed a version (currently 1) and a time in nanoseconds
- # formatted as a string and outputs to stdout all files that have been
- # modified since the given time. Paths must be relative to the root of
- # the working tree and separated by a single NUL.
- #
- # To enable this hook, rename this file to "query-watchman" and set
- # 'git config core.fsmonitor .git/hooks/query-watchman'
- #
- my ($version, $time) = @ARGV;
- 
- # Check the hook interface version
- 
- if ($version == 1) {
- 	# convert nanoseconds to seconds
- 	# subtract one second to make sure watchman will return all changes
- 	$time = int ($time / 1000000000) - 1;
- } else {
- 	die "Unsupported query-fsmonitor hook version '$version'.\n" .
- 	    "Falling back to scanning...\n";
- }
- 
- my $git_work_tree;
- if ($^O =~ 'msys' || $^O =~ 'cygwin') {
- 	$git_work_tree = Win32::GetCwd();
- 	$git_work_tree =~ tr/\\/\//;
- } else {
- 	require Cwd;
- 	$git_work_tree = Cwd::cwd();
- }
- 
- my $retry = 1;
- 
- launch_watchman();
- 
- sub launch_watchman {
- 
- 	my $pid = open2(\*CHLD_OUT, \*CHLD_IN, 'watchman -j --no-pretty')
- 	    or die "open2() failed: $!\n" .
- 	    "Falling back to scanning...\n";
- 
- 	# In the query expression below we're asking for names of files that
- 	# changed since $time but were not transient (ie created after
- 	# $time but no longer exist).
- 	#
- 	# To accomplish this, we're using the "since" generator to use the
- 	# recency index to select candidate nodes and "fields" to limit the
- 	# output to file names only.
- 
- 	my $query = <<"	END";
- 		["query", "$git_work_tree", {
- 			"since": $time,
- 			"fields": ["name"]
- 		}]
- 	END
- 
- 	print CHLD_IN $query;
- 	close CHLD_IN;
- 	my $response = do {local $/; <CHLD_OUT>};
- 
- 	die "Watchman: command returned no output.\n" .
- 	    "Falling back to scanning...\n" if $response eq "";
- 	die "Watchman: command returned invalid output: $response\n" .
- 	    "Falling back to scanning...\n" unless $response =~ /^\{/;
- 
- 	my $json_pkg;
- 	eval {
- 		require JSON::XS;
- 		$json_pkg = "JSON::XS";
- 		1;
- 	} or do {
- 		require JSON::PP;
- 		$json_pkg = "JSON::PP";
- 	};
- 
- 	my $o = $json_pkg->new->utf8->decode($response);
- 
- 	if ($retry > 0 and $o->{error} and $o->{error} =~ m/unable to resolve root .* directory (.*) is not watched/) {
- 		print STDERR "Adding '$git_work_tree' to watchman's watch list.\n";
- 		$retry--;
- 		qx/watchman watch "$git_work_tree"/;
- 		die "Failed to make watchman watch '$git_work_tree'.\n" .
- 		    "Falling back to scanning...\n" if $? != 0;
- 
- 		# Watchman will always return all files on the first query so
- 		# return the fast "everything is dirty" flag to git and do the
- 		# Watchman query just to get it over with now so we won't pay
- 		# the cost in git to look up each individual file.
- 		print "/\0";
- 		eval { launch_watchman() };
- 		exit 0;
- 	}
- 
- 	die "Watchman: $o->{error}.\n" .
- 	    "Falling back to scanning...\n" if $o->{error};
- 
- 	binmode STDOUT, ":utf8";
- 	local $, = "\0";
- 	print @{$o->{files}};
- }
--- 0 ----
diff -crB --new-file ./openfl/.git/hooks/post-update.sample ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/hooks/post-update.sample
*** ./openfl/.git/hooks/post-update.sample	2022-11-18 11:06:24.339187741 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/hooks/post-update.sample	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,8 ****
- #!/bin/sh
- #
- # An example hook script to prepare a packed repository for use over
- # dumb transports.
- #
- # To enable this hook, rename this file to "post-update".
- 
- exec git update-server-info
--- 0 ----
diff -crB --new-file ./openfl/.git/hooks/pre-applypatch.sample ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/hooks/pre-applypatch.sample
*** ./openfl/.git/hooks/pre-applypatch.sample	2022-11-18 11:06:24.339187741 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/hooks/pre-applypatch.sample	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,14 ****
- #!/bin/sh
- #
- # An example hook script to verify what is about to be committed
- # by applypatch from an e-mail message.
- #
- # The hook should exit with non-zero status after issuing an
- # appropriate message if it wants to stop the commit.
- #
- # To enable this hook, rename this file to "pre-applypatch".
- 
- . git-sh-setup
- precommit="$(git rev-parse --git-path hooks/pre-commit)"
- test -x "$precommit" && exec "$precommit" ${1+"$@"}
- :
--- 0 ----
diff -crB --new-file ./openfl/.git/hooks/pre-commit.sample ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/hooks/pre-commit.sample
*** ./openfl/.git/hooks/pre-commit.sample	2022-11-18 11:06:24.339187741 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/hooks/pre-commit.sample	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,49 ****
- #!/bin/sh
- #
- # An example hook script to verify what is about to be committed.
- # Called by "git commit" with no arguments.  The hook should
- # exit with non-zero status after issuing an appropriate message if
- # it wants to stop the commit.
- #
- # To enable this hook, rename this file to "pre-commit".
- 
- if git rev-parse --verify HEAD >/dev/null 2>&1
- then
- 	against=HEAD
- else
- 	# Initial commit: diff against an empty tree object
- 	against=$(git hash-object -t tree /dev/null)
- fi
- 
- # If you want to allow non-ASCII filenames set this variable to true.
- allownonascii=$(git config --bool hooks.allownonascii)
- 
- # Redirect output to stderr.
- exec 1>&2
- 
- # Cross platform projects tend to avoid non-ASCII filenames; prevent
- # them from being added to the repository. We exploit the fact that the
- # printable range starts at the space character and ends with tilde.
- if [ "$allownonascii" != "true" ] &&
- 	# Note that the use of brackets around a tr range is ok here, (it's
- 	# even required, for portability to Solaris 10's /usr/bin/tr), since
- 	# the square bracket bytes happen to fall in the designated range.
- 	test $(git diff --cached --name-only --diff-filter=A -z $against |
- 	  LC_ALL=C tr -d '[ -~]\0' | wc -c) != 0
- then
- 	cat <<\EOF
- Error: Attempt to add a non-ASCII file name.
- 
- This can cause problems if you want to work with people on other platforms.
- 
- To be portable it is advisable to rename the file.
- 
- If you know what you are doing you can disable this check using:
- 
-   git config hooks.allownonascii true
- EOF
- 	exit 1
- fi
- 
- # If there are whitespace errors, print the offending file names and fail.
- exec git diff-index --check --cached $against --
--- 0 ----
diff -crB --new-file ./openfl/.git/hooks/pre-merge-commit.sample ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/hooks/pre-merge-commit.sample
*** ./openfl/.git/hooks/pre-merge-commit.sample	2022-11-18 11:06:24.339187741 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/hooks/pre-merge-commit.sample	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,13 ****
- #!/bin/sh
- #
- # An example hook script to verify what is about to be committed.
- # Called by "git merge" with no arguments.  The hook should
- # exit with non-zero status after issuing an appropriate message to
- # stderr if it wants to stop the merge commit.
- #
- # To enable this hook, rename this file to "pre-merge-commit".
- 
- . git-sh-setup
- test -x "$GIT_DIR/hooks/pre-commit" &&
-         exec "$GIT_DIR/hooks/pre-commit"
- :
--- 0 ----
diff -crB --new-file ./openfl/.git/hooks/prepare-commit-msg.sample ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/hooks/prepare-commit-msg.sample
*** ./openfl/.git/hooks/prepare-commit-msg.sample	2022-11-18 11:06:24.339187741 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/hooks/prepare-commit-msg.sample	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,42 ****
- #!/bin/sh
- #
- # An example hook script to prepare the commit log message.
- # Called by "git commit" with the name of the file that has the
- # commit message, followed by the description of the commit
- # message's source.  The hook's purpose is to edit the commit
- # message file.  If the hook fails with a non-zero status,
- # the commit is aborted.
- #
- # To enable this hook, rename this file to "prepare-commit-msg".
- 
- # This hook includes three examples. The first one removes the
- # "# Please enter the commit message..." help message.
- #
- # The second includes the output of "git diff --name-status -r"
- # into the message, just before the "git status" output.  It is
- # commented because it doesn't cope with --amend or with squashed
- # commits.
- #
- # The third example adds a Signed-off-by line to the message, that can
- # still be edited.  This is rarely a good idea.
- 
- COMMIT_MSG_FILE=$1
- COMMIT_SOURCE=$2
- SHA1=$3
- 
- /usr/bin/perl -i.bak -ne 'print unless(m/^. Please enter the commit message/..m/^#$/)' "$COMMIT_MSG_FILE"
- 
- # case "$COMMIT_SOURCE,$SHA1" in
- #  ,|template,)
- #    /usr/bin/perl -i.bak -pe '
- #       print "\n" . `git diff --cached --name-status -r`
- # 	 if /^#/ && $first++ == 0' "$COMMIT_MSG_FILE" ;;
- #  *) ;;
- # esac
- 
- # SOB=$(git var GIT_COMMITTER_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
- # git interpret-trailers --in-place --trailer "$SOB" "$COMMIT_MSG_FILE"
- # if test -z "$COMMIT_SOURCE"
- # then
- #   /usr/bin/perl -i.bak -pe 'print "\n" if !$first_line++' "$COMMIT_MSG_FILE"
- # fi
--- 0 ----
diff -crB --new-file ./openfl/.git/hooks/pre-push.sample ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/hooks/pre-push.sample
*** ./openfl/.git/hooks/pre-push.sample	2022-11-18 11:06:24.339187741 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/hooks/pre-push.sample	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,53 ****
- #!/bin/sh
- 
- # An example hook script to verify what is about to be pushed.  Called by "git
- # push" after it has checked the remote status, but before anything has been
- # pushed.  If this script exits with a non-zero status nothing will be pushed.
- #
- # This hook is called with the following parameters:
- #
- # $1 -- Name of the remote to which the push is being done
- # $2 -- URL to which the push is being done
- #
- # If pushing without using a named remote those arguments will be equal.
- #
- # Information about the commits which are being pushed is supplied as lines to
- # the standard input in the form:
- #
- #   <local ref> <local sha1> <remote ref> <remote sha1>
- #
- # This sample shows how to prevent push of commits where the log message starts
- # with "WIP" (work in progress).
- 
- remote="$1"
- url="$2"
- 
- z40=0000000000000000000000000000000000000000
- 
- while read local_ref local_sha remote_ref remote_sha
- do
- 	if [ "$local_sha" = $z40 ]
- 	then
- 		# Handle delete
- 		:
- 	else
- 		if [ "$remote_sha" = $z40 ]
- 		then
- 			# New branch, examine all commits
- 			range="$local_sha"
- 		else
- 			# Update to existing branch, examine new commits
- 			range="$remote_sha..$local_sha"
- 		fi
- 
- 		# Check for WIP commit
- 		commit=`git rev-list -n 1 --grep '^WIP' "$range"`
- 		if [ -n "$commit" ]
- 		then
- 			echo >&2 "Found WIP commit in $local_ref, not pushing"
- 			exit 1
- 		fi
- 	fi
- done
- 
- exit 0
--- 0 ----
diff -crB --new-file ./openfl/.git/hooks/pre-rebase.sample ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/hooks/pre-rebase.sample
*** ./openfl/.git/hooks/pre-rebase.sample	2022-11-18 11:06:24.339187741 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/hooks/pre-rebase.sample	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,169 ****
- #!/bin/sh
- #
- # Copyright (c) 2006, 2008 Junio C Hamano
- #
- # The "pre-rebase" hook is run just before "git rebase" starts doing
- # its job, and can prevent the command from running by exiting with
- # non-zero status.
- #
- # The hook is called with the following parameters:
- #
- # $1 -- the upstream the series was forked from.
- # $2 -- the branch being rebased (or empty when rebasing the current branch).
- #
- # This sample shows how to prevent topic branches that are already
- # merged to 'next' branch from getting rebased, because allowing it
- # would result in rebasing already published history.
- 
- publish=next
- basebranch="$1"
- if test "$#" = 2
- then
- 	topic="refs/heads/$2"
- else
- 	topic=`git symbolic-ref HEAD` ||
- 	exit 0 ;# we do not interrupt rebasing detached HEAD
- fi
- 
- case "$topic" in
- refs/heads/??/*)
- 	;;
- *)
- 	exit 0 ;# we do not interrupt others.
- 	;;
- esac
- 
- # Now we are dealing with a topic branch being rebased
- # on top of master.  Is it OK to rebase it?
- 
- # Does the topic really exist?
- git show-ref -q "$topic" || {
- 	echo >&2 "No such branch $topic"
- 	exit 1
- }
- 
- # Is topic fully merged to master?
- not_in_master=`git rev-list --pretty=oneline ^master "$topic"`
- if test -z "$not_in_master"
- then
- 	echo >&2 "$topic is fully merged to master; better remove it."
- 	exit 1 ;# we could allow it, but there is no point.
- fi
- 
- # Is topic ever merged to next?  If so you should not be rebasing it.
- only_next_1=`git rev-list ^master "^$topic" ${publish} | sort`
- only_next_2=`git rev-list ^master           ${publish} | sort`
- if test "$only_next_1" = "$only_next_2"
- then
- 	not_in_topic=`git rev-list "^$topic" master`
- 	if test -z "$not_in_topic"
- 	then
- 		echo >&2 "$topic is already up to date with master"
- 		exit 1 ;# we could allow it, but there is no point.
- 	else
- 		exit 0
- 	fi
- else
- 	not_in_next=`git rev-list --pretty=oneline ^${publish} "$topic"`
- 	/usr/bin/perl -e '
- 		my $topic = $ARGV[0];
- 		my $msg = "* $topic has commits already merged to public branch:\n";
- 		my (%not_in_next) = map {
- 			/^([0-9a-f]+) /;
- 			($1 => 1);
- 		} split(/\n/, $ARGV[1]);
- 		for my $elem (map {
- 				/^([0-9a-f]+) (.*)$/;
- 				[$1 => $2];
- 			} split(/\n/, $ARGV[2])) {
- 			if (!exists $not_in_next{$elem->[0]}) {
- 				if ($msg) {
- 					print STDERR $msg;
- 					undef $msg;
- 				}
- 				print STDERR " $elem->[1]\n";
- 			}
- 		}
- 	' "$topic" "$not_in_next" "$not_in_master"
- 	exit 1
- fi
- 
- <<\DOC_END
- 
- This sample hook safeguards topic branches that have been
- published from being rewound.
- 
- The workflow assumed here is:
- 
-  * Once a topic branch forks from "master", "master" is never
-    merged into it again (either directly or indirectly).
- 
-  * Once a topic branch is fully cooked and merged into "master",
-    it is deleted.  If you need to build on top of it to correct
-    earlier mistakes, a new topic branch is created by forking at
-    the tip of the "master".  This is not strictly necessary, but
-    it makes it easier to keep your history simple.
- 
-  * Whenever you need to test or publish your changes to topic
-    branches, merge them into "next" branch.
- 
- The script, being an example, hardcodes the publish branch name
- to be "next", but it is trivial to make it configurable via
- $GIT_DIR/config mechanism.
- 
- With this workflow, you would want to know:
- 
- (1) ... if a topic branch has ever been merged to "next".  Young
-     topic branches can have stupid mistakes you would rather
-     clean up before publishing, and things that have not been
-     merged into other branches can be easily rebased without
-     affecting other people.  But once it is published, you would
-     not want to rewind it.
- 
- (2) ... if a topic branch has been fully merged to "master".
-     Then you can delete it.  More importantly, you should not
-     build on top of it -- other people may already want to
-     change things related to the topic as patches against your
-     "master", so if you need further changes, it is better to
-     fork the topic (perhaps with the same name) afresh from the
-     tip of "master".
- 
- Let's look at this example:
- 
- 		   o---o---o---o---o---o---o---o---o---o "next"
- 		  /       /           /           /
- 		 /   a---a---b A     /           /
- 		/   /               /           /
- 	       /   /   c---c---c---c B         /
- 	      /   /   /             \         /
- 	     /   /   /   b---b C     \       /
- 	    /   /   /   /             \     /
-     ---o---o---o---o---o---o---o---o---o---o---o "master"
- 
- 
- A, B and C are topic branches.
- 
-  * A has one fix since it was merged up to "next".
- 
-  * B has finished.  It has been fully merged up to "master" and "next",
-    and is ready to be deleted.
- 
-  * C has not merged to "next" at all.
- 
- We would want to allow C to be rebased, refuse A, and encourage
- B to be deleted.
- 
- To compute (1):
- 
- 	git rev-list ^master ^topic next
- 	git rev-list ^master        next
- 
- 	if these match, topic has not merged in next at all.
- 
- To compute (2):
- 
- 	git rev-list master..topic
- 
- 	if this is empty, it is fully merged to "master".
- 
- DOC_END
--- 0 ----
diff -crB --new-file ./openfl/.git/hooks/pre-receive.sample ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/hooks/pre-receive.sample
*** ./openfl/.git/hooks/pre-receive.sample	2022-11-18 11:06:24.339187741 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/hooks/pre-receive.sample	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,24 ****
- #!/bin/sh
- #
- # An example hook script to make use of push options.
- # The example simply echoes all push options that start with 'echoback='
- # and rejects all pushes when the "reject" push option is used.
- #
- # To enable this hook, rename this file to "pre-receive".
- 
- if test -n "$GIT_PUSH_OPTION_COUNT"
- then
- 	i=0
- 	while test "$i" -lt "$GIT_PUSH_OPTION_COUNT"
- 	do
- 		eval "value=\$GIT_PUSH_OPTION_$i"
- 		case "$value" in
- 		echoback=*)
- 			echo "echo from the pre-receive-hook: ${value#*=}" >&2
- 			;;
- 		reject)
- 			exit 1
- 		esac
- 		i=$((i + 1))
- 	done
- fi
--- 0 ----
diff -crB --new-file ./openfl/.git/hooks/update.sample ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/hooks/update.sample
*** ./openfl/.git/hooks/update.sample	2022-11-18 11:06:24.339187741 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/hooks/update.sample	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,128 ****
- #!/bin/sh
- #
- # An example hook script to block unannotated tags from entering.
- # Called by "git receive-pack" with arguments: refname sha1-old sha1-new
- #
- # To enable this hook, rename this file to "update".
- #
- # Config
- # ------
- # hooks.allowunannotated
- #   This boolean sets whether unannotated tags will be allowed into the
- #   repository.  By default they won't be.
- # hooks.allowdeletetag
- #   This boolean sets whether deleting tags will be allowed in the
- #   repository.  By default they won't be.
- # hooks.allowmodifytag
- #   This boolean sets whether a tag may be modified after creation. By default
- #   it won't be.
- # hooks.allowdeletebranch
- #   This boolean sets whether deleting branches will be allowed in the
- #   repository.  By default they won't be.
- # hooks.denycreatebranch
- #   This boolean sets whether remotely creating branches will be denied
- #   in the repository.  By default this is allowed.
- #
- 
- # --- Command line
- refname="$1"
- oldrev="$2"
- newrev="$3"
- 
- # --- Safety check
- if [ -z "$GIT_DIR" ]; then
- 	echo "Don't run this script from the command line." >&2
- 	echo " (if you want, you could supply GIT_DIR then run" >&2
- 	echo "  $0 <ref> <oldrev> <newrev>)" >&2
- 	exit 1
- fi
- 
- if [ -z "$refname" -o -z "$oldrev" -o -z "$newrev" ]; then
- 	echo "usage: $0 <ref> <oldrev> <newrev>" >&2
- 	exit 1
- fi
- 
- # --- Config
- allowunannotated=$(git config --bool hooks.allowunannotated)
- allowdeletebranch=$(git config --bool hooks.allowdeletebranch)
- denycreatebranch=$(git config --bool hooks.denycreatebranch)
- allowdeletetag=$(git config --bool hooks.allowdeletetag)
- allowmodifytag=$(git config --bool hooks.allowmodifytag)
- 
- # check for no description
- projectdesc=$(sed -e '1q' "$GIT_DIR/description")
- case "$projectdesc" in
- "Unnamed repository"* | "")
- 	echo "*** Project description file hasn't been set" >&2
- 	exit 1
- 	;;
- esac
- 
- # --- Check types
- # if $newrev is 0000...0000, it's a commit to delete a ref.
- zero="0000000000000000000000000000000000000000"
- if [ "$newrev" = "$zero" ]; then
- 	newrev_type=delete
- else
- 	newrev_type=$(git cat-file -t $newrev)
- fi
- 
- case "$refname","$newrev_type" in
- 	refs/tags/*,commit)
- 		# un-annotated tag
- 		short_refname=${refname##refs/tags/}
- 		if [ "$allowunannotated" != "true" ]; then
- 			echo "*** The un-annotated tag, $short_refname, is not allowed in this repository" >&2
- 			echo "*** Use 'git tag [ -a | -s ]' for tags you want to propagate." >&2
- 			exit 1
- 		fi
- 		;;
- 	refs/tags/*,delete)
- 		# delete tag
- 		if [ "$allowdeletetag" != "true" ]; then
- 			echo "*** Deleting a tag is not allowed in this repository" >&2
- 			exit 1
- 		fi
- 		;;
- 	refs/tags/*,tag)
- 		# annotated tag
- 		if [ "$allowmodifytag" != "true" ] && git rev-parse $refname > /dev/null 2>&1
- 		then
- 			echo "*** Tag '$refname' already exists." >&2
- 			echo "*** Modifying a tag is not allowed in this repository." >&2
- 			exit 1
- 		fi
- 		;;
- 	refs/heads/*,commit)
- 		# branch
- 		if [ "$oldrev" = "$zero" -a "$denycreatebranch" = "true" ]; then
- 			echo "*** Creating a branch is not allowed in this repository" >&2
- 			exit 1
- 		fi
- 		;;
- 	refs/heads/*,delete)
- 		# delete branch
- 		if [ "$allowdeletebranch" != "true" ]; then
- 			echo "*** Deleting a branch is not allowed in this repository" >&2
- 			exit 1
- 		fi
- 		;;
- 	refs/remotes/*,commit)
- 		# tracking branch
- 		;;
- 	refs/remotes/*,delete)
- 		# delete tracking branch
- 		if [ "$allowdeletebranch" != "true" ]; then
- 			echo "*** Deleting a tracking branch is not allowed in this repository" >&2
- 			exit 1
- 		fi
- 		;;
- 	*)
- 		# Anything else (is there anything else?)
- 		echo "*** Update hook: unknown type of update to ref $refname of type $newrev_type" >&2
- 		exit 1
- 		;;
- esac
- 
- # --- Finished
- exit 0
--- 0 ----
Binary files ./openfl/.git/index and ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/index differ
diff -crB --new-file ./openfl/.git/info/exclude ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/info/exclude
*** ./openfl/.git/info/exclude	2022-11-18 11:06:24.339187741 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/info/exclude	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,6 ****
- # git ls-files --others --exclude-from=.git/info/exclude
- # Lines that start with '#' are comments.
- # For a project mostly in C, the following would be a good set of
- # exclude patterns (uncomment them if you want to use them):
- # *.[oa]
- # *~
--- 0 ----
diff -crB --new-file ./openfl/.git/logs/HEAD ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/logs/HEAD
*** ./openfl/.git/logs/HEAD	2022-11-18 11:08:33.047181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/logs/HEAD	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- 0000000000000000000000000000000000000000 3f2337da62e3f2bf7c3f09bef4be23953b9f2da1 Alam, S M Iftekharul <s.m.iftekharul.alam@intel.com> 1668798389 -0800	clone: from https://github.com/intel/openfl.git
- 3f2337da62e3f2bf7c3f09bef4be23953b9f2da1 c2e8c0d512ec4f3346176edd042ace31405a366b Alam, S M Iftekharul <s.m.iftekharul.alam@intel.com> 1668798513 -0800	checkout: moving from develop to v1.3
--- 0 ----
diff -crB --new-file ./openfl/.git/logs/refs/heads/develop ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/logs/refs/heads/develop
*** ./openfl/.git/logs/refs/heads/develop	2022-11-18 11:06:29.691187478 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/logs/refs/heads/develop	1969-12-31 16:00:00.000000000 -0800
***************
*** 1 ****
- 0000000000000000000000000000000000000000 3f2337da62e3f2bf7c3f09bef4be23953b9f2da1 Alam, S M Iftekharul <s.m.iftekharul.alam@intel.com> 1668798389 -0800	clone: from https://github.com/intel/openfl.git
--- 0 ----
diff -crB --new-file ./openfl/.git/logs/refs/remotes/origin/HEAD ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/logs/refs/remotes/origin/HEAD
*** ./openfl/.git/logs/refs/remotes/origin/HEAD	2022-11-18 11:06:29.691187478 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/logs/refs/remotes/origin/HEAD	1969-12-31 16:00:00.000000000 -0800
***************
*** 1 ****
- 0000000000000000000000000000000000000000 3f2337da62e3f2bf7c3f09bef4be23953b9f2da1 Alam, S M Iftekharul <s.m.iftekharul.alam@intel.com> 1668798389 -0800	clone: from https://github.com/intel/openfl.git
--- 0 ----
Binary files ./openfl/.git/objects/pack/pack-c2edb4b9261240c7409fbdc624ca34cb938d831e.idx and ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/objects/pack/pack-c2edb4b9261240c7409fbdc624ca34cb938d831e.idx differ
Binary files ./openfl/.git/objects/pack/pack-c2edb4b9261240c7409fbdc624ca34cb938d831e.pack and ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/objects/pack/pack-c2edb4b9261240c7409fbdc624ca34cb938d831e.pack differ
diff -crB --new-file ./openfl/.git/packed-refs ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/packed-refs
*** ./openfl/.git/packed-refs	2022-11-18 11:06:29.691187478 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/packed-refs	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,103 ****
- # pack-refs with: peeled fully-peeled sorted 
- 47ecbce8c2154d289bdae7a548da8c2cc86e4c42 refs/remotes/origin/1.3jenkinsadd
- 3562f7abf6952653a1bf0f1712bc7b4e36484f59 refs/remotes/origin/Einse57-docs-improvement
- c282496720151075c900339048a522ba224deac0 refs/remotes/origin/activating_linter_extensions
- 81c0f446c3935a5ea4a82e069f2854c4d709e1ec refs/remotes/origin/add_tests
- 5e93576b95d0e6c636284f71bcadc6659a26cf28 refs/remotes/origin/agg_fn_fix
- d71cdf9191967c867641daef716a7ea096ad0a2b refs/remotes/origin/basic-code-coverage-ci
- dc49548caf7565d774605035faff5e9ad4d889cb refs/remotes/origin/circular_import_issue
- 42777c13f72816649463f0851a8584cf5d9f6752 refs/remotes/origin/correct_typo
- 3f2337da62e3f2bf7c3f09bef4be23953b9f2da1 refs/remotes/origin/develop
- c98455f0107ab829d2cd11473be10e3f9dc9fa74 refs/remotes/origin/dockerezation-launch
- b933e76a05f5f051956ea77cf8f826b72a7154bc refs/remotes/origin/fdl2021
- 96fedde3bd6fa865b0dd42d6f632e726f692d58b refs/remotes/origin/fets
- c7430cc1c9a9026f2c6ddd71ebefd31e57aa0bef refs/remotes/origin/fix298
- 2c42974d3d0afc28f08cf4a81a9ca3498ce590bf refs/remotes/origin/fix_flatten_func
- d1292ce5d2377ed1605581e64c0f37e951f57e6a refs/remotes/origin/fix_send_task_results_rpc
- 4c5863f4057d452336cf3de0e53a035d69583e63 refs/remotes/origin/fix_tutorial
- d84fde864a7dee008ef26d4f88ec8f25a7a5e396 refs/remotes/origin/fixing_grpc_for_develop_install
- dc05e0d4940f283a267695fa347d986019797479 refs/remotes/origin/flake-annotations_openfl-tutotials
- 86ff73e896aab4a73e5741ba4867cfca646298f2 refs/remotes/origin/fluid
- 90a3dfc97c41235d548ce86377562d8d8a978bef refs/remotes/origin/fluid_rebase
- 714e470a2ade450ccc5eaa75b8d21f43bbf0a263 refs/remotes/origin/gh-actions-pylint
- 6d1041ddc0357bd9f59130f17c3b63c782868c28 refs/remotes/origin/icelake_benchmarks
- 34da16a117ebed332e3b17378bf6fbf177e56d9b refs/remotes/origin/icelake_benchmarks_tf
- 029ff4760ac6f9693c61be2a25eb378335714243 refs/remotes/origin/increment_package_version
- 8f9ae8408297d47e82a093da19fd4c410cc1aa10 refs/remotes/origin/jax-support
- 7867eca3fd896d536982aa456c3d1d4b8c363168 refs/remotes/origin/jenkins-build
- 6929bcecd2351d6a9b62c6eae2f5558d68b8d189 refs/remotes/origin/jenkins-v1.4
- 1f5d6e7b7131dd519baf51ecdb9ab29de0e9308b refs/remotes/origin/master
- 1be5e9691af551869fec0886da06af425f4c52f9 refs/remotes/origin/medmnist
- 6637146ca08e11ff553bca27786acc684faf4f1c refs/remotes/origin/miccai_fl_tutorial
- 6232e2a9ccb03edfee287f42490b59922e9c8805 refs/remotes/origin/one_folder_issue
- a35333d1eec7456341bfff5b67e98529d0fcf0d6 refs/remotes/origin/pip-packaging-for-1.4
- cb8aefb1886aa1d137ebe4b79a140a9123163a0b refs/remotes/origin/psfoley-patch-1
- 11290fb0d88537b50a1cb48f63af0d8425bfc8f2 refs/remotes/origin/psfoley-patch-2
- 7517d1c1e654a92dae81afac263b3880177740ee refs/remotes/origin/rc1.3
- 659288aa19a10ee7678fbd3a861880f0dc3aeb8d refs/remotes/origin/secure_api
- 78c0bd826f101255d8e9ead6ea3beb1b2eac9ea0 refs/remotes/origin/snyk-fix-0543da23f39ca12a8754f485b456fb28
- 49c594d944f54caa5e5895ce95fda271e5ae6419 refs/remotes/origin/snyk-fix-072f0b2901e4994f28fa64bb55d0646c
- 59b6e6691dbafcd073fd46a690592016d76f9431 refs/remotes/origin/snyk-fix-09f94368be1c80bc98b89764d0a22e01
- 0cbd581ba2273642cb06a5374e582692eff0f297 refs/remotes/origin/snyk-fix-0b01f0890b45edd23bfdf3a4376f3ca0
- 5300759e5aee3d7089e1a286c84d6873830a3c13 refs/remotes/origin/snyk-fix-0f3b4fcb2be7f6c54231cb384e1a001b
- 6def701c2b341750c5643e68ca10892897e6ac58 refs/remotes/origin/snyk-fix-188ae707c9a0bc620809f736e2436eec
- 9df97273bed5e7949faaf1b037293cee6651f403 refs/remotes/origin/snyk-fix-20b6738f90ae435a1383660bdf5a3cee
- 7c4ea9b6b62fc834d76c76f7da4a3cfac060e733 refs/remotes/origin/snyk-fix-25096b583afd273b6ee28dc5d22f1e40
- a24382c30c0425c46b5d89890d3df7aba7a4c172 refs/remotes/origin/snyk-fix-25aaebeb2fd4245e6821dfeb0ebdc4cd
- 67f62ad28feee8b0c5d02b102f08839a4375cd91 refs/remotes/origin/snyk-fix-2a1b7bb74267202ac1d6a1df0f450844
- 276c982e93b4818707150e2e15102bf135059800 refs/remotes/origin/snyk-fix-2d84f23f9358895b390ac39cbeaaf480
- 85be95c9be4cf22f4b32d1ed7f00c0b0861abc49 refs/remotes/origin/snyk-fix-32af02f4d178dc6171e295da1556ac9e
- 6651e5b74e7ccb41d1fa2c29e7b074186fde0a67 refs/remotes/origin/snyk-fix-37802765302f81a41f2af15ef95f73d6
- dbddbd20841f8ae0037aa997d71ec38f6b17f7a3 refs/remotes/origin/snyk-fix-38361132fac26e5115e39a89fa736888
- cfc4a010ed0607fef8f0b903e249a732db88df01 refs/remotes/origin/snyk-fix-3b8cd9f08d8b9f70e944bfdebcdb47f2
- 7ba9928101b4be3304f131ebddc1604d0ef87f76 refs/remotes/origin/snyk-fix-3bfcaac6978c3ceaa3e9848afe52e819
- f21cc2d6a3581e83597e0fa3275cc92351bdf30a refs/remotes/origin/snyk-fix-42ba2647ba7c474d2bcba0ef2fb7a57f
- bdd8b2f47e05d3ee921424d8a0fd2dd75f2868d3 refs/remotes/origin/snyk-fix-4f07a527c6900bfa2a0b87c96fcd473b
- 8af0a094c744293ca4297bc5f817ccce47678314 refs/remotes/origin/snyk-fix-5434fef0b3d6cb41873b36393fd95a57
- 96b49824840160ccaf1276b45113cf9b7b6099f9 refs/remotes/origin/snyk-fix-57912298552a69d74ed7ec08bc65f3a6
- 57d1c51304213db8a092e0bb878f080a4fe024e4 refs/remotes/origin/snyk-fix-593b05c2ff786a166a7793eb002a3246
- 94c02de4d08bc508d0da72eeff38090c797d5624 refs/remotes/origin/snyk-fix-663af4031807dcd579c6d50c7ee23148
- 8b0f4aae5dcc4c2880d69ac1894b4d6d8bb32fea refs/remotes/origin/snyk-fix-663bd5cafe0b7b31913ce4a66a6fa52a
- 5adc7dbcb9010abcda8418223d7434e52927f680 refs/remotes/origin/snyk-fix-7063a34425fb1364d8804ffdf9c464ef
- 145790b72573a460e5d0622cd7c009192d2041fb refs/remotes/origin/snyk-fix-773d83271c6f91db6a309d5dc099a328
- e824998c30125355f7c1f774e1b96be038f486c8 refs/remotes/origin/snyk-fix-78b4610d1617f4ee51564bed543b4578
- c330f4524fcdc6e730b6b93de82ad4dcd54c8849 refs/remotes/origin/snyk-fix-855b9588b7f87e9b584a586884a8065a
- 69096d549ae25a43fecbe4becfd1e97c1b3a1f7b refs/remotes/origin/snyk-fix-86e51056321f4a2019e83ff089320aeb
- 3ad2e6cfc9a40cb1eea0deb9182109ffcdaf95d2 refs/remotes/origin/snyk-fix-88236640d25fa1ad7eca8bf08b9fb20c
- 63c117d0fe9628dac0e69cabe9b2bf4fd43c6ec1 refs/remotes/origin/snyk-fix-8d51d07960634455a1f8c8d8a773fed8
- 8a3bbfe4a4c4c7b0d244efe84652f9504d7abef6 refs/remotes/origin/snyk-fix-94522a313a42a9a4032d3baa3e0eaece
- afaf2d2920fb354c52f019f1131fd8b256714b46 refs/remotes/origin/snyk-fix-945250ef7fe1d4138756549c27cec610
- f1bc335d53ca0569bfa4b1cb7e40fe446af8ecd4 refs/remotes/origin/snyk-fix-947374d734194ae61e1a99b959b439e6
- 39159d2c4d723dae6889bee9122ce5c4e1779508 refs/remotes/origin/snyk-fix-97c109ce61d00fa96a662359c4cb3a9f
- b2c7a6b7e87632e59ddb6c90dde06bead78f9c22 refs/remotes/origin/snyk-fix-a7b88c5653baffa24b883028fbc6d730
- af92c023d987b04a38b0af279df383c3dd2ddcd6 refs/remotes/origin/snyk-fix-a7bdc46f3e8f74bf4a115b2d8ff94ac4
- 945f405d48ff23141b7b1e921f23674ec79916b1 refs/remotes/origin/snyk-fix-a8857c2bcaa60d2875aeb41fda38cafe
- 36c499ecb9267bf6dea5ad07d7126ab8f69b3092 refs/remotes/origin/snyk-fix-aae410683bccd2fbe29140ca5cf8c609
- 40c7a632d0c956b98003812b675b43e1c2224aff refs/remotes/origin/snyk-fix-af7d124e0d2ed42f7fcaaaddf447ebc2
- dbd9ae4711538980943a55ec0226b58457bda4b6 refs/remotes/origin/snyk-fix-bc66f664adab213c50d2ce40ccdd5980
- 9f1aa22ea228d14f83978eb7c946a61ef95fcfd5 refs/remotes/origin/snyk-fix-c16f1c7d5cb55b6ced0cfcc9e2e1f822
- 1367319510a7445dad38ac73bbcce4901ef371e6 refs/remotes/origin/snyk-fix-cb1c7e612198bf13bd9ccf1d08f24721
- ff693375d3ae362a76dd1fb7adf3600a807411c4 refs/remotes/origin/snyk-fix-d423c44752a8fe4a5ce8cec2f981580a
- 45365b9f96333fd56fd8acd233c6ffad5af86a4c refs/remotes/origin/snyk-fix-d933b74760e888c1df2ff38c06420ca9
- 3476a614f28179c1657e8578c89e881a25837a5d refs/remotes/origin/snyk-fix-dc70fe5e11cd56e6c0d049cd79fb08bc
- 15ea6e8f9d001be73c81bace4a344abbe4fc7539 refs/remotes/origin/snyk-fix-debcfa793b12870d2d1ab774930fa05a
- 108b65c2f3c7d89a52ceba26125449a45c519e30 refs/remotes/origin/snyk-fix-e092d921117ea36156e1cfeb9035a09a
- 886dd87b0a32b1cd7f718656607f97f985908d47 refs/remotes/origin/snyk-fix-e1c143a27f25891222c7e7ee249971b1
- e31eaf4817387c5cd301b0f4eddd00a4e6814df7 refs/remotes/origin/snyk-fix-e2c1ea1849b08d72dcf7a0ed5c0c7764
- 772e4825991646bb80b616a1c86c2d2e66180866 refs/remotes/origin/snyk-fix-e2e8302f8719db8a2dcf69d584b753a7
- e67388c7cb20e9934776c16d57ae3d0d09ab844d refs/remotes/origin/snyk-fix-e64fcd9e382da629bcab4258325a7646
- 53ffd9de2297f69c79ab3cd679c15541483e4279 refs/remotes/origin/snyk-fix-e998370aec45eff164b61282259a34bd
- 376c00e58e0e94f14129e088365a194b2abb841b refs/remotes/origin/snyk-fix-ee86de5ef0800682c53e23f6ecd481d8
- 6d0973aafccbb2a6653cd9436dfb62a5f9f4b810 refs/remotes/origin/snyk-fix-ef371e265951c636b722ce5b51a473a5
- fd990a9cc2bbdfef93c6e917918cff222e098170 refs/remotes/origin/snyk-fix-f1d8c2c8fd658714438d6f1be8eb882d
- 1c127916ea019b269093677f9f30b70771240abc refs/remotes/origin/snyk-fix-f31a9a779021a0928d4e81bcca7276ef
- eea7774af0ef7487a564d9a27cf7464c72e5f259 refs/remotes/origin/snyk-fix-f6b87df814f259f70d58c2dc8feb6eb4
- 6d96756833f5a489177f9d4b1f735031ea112342 refs/remotes/origin/snyk-fix-f907134cb05253186fd641bb15100659
- d3a05a6e376f5e737418d574e0d8af99bf9f5977 refs/remotes/origin/windows_ci
- b41b9ff81129d31776dab3db8337bfa9241e8ad4 refs/tags/v1.0
- 3645f8d57771bf7f3f772c839dafb800b8e87634 refs/tags/v1.0.1
- 1f5d6e7b7131dd519baf51ecdb9ab29de0e9308b refs/tags/v1.1
- 10b60b2b564cdf3b0c507cfe88c7cb36ba9e67b4 refs/tags/v1.2
- 0ce518031c716efc70db3e7b10140e1d83a7091c refs/tags/v1.2.1
- c2e8c0d512ec4f3346176edd042ace31405a366b refs/tags/v1.3
- 3a0d662a3a37aceacb7904a2b14564f136d823ed refs/tags/v1.4
--- 0 ----
diff -crB --new-file ./openfl/.git/refs/heads/develop ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/refs/heads/develop
*** ./openfl/.git/refs/heads/develop	2022-11-18 11:06:29.691187478 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/refs/heads/develop	1969-12-31 16:00:00.000000000 -0800
***************
*** 1 ****
- 3f2337da62e3f2bf7c3f09bef4be23953b9f2da1
--- 0 ----
diff -crB --new-file ./openfl/.git/refs/remotes/origin/HEAD ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/refs/remotes/origin/HEAD
*** ./openfl/.git/refs/remotes/origin/HEAD	2022-11-18 11:06:29.691187478 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.git/refs/remotes/origin/HEAD	1969-12-31 16:00:00.000000000 -0800
***************
*** 1 ****
- ref: refs/remotes/origin/develop
--- 0 ----
diff -crB --new-file ./openfl/.github/ISSUE_TEMPLATE/bug_report.md ../mlwins-simulation-framework/ml-frameworks/federated-learning/.github/ISSUE_TEMPLATE/bug_report.md
*** ./openfl/.github/ISSUE_TEMPLATE/bug_report.md	2022-11-18 11:06:29.703187478 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.github/ISSUE_TEMPLATE/bug_report.md	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,38 ****
- ---
- name: Bug report
- about: Create a report to help us improve
- title: ''
- labels: ''
- assignees: ''
- 
- ---
- 
- **Describe the bug**
- A clear and concise description of what the bug is.
- 
- **To Reproduce**
- Steps to reproduce the behavior:
- 1. Go to '...'
- 2. Click on '....'
- 3. Scroll down to '....'
- 4. See error
- 
- **Expected behavior**
- A clear and concise description of what you expected to happen.
- 
- **Screenshots**
- If applicable, add screenshots to help explain your problem.
- 
- **Desktop (please complete the following information):**
-  - OS: [e.g. iOS]
-  - Browser [e.g. chrome, safari]
-  - Version [e.g. 22]
- 
- **Smartphone (please complete the following information):**
-  - Device: [e.g. iPhone6]
-  - OS: [e.g. iOS8.1]
-  - Browser [e.g. stock browser, safari]
-  - Version [e.g. 22]
- 
- **Additional context**
- Add any other context about the problem here.
--- 0 ----
diff -crB --new-file ./openfl/.github/ISSUE_TEMPLATE/feature_request.md ../mlwins-simulation-framework/ml-frameworks/federated-learning/.github/ISSUE_TEMPLATE/feature_request.md
*** ./openfl/.github/ISSUE_TEMPLATE/feature_request.md	2022-11-18 11:06:29.703187478 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.github/ISSUE_TEMPLATE/feature_request.md	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,20 ****
- ---
- name: Feature request
- about: Suggest an idea for this project
- title: ''
- labels: ''
- assignees: ''
- 
- ---
- 
- **Is your feature request related to a problem? Please describe.**
- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]
- 
- **Describe the solution you'd like**
- A clear and concise description of what you want to happen.
- 
- **Describe alternatives you've considered**
- A clear and concise description of any alternative solutions or features you've considered.
- 
- **Additional context**
- Add any other context or screenshots about the feature request here.
--- 0 ----
diff -crB --new-file ./openfl/.github/workflows/cla.yml ../mlwins-simulation-framework/ml-frameworks/federated-learning/.github/workflows/cla.yml
*** ./openfl/.github/workflows/cla.yml	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.github/workflows/cla.yml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,36 ****
- name: "CLA Assistant"
- on:
-   issue_comment:
-     types: [created]
-   pull_request_target:
-     types: [opened,closed,synchronize]
- 
- jobs:
-   CLAssistant:
-     runs-on: ubuntu-latest
-     steps:
-       - name: "CLA Assistant"
-         if: (github.event.comment.body == 'recheck' || github.event.comment.body == 'I have read the CLA Document and I hereby sign the CLA') || github.event_name == 'pull_request_target'
-         # Beta Release
-         uses: cla-assistant/github-action@v2.1.2-beta
-         env:
-           GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
-           # the below token should have repo scope and must be manually added by you in the repository's secret
-           PERSONAL_ACCESS_TOKEN : ${{ secrets.PERSONAL_ACCESS_TOKEN }}
-         with:
-           path-to-signatures: '.signatures/cla.json'
-           path-to-document: 'https://github.com/intel/openfl/blob/develop/CLA.md' # e.g. a CLA or a DCO document
-           # branch should not be protected
-           branch: 'develop'
-           allowlist: alexey-gruzdev,psfoley,msheller,brandon-edwards,tonyreina,itrushkin,aleksandr-mokrov,igor-davidyuk,operepel,maradionov,mansishr,dmitryagapov,openfl-helper,bot*
- 
-          #below are the optional inputs - If the optional inputs are not given, then default values will be taken
-           #remote-organization-name: enter the remote organization name where the signatures should be stored (Default is storing the signatures in the same repository)
-           #remote-repository-name:  enter the  remote repository name where the signatures should be stored (Default is storing the signatures in the same repository)
-           #create-file-commit-message: 'For example: Creating file for storing CLA Signatures'
-           #signed-commit-message: 'For example: $contributorName has signed the CLA in #$pullRequestNo'
-           #custom-notsigned-prcomment: 'pull request comment with Introductory message to ask new contributors to sign'
-           #custom-pr-sign-comment: 'The signature to be committed in order to sign the CLA'
-           #custom-allsigned-prcomment: 'pull request comment when all contributors has signed, defaults to **CLA Assistant Lite bot** All Contributors have signed the CLA.'
-           #lock-pullrequest-aftermerge: false - if you don't want this bot to automatically lock the pull request after merging (default - true)
-           #use-dco-flag: true - If you are using DCO instead of CLA
--- 0 ----
diff -crB --new-file ./openfl/.gitignore ../mlwins-simulation-framework/ml-frameworks/federated-learning/.gitignore
*** ./openfl/.gitignore	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.gitignore	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,13 ****
- *.egg-info
- *.pkl
- __pycache__
- /build
- /dist
- .vscode
- .ipynb_checkpoints
- venv/*
- .idea
- 
- *.jpg
- *.crt
- *.key
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/LICENSE ../mlwins-simulation-framework/ml-frameworks/federated-learning/LICENSE
*** ./openfl/LICENSE	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/LICENSE	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,1381 ****
-                                 Apache License
-                            Version 2.0, January 2004
-                         http://www.apache.org/licenses/
- 
-    TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
- 
-    1. Definitions.
- 
-       "License" shall mean the terms and conditions for use, reproduction,
-       and distribution as defined by Sections 1 through 9 of this document.
- 
-       "Licensor" shall mean the copyright owner or entity authorized by
-       the copyright owner that is granting the License.
- 
-       "Legal Entity" shall mean the union of the acting entity and all
-       other entities that control, are controlled by, or are under common
-       control with that entity. For the purposes of this definition,
-       "control" means (i) the power, direct or indirect, to cause the
-       direction or management of such entity, whether by contract or
-       otherwise, or (ii) ownership of fifty percent (50%) or more of the
-       outstanding shares, or (iii) beneficial ownership of such entity.
- 
-       "You" (or "Your") shall mean an individual or Legal Entity
-       exercising permissions granted by this License.
- 
-       "Source" form shall mean the preferred form for making modifications,
-       including but not limited to software source code, documentation
-       source, and configuration files.
- 
-       "Object" form shall mean any form resulting from mechanical
-       transformation or translation of a Source form, including but
-       not limited to compiled object code, generated documentation,
-       and conversions to other media types.
- 
-       "Work" shall mean the work of authorship, whether in Source or
-       Object form, made available under the License, as indicated by a
-       copyright notice that is included in or attached to the work
-       (an example is provided in the Appendix below).
- 
-       "Derivative Works" shall mean any work, whether in Source or Object
-       form, that is based on (or derived from) the Work and for which the
-       editorial revisions, annotations, elaborations, or other modifications
-       represent, as a whole, an original work of authorship. For the purposes
-       of this License, Derivative Works shall not include works that remain
-       separable from, or merely link (or bind by name) to the interfaces of,
-       the Work and Derivative Works thereof.
- 
-       "Contribution" shall mean any work of authorship, including
-       the original version of the Work and any modifications or additions
-       to that Work or Derivative Works thereof, that is intentionally
-       submitted to Licensor for inclusion in the Work by the copyright owner
-       or by an individual or Legal Entity authorized to submit on behalf of
-       the copyright owner. For the purposes of this definition, "submitted"
-       means any form of electronic, verbal, or written communication sent
-       to the Licensor or its representatives, including but not limited to
-       communication on electronic mailing lists, source code control systems,
-       and issue tracking systems that are managed by, or on behalf of, the
-       Licensor for the purpose of discussing and improving the Work, but
-       excluding communication that is conspicuously marked or otherwise
-       designated in writing by the copyright owner as "Not a Contribution."
- 
-       "Contributor" shall mean Licensor and any individual or Legal Entity
-       on behalf of whom a Contribution has been received by Licensor and
-       subsequently incorporated within the Work.
- 
-    2. Grant of Copyright License. Subject to the terms and conditions of
-       this License, each Contributor hereby grants to You a perpetual,
-       worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-       copyright license to reproduce, prepare Derivative Works of,
-       publicly display, publicly perform, sublicense, and distribute the
-       Work and such Derivative Works in Source or Object form.
- 
-    3. Grant of Patent License. Subject to the terms and conditions of
-       this License, each Contributor hereby grants to You a perpetual,
-       worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-       (except as stated in this section) patent license to make, have made,
-       use, offer to sell, sell, import, and otherwise transfer the Work,
-       where such license applies only to those patent claims licensable
-       by such Contributor that are necessarily infringed by their
-       Contribution(s) alone or by combination of their Contribution(s)
-       with the Work to which such Contribution(s) was submitted. If You
-       institute patent litigation against any entity (including a
-       cross-claim or counterclaim in a lawsuit) alleging that the Work
-       or a Contribution incorporated within the Work constitutes direct
-       or contributory patent infringement, then any patent licenses
-       granted to You under this License for that Work shall terminate
-       as of the date such litigation is filed.
- 
-    4. Redistribution. You may reproduce and distribute copies of the
-       Work or Derivative Works thereof in any medium, with or without
-       modifications, and in Source or Object form, provided that You
-       meet the following conditions:
- 
-       (a) You must give any other recipients of the Work or
-           Derivative Works a copy of this License; and
- 
-       (b) You must cause any modified files to carry prominent notices
-           stating that You changed the files; and
- 
-       (c) You must retain, in the Source form of any Derivative Works
-           that You distribute, all copyright, patent, trademark, and
-           attribution notices from the Source form of the Work,
-           excluding those notices that do not pertain to any part of
-           the Derivative Works; and
- 
-       (d) If the Work includes a "NOTICE" text file as part of its
-           distribution, then any Derivative Works that You distribute must
-           include a readable copy of the attribution notices contained
-           within such NOTICE file, excluding those notices that do not
-           pertain to any part of the Derivative Works, in at least one
-           of the following places: within a NOTICE text file distributed
-           as part of the Derivative Works; within the Source form or
-           documentation, if provided along with the Derivative Works; or,
-           within a display generated by the Derivative Works, if and
-           wherever such third-party notices normally appear. The contents
-           of the NOTICE file are for informational purposes only and
-           do not modify the License. You may add Your own attribution
-           notices within Derivative Works that You distribute, alongside
-           or as an addendum to the NOTICE text from the Work, provided
-           that such additional attribution notices cannot be construed
-           as modifying the License.
- 
-       You may add Your own copyright statement to Your modifications and
-       may provide additional or different license terms and conditions
-       for use, reproduction, or distribution of Your modifications, or
-       for any such Derivative Works as a whole, provided Your use,
-       reproduction, and distribution of the Work otherwise complies with
-       the conditions stated in this License.
- 
-    5. Submission of Contributions. Unless You explicitly state otherwise,
-       any Contribution intentionally submitted for inclusion in the Work
-       by You to the Licensor shall be under the terms and conditions of
-       this License, without any additional terms or conditions.
-       Notwithstanding the above, nothing herein shall supersede or modify
-       the terms of any separate license agreement you may have executed
-       with Licensor regarding such Contributions.
- 
-    6. Trademarks. This License does not grant permission to use the trade
-       names, trademarks, service marks, or product names of the Licensor,
-       except as required for reasonable and customary use in describing the
-       origin of the Work and reproducing the content of the NOTICE file.
- 
-    7. Disclaimer of Warranty. Unless required by applicable law or
-       agreed to in writing, Licensor provides the Work (and each
-       Contributor provides its Contributions) on an "AS IS" BASIS,
-       WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
-       implied, including, without limitation, any warranties or conditions
-       of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
-       PARTICULAR PURPOSE. You are solely responsible for determining the
-       appropriateness of using or redistributing the Work and assume any
-       risks associated with Your exercise of permissions under this License.
- 
-    8. Limitation of Liability. In no event and under no legal theory,
-       whether in tort (including negligence), contract, or otherwise,
-       unless required by applicable law (such as deliberate and grossly
-       negligent acts) or agreed to in writing, shall any Contributor be
-       liable to You for damages, including any direct, indirect, special,
-       incidental, or consequential damages of any character arising as a
-       result of this License or out of the use or inability to use the
-       Work (including but not limited to damages for loss of goodwill,
-       work stoppage, computer failure or malfunction, or any and all
-       other commercial damages or losses), even if such Contributor
-       has been advised of the possibility of such damages.
- 
-    9. Accepting Warranty or Additional Liability. While redistributing
-       the Work or Derivative Works thereof, You may choose to offer,
-       and charge a fee for, acceptance of support, warranty, indemnity,
-       or other liability obligations and/or rights consistent with this
-       License. However, in accepting such obligations, You may act only
-       on Your own behalf and on Your sole responsibility, not on behalf
-       of any other Contributor, and only if You agree to indemnify,
-       defend, and hold each Contributor harmless for any liability
-       incurred by, or claims asserted against, such Contributor by reason
-       of your accepting any such warranty or additional liability.
- 
-    END OF TERMS AND CONDITIONS
- 
-    APPENDIX: How to apply the Apache License to your work.
- 
-       To apply the Apache License to your work, attach the following
-       boilerplate notice, with the fields enclosed by brackets "[]"
-       replaced with your own identifying information. (Don't include
-       the brackets!)  The text should be enclosed in the appropriate
-       comment syntax for the file format. We also recommend that a
-       file or class name and description of purpose be included on the
-       same "printed page" as the copyright notice for easier
-       identification within third-party archives.
- 
-    Copyright [yyyy] [name of copyright owner]
- 
-    Licensed under the Apache License, Version 2.0 (the "License");
-    you may not use this file except in compliance with the License.
-    You may obtain a copy of the License at
- 
-        http://www.apache.org/licenses/LICENSE-2.0
- 
-    Unless required by applicable law or agreed to in writing, software
-    distributed under the License is distributed on an "AS IS" BASIS,
-    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-    See the License for the specific language governing permissions and
-    limitations under the License.
- 
- 
- From click:
- 
- https://click.palletsprojects.com/en/7.x/license/
- BSD-3-Clause License
- Copyright 2014 Pallets
- 
- Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
- 
- Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
- 
- Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.
- 
- Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.
- 
- THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- 
- From PyTorch:
- 
- Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)
- Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)
- Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
- Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
- Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
- Copyright (c) 2011-2013 NYU                      (Clement Farabet)
- Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
- Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
- Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
- 
- From Caffe2:
- 
- Copyright (c) 2016-present, Facebook Inc. All rights reserved.
- 
- All contributions by Facebook:
- Copyright (c) 2016 Facebook Inc.
-  
- All contributions by Google:
- Copyright (c) 2015 Google Inc.
- All rights reserved.
-  
- All contributions by Yangqing Jia:
- Copyright (c) 2015 Yangqing Jia
- All rights reserved.
-  
- All contributions from Caffe:
- Copyright(c) 2013, 2014, 2015, the respective contributors
- All rights reserved.
-  
- All other contributions:
- Copyright(c) 2015, 2016 the respective contributors
- All rights reserved.
-  
- Caffe2 uses a copyright model similar to Caffe: each contributor holds
- copyright over their contributions to Caffe2. The project versioning records
- all such contribution and copyright details. If a contributor wants to further
- mark their specific copyright on a particular contribution, they should
- indicate their copyright solely in the commit message of the change when it is
- committed.
- 
- All rights reserved.
- 
- Redistribution and use in source and binary forms, with or without
- modification, are permitted provided that the following conditions are met:
- 
- 1. Redistributions of source code must retain the above copyright
-    notice, this list of conditions and the following disclaimer.
- 
- 2. Redistributions in binary form must reproduce the above copyright
-    notice, this list of conditions and the following disclaimer in the
-    documentation and/or other materials provided with the distribution.
- 
- 3. Neither the names of Facebook, Deepmind Technologies, NYU, NEC Laboratories America
-    and IDIAP Research Institute nor the names of its contributors may be
-    used to endorse or promote products derived from this software without
-    specific prior written permission.
- 
- THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
- AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
- ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
- LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
- CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
- SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
- INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
- CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
- ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
- POSSIBILITY OF SUCH DAMAGE.
- 
- from grpc:
- 
-                                  Apache License
-                            Version 2.0, January 2004
-                         http://www.apache.org/licenses/
- 
-    TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
- 
-    1. Definitions.
- 
-       "License" shall mean the terms and conditions for use, reproduction,
-       and distribution as defined by Sections 1 through 9 of this document.
- 
-       "Licensor" shall mean the copyright owner or entity authorized by
-       the copyright owner that is granting the License.
- 
-       "Legal Entity" shall mean the union of the acting entity and all
-       other entities that control, are controlled by, or are under common
-       control with that entity. For the purposes of this definition,
-       "control" means (i) the power, direct or indirect, to cause the
-       direction or management of such entity, whether by contract or
-       otherwise, or (ii) ownership of fifty percent (50%) or more of the
-       outstanding shares, or (iii) beneficial ownership of such entity.
- 
-       "You" (or "Your") shall mean an individual or Legal Entity
-       exercising permissions granted by this License.
- 
-       "Source" form shall mean the preferred form for making modifications,
-       including but not limited to software source code, documentation
-       source, and configuration files.
- 
-       "Object" form shall mean any form resulting from mechanical
-       transformation or translation of a Source form, including but
-       not limited to compiled object code, generated documentation,
-       and conversions to other media types.
- 
-       "Work" shall mean the work of authorship, whether in Source or
-       Object form, made available under the License, as indicated by a
-       copyright notice that is included in or attached to the work
-       (an example is provided in the Appendix below).
- 
-       "Derivative Works" shall mean any work, whether in Source or Object
-       form, that is based on (or derived from) the Work and for which the
-       editorial revisions, annotations, elaborations, or other modifications
-       represent, as a whole, an original work of authorship. For the purposes
-       of this License, Derivative Works shall not include works that remain
-       separable from, or merely link (or bind by name) to the interfaces of,
-       the Work and Derivative Works thereof.
- 
-       "Contribution" shall mean any work of authorship, including
-       the original version of the Work and any modifications or additions
-       to that Work or Derivative Works thereof, that is intentionally
-       submitted to Licensor for inclusion in the Work by the copyright owner
-       or by an individual or Legal Entity authorized to submit on behalf of
-       the copyright owner. For the purposes of this definition, "submitted"
-       means any form of electronic, verbal, or written communication sent
-       to the Licensor or its representatives, including but not limited to
-       communication on electronic mailing lists, source code control systems,
-       and issue tracking systems that are managed by, or on behalf of, the
-       Licensor for the purpose of discussing and improving the Work, but
-       excluding communication that is conspicuously marked or otherwise
-       designated in writing by the copyright owner as "Not a Contribution."
- 
-       "Contributor" shall mean Licensor and any individual or Legal Entity
-       on behalf of whom a Contribution has been received by Licensor and
-       subsequently incorporated within the Work.
- 
-    2. Grant of Copyright License. Subject to the terms and conditions of
-       this License, each Contributor hereby grants to You a perpetual,
-       worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-       copyright license to reproduce, prepare Derivative Works of,
-       publicly display, publicly perform, sublicense, and distribute the
-       Work and such Derivative Works in Source or Object form.
- 
-    3. Grant of Patent License. Subject to the terms and conditions of
-       this License, each Contributor hereby grants to You a perpetual,
-       worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-       (except as stated in this section) patent license to make, have made,
-       use, offer to sell, sell, import, and otherwise transfer the Work,
-       where such license applies only to those patent claims licensable
-       by such Contributor that are necessarily infringed by their
-       Contribution(s) alone or by combination of their Contribution(s)
-       with the Work to which such Contribution(s) was submitted. If You
-       institute patent litigation against any entity (including a
-       cross-claim or counterclaim in a lawsuit) alleging that the Work
-       or a Contribution incorporated within the Work constitutes direct
-       or contributory patent infringement, then any patent licenses
-       granted to You under this License for that Work shall terminate
-       as of the date such litigation is filed.
- 
-    4. Redistribution. You may reproduce and distribute copies of the
-       Work or Derivative Works thereof in any medium, with or without
-       modifications, and in Source or Object form, provided that You
-       meet the following conditions:
- 
-       (a) You must give any other recipients of the Work or
-           Derivative Works a copy of this License; and
- 
-       (b) You must cause any modified files to carry prominent notices
-           stating that You changed the files; and
- 
-       (c) You must retain, in the Source form of any Derivative Works
-           that You distribute, all copyright, patent, trademark, and
-           attribution notices from the Source form of the Work,
-           excluding those notices that do not pertain to any part of
-           the Derivative Works; and
- 
-       (d) If the Work includes a "NOTICE" text file as part of its
-           distribution, then any Derivative Works that You distribute must
-           include a readable copy of the attribution notices contained
-           within such NOTICE file, excluding those notices that do not
-           pertain to any part of the Derivative Works, in at least one
-           of the following places: within a NOTICE text file distributed
-           as part of the Derivative Works; within the Source form or
-           documentation, if provided along with the Derivative Works; or,
-           within a display generated by the Derivative Works, if and
-           wherever such third-party notices normally appear. The contents
-           of the NOTICE file are for informational purposes only and
-           do not modify the License. You may add Your own attribution
-           notices within Derivative Works that You distribute, alongside
-           or as an addendum to the NOTICE text from the Work, provided
-           that such additional attribution notices cannot be construed
-           as modifying the License.
- 
-       You may add Your own copyright statement to Your modifications and
-       may provide additional or different license terms and conditions
-       for use, reproduction, or distribution of Your modifications, or
-       for any such Derivative Works as a whole, provided Your use,
-       reproduction, and distribution of the Work otherwise complies with
-       the conditions stated in this License.
- 
-    5. Submission of Contributions. Unless You explicitly state otherwise,
-       any Contribution intentionally submitted for inclusion in the Work
-       by You to the Licensor shall be under the terms and conditions of
-       this License, without any additional terms or conditions.
-       Notwithstanding the above, nothing herein shall supersede or modify
-       the terms of any separate license agreement you may have executed
-       with Licensor regarding such Contributions.
- 
-    6. Trademarks. This License does not grant permission to use the trade
-       names, trademarks, service marks, or product names of the Licensor,
-       except as required for reasonable and customary use in describing the
-       origin of the Work and reproducing the content of the NOTICE file.
- 
-    7. Disclaimer of Warranty. Unless required by applicable law or
-       agreed to in writing, Licensor provides the Work (and each
-       Contributor provides its Contributions) on an "AS IS" BASIS,
-       WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
-       implied, including, without limitation, any warranties or conditions
-       of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
-       PARTICULAR PURPOSE. You are solely responsible for determining the
-       appropriateness of using or redistributing the Work and assume any
-       risks associated with Your exercise of permissions under this License.
- 
-    8. Limitation of Liability. In no event and under no legal theory,
-       whether in tort (including negligence), contract, or otherwise,
-       unless required by applicable law (such as deliberate and grossly
-       negligent acts) or agreed to in writing, shall any Contributor be
-       liable to You for damages, including any direct, indirect, special,
-       incidental, or consequential damages of any character arising as a
-       result of this License or out of the use or inability to use the
-       Work (including but not limited to damages for loss of goodwill,
-       work stoppage, computer failure or malfunction, or any and all
-       other commercial damages or losses), even if such Contributor
-       has been advised of the possibility of such damages.
- 
-    9. Accepting Warranty or Additional Liability. While redistributing
-       the Work or Derivative Works thereof, You may choose to offer,
-       and charge a fee for, acceptance of support, warranty, indemnity,
-       or other liability obligations and/or rights consistent with this
-       License. However, in accepting such obligations, You may act only
-       on Your own behalf and on Your sole responsibility, not on behalf
-       of any other Contributor, and only if You agree to indemnify,
-       defend, and hold each Contributor harmless for any liability
-       incurred by, or claims asserted against, such Contributor by reason
-       of your accepting any such warranty or additional liability.
- 
-    END OF TERMS AND CONDITIONS
- 
-    APPENDIX: How to apply the Apache License to your work.
- 
-       To apply the Apache License to your work, attach the following
-       boilerplate notice, with the fields enclosed by brackets "[]"
-       replaced with your own identifying information. (Don't include
-       the brackets!)  The text should be enclosed in the appropriate
-       comment syntax for the file format. We also recommend that a
-       file or class name and description of purpose be included on the
-       same "printed page" as the copyright notice for easier
-       identification within third-party archives.
- 
-    Copyright [yyyy] [name of copyright owner]
- 
-    Licensed under the Apache License, Version 2.0 (the "License");
-    you may not use this file except in compliance with the License.
-    You may obtain a copy of the License at
- 
-        http://www.apache.org/licenses/LICENSE-2.0
- 
-    Unless required by applicable law or agreed to in writing, software
-    distributed under the License is distributed on an "AS IS" BASIS,
-    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-    See the License for the specific language governing permissions and
-    limitations under the License.
- 
- From numpy:
- 
- Copyright (c) 2005-2019, NumPy Developers.
- All rights reserved.
- 
- Redistribution and use in source and binary forms, with or without
- modification, are permitted provided that the following conditions are
- met:
- 
-     * Redistributions of source code must retain the above copyright
-        notice, this list of conditions and the following disclaimer.
- 
-     * Redistributions in binary form must reproduce the above
-        copyright notice, this list of conditions and the following
-        disclaimer in the documentation and/or other materials provided
-        with the distribution.
- 
-     * Neither the name of the NumPy Developers nor the names of any
-        contributors may be used to endorse or promote products derived
-        from this software without specific prior written permission.
- 
- THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- 
- From protobuf:
- 
- Copyright 2008 Google Inc.  All rights reserved.
- 
- Redistribution and use in source and binary forms, with or without
- modification, are permitted provided that the following conditions are
- met:
- 
-     * Redistributions of source code must retain the above copyright
- notice, this list of conditions and the following disclaimer.
-     * Redistributions in binary form must reproduce the above
- copyright notice, this list of conditions and the following disclaimer
- in the documentation and/or other materials provided with the
- distribution.
-     * Neither the name of Google Inc. nor the names of its
- contributors may be used to endorse or promote products derived from
- this software without specific prior written permission.
- 
- THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- 
- Code generated by the Protocol Buffer compiler is owned by the owner
- of the input file used when generating it.  This code is not
- standalone and requires a support library to be linked with it.  This
- support library is itself covered by the above license.
- 
- From tensorflow:
- 
- Copyright 2019 The TensorFlow Authors.  All rights reserved.
- 
-                                  Apache License
-                            Version 2.0, January 2004
-                         http://www.apache.org/licenses/
- 
-    TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
- 
-    1. Definitions.
- 
-       "License" shall mean the terms and conditions for use, reproduction,
-       and distribution as defined by Sections 1 through 9 of this document.
- 
-       "Licensor" shall mean the copyright owner or entity authorized by
-       the copyright owner that is granting the License.
- 
-       "Legal Entity" shall mean the union of the acting entity and all
-       other entities that control, are controlled by, or are under common
-       control with that entity. For the purposes of this definition,
-       "control" means (i) the power, direct or indirect, to cause the
-       direction or management of such entity, whether by contract or
-       otherwise, or (ii) ownership of fifty percent (50%) or more of the
-       outstanding shares, or (iii) beneficial ownership of such entity.
- 
-       "You" (or "Your") shall mean an individual or Legal Entity
-       exercising permissions granted by this License.
- 
-       "Source" form shall mean the preferred form for making modifications,
-       including but not limited to software source code, documentation
-       source, and configuration files.
- 
-       "Object" form shall mean any form resulting from mechanical
-       transformation or translation of a Source form, including but
-       not limited to compiled object code, generated documentation,
-       and conversions to other media types.
- 
-       "Work" shall mean the work of authorship, whether in Source or
-       Object form, made available under the License, as indicated by a
-       copyright notice that is included in or attached to the work
-       (an example is provided in the Appendix below).
- 
-       "Derivative Works" shall mean any work, whether in Source or Object
-       form, that is based on (or derived from) the Work and for which the
-       editorial revisions, annotations, elaborations, or other modifications
-       represent, as a whole, an original work of authorship. For the purposes
-       of this License, Derivative Works shall not include works that remain
-       separable from, or merely link (or bind by name) to the interfaces of,
-       the Work and Derivative Works thereof.
- 
-       "Contribution" shall mean any work of authorship, including
-       the original version of the Work and any modifications or additions
-       to that Work or Derivative Works thereof, that is intentionally
-       submitted to Licensor for inclusion in the Work by the copyright owner
-       or by an individual or Legal Entity authorized to submit on behalf of
-       the copyright owner. For the purposes of this definition, "submitted"
-       means any form of electronic, verbal, or written communication sent
-       to the Licensor or its representatives, including but not limited to
-       communication on electronic mailing lists, source code control systems,
-       and issue tracking systems that are managed by, or on behalf of, the
-       Licensor for the purpose of discussing and improving the Work, but
-       excluding communication that is conspicuously marked or otherwise
-       designated in writing by the copyright owner as "Not a Contribution."
- 
-       "Contributor" shall mean Licensor and any individual or Legal Entity
-       on behalf of whom a Contribution has been received by Licensor and
-       subsequently incorporated within the Work.
- 
-    2. Grant of Copyright License. Subject to the terms and conditions of
-       this License, each Contributor hereby grants to You a perpetual,
-       worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-       copyright license to reproduce, prepare Derivative Works of,
-       publicly display, publicly perform, sublicense, and distribute the
-       Work and such Derivative Works in Source or Object form.
- 
-    3. Grant of Patent License. Subject to the terms and conditions of
-       this License, each Contributor hereby grants to You a perpetual,
-       worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-       (except as stated in this section) patent license to make, have made,
-       use, offer to sell, sell, import, and otherwise transfer the Work,
-       where such license applies only to those patent claims licensable
-       by such Contributor that are necessarily infringed by their
-       Contribution(s) alone or by combination of their Contribution(s)
-       with the Work to which such Contribution(s) was submitted. If You
-       institute patent litigation against any entity (including a
-       cross-claim or counterclaim in a lawsuit) alleging that the Work
-       or a Contribution incorporated within the Work constitutes direct
-       or contributory patent infringement, then any patent licenses
-       granted to You under this License for that Work shall terminate
-       as of the date such litigation is filed.
- 
-    4. Redistribution. You may reproduce and distribute copies of the
-       Work or Derivative Works thereof in any medium, with or without
-       modifications, and in Source or Object form, provided that You
-       meet the following conditions:
- 
-       (a) You must give any other recipients of the Work or
-           Derivative Works a copy of this License; and
- 
-       (b) You must cause any modified files to carry prominent notices
-           stating that You changed the files; and
- 
-       (c) You must retain, in the Source form of any Derivative Works
-           that You distribute, all copyright, patent, trademark, and
-           attribution notices from the Source form of the Work,
-           excluding those notices that do not pertain to any part of
-           the Derivative Works; and
- 
-       (d) If the Work includes a "NOTICE" text file as part of its
-           distribution, then any Derivative Works that You distribute must
-           include a readable copy of the attribution notices contained
-           within such NOTICE file, excluding those notices that do not
-           pertain to any part of the Derivative Works, in at least one
-           of the following places: within a NOTICE text file distributed
-           as part of the Derivative Works; within the Source form or
-           documentation, if provided along with the Derivative Works; or,
-           within a display generated by the Derivative Works, if and
-           wherever such third-party notices normally appear. The contents
-           of the NOTICE file are for informational purposes only and
-           do not modify the License. You may add Your own attribution
-           notices within Derivative Works that You distribute, alongside
-           or as an addendum to the NOTICE text from the Work, provided
-           that such additional attribution notices cannot be construed
-           as modifying the License.
- 
-       You may add Your own copyright statement to Your modifications and
-       may provide additional or different license terms and conditions
-       for use, reproduction, or distribution of Your modifications, or
-       for any such Derivative Works as a whole, provided Your use,
-       reproduction, and distribution of the Work otherwise complies with
-       the conditions stated in this License.
- 
-    5. Submission of Contributions. Unless You explicitly state otherwise,
-       any Contribution intentionally submitted for inclusion in the Work
-       by You to the Licensor shall be under the terms and conditions of
-       this License, without any additional terms or conditions.
-       Notwithstanding the above, nothing herein shall supersede or modify
-       the terms of any separate license agreement you may have executed
-       with Licensor regarding such Contributions.
- 
-    6. Trademarks. This License does not grant permission to use the trade
-       names, trademarks, service marks, or product names of the Licensor,
-       except as required for reasonable and customary use in describing the
-       origin of the Work and reproducing the content of the NOTICE file.
- 
-    7. Disclaimer of Warranty. Unless required by applicable law or
-       agreed to in writing, Licensor provides the Work (and each
-       Contributor provides its Contributions) on an "AS IS" BASIS,
-       WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
-       implied, including, without limitation, any warranties or conditions
-       of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
-       PARTICULAR PURPOSE. You are solely responsible for determining the
-       appropriateness of using or redistributing the Work and assume any
-       risks associated with Your exercise of permissions under this License.
- 
-    8. Limitation of Liability. In no event and under no legal theory,
-       whether in tort (including negligence), contract, or otherwise,
-       unless required by applicable law (such as deliberate and grossly
-       negligent acts) or agreed to in writing, shall any Contributor be
-       liable to You for damages, including any direct, indirect, special,
-       incidental, or consequential damages of any character arising as a
-       result of this License or out of the use or inability to use the
-       Work (including but not limited to damages for loss of goodwill,
-       work stoppage, computer failure or malfunction, or any and all
-       other commercial damages or losses), even if such Contributor
-       has been advised of the possibility of such damages.
- 
-    9. Accepting Warranty or Additional Liability. While redistributing
-       the Work or Derivative Works thereof, You may choose to offer,
-       and charge a fee for, acceptance of support, warranty, indemnity,
-       or other liability obligations and/or rights consistent with this
-       License. However, in accepting such obligations, You may act only
-       on Your own behalf and on Your sole responsibility, not on behalf
-       of any other Contributor, and only if You agree to indemnify,
-       defend, and hold each Contributor harmless for any liability
-       incurred by, or claims asserted against, such Contributor by reason
-       of your accepting any such warranty or additional liability.
- 
-    END OF TERMS AND CONDITIONS
- 
-    APPENDIX: How to apply the Apache License to your work.
- 
-       To apply the Apache License to your work, attach the following
-       boilerplate notice, with the fields enclosed by brackets "[]"
-       replaced with your own identifying information. (Don't include
-       the brackets!)  The text should be enclosed in the appropriate
-       comment syntax for the file format. We also recommend that a
-       file or class name and description of purpose be included on the
-       same "printed page" as the copyright notice for easier
-       identification within third-party archives.
- 
-    Copyright [yyyy] [name of copyright owner]
- 
-    Licensed under the Apache License, Version 2.0 (the "License");
-    you may not use this file except in compliance with the License.
-    You may obtain a copy of the License at
- 
-        http://www.apache.org/licenses/LICENSE-2.0
- 
-    Unless required by applicable law or agreed to in writing, software
-    distributed under the License is distributed on an "AS IS" BASIS,
-    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-    See the License for the specific language governing permissions and
-    limitations under the License.
- 
- From pyyaml:
- 
- Copyright (c) 2017-2020 Ingy döt Net
- Copyright (c) 2006-2016 Kirill Simonov
- 
- Permission is hereby granted, free of charge, to any person obtaining a copy of
- this software and associated documentation files (the "Software"), to deal in
- the Software without restriction, including without limitation the rights to
- use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
- of the Software, and to permit persons to whom the Software is furnished to do
- so, subject to the following conditions:
- 
- The above copyright notice and this permission notice shall be included in all
- copies or substantial portions of the Software.
- 
- THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
- IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
- FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
- AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
- LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
- OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- SOFTWARE.
- 
- 
- From pandas:
- 
- BSD 3-Clause License
- 
- Copyright (c) 2008-2011, AQR Capital Management, LLC, Lambda Foundry, Inc. and PyData Development Team
- All rights reserved.
- 
- Copyright (c) 2011-2020, Open source contributors.
- 
- Redistribution and use in source and binary forms, with or without
- modification, are permitted provided that the following conditions are met:
- 
- * Redistributions of source code must retain the above copyright notice, this
-   list of conditions and the following disclaimer.
- 
- * Redistributions in binary form must reproduce the above copyright notice,
-   this list of conditions and the following disclaimer in the documentation
-   and/or other materials provided with the distribution.
- 
- * Neither the name of the copyright holder nor the names of its
-   contributors may be used to endorse or promote products derived from
-   this software without specific prior written permission.
- 
- THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
- AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
- DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
- FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
- DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
- SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
- CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
- OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- 
- 
- From rich:
- 
- Copyright 2020 Will McGugan
- 
- Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
- 
- The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
- 
- THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
- 
- 
- From tqdm:
- 
- `tqdm` is a product of collaborative work.
- Unless otherwise stated, all authors (see commit logs) retain copyright
- for their respective work, and release the work under the MIT licence
- (text below).
- 
- Exceptions or notable authors are listed below
- in reverse chronological order:
- 
- * files: *
-   MPLv2.0 2015-2020 (c) Casper da Costa-Luis
-   [casperdcl](https://github.com/casperdcl).
- * files: tqdm/_tqdm.py
-   MIT 2016 (c) [PR #96] on behalf of Google Inc.
- * files: tqdm/_tqdm.py setup.py README.rst MANIFEST.in .gitignore
-   MIT 2013 (c) Noam Yorav-Raphael, original author.
- 
- [PR #96]: https://github.com/tqdm/tqdm/pull/96
- 
- 
- Mozilla Public Licence (MPL) v. 2.0 - Exhibit A
- -----------------------------------------------
- 
- This Source Code Form is subject to the terms of the
- Mozilla Public License, v. 2.0.
- If a copy of the MPL was not distributed with this file,
- You can obtain one at https://mozilla.org/MPL/2.0/.
- 
- 
- MIT License (MIT)
- -----------------
- 
- Copyright (c) 2013 noamraph
- 
- Permission is hereby granted, free of charge, to any person obtaining a copy of
- this software and associated documentation files (the "Software"), to deal in
- the Software without restriction, including without limitation the rights to
- use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
- the Software, and to permit persons to whom the Software is furnished to do so,
- subject to the following conditions:
- 
- The above copyright notice and this permission notice shall be included in all
- copies or substantial portions of the Software.
- 
- THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
- IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
- FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
- COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
- IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
- 
- 
- From scikit-learn:
- 
- BSD 3-Clause License
- 
- Copyright (c) 2007-2020 The scikit-learn developers.
- All rights reserved.
- 
- Redistribution and use in source and binary forms, with or without
- modification, are permitted provided that the following conditions are met:
- 
- * Redistributions of source code must retain the above copyright notice, this
-   list of conditions and the following disclaimer.
- 
- * Redistributions in binary form must reproduce the above copyright notice,
-   this list of conditions and the following disclaimer in the documentation
-   and/or other materials provided with the distribution.
- 
- * Neither the name of the copyright holder nor the names of its
-   contributors may be used to endorse or promote products derived from
-   this software without specific prior written permission.
- 
- THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
- AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
- DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
- FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
- DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
- SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
- CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
- OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- 
- from docker-py:
- 
-                                  Apache License
-                            Version 2.0, January 2004
-                         http://www.apache.org/licenses/
- 
-    TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
- 
-    1. Definitions.
- 
-       "License" shall mean the terms and conditions for use, reproduction,
-       and distribution as defined by Sections 1 through 9 of this document.
- 
-       "Licensor" shall mean the copyright owner or entity authorized by
-       the copyright owner that is granting the License.
- 
-       "Legal Entity" shall mean the union of the acting entity and all
-       other entities that control, are controlled by, or are under common
-       control with that entity. For the purposes of this definition,
-       "control" means (i) the power, direct or indirect, to cause the
-       direction or management of such entity, whether by contract or
-       otherwise, or (ii) ownership of fifty percent (50%) or more of the
-       outstanding shares, or (iii) beneficial ownership of such entity.
- 
-       "You" (or "Your") shall mean an individual or Legal Entity
-       exercising permissions granted by this License.
- 
-       "Source" form shall mean the preferred form for making modifications,
-       including but not limited to software source code, documentation
-       source, and configuration files.
- 
-       "Object" form shall mean any form resulting from mechanical
-       transformation or translation of a Source form, including but
-       not limited to compiled object code, generated documentation,
-       and conversions to other media types.
- 
-       "Work" shall mean the work of authorship, whether in Source or
-       Object form, made available under the License, as indicated by a
-       copyright notice that is included in or attached to the work
-       (an example is provided in the Appendix below).
- 
-       "Derivative Works" shall mean any work, whether in Source or Object
-       form, that is based on (or derived from) the Work and for which the
-       editorial revisions, annotations, elaborations, or other modifications
-       represent, as a whole, an original work of authorship. For the purposes
-       of this License, Derivative Works shall not include works that remain
-       separable from, or merely link (or bind by name) to the interfaces of,
-       the Work and Derivative Works thereof.
- 
-       "Contribution" shall mean any work of authorship, including
-       the original version of the Work and any modifications or additions
-       to that Work or Derivative Works thereof, that is intentionally
-       submitted to Licensor for inclusion in the Work by the copyright owner
-       or by an individual or Legal Entity authorized to submit on behalf of
-       the copyright owner. For the purposes of this definition, "submitted"
-       means any form of electronic, verbal, or written communication sent
-       to the Licensor or its representatives, including but not limited to
-       communication on electronic mailing lists, source code control systems,
-       and issue tracking systems that are managed by, or on behalf of, the
-       Licensor for the purpose of discussing and improving the Work, but
-       excluding communication that is conspicuously marked or otherwise
-       designated in writing by the copyright owner as "Not a Contribution."
- 
-       "Contributor" shall mean Licensor and any individual or Legal Entity
-       on behalf of whom a Contribution has been received by Licensor and
-       subsequently incorporated within the Work.
- 
-    2. Grant of Copyright License. Subject to the terms and conditions of
-       this License, each Contributor hereby grants to You a perpetual,
-       worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-       copyright license to reproduce, prepare Derivative Works of,
-       publicly display, publicly perform, sublicense, and distribute the
-       Work and such Derivative Works in Source or Object form.
- 
-    3. Grant of Patent License. Subject to the terms and conditions of
-       this License, each Contributor hereby grants to You a perpetual,
-       worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-       (except as stated in this section) patent license to make, have made,
-       use, offer to sell, sell, import, and otherwise transfer the Work,
-       where such license applies only to those patent claims licensable
-       by such Contributor that are necessarily infringed by their
-       Contribution(s) alone or by combination of their Contribution(s)
-       with the Work to which such Contribution(s) was submitted. If You
-       institute patent litigation against any entity (including a
-       cross-claim or counterclaim in a lawsuit) alleging that the Work
-       or a Contribution incorporated within the Work constitutes direct
-       or contributory patent infringement, then any patent licenses
-       granted to You under this License for that Work shall terminate
-       as of the date such litigation is filed.
- 
-    4. Redistribution. You may reproduce and distribute copies of the
-       Work or Derivative Works thereof in any medium, with or without
-       modifications, and in Source or Object form, provided that You
-       meet the following conditions:
- 
-       (a) You must give any other recipients of the Work or
-           Derivative Works a copy of this License; and
- 
-       (b) You must cause any modified files to carry prominent notices
-           stating that You changed the files; and
- 
-       (c) You must retain, in the Source form of any Derivative Works
-           that You distribute, all copyright, patent, trademark, and
-           attribution notices from the Source form of the Work,
-           excluding those notices that do not pertain to any part of
-           the Derivative Works; and
- 
-       (d) If the Work includes a "NOTICE" text file as part of its
-           distribution, then any Derivative Works that You distribute must
-           include a readable copy of the attribution notices contained
-           within such NOTICE file, excluding those notices that do not
-           pertain to any part of the Derivative Works, in at least one
-           of the following places: within a NOTICE text file distributed
-           as part of the Derivative Works; within the Source form or
-           documentation, if provided along with the Derivative Works; or,
-           within a display generated by the Derivative Works, if and
-           wherever such third-party notices normally appear. The contents
-           of the NOTICE file are for informational purposes only and
-           do not modify the License. You may add Your own attribution
-           notices within Derivative Works that You distribute, alongside
-           or as an addendum to the NOTICE text from the Work, provided
-           that such additional attribution notices cannot be construed
-           as modifying the License.
- 
-       You may add Your own copyright statement to Your modifications and
-       may provide additional or different license terms and conditions
-       for use, reproduction, or distribution of Your modifications, or
-       for any such Derivative Works as a whole, provided Your use,
-       reproduction, and distribution of the Work otherwise complies with
-       the conditions stated in this License.
- 
-    5. Submission of Contributions. Unless You explicitly state otherwise,
-       any Contribution intentionally submitted for inclusion in the Work
-       by You to the Licensor shall be under the terms and conditions of
-       this License, without any additional terms or conditions.
-       Notwithstanding the above, nothing herein shall supersede or modify
-       the terms of any separate license agreement you may have executed
-       with Licensor regarding such Contributions.
- 
-    6. Trademarks. This License does not grant permission to use the trade
-       names, trademarks, service marks, or product names of the Licensor,
-       except as required for reasonable and customary use in describing the
-       origin of the Work and reproducing the content of the NOTICE file.
- 
-    7. Disclaimer of Warranty. Unless required by applicable law or
-       agreed to in writing, Licensor provides the Work (and each
-       Contributor provides its Contributions) on an "AS IS" BASIS,
-       WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
-       implied, including, without limitation, any warranties or conditions
-       of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
-       PARTICULAR PURPOSE. You are solely responsible for determining the
-       appropriateness of using or redistributing the Work and assume any
-       risks associated with Your exercise of permissions under this License.
- 
-    8. Limitation of Liability. In no event and under no legal theory,
-       whether in tort (including negligence), contract, or otherwise,
-       unless required by applicable law (such as deliberate and grossly
-       negligent acts) or agreed to in writing, shall any Contributor be
-       liable to You for damages, including any direct, indirect, special,
-       incidental, or consequential damages of any character arising as a
-       result of this License or out of the use or inability to use the
-       Work (including but not limited to damages for loss of goodwill,
-       work stoppage, computer failure or malfunction, or any and all
-       other commercial damages or losses), even if such Contributor
-       has been advised of the possibility of such damages.
- 
-    9. Accepting Warranty or Additional Liability. While redistributing
-       the Work or Derivative Works thereof, You may choose to offer,
-       and charge a fee for, acceptance of support, warranty, indemnity,
-       or other liability obligations and/or rights consistent with this
-       License. However, in accepting such obligations, You may act only
-       on Your own behalf and on Your sole responsibility, not on behalf
-       of any other Contributor, and only if You agree to indemnify,
-       defend, and hold each Contributor harmless for any liability
-       incurred by, or claims asserted against, such Contributor by reason
-       of your accepting any such warranty or additional liability.
- 
-    END OF TERMS AND CONDITIONS
- 
-    Copyright 2016 Docker, Inc.
- 
-    Licensed under the Apache License, Version 2.0 (the "License");
-    you may not use this file except in compliance with the License.
-    You may obtain a copy of the License at
- 
-        http://www.apache.org/licenses/LICENSE-2.0
- 
-    Unless required by applicable law or agreed to in writing, software
-    distributed under the License is distributed on an "AS IS" BASIS,
-    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-    See the License for the specific language governing permissions and
-    limitations under the License.
- 
- From jupyter:
- 
- BSD 3-Clause License
- 
- Copyright (c) 2017, Project Jupyter Contributors
- All rights reserved.
- 
- Redistribution and use in source and binary forms, with or without
- modification, are permitted provided that the following conditions are met:
- 
- * Redistributions of source code must retain the above copyright notice, this
-   list of conditions and the following disclaimer.
- 
- * Redistributions in binary form must reproduce the above copyright notice,
-   this list of conditions and the following disclaimer in the documentation
-   and/or other materials provided with the distribution.
- 
- * Neither the name of the copyright holder nor the names of its
-   contributors may be used to endorse or promote products derived from
-   this software without specific prior written permission.
- 
- THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
- AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
- DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
- FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
- DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
- SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
- CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
- OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- 
- 
- From ipykernel:
- 
- # Copyright (c) IPython Development Team.
- # Distributed under the terms of the Modified BSD License.
- 
- From flatten_json:
- 
- MIT License
- 
- Copyright (c) 2016 Amir Ziai
- 
- Permission is hereby granted, free of charge, to any person obtaining a copy
- of this software and associated documentation files (the "Software"), to deal
- in the Software without restriction, including without limitation the rights
- to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
- copies of the Software, and to permit persons to whom the Software is
- furnished to do so, subject to the following conditions:
- 
- The above copyright notice and this permission notice shall be included in all
- copies or substantial portions of the Software.
- 
- THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
- IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
- FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
- AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
- LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
- OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- SOFTWARE.
- 
- From cryptography:
- 
-                                  Apache License
-                            Version 2.0, January 2004
-                         https://www.apache.org/licenses/
- 
-    TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
- 
-    1. Definitions.
- 
-       "License" shall mean the terms and conditions for use, reproduction,
-       and distribution as defined by Sections 1 through 9 of this document.
- 
-       "Licensor" shall mean the copyright owner or entity authorized by
-       the copyright owner that is granting the License.
- 
-       "Legal Entity" shall mean the union of the acting entity and all
-       other entities that control, are controlled by, or are under common
-       control with that entity. For the purposes of this definition,
-       "control" means (i) the power, direct or indirect, to cause the
-       direction or management of such entity, whether by contract or
-       otherwise, or (ii) ownership of fifty percent (50%) or more of the
-       outstanding shares, or (iii) beneficial ownership of such entity.
- 
-       "You" (or "Your") shall mean an individual or Legal Entity
-       exercising permissions granted by this License.
- 
-       "Source" form shall mean the preferred form for making modifications,
-       including but not limited to software source code, documentation
-       source, and configuration files.
- 
-       "Object" form shall mean any form resulting from mechanical
-       transformation or translation of a Source form, including but
-       not limited to compiled object code, generated documentation,
-       and conversions to other media types.
- 
-       "Work" shall mean the work of authorship, whether in Source or
-       Object form, made available under the License, as indicated by a
-       copyright notice that is included in or attached to the work
-       (an example is provided in the Appendix below).
- 
-       "Derivative Works" shall mean any work, whether in Source or Object
-       form, that is based on (or derived from) the Work and for which the
-       editorial revisions, annotations, elaborations, or other modifications
-       represent, as a whole, an original work of authorship. For the purposes
-       of this License, Derivative Works shall not include works that remain
-       separable from, or merely link (or bind by name) to the interfaces of,
-       the Work and Derivative Works thereof.
- 
-       "Contribution" shall mean any work of authorship, including
-       the original version of the Work and any modifications or additions
-       to that Work or Derivative Works thereof, that is intentionally
-       submitted to Licensor for inclusion in the Work by the copyright owner
-       or by an individual or Legal Entity authorized to submit on behalf of
-       the copyright owner. For the purposes of this definition, "submitted"
-       means any form of electronic, verbal, or written communication sent
-       to the Licensor or its representatives, including but not limited to
-       communication on electronic mailing lists, source code control systems,
-       and issue tracking systems that are managed by, or on behalf of, the
-       Licensor for the purpose of discussing and improving the Work, but
-       excluding communication that is conspicuously marked or otherwise
-       designated in writing by the copyright owner as "Not a Contribution."
- 
-       "Contributor" shall mean Licensor and any individual or Legal Entity
-       on behalf of whom a Contribution has been received by Licensor and
-       subsequently incorporated within the Work.
- 
-    2. Grant of Copyright License. Subject to the terms and conditions of
-       this License, each Contributor hereby grants to You a perpetual,
-       worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-       copyright license to reproduce, prepare Derivative Works of,
-       publicly display, publicly perform, sublicense, and distribute the
-       Work and such Derivative Works in Source or Object form.
- 
-    3. Grant of Patent License. Subject to the terms and conditions of
-       this License, each Contributor hereby grants to You a perpetual,
-       worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-       (except as stated in this section) patent license to make, have made,
-       use, offer to sell, sell, import, and otherwise transfer the Work,
-       where such license applies only to those patent claims licensable
-       by such Contributor that are necessarily infringed by their
-       Contribution(s) alone or by combination of their Contribution(s)
-       with the Work to which such Contribution(s) was submitted. If You
-       institute patent litigation against any entity (including a
-       cross-claim or counterclaim in a lawsuit) alleging that the Work
-       or a Contribution incorporated within the Work constitutes direct
-       or contributory patent infringement, then any patent licenses
-       granted to You under this License for that Work shall terminate
-       as of the date such litigation is filed.
- 
-    4. Redistribution. You may reproduce and distribute copies of the
-       Work or Derivative Works thereof in any medium, with or without
-       modifications, and in Source or Object form, provided that You
-       meet the following conditions:
- 
-       (a) You must give any other recipients of the Work or
-           Derivative Works a copy of this License; and
- 
-       (b) You must cause any modified files to carry prominent notices
-           stating that You changed the files; and
- 
-       (c) You must retain, in the Source form of any Derivative Works
-           that You distribute, all copyright, patent, trademark, and
-           attribution notices from the Source form of the Work,
-           excluding those notices that do not pertain to any part of
-           the Derivative Works; and
- 
-       (d) If the Work includes a "NOTICE" text file as part of its
-           distribution, then any Derivative Works that You distribute must
-           include a readable copy of the attribution notices contained
-           within such NOTICE file, excluding those notices that do not
-           pertain to any part of the Derivative Works, in at least one
-           of the following places: within a NOTICE text file distributed
-           as part of the Derivative Works; within the Source form or
-           documentation, if provided along with the Derivative Works; or,
-           within a display generated by the Derivative Works, if and
-           wherever such third-party notices normally appear. The contents
-           of the NOTICE file are for informational purposes only and
-           do not modify the License. You may add Your own attribution
-           notices within Derivative Works that You distribute, alongside
-           or as an addendum to the NOTICE text from the Work, provided
-           that such additional attribution notices cannot be construed
-           as modifying the License.
- 
-       You may add Your own copyright statement to Your modifications and
-       may provide additional or different license terms and conditions
-       for use, reproduction, or distribution of Your modifications, or
-       for any such Derivative Works as a whole, provided Your use,
-       reproduction, and distribution of the Work otherwise complies with
-       the conditions stated in this License.
- 
-    5. Submission of Contributions. Unless You explicitly state otherwise,
-       any Contribution intentionally submitted for inclusion in the Work
-       by You to the Licensor shall be under the terms and conditions of
-       this License, without any additional terms or conditions.
-       Notwithstanding the above, nothing herein shall supersede or modify
-       the terms of any separate license agreement you may have executed
-       with Licensor regarding such Contributions.
- 
-    6. Trademarks. This License does not grant permission to use the trade
-       names, trademarks, service marks, or product names of the Licensor,
-       except as required for reasonable and customary use in describing the
-       origin of the Work and reproducing the content of the NOTICE file.
- 
-    7. Disclaimer of Warranty. Unless required by applicable law or
-       agreed to in writing, Licensor provides the Work (and each
-       Contributor provides its Contributions) on an "AS IS" BASIS,
-       WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
-       implied, including, without limitation, any warranties or conditions
-       of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
-       PARTICULAR PURPOSE. You are solely responsible for determining the
-       appropriateness of using or redistributing the Work and assume any
-       risks associated with Your exercise of permissions under this License.
- 
-    8. Limitation of Liability. In no event and under no legal theory,
-       whether in tort (including negligence), contract, or otherwise,
-       unless required by applicable law (such as deliberate and grossly
-       negligent acts) or agreed to in writing, shall any Contributor be
-       liable to You for damages, including any direct, indirect, special,
-       incidental, or consequential damages of any character arising as a
-       result of this License or out of the use or inability to use the
-       Work (including but not limited to damages for loss of goodwill,
-       work stoppage, computer failure or malfunction, or any and all
-       other commercial damages or losses), even if such Contributor
-       has been advised of the possibility of such damages.
- 
-    9. Accepting Warranty or Additional Liability. While redistributing
-       the Work or Derivative Works thereof, You may choose to offer,
-       and charge a fee for, acceptance of support, warranty, indemnity,
-       or other liability obligations and/or rights consistent with this
-       License. However, in accepting such obligations, You may act only
-       on Your own behalf and on Your sole responsibility, not on behalf
-       of any other Contributor, and only if You agree to indemnify,
-       defend, and hold each Contributor harmless for any liability
-       incurred by, or claims asserted against, such Contributor by reason
-       of your accepting any such warranty or additional liability.
- 
-    END OF TERMS AND CONDITIONS
- 
-    APPENDIX: How to apply the Apache License to your work.
- 
-       To apply the Apache License to your work, attach the following
-       boilerplate notice, with the fields enclosed by brackets "[]"
-       replaced with your own identifying information. (Don't include
-       the brackets!)  The text should be enclosed in the appropriate
-       comment syntax for the file format. We also recommend that a
-       file or class name and description of purpose be included on the
-       same "printed page" as the copyright notice for easier
-       identification within third-party archives.
- 
-    Copyright [yyyy] [name of copyright owner]
- 
-    Licensed under the Apache License, Version 2.0 (the "License");
-    you may not use this file except in compliance with the License.
-    You may obtain a copy of the License at
- 
-        https://www.apache.org/licenses/LICENSE-2.0
- 
-    Unless required by applicable law or agreed to in writing, software
-    distributed under the License is distributed on an "AS IS" BASIS,
-    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-    See the License for the specific language governing permissions and
-    limitations under the License.
--- 0 ----
diff -crB --new-file ./openfl/MANIFEST.in ../mlwins-simulation-framework/ml-frameworks/federated-learning/MANIFEST.in
*** ./openfl/MANIFEST.in	2022-11-18 11:06:29.707187478 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/MANIFEST.in	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- recursive-include openfl-workspace *
- recursive-include openfl-docker *
- recursive-include openfl-gramine *
- recursive-include openfl-tutorials *
--- 0 ----
diff -crB --new-file ./openfl/NOTICE ../mlwins-simulation-framework/ml-frameworks/federated-learning/NOTICE
*** ./openfl/NOTICE	2022-11-18 11:06:29.707187478 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/NOTICE	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,15 ****
- from gprc:
- 
- Copyright 2014 gRPC authors.
- 
- Licensed under the Apache License, Version 2.0 (the "License");
- you may not use this file except in compliance with the License.
- You may obtain a copy of the License at
- 
-     http://www.apache.org/licenses/LICENSE-2.0
- 
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--- 0 ----
diff -crB --new-file ./openfl/openfl/component/aggregation_functions/adagrad_adaptive_aggregation.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/adagrad_adaptive_aggregation.py
*** ./openfl/openfl/component/aggregation_functions/adagrad_adaptive_aggregation.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/adagrad_adaptive_aggregation.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,50 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Adagrad adaptive aggregation module."""
- 
- from typing import Dict
- from typing import Optional
- 
- import numpy as np
- 
- from openfl.utilities.optimizers.numpy import NumPyAdagrad
- from .core import AdaptiveAggregation
- from .core import AggregationFunction
- from .weighted_average import WeightedAverage
- 
- 
- DEFAULT_AGG_FUNC = WeightedAverage()
- 
- 
- class AdagradAdaptiveAggregation(AdaptiveAggregation):
-     """Adagrad adaptive Federated Aggregation funtcion."""
- 
-     def __init__(
-         self,
-         *,
-         agg_func: AggregationFunction = DEFAULT_AGG_FUNC,
-         params: Optional[Dict[str, np.ndarray]] = None,
-         model_interface=None,
-         learning_rate: float = 0.01,
-         initial_accumulator_value: float = 0.1,
-         epsilon: float = 1e-10,
-     ) -> None:
-         """Initialize.
- 
-         Args:
-             agg_func: Aggregate function for aggregating
-                 parameters that are not inside the optimizer (default: WeightedAverage()).
-             params: Parameters to be stored for optimization.
-             model_interface: Model interface instance to provide parameters.
-             learning_rate: Tuning parameter that determines
-                 the step size at each iteration.
-             initial_accumulator_value: Initial value for squared gradients.
-             epsilon: Value for computational stability.
-         """
-         opt = NumPyAdagrad(params=params,
-                            model_interface=model_interface,
-                            learning_rate=learning_rate,
-                            initial_accumulator_value=initial_accumulator_value,
-                            epsilon=epsilon)
-         super().__init__(opt, agg_func)
--- 0 ----
diff -crB --new-file ./openfl/openfl/component/aggregation_functions/adam_adaptive_aggregation.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/adam_adaptive_aggregation.py
*** ./openfl/openfl/component/aggregation_functions/adam_adaptive_aggregation.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/adam_adaptive_aggregation.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,56 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Adam adaptive aggregation module."""
- 
- from typing import Dict
- from typing import Optional
- from typing import Tuple
- 
- import numpy as np
- 
- from openfl.utilities.optimizers.numpy import NumPyAdam
- from .core import AdaptiveAggregation
- from .core import AggregationFunction
- from .weighted_average import WeightedAverage
- 
- 
- DEFAULT_AGG_FUNC = WeightedAverage()
- 
- 
- class AdamAdaptiveAggregation(AdaptiveAggregation):
-     """Adam adaptive Federated Aggregation funtcion."""
- 
-     def __init__(
-         self,
-         *,
-         agg_func: AggregationFunction = DEFAULT_AGG_FUNC,
-         params: Optional[Dict[str, np.ndarray]] = None,
-         model_interface=None,
-         learning_rate: float = 0.01,
-         betas: Tuple[float, float] = (0.9, 0.999),
-         initial_accumulator_value: float = 0.0,
-         epsilon: float = 1e-8,
-     ) -> None:
-         """Initialize.
- 
-         Args:
-             agg_func: Aggregate function for aggregating
-                 parameters that are not inside the optimizer (default: WeightedAverage()).
-             params: Parameters to be stored for optimization.
-             model_interface: Model interface instance to provide parameters.
-             learning_rate: Tuning parameter that determines
-                 the step size at each iteration.
-             betas: Coefficients used for computing running
-                 averages of gradient and its square.
-             initial_accumulator_value: Initial value for gradients
-                 and squared gradients.
-             epsilon: Value for computational stability.
-         """
-         opt = NumPyAdam(params=params,
-                         model_interface=model_interface,
-                         learning_rate=learning_rate,
-                         betas=betas,
-                         initial_accumulator_value=initial_accumulator_value,
-                         epsilo=epsilon)
-         super().__init__(opt, agg_func)
--- 0 ----
diff -crB --new-file ./openfl/openfl/component/aggregation_functions/core/adaptive_aggregation.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/core/adaptive_aggregation.py
*** ./openfl/openfl/component/aggregation_functions/core/adaptive_aggregation.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/core/adaptive_aggregation.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,104 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Adaptive aggregation module."""
- 
- from typing import List
- 
- import numpy as np
- 
- from openfl.utilities.optimizers.numpy.base_optimizer import Optimizer
- from openfl.utilities.types import LocalTensor
- from .interface import AggregationFunction
- 
- 
- class AdaptiveAggregation(AggregationFunction):
-     """Adaptive Federated Aggregation funtcion.
- 
-     According to https://arxiv.org/abs/2003.00295
-     """
- 
-     def __init__(
-         self,
-         optimizer: Optimizer,
-         agg_func: AggregationFunction,
-     ) -> None:
-         """Initialize.
- 
-         Args:
-             optimizer: One of numpy optimizer class instance.
-             agg_func: Aggregate function for aggregating
-                 parameters that are not inside the optimizer.
-         """
-         self.optimizer = optimizer
-         self.default_agg_func = agg_func
- 
-     @staticmethod
-     def _make_gradient(
-         base_model_nparray: np.ndarray,
-         local_tensors: List[LocalTensor]
-     ) -> np.ndarray:
-         """Make gradient."""
-         return sum([local_tensor.weight * (base_model_nparray - local_tensor.tensor)
-                     for local_tensor in local_tensors])
- 
-     def call(
-         self,
-         local_tensors,
-         db_iterator,
-         tensor_name,
-         fl_round,
-         tags
-     ) -> np.ndarray:
-         """Aggregate tensors.
- 
-         Args:
-             local_tensors(list[openfl.utilities.LocalTensor]): List of local tensors to aggregate.
-             db_iterator: iterator over history of all tensors. Columns:
-                 - 'tensor_name': name of the tensor.
-                     Examples for `torch.nn.Module`s: 'conv1.weight', 'fc2.bias'.
-                 - 'fl_round': 0-based number of round corresponding to this tensor.
-                 - 'tags': tuple of tensor tags. Tags that can appear:
-                     - 'model' indicates that the tensor is a model parameter.
-                     - 'trained' indicates that tensor is a part of a training result.
-                         These tensors are passed to the aggregator node after local learning.
-                     - 'aggregated' indicates that tensor is a result of aggregation.
-                         These tensors are sent to collaborators for the next round.
-                     - 'delta' indicates that value is a difference between rounds
-                         for a specific tensor.
-                     also one of the tags is a collaborator name
-                     if it corresponds to a result of a local task.
- 
-                 - 'nparray': value of the tensor.
-             tensor_name: name of the tensor
-             fl_round: round number
-             tags: tuple of tags for this tensor
-         Returns:
-             np.ndarray: aggregated tensor
-         """
-         if tensor_name not in self.optimizer.params:
-             return self.default_agg_func(local_tensors,
-                                          db_iterator,
-                                          tensor_name,
-                                          fl_round,
-                                          tags)
- 
-         base_model_nparray = None
-         search_tag = 'aggregated' if fl_round != 0 else 'model'
-         for record in db_iterator:
-             if (
-                 record['round'] == fl_round
-                 and record['tensor_name'] == tensor_name
-                 and search_tag in record['tags']
-                 and 'delta' not in record['tags']
-             ):
-                 base_model_nparray = record['nparray']
- 
-         if base_model_nparray is None:
-             raise KeyError(
-                 f'There is no current global model in TensorDB for tensor name: {tensor_name}')
- 
-         gradient = self._make_gradient(base_model_nparray, local_tensors)
-         gradients = {tensor_name: gradient}
-         self.optimizer.step(gradients)
-         return self.optimizer.params[tensor_name]
--- 0 ----
diff -crB --new-file ./openfl/openfl/component/aggregation_functions/core/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/core/__init__.py
*** ./openfl/openfl/component/aggregation_functions/core/__init__.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/core/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,10 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Aggregation functions core package."""
- 
- from .adaptive_aggregation import AdaptiveAggregation
- from .interface import AggregationFunction
- 
- __all__ = ['AggregationFunction',
-            'AdaptiveAggregation']
--- 0 ----
diff -crB --new-file ./openfl/openfl/component/aggregation_functions/core/interface.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/core/interface.py
*** ./openfl/openfl/component/aggregation_functions/core/interface.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/core/interface.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,60 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Aggregation function interface module."""
- from abc import abstractmethod
- from typing import Iterator
- from typing import List
- from typing import Tuple
- 
- import numpy as np
- import pandas as pd
- 
- from openfl.utilities import LocalTensor
- from openfl.utilities import SingletonABCMeta
- 
- 
- class AggregationFunction(metaclass=SingletonABCMeta):
-     """Interface for specifying aggregation function."""
- 
-     @abstractmethod
-     def call(self,
-              local_tensors: List[LocalTensor],
-              db_iterator: Iterator[pd.Series],
-              tensor_name: str,
-              fl_round: int,
-              tags: Tuple[str]) -> np.ndarray:
-         """Aggregate tensors.
- 
-         Args:
-             local_tensors(list[openfl.utilities.LocalTensor]): List of local tensors to aggregate.
-             db_iterator: iterator over history of all tensors. Columns:
-                 - 'tensor_name': name of the tensor.
-                     Examples for `torch.nn.Module`s: 'conv1.weight', 'fc2.bias'.
-                 - 'round': 0-based number of round corresponding to this tensor.
-                 - 'tags': tuple of tensor tags. Tags that can appear:
-                     - 'model' indicates that the tensor is a model parameter.
-                     - 'trained' indicates that tensor is a part of a training result.
-                         These tensors are passed to the aggregator node after local learning.
-                     - 'aggregated' indicates that tensor is a result of aggregation.
-                         These tensors are sent to collaborators for the next round.
-                     - 'delta' indicates that value is a difference between rounds
-                         for a specific tensor.
-                     also one of the tags is a collaborator name
-                     if it corresponds to a result of a local task.
- 
-                 - 'nparray': value of the tensor.
-             tensor_name: name of the tensor
-             fl_round: round number
-             tags: tuple of tags for this tensor
-         Returns:
-             np.ndarray: aggregated tensor
-         """
-         raise NotImplementedError
- 
-     def __call__(self, local_tensors,
-                  db_iterator,
-                  tensor_name,
-                  fl_round,
-                  tags):
-         """Use magic function for ease."""
-         return self.call(local_tensors, db_iterator, tensor_name, fl_round, tags)
--- 0 ----
diff -crB --new-file ./openfl/openfl/component/aggregation_functions/fedcurv_weighted_average.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/fedcurv_weighted_average.py
*** ./openfl/openfl/component/aggregation_functions/fedcurv_weighted_average.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/fedcurv_weighted_average.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,29 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """FedCurv Aggregation function module."""
- import numpy as np
- 
- from .weighted_average import WeightedAverage
- 
- 
- class FedCurvWeightedAverage(WeightedAverage):
-     """Aggregation function of FedCurv algorithm.
- 
-     Applies weighted average aggregation to all tensors
-     except Fisher matrices variables (u_t, v_t).
-     These variables are summed without weights.
- 
-     FedCurv paper: https://arxiv.org/pdf/1910.07796.pdf
-     """
- 
-     def call(self, local_tensors, db_iterator, tensor_name, fl_round, tags):
-         """Apply aggregation."""
-         if (
-             tensor_name.endswith('_u')
-             or tensor_name.endswith('_v')
-             or tensor_name.endswith('_w')
-         ):
-             tensors = [local_tensor.tensor for local_tensor in local_tensors]
-             agg_result = np.sum(tensors, axis=0)
-             return agg_result
-         return super().call(local_tensors)
--- 0 ----
diff -crB --new-file ./openfl/openfl/component/aggregation_functions/geometric_median.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/geometric_median.py
*** ./openfl/openfl/component/aggregation_functions/geometric_median.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/geometric_median.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,78 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Geometric median module."""
- 
- import numpy as np
- 
- from .core import AggregationFunction
- from .weighted_average import weighted_average
- 
- 
- def _geometric_median_objective(median, tensors, weights):
-     """Compute geometric median objective."""
-     return sum([w * _l2dist(median, x) for w, x in zip(weights, tensors)])
- 
- 
- def geometric_median(tensors, weights, maxiter=4, eps=1e-5, ftol=1e-6):
-     """Compute geometric median of tensors with weights using Weiszfeld's Algorithm."""
-     weights = np.asarray(weights) / sum(weights)
-     median = weighted_average(tensors, weights)
-     num_oracle_calls = 1
- 
-     obj_val = _geometric_median_objective(median, tensors, weights)
- 
-     for _ in range(maxiter):
-         prev_obj_val = obj_val
-         weights = np.asarray([w / max(eps, _l2dist(median, x)) for w, x in zip(weights, tensors)])
-         weights = weights / weights.sum()
-         median = weighted_average(tensors, weights)
-         num_oracle_calls += 1
-         obj_val = _geometric_median_objective(median, tensors, weights)
-         if abs(prev_obj_val - obj_val) < ftol * obj_val:
-             break
-     return median
- 
- 
- def _l2dist(p1, p2):
-     """L2 distance between p1, p2, each of which is a list of nd-arrays."""
-     if p1.ndim != p2.ndim:
-         raise RuntimeError('Tensor shapes should be equal')
-     if p1.ndim < 2:
-         return _l2dist(*[np.expand_dims(x, axis=0) for x in [p1, p2]])
-     return np.linalg.norm([np.linalg.norm(x1 - x2) for x1, x2 in zip(p1, p2)])
- 
- 
- class GeometricMedian(AggregationFunction):
-     """Geometric median aggregation."""
- 
-     def call(self, local_tensors, *_) -> np.ndarray:
-         """Aggregate tensors.
- 
-         Args:
-             local_tensors(list[openfl.utilities.LocalTensor]): List of local tensors to aggregate.
-             db_iterator: iterator over history of all tensors. Columns:
-                 - 'tensor_name': name of the tensor.
-                     Examples for `torch.nn.Module`s: 'conv1.weight', 'fc2.bias'.
-                 - 'round': 0-based number of round corresponding to this tensor.
-                 - 'tags': tuple of tensor tags. Tags that can appear:
-                     - 'model' indicates that the tensor is a model parameter.
-                     - 'trained' indicates that tensor is a part of a training result.
-                         These tensors are passed to the aggregator node after local learning.
-                     - 'aggregated' indicates that tensor is a result of aggregation.
-                         These tensors are sent to collaborators for the next round.
-                     - 'delta' indicates that value is a difference between rounds
-                         for a specific tensor.
-                     also one of the tags is a collaborator name
-                     if it corresponds to a result of a local task.
- 
-                 - 'nparray': value of the tensor.
-             tensor_name: name of the tensor
-             fl_round: round number
-             tags: tuple of tags for this tensor
-         Returns:
-             np.ndarray: aggregated tensor
-         """
-         tensors, weights = zip(*[(x.tensor, x.weight) for x in local_tensors])
-         tensors, weights = np.array(tensors), np.array(weights)
-         return geometric_median(tensors, weights)
--- 0 ----
diff -crB --new-file ./openfl/openfl/component/aggregation_functions/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/__init__.py
*** ./openfl/openfl/component/aggregation_functions/__init__.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,22 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Aggregation functions package."""
- 
- from .adagrad_adaptive_aggregation import AdagradAdaptiveAggregation
- from .adam_adaptive_aggregation import AdamAdaptiveAggregation
- from .core import AggregationFunction
- from .fedcurv_weighted_average import FedCurvWeightedAverage
- from .geometric_median import GeometricMedian
- from .median import Median
- from .weighted_average import WeightedAverage
- from .yogi_adaptive_aggregation import YogiAdaptiveAggregation
- 
- __all__ = ['Median',
-            'WeightedAverage',
-            'GeometricMedian',
-            'AdagradAdaptiveAggregation',
-            'AdamAdaptiveAggregation',
-            'YogiAdaptiveAggregation',
-            'AggregationFunction',
-            'FedCurvWeightedAverage']
--- 0 ----
diff -crB --new-file ./openfl/openfl/component/aggregation_functions/median.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/median.py
*** ./openfl/openfl/component/aggregation_functions/median.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/median.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,42 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Median module."""
- 
- import numpy as np
- 
- from .core import AggregationFunction
- 
- 
- class Median(AggregationFunction):
-     """Median aggregation."""
- 
-     def call(self, local_tensors, *_) -> np.ndarray:
-         """Aggregate tensors.
- 
-         Args:
-             local_tensors(list[openfl.utilities.LocalTensor]): List of local tensors to aggregate.
-             db_iterator: iterator over history of all tensors. Columns:
-                 - 'tensor_name': name of the tensor.
-                     Examples for `torch.nn.Module`s: 'conv1.weight', 'fc2.bias'.
-                 - 'round': 0-based number of round corresponding to this tensor.
-                 - 'tags': tuple of tensor tags. Tags that can appear:
-                     - 'model' indicates that the tensor is a model parameter.
-                     - 'trained' indicates that tensor is a part of a training result.
-                         These tensors are passed to the aggregator node after local learning.
-                     - 'aggregated' indicates that tensor is a result of aggregation.
-                         These tensors are sent to collaborators for the next round.
-                     - 'delta' indicates that value is a difference between rounds
-                         for a specific tensor.
-                     also one of the tags is a collaborator name
-                     if it corresponds to a result of a local task.
- 
-                 - 'nparray': value of the tensor.
-             tensor_name: name of the tensor
-             fl_round: round number
-             tags: tuple of tags for this tensor
-         Returns:
-             np.ndarray: aggregated tensor
-         """
-         tensors = np.array([x.tensor for x in local_tensors])
-         return np.median(tensors, axis=0)
--- 0 ----
diff -crB --new-file ./openfl/openfl/component/aggregation_functions/weighted_average.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/weighted_average.py
*** ./openfl/openfl/component/aggregation_functions/weighted_average.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/weighted_average.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,47 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Federated averaging module."""
- 
- import numpy as np
- 
- from .core import AggregationFunction
- 
- 
- def weighted_average(tensors, weights):
-     """Compute average."""
-     return np.average(tensors, weights=weights, axis=0)
- 
- 
- class WeightedAverage(AggregationFunction):
-     """Weighted average aggregation."""
- 
-     def call(self, local_tensors, *_) -> np.ndarray:
-         """Aggregate tensors.
- 
-         Args:
-             local_tensors(list[openfl.utilities.LocalTensor]): List of local tensors to aggregate.
-             db_iterator: iterator over history of all tensors. Columns:
-                 - 'tensor_name': name of the tensor.
-                     Examples for `torch.nn.Module`s: 'conv1.weight', 'fc2.bias'.
-                 - 'round': 0-based number of round corresponding to this tensor.
-                 - 'tags': tuple of tensor tags. Tags that can appear:
-                     - 'model' indicates that the tensor is a model parameter.
-                     - 'trained' indicates that tensor is a part of a training result.
-                         These tensors are passed to the aggregator node after local learning.
-                     - 'aggregated' indicates that tensor is a result of aggregation.
-                         These tensors are sent to collaborators for the next round.
-                     - 'delta' indicates that value is a difference between rounds
-                         for a specific tensor.
-                     also one of the tags is a collaborator name
-                     if it corresponds to a result of a local task.
- 
-                 - 'nparray': value of the tensor.
-             tensor_name: name of the tensor
-             fl_round: round number
-             tags: tuple of tags for this tensor
-         Returns:
-             np.ndarray: aggregated tensor
-         """
-         tensors, weights = zip(*[(x.tensor, x.weight) for x in local_tensors])
-         return weighted_average(tensors, weights)
--- 0 ----
diff -crB --new-file ./openfl/openfl/component/aggregation_functions/yogi_adaptive_aggregation.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/yogi_adaptive_aggregation.py
*** ./openfl/openfl/component/aggregation_functions/yogi_adaptive_aggregation.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/yogi_adaptive_aggregation.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,56 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Yogi adaptive aggregation module."""
- 
- from typing import Dict
- from typing import Optional
- from typing import Tuple
- 
- import numpy as np
- 
- from openfl.utilities.optimizers.numpy import NumPyYogi
- from .core import AdaptiveAggregation
- from .core import AggregationFunction
- from .weighted_average import WeightedAverage
- 
- 
- DEFAULT_AGG_FUNC = WeightedAverage()
- 
- 
- class YogiAdaptiveAggregation(AdaptiveAggregation):
-     """Yogi adaptive Federated Aggregation funtcion."""
- 
-     def __init__(
-         self,
-         *,
-         agg_func: AggregationFunction = DEFAULT_AGG_FUNC,
-         params: Optional[Dict[str, np.ndarray]] = None,
-         model_interface=None,
-         learning_rate: float = 0.01,
-         betas: Tuple[float, float] = (0.9, 0.999),
-         initial_accumulator_value: float = 0.0,
-         epsilon: float = 1e-8,
-     ) -> None:
-         """Initialize.
- 
-         Args:
-             agg_func: Aggregate function for aggregating
-                 parameters that are not inside the optimizer (default: WeightedAverage()).
-             params: Parameters to be stored for optimization.
-             model_interface: Model interface instance to provide parameters.
-             learning_rate: Tuning parameter that determines
-                 the step size at each iteration.
-             betas: Coefficients used for computing running
-                 averages of gradient and its square.
-             initial_accumulator_value: Initial value for gradients
-                 and squared gradients.
-             epsilon: Value for computational stability.
-         """
-         opt = NumPyYogi(params=params,
-                         model_interface=model_interface,
-                         learning_rate=learning_rate,
-                         betas=betas,
-                         initial_accumulator_value=initial_accumulator_value,
-                         epsilo=epsilon)
-         super().__init__(opt, agg_func)
--- 0 ----
diff -crB --new-file ./openfl/openfl/component/aggregator/aggregator.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregator/aggregator.py
*** ./openfl/openfl/component/aggregator/aggregator.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregator/aggregator.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,971 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Aggregator module."""
- import queue
- from logging import getLogger
- 
- from openfl.component.aggregation_functions import WeightedAverage
- from openfl.databases import TensorDB
- from openfl.pipelines import NoCompressionPipeline
- from openfl.pipelines import TensorCodec
- from openfl.protocols import base_pb2
- from openfl.protocols import utils
- from openfl.utilities import TaskResultKey
- from openfl.utilities import TensorKey
- from openfl.utilities.logs import write_metric
- 
- 
- class Aggregator:
-     r"""An Aggregator is the central node in federated learning.
- 
-     Args:
-         aggregator_uuid (str): Aggregation ID.
-         federation_uuid (str): Federation ID.
-         authorized_cols (list of str): The list of IDs of enrolled collaborators.
-         init_state_path* (str): The location of the initial weight file.
-         last_state_path* (str): The file location to store the latest weight.
-         best_state_path* (str): The file location to store the weight of the best model.
-         db_store_rounds* (int): Rounds to store in TensorDB.
- 
-     Note:
-         \* - plan setting.
-     """
- 
-     def __init__(self,
- 
-                  aggregator_uuid,
-                  federation_uuid,
-                  authorized_cols,
- 
-                  init_state_path,
-                  best_state_path,
-                  last_state_path,
- 
-                  assigner,
- 
-                  rounds_to_train=256,
-                  single_col_cert_common_name=None,
-                  compression_pipeline=None,
-                  db_store_rounds=1,
-                  write_logs=False,
-                  **kwargs):
-         """Initialize."""
-         self.round_number = 0
-         self.single_col_cert_common_name = single_col_cert_common_name
- 
-         if self.single_col_cert_common_name is not None:
-             self._log_big_warning()
-         else:
-             # FIXME: '' instead of None is just for protobuf compatibility.
-             # Cleaner solution?
-             self.single_col_cert_common_name = ''
- 
-         self.rounds_to_train = rounds_to_train
- 
-         # if the collaborator requests a delta, this value is set to true
-         self.authorized_cols = authorized_cols
-         self.uuid = aggregator_uuid
-         self.federation_uuid = federation_uuid
-         self.assigner = assigner
-         self.quit_job_sent_to = []
- 
-         self.tensor_db = TensorDB()
-         # FIXME: I think next line generates an error on the second round
-         # if it is set to 1 for the aggregator.
-         self.db_store_rounds = db_store_rounds
- 
-         # Gathered together logging-related objects
-         self.write_logs = write_logs
-         if self.write_logs:
-             self.log_metric = write_metric
-         self.logger = getLogger(__name__)
-         self.best_model_score = None
-         self.metric_queue = queue.Queue()
- 
-         self.compression_pipeline = compression_pipeline or NoCompressionPipeline()
-         self.tensor_codec = TensorCodec(self.compression_pipeline)
- 
-         self.init_state_path = init_state_path
-         self.best_state_path = best_state_path
-         self.last_state_path = last_state_path
- 
-         self.best_tensor_dict: dict = {}
-         self.last_tensor_dict: dict = {}
- 
-         if kwargs.get('initial_tensor_dict', None) is not None:
-             self._load_initial_tensors_from_dict(kwargs['initial_tensor_dict'])
-             self.model = utils.construct_model_proto(
-                 tensor_dict=kwargs['initial_tensor_dict'],
-                 round_number=0,
-                 tensor_pipe=self.compression_pipeline)
-         else:
-             self.model: base_pb2.ModelProto = utils.load_proto(self.init_state_path)
-             self._load_initial_tensors()  # keys are TensorKeys
- 
-         self.collaborator_tensor_results = {}  # {TensorKey: nparray}}
- 
-         # these enable getting all tensors for a task
-         self.collaborator_tasks_results = {}  # {TaskResultKey: list of TensorKeys}
- 
-         self.collaborator_task_weight = {}  # {TaskResultKey: data_size}
- 
-     def _load_initial_tensors(self):
-         """
-         Load all of the tensors required to begin federated learning.
- 
-         Required tensors are: \
-             1. Initial model.
- 
-         Returns:
-             None
-         """
-         tensor_dict, round_number = utils.deconstruct_model_proto(
-             self.model, compression_pipeline=self.compression_pipeline)
- 
-         if round_number > self.round_number:
-             self.logger.info(
-                 f'Starting training from round {round_number} of previously saved model'
-             )
-             self.round_number = round_number
-         tensor_key_dict = {
-             TensorKey(k, self.uuid, self.round_number, False, ('model',)):
-                 v for k, v in tensor_dict.items()
-         }
-         # all initial model tensors are loaded here
-         self.tensor_db.cache_tensor(tensor_key_dict)
-         self.logger.debug(f'This is the initial tensor_db: {self.tensor_db}')
- 
-     def _load_initial_tensors_from_dict(self, tensor_dict):
-         """
-         Load all of the tensors required to begin federated learning.
- 
-         Required tensors are: \
-             1. Initial model.
- 
-         Returns:
-             None
-         """
-         tensor_key_dict = {
-             TensorKey(k, self.uuid, self.round_number, False, ('model',)):
-                 v for k, v in tensor_dict.items()
-         }
-         # all initial model tensors are loaded here
-         self.tensor_db.cache_tensor(tensor_key_dict)
-         self.logger.debug(f'This is the initial tensor_db: {self.tensor_db}')
- 
-     def _save_model(self, round_number, file_path):
-         """
-         Save the best or latest model.
- 
-         Args:
-             round_number: int
-                 Model round to be saved
-             file_path: str
-                 Either the best model or latest model file path
- 
-         Returns:
-             None
-         """
-         # Extract the model from TensorDB and set it to the new model
-         og_tensor_dict, _ = utils.deconstruct_model_proto(
-             self.model, compression_pipeline=self.compression_pipeline)
-         tensor_keys = [
-             TensorKey(
-                 k, self.uuid, round_number, False, ('model',)
-             ) for k, v in og_tensor_dict.items()
-         ]
-         tensor_dict = {}
-         for tk in tensor_keys:
-             tk_name, _, _, _, _ = tk
-             tensor_dict[tk_name] = self.tensor_db.get_tensor_from_cache(tk)
-             if tensor_dict[tk_name] is None:
-                 self.logger.info(f'Cannot save model for round {round_number}. Continuing...')
-                 return
-         if file_path == self.best_state_path:
-             self.best_tensor_dict = tensor_dict
-         if file_path == self.last_state_path:
-             self.last_tensor_dict = tensor_dict
-         self.model = utils.construct_model_proto(
-             tensor_dict, round_number, self.compression_pipeline)
-         utils.dump_proto(self.model, file_path)
- 
-     def valid_collaborator_cn_and_id(self, cert_common_name,
-                                      collaborator_common_name):
-         """
-         Determine if the collaborator certificate and ID are valid for this federation.
- 
-         Args:
-             cert_common_name: Common name for security certificate
-             collaborator_common_name: Common name for collaborator
- 
-         Returns:
-             bool: True means the collaborator common name matches the name in
-                   the security certificate.
- 
-         """
-         # if self.test_mode_whitelist is None, then the common_name must
-         # match collaborator_common_name and be in authorized_cols
-         # FIXME: '' instead of None is just for protobuf compatibility.
-         #  Cleaner solution?
-         if self.single_col_cert_common_name == '':
-             return (cert_common_name == collaborator_common_name
-                     and collaborator_common_name in self.authorized_cols)
-         # otherwise, common_name must be in whitelist and
-         # collaborator_common_name must be in authorized_cols
-         else:
-             return (cert_common_name == self.single_col_cert_common_name
-                     and collaborator_common_name in self.authorized_cols)
- 
-     def all_quit_jobs_sent(self):
-         """Assert all quit jobs are sent to collaborators."""
-         return set(self.quit_job_sent_to) == set(self.authorized_cols)
- 
-     @staticmethod
-     def _get_sleep_time():
-         """
-         Sleep 10 seconds.
- 
-         Returns:
-             sleep_time: int
-         """
-         # Decrease sleep period for finer discretezation
-         return 10
- 
-     def _time_to_quit(self):
-         """
-         If all rounds are complete, it's time to quit.
- 
-         Returns:
-             is_time_to_quit: bool
-         """
-         if self.round_number >= self.rounds_to_train:
-             return True
-         return False
- 
-     def get_tasks(self, collaborator_name):
-         """
-         RPC called by a collaborator to determine which tasks to perform.
- 
-         Args:
-             collaborator_name: str
-                 Requested collaborator name
- 
-         Returns:
-             tasks: list[str]
-                 List of tasks to be performed by the requesting collaborator
-                 for the current round.
-             sleep_time: int
-             time_to_quit: bool
-         """
-         self.logger.debug(
-             f'Aggregator GetTasks function reached from collaborator {collaborator_name}...'
-         )
- 
-         # first, if it is time to quit, inform the collaborator
-         if self._time_to_quit():
-             self.logger.info(f'Sending signal to collaborator {collaborator_name} to shutdown...')
-             self.quit_job_sent_to.append(collaborator_name)
- 
-             tasks = None
-             sleep_time = 0
-             time_to_quit = True
- 
-             return tasks, self.round_number, sleep_time, time_to_quit
- 
-         time_to_quit = False
- 
-         # otherwise, get the tasks from our task assigner
-         tasks = self.assigner.get_tasks_for_collaborator(collaborator_name, self.round_number)
- 
-         # if no tasks, tell the collaborator to sleep
-         if len(tasks) == 0:
-             tasks = None
-             sleep_time = self._get_sleep_time()
- 
-             return tasks, self.round_number, sleep_time, time_to_quit
- 
-         # if we do have tasks, remove any that we already have results for
-         if isinstance(tasks[0], str):
-             # backward compatibility
-             tasks = [
-                 t for t in tasks if not self._collaborator_task_completed(
-                     collaborator_name, t, self.round_number)
-             ]
-         else:
-             tasks = [
-                 t for t in tasks if not self._collaborator_task_completed(
-                     collaborator_name, t.name, self.round_number)
-             ]
- 
-         # Do the check again because it's possible that all tasks have
-         # been completed
-         if len(tasks) == 0:
-             tasks = None
-             sleep_time = self._get_sleep_time()
- 
-             return tasks, self.round_number, sleep_time, time_to_quit
- 
-         self.logger.info(
-             f'Sending tasks to collaborator {collaborator_name} for round {self.round_number}'
-         )
-         sleep_time = 0
- 
-         return tasks, self.round_number, sleep_time, time_to_quit
- 
-     def get_aggregated_tensor(self, collaborator_name, tensor_name,
-                               round_number, report, tags, require_lossless):
-         """
-         RPC called by collaborator.
- 
-         Performs local lookup to determine if there is an aggregated tensor available \
-             that matches the request.
- 
-         Args:
-             collaborator_name : str
-                 Requested tensor key collaborator name
-             tensor_name: str
-             require_lossless: bool
-             round_number: int
-             report: bool
-             tags: list[str]
-         Returns:
-             named_tensor : protobuf NamedTensor
-                 the tensor requested by the collaborator
-         """
-         self.logger.debug(f'Retrieving aggregated tensor {tensor_name},{round_number},{tags} '
-                           f'for collaborator {collaborator_name}')
- 
-         if 'compressed' in tags or require_lossless:
-             compress_lossless = True
-         else:
-             compress_lossless = False
- 
-         tags = list(tags)
- 
-         # TODO the TensorDB doesn't support compressed data yet.
-         #  The returned tensor will
-         # be recompressed anyway.
-         if 'compressed' in tags:
-             tags.remove('compressed')
-         if 'lossy_compressed' in tags:
-             tags.remove('lossy_compressed')
- 
-         tensor_key = TensorKey(
-             tensor_name, self.uuid, round_number, report, tuple(tags)
-         )
-         tensor_name, origin, round_number, report, tags = tensor_key
- 
-         if 'aggregated' in tags and 'delta' in tags and round_number != 0:
-             agg_tensor_key = TensorKey(
-                 tensor_name, origin, round_number, report, ('aggregated',)
-             )
-         else:
-             agg_tensor_key = tensor_key
- 
-         nparray = self.tensor_db.get_tensor_from_cache(agg_tensor_key)
- 
-         if nparray is None:
-             raise ValueError(f'Aggregator does not have an aggregated tensor for {tensor_key}')
- 
-         # quite a bit happens in here, including compression, delta handling,
-         # etc...
-         # we might want to cache these as well
-         named_tensor = self._nparray_to_named_tensor(
-             agg_tensor_key,
-             nparray,
-             send_model_deltas=True,
-             compress_lossless=compress_lossless
-         )
- 
-         return named_tensor
- 
-     def _nparray_to_named_tensor(self, tensor_key, nparray, send_model_deltas,
-                                  compress_lossless):
-         """
-         Construct the NamedTensor Protobuf.
- 
-         Also includes logic to create delta, compress tensors with the TensorCodec, etc.
-         """
-         tensor_name, origin, round_number, report, tags = tensor_key
-         # if we have an aggregated tensor, we can make a delta
-         if 'aggregated' in tags and send_model_deltas:
-             # Should get the pretrained model to create the delta. If training
-             # has happened, Model should already be stored in the TensorDB
-             model_tk = TensorKey(tensor_name,
-                                  origin,
-                                  round_number - 1,
-                                  report,
-                                  ('model',))
- 
-             model_nparray = self.tensor_db.get_tensor_from_cache(model_tk)
- 
-             assert (model_nparray is not None), (
-                 'The original model layer should be present if the latest '
-                 'aggregated model is present')
-             delta_tensor_key, delta_nparray = self.tensor_codec.generate_delta(
-                 tensor_key,
-                 nparray,
-                 model_nparray
-             )
-             delta_comp_tensor_key, delta_comp_nparray, metadata = self.tensor_codec.compress(
-                 delta_tensor_key,
-                 delta_nparray,
-                 lossless=compress_lossless
-             )
-             named_tensor = utils.construct_named_tensor(
-                 delta_comp_tensor_key,
-                 delta_comp_nparray,
-                 metadata,
-                 lossless=compress_lossless
-             )
- 
-         else:
-             # Assume every other tensor requires lossless compression
-             compressed_tensor_key, compressed_nparray, metadata = self.tensor_codec.compress(
-                 tensor_key,
-                 nparray,
-                 require_lossless=True
-             )
-             named_tensor = utils.construct_named_tensor(
-                 compressed_tensor_key,
-                 compressed_nparray,
-                 metadata,
-                 lossless=compress_lossless
-             )
- 
-         return named_tensor
- 
-     def _collaborator_task_completed(self, collaborator, task_name, round_num):
-         """
-         Check if the collaborator has completed the task for the round.
- 
-         The aggregator doesn't actually know which tensors should be sent from the collaborator \
-             so it must to rely specifically on the presence of previous results
- 
-         Args:
-             collaborator : str
-                 collaborator to check if their task has been completed
-             task_name : str
-                 The name of the task (TaskRunner function)
-             round_num : int
- 
-         Returns:
-             task_competed : bool
-                 Whether or not the collaborator has completed the task for this
-                 round
-         """
-         task_key = TaskResultKey(task_name, collaborator, round_num)
-         return task_key in self.collaborator_tasks_results
- 
-     def send_local_task_results(self, collaborator_name, round_number, task_name,
-                                 data_size, named_tensors):
-         """
-         RPC called by collaborator.
- 
-         Transmits collaborator's task results to the aggregator.
- 
-         Args:
-             collaborator_name: str
-             task_name: str
-             round_number: int
-             data_size: int
-             named_tensors: protobuf NamedTensor
-         Returns:
-              None
-         """
-         self.logger.info(
-             f'Collaborator {collaborator_name} is sending task results '
-             f'for {task_name}, round {round_number}'
-         )
- 
-         task_key = TaskResultKey(task_name, collaborator_name, round_number)
- 
-         # we mustn't have results already
-         if self._collaborator_task_completed(
-                 collaborator_name, task_name, round_number
-         ):
-             raise ValueError(
-                 f'Aggregator already has task results from collaborator {collaborator_name}'
-                 f' for task {task_key}'
-             )
- 
-         # initialize the list of tensors that go with this task
-         # Setting these incrementally is leading to missing values
-         task_results = []
- 
-         # go through the tensors and add them to the tensor dictionary and the
-         # task dictionary
-         for named_tensor in named_tensors:
-             # sanity check that this tensor has been updated
-             if named_tensor.round_number != round_number:
-                 raise ValueError(
-                     f'Collaborator {collaborator_name} is reporting results for the wrong round.'
-                     f' Exiting...'
-                 )
- 
-             # quite a bit happens in here, including decompression, delta
-             # handling, etc...
-             tensor_key, nparray = self._process_named_tensor(
-                 named_tensor, collaborator_name
-             )
-             if 'metric' in tensor_key.tags:
-                 metric_value = nparray.item()
-                 metric_dict = {
-                     'metric_origin': tensor_key.tags[-1],
-                     'task_name': task_name,
-                     'metric_name': tensor_key.tensor_name,
-                     'metric_value': metric_value,
-                     'round': round_number}
-                 if self.write_logs:
-                     self.log_metric(tensor_key.tags[-1], task_name,
-                                     tensor_key.tensor_name, nparray, round_number)
-                 self.logger.metric(f'Round {round_number}, '
-                                    f'collaborator {tensor_key.tags[-1]} '
-                                    f'{task_name} result '
-                                    f'{tensor_key.tensor_name}:\t{metric_value:f}')
-                 self.metric_queue.put(metric_dict)
- 
-             task_results.append(tensor_key)
-             # By giving task_key it's own weight, we can support different
-             # training/validation weights
-             # As well as eventually supporting weights that change by round
-             # (if more data is added)
-             self.collaborator_task_weight[task_key] = data_size
- 
-         self.collaborator_tasks_results[task_key] = task_results
- 
-         self._end_of_task_check(task_name)
- 
-     def _process_named_tensor(self, named_tensor, collaborator_name):
-         """
-         Extract the named tensor fields.
- 
-         Performs decompression, delta computation, and inserts results into TensorDB.
- 
-         Args:
-             named_tensor:       NamedTensor (protobuf)
-                 protobuf that will be extracted from and processed
-             collaborator_name:  str
-                 Collaborator name is needed for proper tagging of resulting
-                 tensorkeys
- 
-         Returns:
-             tensor_key : TensorKey (named_tuple)
-                 The tensorkey extracted from the protobuf
-             nparray : np.array
-                 The numpy array associated with the returned tensorkey
-         """
-         raw_bytes = named_tensor.data_bytes
-         metadata = [{'int_to_float': proto.int_to_float,
-                      'int_list': proto.int_list,
-                      'bool_list': proto.bool_list}
-                     for proto in named_tensor.transformer_metadata]
-         # The tensor has already been transfered to aggregator,
-         # so the newly constructed tensor should have the aggregator origin
-         tensor_key = TensorKey(
-             named_tensor.name,
-             self.uuid,
-             named_tensor.round_number,
-             named_tensor.report,
-             tuple(named_tensor.tags)
-         )
-         tensor_name, origin, round_number, report, tags = tensor_key
-         assert ('compressed' in tags or 'lossy_compressed' in tags), (
-             f'Named tensor {tensor_key} is not compressed'
-         )
-         if 'compressed' in tags:
-             dec_tk, decompressed_nparray = self.tensor_codec.decompress(
-                 tensor_key,
-                 data=raw_bytes,
-                 transformer_metadata=metadata,
-                 require_lossless=True
-             )
-             dec_name, dec_origin, dec_round_num, dec_report, dec_tags = dec_tk
-             # Need to add the collaborator tag to the resulting tensor
-             if type(dec_tags) == str:
-                 new_tags = tuple([dec_tags] + [collaborator_name])
-             else:
-                 new_tags = tuple(list(dec_tags) + [collaborator_name])
-             # layer.agg.n.trained.delta.col_i
-             decompressed_tensor_key = TensorKey(
-                 dec_name, dec_origin, dec_round_num, dec_report, new_tags
-             )
-         if 'lossy_compressed' in tags:
-             dec_tk, decompressed_nparray = self.tensor_codec.decompress(
-                 tensor_key,
-                 data=raw_bytes,
-                 transformer_metadata=metadata,
-                 require_lossless=False
-             )
-             dec_name, dec_origin, dec_round_num, dec_report, dec_tags = dec_tk
-             if type(dec_tags) == str:
-                 new_tags = tuple([dec_tags] + [collaborator_name])
-             else:
-                 new_tags = tuple(list(dec_tags) + [collaborator_name])
-             # layer.agg.n.trained.delta.lossy_decompressed.col_i
-             decompressed_tensor_key = TensorKey(
-                 dec_name, dec_origin, dec_round_num, dec_report, new_tags
-             )
- 
-         if 'delta' in tags:
-             base_model_tensor_key = TensorKey(
-                 tensor_name, origin, round_number, report, ('model',)
-             )
-             base_model_nparray = self.tensor_db.get_tensor_from_cache(
-                 base_model_tensor_key
-             )
-             if base_model_nparray is None:
-                 raise ValueError(f'Base model {base_model_tensor_key} not present in TensorDB')
-             final_tensor_key, final_nparray = self.tensor_codec.apply_delta(
-                 decompressed_tensor_key,
-                 decompressed_nparray, base_model_nparray
-             )
-         else:
-             final_tensor_key = decompressed_tensor_key
-             final_nparray = decompressed_nparray
- 
-         assert (final_nparray is not None), f'Could not create tensorkey {final_tensor_key}'
-         self.tensor_db.cache_tensor({final_tensor_key: final_nparray})
-         self.logger.debug(f'Created TensorKey: {final_tensor_key}')
- 
-         return final_tensor_key, final_nparray
- 
-     def _end_of_task_check(self, task_name):
-         """
-         Check whether all collaborators who are supposed to perform the task complete.
- 
-         Args:
-             task_name : str
-                 The task name to check
- 
-         Returns:
-             complete : boolean
-                 Is the task done
-         """
-         if self._is_task_done(task_name):
-             # now check for the end of the round
-             self._end_of_round_check()
- 
-     def _prepare_trained(self, tensor_name, origin, round_number, report, agg_results):
-         """
-         Prepare aggregated tensorkey tags.
- 
-         Args:
-            tensor_name : str
-            origin:
-            round_number: int
-            report: bool
-            agg_results: np.array
-         """
-         # The aggregated tensorkey tags should have the form of
-         # 'trained' or 'trained.lossy_decompressed'
-         # They need to be relabeled to 'aggregated' and
-         # reinserted. Then delta performed, compressed, etc.
-         # then reinserted to TensorDB with 'model' tag
- 
-         # First insert the aggregated model layer with the
-         # correct tensorkey
-         agg_tag_tk = TensorKey(
-             tensor_name,
-             origin,
-             round_number + 1,
-             report,
-             ('aggregated',)
-         )
-         self.tensor_db.cache_tensor({agg_tag_tk: agg_results})
- 
-         # Create delta and save it in TensorDB
-         base_model_tk = TensorKey(
-             tensor_name,
-             origin,
-             round_number,
-             report,
-             ('model',)
-         )
-         base_model_nparray = self.tensor_db.get_tensor_from_cache(base_model_tk)
-         if base_model_nparray is not None:
-             delta_tk, delta_nparray = self.tensor_codec.generate_delta(
-                 agg_tag_tk,
-                 agg_results,
-                 base_model_nparray
-             )
-         else:
-             # This condition is possible for base model
-             # optimizer states (i.e. Adam/iter:0, SGD, etc.)
-             # These values couldn't be present for the base
-             # model because no training occurs on the aggregator
-             delta_tk, delta_nparray = agg_tag_tk, agg_results
- 
-         # Compress lossless/lossy
-         compressed_delta_tk, compressed_delta_nparray, metadata = self.tensor_codec.compress(
-             delta_tk, delta_nparray
-         )
- 
-         # TODO extend the TensorDB so that compressed data is
-         #  supported. Once that is in place
-         # the compressed delta can just be stored here instead
-         # of recreating it for every request
- 
-         # Decompress lossless/lossy
-         decompressed_delta_tk, decompressed_delta_nparray = self.tensor_codec.decompress(
-             compressed_delta_tk,
-             compressed_delta_nparray,
-             metadata
-         )
- 
-         self.tensor_db.cache_tensor({decompressed_delta_tk: decompressed_delta_nparray})
- 
-         # Apply delta (unless delta couldn't be created)
-         if base_model_nparray is not None:
-             self.logger.debug(f'Applying delta for layer {decompressed_delta_tk[0]}')
-             new_model_tk, new_model_nparray = self.tensor_codec.apply_delta(
-                 decompressed_delta_tk,
-                 decompressed_delta_nparray,
-                 base_model_nparray
-             )
-         else:
-             new_model_tk, new_model_nparray = decompressed_delta_tk, decompressed_delta_nparray
- 
-         # Now that the model has been compressed/decompressed
-         # with delta operations,
-         # Relabel the tags to 'model'
-         (new_model_tensor_name, new_model_origin, new_model_round_number,
-          new_model_report, new_model_tags) = new_model_tk
-         final_model_tk = TensorKey(
-             new_model_tensor_name,
-             new_model_origin,
-             new_model_round_number,
-             new_model_report,
-             ('model',)
-         )
- 
-         # Finally, cache the updated model tensor
-         self.tensor_db.cache_tensor({final_model_tk: new_model_nparray})
- 
-     def _compute_validation_related_task_metrics(self, task_name):
-         """
-         Compute all validation related metrics.
- 
-         Args:
-             task_name : str
-                 The task name to compute
-         """
-         # By default, print out all of the metrics that the validation
-         # task sent
-         # This handles getting the subset of collaborators that may be
-         # part of the validation task
-         collaborators_for_task = self.assigner.get_collaborators_for_task(
-             task_name, self.round_number
-         )
-         # The collaborator data sizes for that task
-         collaborator_weights_unnormalized = {
-             c: self.collaborator_task_weight[TaskResultKey(task_name, c, self.round_number)]
-             for c in collaborators_for_task}
-         weight_total = sum(collaborator_weights_unnormalized.values())
-         collaborator_weight_dict = {
-             k: v / weight_total
-             for k, v in collaborator_weights_unnormalized.items()
-         }
- 
-         # The validation task should have just a couple tensors (i.e.
-         # metrics) associated with it. Because each collaborator should
-         # have sent the same tensor list, we can use the first
-         # collaborator in our subset, and apply the correct
-         # transformations to the tensorkey to resolve the aggregated
-         # tensor for that round
-         task_agg_function = self.assigner.get_aggregation_type_for_task(task_name)
-         task_key = TaskResultKey(task_name, collaborators_for_task[0], self.round_number)
-         for tensor_key in self.collaborator_tasks_results[task_key]:
-             tensor_name, origin, round_number, report, tags = tensor_key
-             assert (tags[-1] == collaborators_for_task[0]), (
-                 f'Tensor {tensor_key} in task {task_name} has not been processed correctly'
-             )
-             # Strip the collaborator label, and lookup aggregated tensor
-             new_tags = tuple(tags[:-1])
-             agg_tensor_key = TensorKey(tensor_name, origin, round_number, report, new_tags)
-             agg_tensor_name, agg_origin, agg_round_number, agg_report, agg_tags = agg_tensor_key
-             agg_function = WeightedAverage() if 'metric' in tags else task_agg_function
-             agg_results = self.tensor_db.get_aggregated_tensor(
-                 agg_tensor_key, collaborator_weight_dict, aggregation_function=agg_function)
-             if report:
-                 # Print the aggregated metric
-                 metric_dict = {
-                     'metric_origin': 'Aggregator',
-                     'task_name': task_name,
-                     'metric_name': tensor_key.tensor_name,
-                     'metric_value': agg_results.item(),
-                     'round': round_number}
- 
-                 if agg_results is None:
-                     self.logger.warning(
-                         f'Aggregated metric {agg_tensor_name} could not be collected '
-                         f'for round {self.round_number}. Skipping reporting for this round')
-                 if agg_function:
-                     self.logger.metric(f'Round {round_number}, aggregator: {task_name} '
-                                        f'{agg_function} {agg_tensor_name}:\t{agg_results:f}')
-                 else:
-                     self.logger.metric(f'Round {round_number}, aggregator: {task_name} '
-                                        f'{agg_tensor_name}:\t{agg_results:f}')
-                 if self.write_logs:
-                     self.log_metric('Aggregator', task_name,
-                                     tensor_key.tensor_name,
-                                     agg_results, round_number)
-                 self.metric_queue.put(metric_dict)
-                 # TODO Add all of the logic for saving the model based
-                 #  on best accuracy, lowest loss, etc.
-                 if 'validate_agg' in tags:
-                     # Compare the accuracy of the model, and
-                     # potentially save it
-                     if self.best_model_score is None or self.best_model_score < agg_results:
-                         self.logger.metric(f'Round {round_number}: saved the best '
-                                            f'model with score {agg_results:f}')
-                         self.best_model_score = agg_results
-                         self._save_model(round_number, self.best_state_path)
-             if 'trained' in tags:
-                 self._prepare_trained(tensor_name, origin, round_number, report, agg_results)
- 
-     def _end_of_round_check(self):
-         """
-         Check if the round complete.
- 
-         If so, perform many end of round operations,
-         such as model aggregation, metric reporting, delta generation (+
-         associated tensorkey labeling), and save the model
- 
-         Args:
-             None
- 
-         Returns:
-             None
-         """
-         if not self._is_round_done():
-             return
- 
-         # Compute all validation related metrics
-         all_tasks = self.assigner.get_all_tasks_for_round(self.round_number)
-         for task_name in all_tasks:
-             self._compute_validation_related_task_metrics(task_name)
- 
-         # Once all of the task results have been processed
-         self.round_number += 1
- 
-         # Save the latest model
-         self.logger.info(f'Saving round {self.round_number} model...')
-         self._save_model(self.round_number, self.last_state_path)
- 
-         # TODO This needs to be fixed!
-         if self._time_to_quit():
-             self.logger.info('Experiment Completed. Cleaning up...')
-         else:
-             self.logger.info(f'Starting round {self.round_number}...')
- 
-         # Cleaning tensor db
-         self.tensor_db.clean_up(self.db_store_rounds)
- 
-     def _is_task_done(self, task_name):
-         """Check that task is done."""
-         collaborators_needed = self.assigner.get_collaborators_for_task(
-             task_name, self.round_number
-         )
- 
-         return all([
-             self._collaborator_task_completed(
-                 c, task_name, self.round_number
-             ) for c in collaborators_needed
-         ])
- 
-     def _is_round_done(self):
-         """Check that round is done."""
-         tasks_for_round = self.assigner.get_all_tasks_for_round(self.round_number)
- 
-         return all([self._is_task_done(task_name) for task_name in tasks_for_round])
- 
-     def _log_big_warning(self):
-         """Warn user about single collaborator cert mode."""
-         self.logger.warning(
-             f'\n{the_dragon}\nYOU ARE RUNNING IN SINGLE COLLABORATOR CERT MODE! THIS IS'
-             f' NOT PROPER PKI AND '
-             f'SHOULD ONLY BE USED IN DEVELOPMENT SETTINGS!!!! YE HAVE BEEN'
-             f' WARNED!!!'
-         )
- 
-     def stop(self, failed_collaborator: str = None) -> None:
-         """Stop aggregator execution."""
-         self.logger.info('Force stopping the aggregator execution.')
-         for collaborator_name in filter(lambda c: c != failed_collaborator, self.authorized_cols):
-             self.logger.info(f'Sending signal to collaborator {collaborator_name} to shutdown...')
-             self.quit_job_sent_to.append(collaborator_name)
- 
- 
- the_dragon = '''
- 
-  ,@@.@@+@@##@,@@@@.`@@#@+  *@@@@ #@##@  `@@#@# @@@@@   @@    @@@@` #@@@ :@@ `@#`@@@#.@
-   @@ #@ ,@ +. @@.@* #@ :`   @+*@ .@`+.   @@ *@::@`@@   @@#  @@  #`;@`.@@ @@@`@`#@* +:@`
-   @@@@@ ,@@@  @@@@  +@@+    @@@@ .@@@    @@ .@+:@@@:  .;+@` @@ ,;,#@` @@ @@@@@ ,@@@* @
-   @@ #@ ,@`*. @@.@@ #@ ,;  `@+,@#.@.*`   @@ ,@::@`@@` @@@@# @@`:@;*@+ @@ @`:@@`@ *@@ `
-  .@@`@@,+@+;@.@@ @@`@@;*@  ;@@#@:*@+;@  `@@;@@ #@**@+;@ `@@:`@@@@  @@@@.`@+ .@ +@+@*,@
-   `` ``     ` ``  .     `     `      `     `    `  .` `  ``   ``    ``   `       .   `
- 
- 
- 
-                                             .**
-                                       ;`  `****:
-                                      @**`*******
-                          ***        +***********;
-                         ,@***;` .*:,;************
-                         ;***********@@***********
-                         ;************************,
-                         `*************************
-                          *************************
-                          ,************************
-                           **#*********************
-                           *@****`     :**********;
-                           +**;          .********.
-                           ;*;            `*******#:                       `,:
-                                           ****@@@++::                ,,;***.
-                                           *@@@**;#;:         +:      **++*,
-                                           @***#@@@:          +*;     ,****
-                                           @*@+****           ***`     ****,
-                                          ,@#******.  ,       ****     **;,**.
-                                          * ******** :,       ;*:*+    **  :,**
-                                         #  ********::      *,.*:**`   *      ,*;
-                                         .  *********:      .+,*:;*:   :      `:**
-                                        ;   :********:       ***::**   `       ` **
-                                        +   :****::***  ,    *;;::**`             :*
-                                       ``   .****::;**:::    *;::::*;              ;*
-                                       *     *****::***:.    **::::**               ;:
-                                       #     *****;:****     ;*::;***               ,*`
-                                       ;     ************`  ,**:****;               ::*
-                                       :     *************;:;*;*++:                   *.
-                                       :     *****************;*                      `*
-                                      `.    `*****************;  :                     *.
-                                      .`    .*+************+****;:                     :*
-                                      `.    :;+***********+******;`    :              .,*
-                                       ;    ::*+*******************. `::              .`:.
-                                       +    :::**********************;;:`                *
-                                       +    ,::;*************;:::*******.                *
-                                       #    `:::+*************:::;********  :,           *
-                                       @     :::***************;:;*********;:,           *
-                                       @     ::::******:*********************:         ,:*
-                                       @     .:::******:;*********************,         :*
-                                       #      :::******::******###@*******;;****        *,
-                                       #      .::;*****::*****#****@*****;:::***;  ``  **
-                                       *       ::;***********+*****+#******::*****,,,,**
-                                       :        :;***********#******#******************
-                                       .`       `;***********#******+****+************
-                                       `,        ***#**@**+***+*****+**************;`
-                                        ;         *++**#******#+****+`      `.,..
-                                        +         `@***#*******#****#
-                                        +          +***@********+**+:
-                                        *         .+**+;**;;;**;#**#
-                                       ,`         ****@         +*+:
-                                       #          +**+         :+**
-                                       @         ;**+,       ,***+
-                                       #      #@+****      *#****+
-                                      `;     @+***+@      `#**+#++
-                                      #      #*#@##,      .++:.,#
-                                     `*      @#            +.
-                                   @@@
-                                  # `@
-                                   ,                                                        '''
--- 0 ----
diff -crB --new-file ./openfl/openfl/component/aggregator/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregator/__init__.py
*** ./openfl/openfl/component/aggregator/__init__.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregator/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,10 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Aggregator package."""
- 
- from .aggregator import Aggregator
- 
- __all__ = [
-     'Aggregator',
- ]
--- 0 ----
diff -crB --new-file ./openfl/openfl/component/assigner/assigner.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/assigner/assigner.py
*** ./openfl/openfl/component/assigner/assigner.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/assigner/assigner.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,72 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Assigner module."""
- 
- 
- class Assigner:
-     r"""
-     The task assigner maintains a list of tasks.
- 
-     Also it decides the policy for which collaborator should run those tasks.
-     There may be many types of policies implemented, but a natural place to start is with a:
- 
-     RandomGroupedTaskAssigner  - Given a set of task groups, and a percentage,
-                                  assign that task group to that
-                                  percentage of collaborators in the federation.
-                                  After assigning the tasks to
-                                  collaborator, those tasks should be carried
-                                  out each round (no reassignment
-                                  between rounds)
-     GroupedTaskAssigner - Given task groups and a list of collaborators that
-                           belong to that task group,
-                           carry out tasks for each round of experiment
- 
-     Args:
-         tasks* (list of object): list of tasks to assign.
-         authorized_cols (list of str): collaborators.
-         rounds_to_train (int): number of training rounds.
- 
-     Note:
-         \* - ``tasks`` argument is taken from ``tasks`` section of FL plan YAML file.
-     """
- 
-     def __init__(self, tasks, authorized_cols,
-                  rounds_to_train, **kwargs):
-         """Initialize."""
-         self.tasks = tasks
-         self.authorized_cols = authorized_cols
-         self.rounds = rounds_to_train
-         self.all_tasks_in_groups = []
- 
-         self.task_group_collaborators = {}
-         self.collaborators_for_task = {}
-         self.collaborator_tasks = {}
- 
-         self.define_task_assignments()
- 
-     def define_task_assignments(self):
-         """Abstract method."""
-         raise NotImplementedError
- 
-     def get_tasks_for_collaborator(self, collaborator_name, round_number):
-         """Abstract method."""
-         raise NotImplementedError
- 
-     def get_collaborators_for_task(self, task_name, round_number):
-         """Abstract method."""
-         raise NotImplementedError
- 
-     def get_all_tasks_for_round(self, round_number):
-         """
-         Return tasks for the current round.
- 
-         Currently all tasks are performed on each round,
-         But there may be a reason to change this.
-         """
-         return self.all_tasks_in_groups
- 
-     def get_aggregation_type_for_task(self, task_name):
-         """Extract aggregation type from self.tasks."""
-         if 'aggregation_type' not in self.tasks[task_name]:
-             return None
-         return self.tasks[task_name]['aggregation_type']
--- 0 ----
diff -crB --new-file ./openfl/openfl/component/assigner/custom_assigner.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/assigner/custom_assigner.py
*** ./openfl/openfl/component/assigner/custom_assigner.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/assigner/custom_assigner.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,75 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Custom Assigner module."""
- 
- 
- import logging
- from collections import defaultdict
- 
- from openfl.component.aggregation_functions import WeightedAverage
- 
- logger = logging.getLogger(__name__)
- 
- 
- class Assigner:
-     """Custom assigner class."""
- 
-     def __init__(
-             self,
-             *,
-             assigner_function,
-             aggregation_functions_by_task,
-             authorized_cols,
-             rounds_to_train
-     ):
-         """Initialize."""
-         self.agg_functions_by_task = aggregation_functions_by_task
-         self.agg_functions_by_task_name = {}
-         self.authorized_cols = authorized_cols
-         self.rounds_to_train = rounds_to_train
-         self.all_tasks_for_round = defaultdict(dict)
-         self.collaborators_for_task = defaultdict(lambda: defaultdict(list))
-         self.collaborator_tasks = defaultdict(lambda: defaultdict(list))
-         self.assigner_function = assigner_function
- 
-         self.define_task_assignments()
- 
-     def define_task_assignments(self):
-         """Abstract method."""
-         for round_number in range(self.rounds_to_train):
-             tasks_by_collaborator = self.assigner_function(
-                 self.authorized_cols,
-                 round_number,
-                 number_of_callaborators=len(self.authorized_cols)
-             )
-             for collaborator_name, tasks in tasks_by_collaborator.items():
-                 self.collaborator_tasks[round_number][collaborator_name].extend(tasks)
-                 for task in tasks:
-                     self.all_tasks_for_round[round_number][task.name] = task
-                     self.collaborators_for_task[round_number][task.name].append(collaborator_name)
-                     if self.agg_functions_by_task:
-                         self.agg_functions_by_task_name[
-                             task.name
-                         ] = self.agg_functions_by_task.get(task.function_name, WeightedAverage())
- 
-     def get_tasks_for_collaborator(self, collaborator_name, round_number):
-         """Abstract method."""
-         return self.collaborator_tasks[round_number][collaborator_name]
- 
-     def get_collaborators_for_task(self, task_name, round_number):
-         """Abstract method."""
-         return self.collaborators_for_task[round_number][task_name]
- 
-     def get_all_tasks_for_round(self, round_number):
-         """
-         Return tasks for the current round.
- 
-         Currently all tasks are performed on each round,
-         But there may be a reason to change this.
-         """
-         return [task.name for task in self.all_tasks_for_round[round_number].values()]
- 
-     def get_aggregation_type_for_task(self, task_name):
-         """Extract aggregation type from self.tasks."""
-         agg_fn = self.agg_functions_by_task_name.get(task_name, WeightedAverage())
-         return agg_fn
--- 0 ----
diff -crB --new-file ./openfl/openfl/component/assigner/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/assigner/__init__.py
*** ./openfl/openfl/component/assigner/__init__.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/assigner/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,15 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Assigner package."""
- 
- from .assigner import Assigner
- from .random_grouped_assigner import RandomGroupedAssigner
- from .static_grouped_assigner import StaticGroupedAssigner
- 
- 
- __all__ = [
-     'Assigner',
-     'RandomGroupedAssigner',
-     'StaticGroupedAssigner',
- ]
--- 0 ----
diff -crB --new-file ./openfl/openfl/component/assigner/random_grouped_assigner.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/assigner/random_grouped_assigner.py
*** ./openfl/openfl/component/assigner/random_grouped_assigner.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/assigner/random_grouped_assigner.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,96 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Random grouped assigner module."""
- 
- 
- import numpy as np
- 
- from .assigner import Assigner
- 
- 
- class RandomGroupedAssigner(Assigner):
-     r"""
-     The task assigner maintains a list of tasks.
- 
-     Also it decides the policy for
-     which collaborator should run those tasks
-     There may be many types of policies implemented, but a natural place to
-     start is with a:
- 
-     RandomGroupedAssigner  - Given a set of task groups, and a percentage,
-                              assign that task group to that percentage
-                              of collaborators in the federation. After
-                              assigning the tasks to collaborator, those
-                              tasks should be carried out each round (no
-                              reassignment between rounds)
-     GroupedAssigner -        Given task groups and a list of collaborators
-                              that belong to that task group,
-                              carry out tasks for each round of experiment
- 
-     Args:
-         task_groups* (list of object): task groups to assign.
- 
-     Note:
-         \* - Plan setting.
-     """
- 
-     def __init__(self, task_groups, **kwargs):
-         """Initialize."""
-         self.task_groups = task_groups
-         super().__init__(**kwargs)
- 
-     def define_task_assignments(self):
-         """All of the logic to set up the map of tasks to collaborators is done here."""
-         assert (np.abs(1.0 - np.sum([group['percentage']
-                                      for group in self.task_groups])) < 0.01), (
-             'Task group percentages must sum to 100%')
- 
-         # Start by finding all of the tasks in all specified groups
-         self.all_tasks_in_groups = list({
-             task
-             for group in self.task_groups
-             for task in group['tasks']
-         })
- 
-         # Initialize the map of collaborators for a given task on a given round
-         for task in self.all_tasks_in_groups:
-             self.collaborators_for_task[task] = {
-                 i: [] for i in range(self.rounds)
-             }
- 
-         for col in self.authorized_cols:
-             self.collaborator_tasks[col] = {i: [] for i in range(self.rounds)}
- 
-         col_list_size = len(self.authorized_cols)
-         for round_num in range(self.rounds):
-             randomized_col_idx = np.random.choice(
-                 len(self.authorized_cols),
-                 len(self.authorized_cols),
-                 replace=False
-             )
-             col_idx = 0
-             for group in self.task_groups:
-                 num_col_in_group = int(group['percentage'] * col_list_size)
-                 rand_col_group_list = [
-                     self.authorized_cols[i] for i in
-                     randomized_col_idx[col_idx:col_idx + num_col_in_group]
-                 ]
-                 self.task_group_collaborators[group['name']] = rand_col_group_list
-                 for col in rand_col_group_list:
-                     self.collaborator_tasks[col][round_num] = group['tasks']
-                 # Now populate reverse lookup of tasks->group
-                 for task in group['tasks']:
-                     # This should append the list of collaborators performing
-                     # that task
-                     self.collaborators_for_task[task][round_num] += rand_col_group_list
-                 col_idx += num_col_in_group
-             assert (col_idx == col_list_size), 'Task groups were not divided properly'
- 
-     def get_tasks_for_collaborator(self, collaborator_name, round_number):
-         """Get tasks for the collaborator specified."""
-         return self.collaborator_tasks[collaborator_name][round_number]
- 
-     def get_collaborators_for_task(self, task_name, round_number):
-         """Get collaborators for the task specified."""
-         return self.collaborators_for_task[task_name][round_number]
--- 0 ----
diff -crB --new-file ./openfl/openfl/component/assigner/static_grouped_assigner.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/assigner/static_grouped_assigner.py
*** ./openfl/openfl/component/assigner/static_grouped_assigner.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/assigner/static_grouped_assigner.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,94 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Static grouped assigner module."""
- 
- from .assigner import Assigner
- 
- 
- class StaticGroupedAssigner(Assigner):
-     r"""
-     The task assigner maintains a list of tasks.
- 
-     Also it decides the policy for
-     which collaborator should run those tasks
-     There may be many types of policies implemented, but a natural place to
-     start is with a:
- 
-     StaticGroupedAssigner  - Given a set of task groups, and a list of
-                              collaborators for that group, assign tasks for
-                              of collaborators in the federation. After assigning
-                              the tasks to collaborator, those tasks
-                              should be carried out each round (no reassignment
-                              between rounds)
-     GroupedAssigner -        Given task groups and a list of collaborators that
-                              belong to that task group, carry out tasks for
-                              each round of experiment
- 
-     Args:
-         task_groups* (list of obj): task groups to assign.
- 
-     Note:
-         \* - Plan setting.
-     """
- 
-     def __init__(self, task_groups, **kwargs):
-         """Initialize."""
-         self.task_groups = task_groups
-         super().__init__(**kwargs)
- 
-     def define_task_assignments(self):
-         """All of the logic to set up the map of tasks to collaborators is done here."""
-         cols_amount = sum([
-             len(group['collaborators']) for group in self.task_groups
-         ])
-         authorized_cols_amount = len(self.authorized_cols)
- 
-         unique_cols = {
-             col
-             for group in self.task_groups
-             for col in group['collaborators']
-         }
-         unique_authorized_cols = set(self.authorized_cols)
- 
-         assert (cols_amount == authorized_cols_amount and unique_cols == unique_authorized_cols), (
-             f'Collaborators in each group must be distinct: '
-             f'{unique_cols}, {unique_authorized_cols}'
-         )
- 
-         # Start by finding all of the tasks in all specified groups
-         self.all_tasks_in_groups = list({
-             task
-             for group in self.task_groups
-             for task in group['tasks']
-         })
- 
-         # Initialize the map of collaborators for a given task on a given round
-         for task in self.all_tasks_in_groups:
-             self.collaborators_for_task[task] = {
-                 i: [] for i in range(self.rounds)
-             }
- 
-         for group in self.task_groups:
-             group_col_list = group['collaborators']
-             self.task_group_collaborators[group['name']] = group_col_list
-             for col in group_col_list:
-                 # For now, we assume that collaborators have the same tasks for
-                 # every round
-                 self.collaborator_tasks[col] = {
-                     i: group['tasks'] for i in range(self.rounds)
-                 }
-             # Now populate reverse lookup of tasks->group
-             for task in group['tasks']:
-                 for round_ in range(self.rounds):
-                     # This should append the list of collaborators performing
-                     # that task
-                     self.collaborators_for_task[task][round_] += group_col_list
- 
-     def get_tasks_for_collaborator(self, collaborator_name, round_number):
-         """Get tasks for the collaborator specified."""
-         return self.collaborator_tasks[collaborator_name][round_number]
- 
-     def get_collaborators_for_task(self, task_name, round_number):
-         """Get collaborators for the task specified."""
-         return self.collaborators_for_task[task_name][round_number]
--- 0 ----
diff -crB --new-file ./openfl/openfl/component/assigner/tasks.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/assigner/tasks.py
*** ./openfl/openfl/component/assigner/tasks.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/assigner/tasks.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,32 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Task module."""
- 
- 
- from dataclasses import dataclass
- from dataclasses import field
- 
- 
- @dataclass
- class Task:
-     """Task base dataclass."""
- 
-     name: str
-     function_name: str
-     task_type: str
-     apply_local: bool = False
-     parameters: dict = field(default_factory=dict)  # We can expend it in the future
- 
- 
- @dataclass
- class TrainTask(Task):
-     """TrainTask class."""
- 
-     task_type: str = 'train'
- 
- 
- @dataclass
- class ValidateTask(Task):
-     """Validation Task class."""
- 
-     task_type: str = 'validate'
--- 0 ----
diff -crB --new-file ./openfl/openfl/component/ca/ca.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/ca/ca.py
*** ./openfl/openfl/component/ca/ca.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/ca/ca.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,275 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Aggregator module."""
- 
- import base64
- import json
- import os
- import platform
- import shutil
- import signal
- import subprocess
- import time
- import urllib.request
- from logging import getLogger
- from pathlib import Path
- from subprocess import call
- 
- import requests
- from click import confirm
- 
- logger = getLogger(__name__)
- 
- TOKEN_DELIMITER = '.'
- CA_STEP_CONFIG_DIR = Path('step_config')
- CA_PKI_DIR = Path('cert')
- CA_PASSWORD_FILE = Path('pass_file')
- CA_CONFIG_JSON = Path('config/ca.json')
- 
- 
- def get_system_and_architecture():
-     """Get system and architecture of machine."""
-     uname_res = platform.uname()
-     system = uname_res.system.lower()
- 
-     architecture_aliases = {
-         'x86_64': 'amd64',
-         'armv6l': 'armv6',
-         'armv7l': 'armv7',
-         'aarch64': 'arm64'
-     }
-     architecture = uname_res.machine.lower()
-     for alias in architecture_aliases:
-         if architecture == alias:
-             architecture = architecture_aliases[alias]
-             break
- 
-     return system, architecture
- 
- 
- def download_step_bin(url, grep_name, architecture, prefix='.', confirmation=True):
-     """
-     Donwload step binaries from github.
- 
-     Args:
-         url: address of latest release
-         grep_name: name to grep over github assets
-         architecture: architecture type to grep
-         prefix: folder path to download
-         confirmation: request user confirmation or not
-     """
-     if confirmation:
-         confirm('CA binaries from github will be downloaded now', default=True, abort=True)
-     result = requests.get(url)
-     if result.status_code != 200:
-         logger.warning('Can\'t download binaries from github. Please try lately.')
-         return
- 
-     assets = result.json().get('assets', [])
-     archive_urls = [
-         a['browser_download_url']
-         for a in assets
-         if (grep_name in a['name'] and architecture in a['name']
-             and 'application/gzip' in a['content_type'])
-     ]
-     if len(archive_urls) == 0:
-         raise Exception('Applicable CA binaries from github were not found '
-                         f'(name: {grep_name}, architecture: {architecture})')
-     archive_url = archive_urls[-1]
-     archive_url = archive_url.replace('https', 'http')
-     name = archive_url.split('/')[-1]
-     logger.info(f'Downloading {name}')
-     urllib.request.urlretrieve(archive_url, f'{prefix}/{name}')
-     shutil.unpack_archive(f'{prefix}/{name}', f'{prefix}/step')
- 
- 
- def get_token(name, ca_url, ca_path='.'):
-     """
-     Create authentication token.
- 
-     Args:
-         name: common name for following certificate
-                     (aggregator fqdn or collaborator name)
-         ca_url: full url of CA server
-         ca_path: path to ca folder
-     """
-     ca_path = Path(ca_path)
-     step_config_dir = ca_path / CA_STEP_CONFIG_DIR
-     pki_dir = ca_path / CA_PKI_DIR
-     step_path, _ = get_ca_bin_paths(ca_path)
-     if not step_path:
-         raise Exception('Step-CA is not installed!\nRun `fx pki install` first')
- 
-     priv_json = step_config_dir / 'secrets' / 'priv.json'
-     pass_file = pki_dir / CA_PASSWORD_FILE
-     root_crt = step_config_dir / 'certs' / 'root_ca.crt'
-     try:
-         token = subprocess.check_output(
-             f'{step_path} ca token {name} '
-             f'--key {priv_json} --root {root_crt} '
-             f'--password-file {pass_file} 'f'--ca-url {ca_url}', shell=True)
-     except subprocess.CalledProcessError as exc:
-         logger.error(f'Error code {exc.returncode}: {exc.output}')
-         return
- 
-     token = token.strip()
-     token_b64 = base64.b64encode(token)
- 
-     with open(root_crt, mode='rb') as file:
-         root_certificate_b = file.read()
-     root_ca_b64 = base64.b64encode(root_certificate_b)
- 
-     return TOKEN_DELIMITER.join([
-         token_b64.decode('utf-8'),
-         root_ca_b64.decode('utf-8'),
-     ])
- 
- 
- def get_ca_bin_paths(ca_path):
-     """Get paths of step binaries."""
-     ca_path = Path(ca_path)
-     step = None
-     step_ca = None
-     if (ca_path / 'step').exists():
-         dirs = os.listdir(ca_path / 'step')
-         for dir_ in dirs:
-             if 'step_' in dir_:
-                 step = ca_path / 'step' / dir_ / 'bin' / 'step'
-             if 'step-ca' in dir_:
-                 step_ca = ca_path / 'step' / dir_ / 'bin' / 'step-ca'
-     return step, step_ca
- 
- 
- def certify(name, cert_path: Path, token_with_cert, ca_path: Path):
-     """Create an envoy workspace."""
-     os.makedirs(cert_path, exist_ok=True)
- 
-     token, root_certificate = token_with_cert.split(TOKEN_DELIMITER)
-     token = base64.b64decode(token).decode('utf-8')
-     root_certificate = base64.b64decode(root_certificate)
- 
-     step_path, _ = get_ca_bin_paths(ca_path)
-     if not step_path:
-         url = 'http://api.github.com/repos/smallstep/cli/releases/latest'
-         system, arch = get_system_and_architecture()
-         download_step_bin(url, f'step_{system}', arch, prefix=ca_path)
-         step_path, _ = get_ca_bin_paths(ca_path)
-     if not step_path:
-         raise Exception('Step-CA is not installed!\nRun `fx pki install` first')
- 
-     with open(f'{cert_path}/root_ca.crt', mode='wb') as file:
-         file.write(root_certificate)
-     call(f'{step_path} ca certificate {name} {cert_path}/{name}.crt '
-          f'{cert_path}/{name}.key --kty EC --curve P-384 -f --token {token}', shell=True)
- 
- 
- def remove_ca(ca_path):
-     """Kill step-ca process and rm ca directory."""
-     _check_kill_process('step-ca')
-     shutil.rmtree(ca_path, ignore_errors=True)
- 
- 
- def install(ca_path, ca_url, password):
-     """
-     Create certificate authority for federation.
- 
-     Args:
-         ca_path: path to ca directory
-         ca_url: url for ca server like: 'host:port'
-         password: Simple password for encrypting root private keys
- 
-     """
-     logger.info('Creating CA')
- 
-     ca_path = Path(ca_path)
-     ca_path.mkdir(parents=True, exist_ok=True)
-     step_config_dir = ca_path / CA_STEP_CONFIG_DIR
-     os.environ['STEPPATH'] = str(step_config_dir)
-     step_path, step_ca_path = get_ca_bin_paths(ca_path)
- 
-     if not (step_path and step_ca_path and step_path.exists() and step_ca_path.exists()):
-         confirm('CA binaries from github will be downloaded now', default=True, abort=True)
-         system, arch = get_system_and_architecture()
-         url = 'http://api.github.com/repos/smallstep/certificates/releases/latest'
-         download_step_bin(url, f'step-ca_{system}', arch, prefix=ca_path, confirmation=False)
-         url = 'http://api.github.com/repos/smallstep/cli/releases/latest'
-         download_step_bin(url, f'step_{system}', arch, prefix=ca_path, confirmation=False)
-     step_config_dir = ca_path / CA_STEP_CONFIG_DIR
-     if (not step_config_dir.exists()
-             or confirm('CA exists, do you want to recreate it?', default=True)):
-         _create_ca(ca_path, ca_url, password)
-     _configure(step_config_dir)
- 
- 
- def run_ca(step_ca, pass_file, ca_json):
-     """Run CA server."""
-     if _check_kill_process('step-ca', confirmation=True):
-         logger.info('Up CA server')
-         call(f'{step_ca} --password-file {pass_file} {ca_json}', shell=True)
- 
- 
- def _check_kill_process(pstring, confirmation=False):
-     """Kill process by name."""
-     pids = []
-     proc = subprocess.Popen(f'ps ax | grep {pstring} | grep -v grep',
-                             shell=True, stdout=subprocess.PIPE)
-     text = proc.communicate()[0].decode('utf-8')
- 
-     for line in text.splitlines():
-         fields = line.split()
-         pids.append(fields[0])
- 
-     if len(pids):
-         if confirmation and not confirm('CA server is already running. Stop him?', default=True):
-             return False
-         for pid in pids:
-             os.kill(int(pid), signal.SIGKILL)
-         time.sleep(2)
-     return True
- 
- 
- def _create_ca(ca_path: Path, ca_url: str, password: str):
-     """Create a ca workspace."""
-     import os
-     pki_dir = ca_path / CA_PKI_DIR
-     step_config_dir = ca_path / CA_STEP_CONFIG_DIR
- 
-     pki_dir.mkdir(parents=True, exist_ok=True)
-     step_config_dir.mkdir(parents=True, exist_ok=True)
- 
-     with open(f'{pki_dir}/pass_file', 'w') as f:
-         f.write(password)
-     os.chmod(f'{pki_dir}/pass_file', 0o600)
-     step_path, step_ca_path = get_ca_bin_paths(ca_path)
-     assert (step_path and step_ca_path and step_path.exists() and step_ca_path.exists())
- 
-     logger.info('Create CA Config')
-     os.environ['STEPPATH'] = str(step_config_dir)
-     shutil.rmtree(step_config_dir, ignore_errors=True)
-     name = ca_url.split(':')[0]
-     call(f'{step_path} ca init --name name --dns {name} '
-          f'--address {ca_url}  --provisioner prov '
-          f'--password-file {pki_dir}/pass_file', shell=True)
- 
-     call(f'{step_path} ca provisioner remove prov --all', shell=True)
-     call(f'{step_path} crypto jwk create {step_config_dir}/certs/pub.json '
-          f'{step_config_dir}/secrets/priv.json --password-file={pki_dir}/pass_file', shell=True)
-     call(
-         f'{step_path} ca provisioner add provisioner {step_config_dir}/certs/pub.json',
-         shell=True
-     )
- 
- 
- def _configure(step_config_dir):
-     conf_file = step_config_dir / CA_CONFIG_JSON
-     with open(conf_file, 'r+') as f:
-         data = json.load(f)
-         data.setdefault('authority', {}).setdefault('claims', {})
-         data['authority']['claims']['maxTLSCertDuration'] = f'{365 * 24}h'
-         data['authority']['claims']['defaultTLSCertDuration'] = f'{365 * 24}h'
-         data['authority']['claims']['maxUserSSHCertDuration'] = '24h'
-         data['authority']['claims']['defaultUserSSHCertDuration'] = '24h'
-         f.seek(0)
-         json.dump(data, f, indent=4)
-         f.truncate()
--- 0 ----
diff -crB --new-file ./openfl/openfl/component/ca/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/ca/__init__.py
*** ./openfl/openfl/component/ca/__init__.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/ca/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """CA package."""
--- 0 ----
diff -crB --new-file ./openfl/openfl/component/collaborator/collaborator.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/collaborator/collaborator.py
*** ./openfl/openfl/component/collaborator/collaborator.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/collaborator/collaborator.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,524 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Collaborator module."""
- 
- from enum import Enum
- from logging import getLogger
- from time import sleep
- from typing import Tuple
- 
- from openfl.databases import TensorDB
- from openfl.pipelines import NoCompressionPipeline
- from openfl.pipelines import TensorCodec
- from openfl.protocols import utils
- from openfl.utilities import TensorKey
- 
- 
- class DevicePolicy(Enum):
-     """Device assignment policy."""
- 
-     CPU_ONLY = 1
- 
-     CUDA_PREFERRED = 2
- 
- 
- class OptTreatment(Enum):
-     """Optimizer Methods.
- 
-     - RESET tells each collaborator to reset the optimizer state at the beginning
-     of each round.
- 
-     - CONTINUE_LOCAL tells each collaborator to continue with the local optimizer
-     state from the previous round.
- 
-     - CONTINUE_GLOBAL tells each collaborator to continue with the federally
-     averaged optimizer state from the previous round.
-     """
- 
-     RESET = 1
-     CONTINUE_LOCAL = 2
-     CONTINUE_GLOBAL = 3
- 
- 
- class Collaborator:
-     r"""The Collaborator object class.
- 
-     Args:
-         collaborator_name (string): The common name for the collaborator
-         aggregator_uuid: The unique id for the client
-         federation_uuid: The unique id for the federation
-         model: The model
-         opt_treatment* (string): The optimizer state treatment (Defaults to
-             "CONTINUE_GLOBAL", which is aggreagated state from previous round.)
- 
-         compression_pipeline: The compression pipeline (Defaults to None)
- 
-         num_batches_per_round (int): Number of batches per round
-                                      (Defaults to None)
- 
-         delta_updates* (bool): True = Only model delta gets sent.
-                                False = Whole model gets sent to collaborator.
-                                Defaults to False.
- 
-         single_col_cert_common_name: (Defaults to None)
- 
-     Note:
-         \* - Plan setting.
-     """
- 
-     def __init__(self,
-                  collaborator_name,
-                  aggregator_uuid,
-                  federation_uuid,
-                  client,
-                  task_runner,
-                  task_config,
-                  opt_treatment='RESET',
-                  device_assignment_policy='CPU_ONLY',
-                  delta_updates=False,
-                  compression_pipeline=None,
-                  db_store_rounds=1,
-                  **kwargs):
-         """Initialize."""
-         self.single_col_cert_common_name = None
- 
-         if self.single_col_cert_common_name is None:
-             self.single_col_cert_common_name = ''  # for protobuf compatibility
-         # we would really want this as an object
- 
-         self.collaborator_name = collaborator_name
-         self.aggregator_uuid = aggregator_uuid
-         self.federation_uuid = federation_uuid
- 
-         self.compression_pipeline = compression_pipeline or NoCompressionPipeline()
-         self.tensor_codec = TensorCodec(self.compression_pipeline)
-         self.tensor_db = TensorDB()
-         self.db_store_rounds = db_store_rounds
- 
-         self.task_runner = task_runner
-         self.delta_updates = delta_updates
- 
-         self.client = client
- 
-         self.task_config = task_config
- 
-         self.logger = getLogger(__name__)
- 
-         # RESET/CONTINUE_LOCAL/CONTINUE_GLOBAL
-         if hasattr(OptTreatment, opt_treatment):
-             self.opt_treatment = OptTreatment[opt_treatment]
-         else:
-             self.logger.error(f'Unknown opt_treatment: {opt_treatment.name}.')
-             raise NotImplementedError(f'Unknown opt_treatment: {opt_treatment}.')
- 
-         if hasattr(DevicePolicy, device_assignment_policy):
-             self.device_assignment_policy = DevicePolicy[device_assignment_policy]
-         else:
-             self.logger.error('Unknown device_assignment_policy: '
-                               f'{device_assignment_policy.name}.')
-             raise NotImplementedError(
-                 f'Unknown device_assignment_policy: {device_assignment_policy}.'
-             )
- 
-         self.task_runner.set_optimizer_treatment(self.opt_treatment.name)
- 
-     def set_available_devices(self, cuda: Tuple[str] = ()):
-         """
-         Set available CUDA devices.
- 
-         Cuda tuple contains string indeces, ('1', '3').
-         """
-         self.cuda_devices = cuda
- 
-     def run(self):
-         """Run the collaborator."""
-         while True:
-             tasks, round_number, sleep_time, time_to_quit = self.get_tasks()
-             if time_to_quit:
-                 break
-             elif sleep_time > 0:
-                 sleep(sleep_time)  # some sleep function
-             else:
-                 self.logger.info(f'Received the following tasks: {tasks}')
-                 for task in tasks:
-                     self.do_task(task, round_number)
- 
-                 # Cleaning tensor db
-                 self.tensor_db.clean_up(self.db_store_rounds)
- 
-         self.logger.info('End of Federation reached. Exiting...')
- 
-     def run_simulation(self):
-         """
-         Specific function for the simulation.
- 
-         After the tasks have
-         been performed for a roundquit, and then the collaborator object will
-         be reinitialized after the next round
-         """
-         while True:
-             tasks, round_number, sleep_time, time_to_quit = self.get_tasks()
-             if time_to_quit:
-                 self.logger.info('End of Federation reached. Exiting...')
-                 break
-             elif sleep_time > 0:
-                 sleep(sleep_time)  # some sleep function
-             else:
-                 self.logger.info(f'Received the following tasks: {tasks}')
-                 for task in tasks:
-                     self.do_task(task, round_number)
-                 self.logger.info(f'All tasks completed on {self.collaborator_name} '
-                                  f'for round {round_number}...')
-                 break
- 
-     def get_tasks(self):
-         """Get tasks from the aggregator."""
-         # logging wait time to analyze training process
-         self.logger.info('Waiting for tasks...')
-         tasks, round_number, sleep_time, time_to_quit = self.client.get_tasks(
-             self.collaborator_name)
- 
-         return tasks, round_number, sleep_time, time_to_quit
- 
-     def do_task(self, task, round_number):
-         """Do the specified task."""
-         # map this task to an actual function name and kwargs
-         if hasattr(self.task_runner, 'TASK_REGISTRY'):
-             func_name = task.function_name
-             task_name = task.name
-             kwargs = {}
-             if task.task_type == 'validate':
-                 if task.apply_local:
-                     kwargs['apply'] = 'local'
-                 else:
-                     kwargs['apply'] = 'global'
-         else:
-             if isinstance(task, str):
-                 task_name = task
-             else:
-                 task_name = task.name
-             func_name = self.task_config[task_name]['function']
-             kwargs = self.task_config[task_name]['kwargs']
- 
-         # this would return a list of what tensors we require as TensorKeys
-         required_tensorkeys_relative = self.task_runner.get_required_tensorkeys_for_function(
-             func_name,
-             **kwargs
-         )
- 
-         # models actually return "relative" tensorkeys of (name, LOCAL|GLOBAL,
-         # round_offset)
-         # so we need to update these keys to their "absolute values"
-         required_tensorkeys = []
-         for tname, origin, rnd_num, report, tags in required_tensorkeys_relative:
-             if origin == 'GLOBAL':
-                 origin = self.aggregator_uuid
-             else:
-                 origin = self.collaborator_name
- 
-             # rnd_num is the relative round. So if rnd_num is -1, get the
-             # tensor from the previous round
-             required_tensorkeys.append(
-                 TensorKey(tname, origin, rnd_num + round_number, report, tags)
-             )
- 
-         # print('Required tensorkeys = {}'.format(
-         # [tk[0] for tk in required_tensorkeys]))
-         input_tensor_dict = self.get_numpy_dict_for_tensorkeys(
-             required_tensorkeys
-         )
- 
-         # now we have whatever the model needs to do the task
-         if hasattr(self.task_runner, 'TASK_REGISTRY'):
-             # New interactive python API
-             # New `Core` TaskRunner contains registry of tasks
-             func = self.task_runner.TASK_REGISTRY[func_name]
-             self.logger.info('Using Interactive Python API')
- 
-             # So far 'kwargs' contained parameters read from the plan
-             # those are parameters that the eperiment owner registered for
-             # the task.
-             # There is another set of parameters that created on the
-             # collaborator side, for instance, local processing unit identifier:s
-             if (self.device_assignment_policy is DevicePolicy.CUDA_PREFERRED
-                     and len(self.cuda_devices) > 0):
-                 kwargs['device'] = f'cuda:{self.cuda_devices[0]}'
-             else:
-                 kwargs['device'] = 'cpu'
-         else:
-             # TaskRunner subclassing API
-             # Tasks are defined as methods of TaskRunner
-             func = getattr(self.task_runner, func_name)
-             self.logger.info('Using TaskRunner subclassing API')
- 
-         global_output_tensor_dict, local_output_tensor_dict = func(
-             col_name=self.collaborator_name,
-             round_num=round_number,
-             input_tensor_dict=input_tensor_dict,
-             **kwargs)
- 
-         # Save global and local output_tensor_dicts to TensorDB
-         self.tensor_db.cache_tensor(global_output_tensor_dict)
-         self.tensor_db.cache_tensor(local_output_tensor_dict)
- 
-         # send the results for this tasks; delta and compression will occur in
-         # this function
-         self.send_task_results(global_output_tensor_dict, round_number, task_name)
- 
-     def get_numpy_dict_for_tensorkeys(self, tensor_keys):
-         """Get tensor dictionary for specified tensorkey set."""
-         return {k.tensor_name: self.get_data_for_tensorkey(k) for k in tensor_keys}
- 
-     def get_data_for_tensorkey(self, tensor_key):
-         """
-         Resolve the tensor corresponding to the requested tensorkey.
- 
-         Args
-         ----
-         tensor_key:         Tensorkey that will be resolved locally or
-                             remotely. May be the product of other tensors
-         """
-         # try to get from the store
-         tensor_name, origin, round_number, report, tags = tensor_key
-         self.logger.debug(f'Attempting to retrieve tensor {tensor_key} from local store')
-         nparray = self.tensor_db.get_tensor_from_cache(tensor_key)
- 
-         # if None and origin is our client, request it from the client
-         if nparray is None:
-             if origin == self.collaborator_name:
-                 self.logger.info(
-                     f'Attempting to find locally stored {tensor_name} tensor from prior round...'
-                 )
-                 prior_round = round_number - 1
-                 while prior_round >= 0:
-                     nparray = self.tensor_db.get_tensor_from_cache(
-                         TensorKey(tensor_name, origin, prior_round, report, tags))
-                     if nparray is not None:
-                         self.logger.debug(f'Found tensor {tensor_name} in local TensorDB '
-                                           f'for round {prior_round}')
-                         return nparray
-                     prior_round -= 1
-                 self.logger.info(
-                     f'Cannot find any prior version of tensor {tensor_name} locally...'
-                 )
-             self.logger.debug('Unable to get tensor from local store...'
-                               'attempting to retrieve from client')
-             # Determine whether there are additional compression related
-             # dependencies.
-             # Typically, dependencies are only relevant to model layers
-             tensor_dependencies = self.tensor_codec.find_dependencies(
-                 tensor_key, self.delta_updates
-             )
-             if len(tensor_dependencies) > 0:
-                 # Resolve dependencies
-                 # tensor_dependencies[0] corresponds to the prior version
-                 # of the model.
-                 # If it exists locally, should pull the remote delta because
-                 # this is the least costly path
-                 prior_model_layer = self.tensor_db.get_tensor_from_cache(
-                     tensor_dependencies[0]
-                 )
-                 if prior_model_layer is not None:
-                     uncompressed_delta = self.get_aggregated_tensor_from_aggregator(
-                         tensor_dependencies[1]
-                     )
-                     new_model_tk, nparray = self.tensor_codec.apply_delta(
-                         tensor_dependencies[1],
-                         uncompressed_delta,
-                         prior_model_layer,
-                         creates_model=True,
-                     )
-                     self.tensor_db.cache_tensor({new_model_tk: nparray})
-                 else:
-                     self.logger.info('Count not find previous model layer.'
-                                      'Fetching latest layer from aggregator')
-                     # The original model tensor should be fetched from client
-                     nparray = self.get_aggregated_tensor_from_aggregator(
-                         tensor_key,
-                         require_lossless=True
-                     )
-             elif 'model' in tags:
-                 # Pulling the model for the first time
-                 nparray = self.get_aggregated_tensor_from_aggregator(
-                     tensor_key,
-                     require_lossless=True
-                 )
-         else:
-             self.logger.debug(f'Found tensor {tensor_key} in local TensorDB')
- 
-         return nparray
- 
-     def get_aggregated_tensor_from_aggregator(self, tensor_key,
-                                               require_lossless=False):
-         """
-         Return the decompressed tensor associated with the requested tensor key.
- 
-         If the key requests a compressed tensor (in the tag), the tensor will
-         be decompressed before returning
-         If the key specifies an uncompressed tensor (or just omits a compressed
-         tag), the decompression operation will be skipped
- 
-         Args
-         ----
-         tensor_key  :               The requested tensor
-         require_lossless:   Should compression of the tensor be allowed
-                                     in flight?
-                                     For the initial model, it may affect
-                                     convergence to apply lossy
-                                     compression. And metrics shouldn't be
-                                     compressed either
- 
-         Returns
-         -------
-         nparray     : The decompressed tensor associated with the requested
-                       tensor key
-         """
-         tensor_name, origin, round_number, report, tags = tensor_key
- 
-         self.logger.debug(f'Requesting aggregated tensor {tensor_key}')
-         tensor = self.client.get_aggregated_tensor(
-             self.collaborator_name, tensor_name, round_number, report, tags, require_lossless)
- 
-         # this translates to a numpy array and includes decompression, as
-         # necessary
-         nparray = self.named_tensor_to_nparray(tensor)
- 
-         # cache this tensor
-         self.tensor_db.cache_tensor({tensor_key: nparray})
- 
-         return nparray
- 
-     def send_task_results(self, tensor_dict, round_number, task_name):
-         """Send task results to the aggregator."""
-         named_tensors = [
-             self.nparray_to_named_tensor(k, v) for k, v in tensor_dict.items()
-         ]
- 
-         # for general tasks, there may be no notion of data size to send.
-         # But that raises the question how to properly aggregate results.
- 
-         data_size = -1
- 
-         if 'train' in task_name:
-             data_size = self.task_runner.get_train_data_size()
- 
-         if 'valid' in task_name:
-             data_size = self.task_runner.get_valid_data_size()
- 
-         self.logger.debug(f'{task_name} data size = {data_size}')
- 
-         for tensor in tensor_dict:
-             tensor_name, origin, fl_round, report, tags = tensor
- 
-             if report:
-                 self.logger.metric(
-                     f'Round {round_number}, collaborator {self.collaborator_name} '
-                     f'is sending metric for task {task_name}:'
-                     f' {tensor_name}\t{tensor_dict[tensor]:f}')
- 
-         self.client.send_local_task_results(
-             self.collaborator_name, round_number, task_name, data_size, named_tensors)
- 
-     def nparray_to_named_tensor(self, tensor_key, nparray):
-         """
-         Construct the NamedTensor Protobuf.
- 
-         Includes logic to create delta, compress tensors with the TensorCodec, etc.
-         """
-         # if we have an aggregated tensor, we can make a delta
-         tensor_name, origin, round_number, report, tags = tensor_key
-         if 'trained' in tags and self.delta_updates:
-             # Should get the pretrained model to create the delta. If training
-             # has happened,
-             # Model should already be stored in the TensorDB
-             model_nparray = self.tensor_db.get_tensor_from_cache(
-                 TensorKey(
-                     tensor_name,
-                     origin,
-                     round_number,
-                     report,
-                     ('model',)
-                 )
-             )
- 
-             # The original model will not be present for the optimizer on the
-             # first round.
-             if model_nparray is not None:
-                 delta_tensor_key, delta_nparray = self.tensor_codec.generate_delta(
-                     tensor_key,
-                     nparray,
-                     model_nparray
-                 )
-                 delta_comp_tensor_key, delta_comp_nparray, metadata = self.tensor_codec.compress(
-                     delta_tensor_key,
-                     delta_nparray
-                 )
- 
-                 named_tensor = utils.construct_named_tensor(
-                     delta_comp_tensor_key,
-                     delta_comp_nparray,
-                     metadata,
-                     lossless=False
-                 )
-                 return named_tensor
- 
-         # Assume every other tensor requires lossless compression
-         compressed_tensor_key, compressed_nparray, metadata = self.tensor_codec.compress(
-             tensor_key,
-             nparray,
-             require_lossless=True
-         )
-         named_tensor = utils.construct_named_tensor(
-             compressed_tensor_key,
-             compressed_nparray,
-             metadata,
-             lossless=True
-         )
- 
-         return named_tensor
- 
-     def named_tensor_to_nparray(self, named_tensor):
-         """Convert named tensor to a numpy array."""
-         # do the stuff we do now for decompression and frombuffer and stuff
-         # This should probably be moved back to protoutils
-         raw_bytes = named_tensor.data_bytes
-         metadata = [{'int_to_float': proto.int_to_float,
-                      'int_list': proto.int_list,
-                      'bool_list': proto.bool_list
-                      } for proto in named_tensor.transformer_metadata]
-         # The tensor has already been transfered to collaborator, so
-         # the newly constructed tensor should have the collaborator origin
-         tensor_key = TensorKey(
-             named_tensor.name,
-             self.collaborator_name,
-             named_tensor.round_number,
-             named_tensor.report,
-             tuple(named_tensor.tags)
-         )
-         tensor_name, origin, round_number, report, tags = tensor_key
-         if 'compressed' in tags:
-             decompressed_tensor_key, decompressed_nparray = self.tensor_codec.decompress(
-                 tensor_key,
-                 data=raw_bytes,
-                 transformer_metadata=metadata,
-                 require_lossless=True
-             )
-         elif 'lossy_compressed' in tags:
-             decompressed_tensor_key, decompressed_nparray = self.tensor_codec.decompress(
-                 tensor_key,
-                 data=raw_bytes,
-                 transformer_metadata=metadata
-             )
-         else:
-             # There could be a case where the compression pipeline is bypassed
-             # entirely
-             self.logger.warning('Bypassing tensor codec...')
-             decompressed_tensor_key = tensor_key
-             decompressed_nparray = raw_bytes
- 
-         self.tensor_db.cache_tensor(
-             {decompressed_tensor_key: decompressed_nparray}
-         )
- 
-         return decompressed_nparray
--- 0 ----
diff -crB --new-file ./openfl/openfl/component/collaborator/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/collaborator/__init__.py
*** ./openfl/openfl/component/collaborator/__init__.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/collaborator/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,10 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Collaborator package."""
- 
- from .collaborator import Collaborator
- 
- __all__ = [
-     'Collaborator',
- ]
--- 0 ----
diff -crB --new-file ./openfl/openfl/component/director/director.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/director/director.py
*** ./openfl/openfl/component/director/director.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/director/director.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,321 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Director module."""
- 
- import asyncio
- import logging
- import time
- from collections import defaultdict
- from pathlib import Path
- from typing import Iterable
- from typing import List
- from typing import Union
- 
- from .experiment import Experiment
- from .experiment import ExperimentsRegistry
- from .experiment import Status
- 
- logger = logging.getLogger(__name__)
- 
- ENVOY_HEALTH_CHECK_PERIOD = 60  # in seconds
- 
- 
- class Director:
-     """Director class."""
- 
-     def __init__(
-             self, *,
-             tls: bool = True,
-             root_certificate: Union[Path, str] = None,
-             private_key: Union[Path, str] = None,
-             certificate: Union[Path, str] = None,
-             sample_shape: list = None,
-             target_shape: list = None,
-             settings: dict = None
-     ) -> None:
-         """Initialize a director object."""
-         self.sample_shape, self.target_shape = sample_shape, target_shape
-         self._shard_registry = {}
-         self.tls = tls
-         self.root_certificate = root_certificate
-         self.private_key = private_key
-         self.certificate = certificate
-         self.experiments_registry = ExperimentsRegistry()
-         self.settings = settings or {}
-         self.col_exp_queues = defaultdict(asyncio.Queue)
-         self.col_exp = {}
- 
-     def acknowledge_shard(self, shard_info: dict) -> bool:
-         """Save shard info to shard registry if it's acceptable."""
-         is_accepted = False
-         if (self.sample_shape != shard_info['sample_shape']
-                 or self.target_shape != shard_info['target_shape']):
-             logger.info('Request was not accepted')
-             return is_accepted
-         logger.info('Request was accepted')
-         hc_period = self.settings.get('envoy_health_check_period', ENVOY_HEALTH_CHECK_PERIOD)
-         self._shard_registry[shard_info['node_info']['name']] = {
-             'shard_info': shard_info,
-             'is_online': True,
-             'is_experiment_running': False,
-             'valid_duration': 2 * hc_period,
-             'last_updated': time.time(),
-         }
-         is_accepted = True
-         return is_accepted
- 
-     async def set_new_experiment(
-             self, *,
-             experiment_name: str,
-             sender_name: str,
-             tensor_dict: dict,
-             collaborator_names: Iterable[str],
-             experiment_archive_path: Path,
-     ) -> bool:
-         """Set new experiment."""
-         experiment = Experiment(
-             name=experiment_name,
-             archive_path=experiment_archive_path,
-             collaborators=list(collaborator_names),
-             users=[sender_name],
-             sender=sender_name,
-             init_tensor_dict=tensor_dict,
-         )
-         self.experiments_registry.add(experiment)
-         return True
- 
-     def get_trained_model(self, experiment_name: str, caller: str, model_type: str):
-         """Get trained model."""
-         if (experiment_name not in self.experiments_registry
-                 or caller not in self.experiments_registry[experiment_name].users):
-             logger.error('No experiment data in the stash')
-             return None
- 
-         aggregator = self.experiments_registry[experiment_name].aggregator
- 
-         if aggregator.last_tensor_dict is None:
-             logger.error('Aggregator have no aggregated model to return')
-             return None
- 
-         if model_type == 'best':
-             return aggregator.best_tensor_dict
-         elif model_type == 'last':
-             return aggregator.last_tensor_dict
-         else:
-             logger.error('Unknown model type required.')
-             return None
- 
-     def get_experiment_data(self, experiment_name: str) -> Path:
-         """Get experiment data."""
-         return self.experiments_registry[experiment_name].archive_path
- 
-     async def wait_experiment(self, envoy_name: str) -> str:
-         """Wait an experiment."""
-         self.col_exp[envoy_name] = None
-         queue = self.col_exp_queues[envoy_name]
-         experiment_name = await queue.get()
-         self.col_exp[envoy_name] = experiment_name
- 
-         return experiment_name
- 
-     def get_dataset_info(self):
-         """Get dataset info."""
-         return self.sample_shape, self.target_shape
- 
-     def get_registered_shards(self) -> list:  # Why is it here?
-         """Get registered shard infos."""
-         return [shard_status['shard_info'] for shard_status in self._shard_registry.values()]
- 
-     async def stream_metrics(self, experiment_name: str, caller: str):
-         """
-         Stream metrics from the aggregator.
- 
-         This method takes next metric dictionary from the aggregator's queue
-         and returns it to the caller.
- 
-         Inputs:
-             experiment_name - string id for experiment
-             caller - string id for experiment owner
- 
-         Returns:
-             metric_dict - {'metric_origin','task_name','metric_name','metric_value','round'}
-                 if the queue is not empty
-             None - f queue is empty but the experiment is still running
- 
-         Raises:
-             StopIteration - if the experiment is finished and there is no more metrics to report
-         """
-         if (experiment_name not in self.experiments_registry
-                 or caller not in self.experiments_registry[experiment_name].users):
-             raise Exception(
-                 f'No experiment name "{experiment_name}" in experiments list, or caller "{caller}"'
-                 f' does not have access to this experiment'
-             )
- 
-         while not self.experiments_registry[experiment_name].aggregator:
-             await asyncio.sleep(1)
-         aggregator = self.experiments_registry[experiment_name].aggregator
- 
-         while True:
-             if not aggregator.metric_queue.empty():
-                 yield aggregator.metric_queue.get()
-                 continue
- 
-             if aggregator.all_quit_jobs_sent() and aggregator.metric_queue.empty():
-                 return
- 
-             yield None
- 
-     def remove_experiment_data(self, experiment_name: str, caller: str):
-         """Remove experiment data from stash."""
-         if (experiment_name in self.experiments_registry
-                 and caller in self.experiments_registry[experiment_name].users):
-             self.experiments_registry.remove(experiment_name)
- 
-     def set_experiment_failed(self, *, experiment_name: str, collaborator_name: str):
-         """Set experiment failed."""
-         if experiment_name in self.experiments_registry:
-             aggregator = self.experiments_registry[experiment_name].aggregator
-             aggregator.stop(failed_collaborator=collaborator_name)
- 
-     def update_envoy_status(
-             self, *,
-             envoy_name: str,
-             is_experiment_running: bool,
-             cuda_devices_status: list = None,
-     ) -> int:
-         """Accept health check from envoy."""
-         shard_info = self._shard_registry.get(envoy_name)
-         if not shard_info:
-             raise Exception(f'Unknown shard {envoy_name}')
- 
-         hc_period = self.settings.get('envoy_health_check_period', ENVOY_HEALTH_CHECK_PERIOD)
-         shard_info['is_online']: True
-         shard_info['is_experiment_running'] = is_experiment_running
-         shard_info['valid_duration'] = 2 * hc_period
-         shard_info['last_updated'] = time.time()
- 
-         if cuda_devices_status is not None:
-             for i in range(len(cuda_devices_status)):
-                 shard_info['shard_info']['node_info']['cuda_devices'][i] = cuda_devices_status[i]
- 
-         return hc_period
- 
-     def get_envoys(self) -> list:
-         """Get a status information about envoys."""
-         logger.info(f'Shard registry: {self._shard_registry}')
-         for envoy_info in self._shard_registry.values():
-             envoy_info['is_online'] = (
-                 time.time() < envoy_info.get('last_updated', 0)
-                 + envoy_info.get('valid_duration', 0)
-             )
-             envoy_name = envoy_info['shard_info']['node_info']['name']
-             envoy_info['experiment_name'] = self.col_exp[envoy_name]
- 
-         return self._shard_registry.values()
- 
-     def get_experiments_list(self, caller: str) -> list:
-         """Get experiments list for specific user."""
-         experiments = self.experiments_registry.get_user_experiments(caller)
-         result = []
-         for exp in experiments:
-             exp_data = {
-                 'name': exp.name,
-                 'status': exp.status,
-                 'collaborators_amount': len(exp.collaborators),
-             }
-             progress = _get_experiment_progress(exp)
-             if progress is not None:
-                 exp_data['progress'] = progress
-             if exp.aggregator:
-                 tasks_amount = len({
-                     task['function']
-                     for task in exp.aggregator.assigner.tasks.values()
-                 })
-                 exp_data['tasks_amount'] = tasks_amount
-             result.append(exp_data)
- 
-         return result
- 
-     def get_experiment_description(self, caller: str, name: str) -> dict:
-         """Get a experiment information by name for specific user."""
-         exp = self.experiments_registry.get(name)
-         if not exp or caller not in exp.users:
-             return {}
-         progress = _get_experiment_progress(exp)
-         model_statuses = _get_model_download_statuses(exp)
-         tasks = _get_experiment_tasks(exp)
-         collaborators = _get_experiment_collaborators(exp)
-         result = {
-             'name': name,
-             'status': exp.status,
-             'current_round': exp.aggregator.round_number,
-             'total_rounds': exp.aggregator.rounds_to_train,
-             'download_statuses': {
-                 'models': model_statuses,
-                 'logs': [{
-                     'name': 'aggregator',
-                     'status': 'ready'
-                 }],
-             },
-             'collaborators': collaborators,
-             'tasks': tasks,
-             'progress': progress
-         }
-         return result
- 
-     async def start_experiment_execution_loop(self):
-         """Run task to monitor and run experiments."""
-         while True:
-             async with self.experiments_registry.get_next_experiment() as experiment:
-                 loop = asyncio.get_event_loop()
-                 run_aggregator_future = loop.create_task(experiment.start(
-                     root_certificate=self.root_certificate,
-                     certificate=self.certificate,
-                     private_key=self.private_key,
-                     tls=self.tls,
-                 ))
-                 for col_name in experiment.collaborators:
-                     queue = self.col_exp_queues[col_name]
-                     await queue.put(experiment.name)
-                 await run_aggregator_future
- 
- 
- def _get_model_download_statuses(experiment) -> List[dict]:
-     best_model_status = 'ready' if experiment.aggregator.best_tensor_dict else 'pending'
-     last_model_status = 'ready' if experiment.aggregator.last_tensor_dict else 'pending'
-     model_statuses = [{
-         'name': 'best',
-         'status': best_model_status,
-     }, {
-         'name': 'last',
-         'status': last_model_status,
-     }, {
-         'name': 'init',
-         'status': 'ready'
-     }]
-     return model_statuses
- 
- 
- def _get_experiment_progress(experiment) -> Union[float, None]:
-     if experiment.status == Status.IN_PROGRESS:
-         return experiment.aggregator.round_number / experiment.aggregator.rounds_to_train
- 
- 
- def _get_experiment_tasks(experiment) -> List[dict]:
-     return [{
-         'name': task['function'],
-         'description': 'Task description Mock',
-     } for task in experiment.aggregator.assigner.tasks.values()]
- 
- 
- def _get_experiment_collaborators(experiment) -> List[dict]:
-     return [{
-         'name': name,
-         'status': 'pending_mock',
-         'progress': 0.0,
-         'round': 0,
-         'current_task': 'Current Task Mock',
-         'next_task': 'Next Task Mock'
-     } for name in experiment.aggregator.authorized_cols]
--- 0 ----
diff -crB --new-file ./openfl/openfl/component/director/experiment.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/director/experiment.py
*** ./openfl/openfl/component/director/experiment.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/director/experiment.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,207 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Experiment module."""
- 
- import asyncio
- import logging
- from contextlib import asynccontextmanager
- from pathlib import Path
- from typing import Iterable
- from typing import List
- from typing import Union
- 
- from openfl.federated import Plan
- from openfl.transport import AggregatorGRPCServer
- from openfl.utilities.workspace import ExperimentWorkspace
- 
- logger = logging.getLogger(__name__)
- 
- 
- class Status:
-     """Experiment's statuses."""
- 
-     PENDING = 'pending'
-     FINISHED = 'finished'
-     IN_PROGRESS = 'in_progress'
-     FAILED = 'failed'
- 
- 
- class Experiment:
-     """Experiment class."""
- 
-     def __init__(
-             self, *,
-             name: str,
-             archive_path: Union[Path, str],
-             collaborators: List[str],
-             sender: str,
-             init_tensor_dict: dict,
-             plan_path: Union[Path, str] = 'plan/plan.yaml',
-             users: Iterable[str] = None,
-     ) -> None:
-         """Initialize an experiment object."""
-         self.name = name
-         if isinstance(archive_path, str):
-             archive_path = Path(archive_path)
-         self.archive_path = archive_path
-         self.collaborators = collaborators
-         self.sender = sender
-         self.init_tensor_dict = init_tensor_dict
-         if isinstance(plan_path, str):
-             plan_path = Path(plan_path)
-         self.plan_path = plan_path
-         self.users = set() if users is None else set(users)
-         self.status = Status.PENDING
-         self.aggregator = None
- 
-     async def start(
-             self, *,
-             tls: bool = True,
-             root_certificate: Union[Path, str] = None,
-             private_key: Union[Path, str] = None,
-             certificate: Union[Path, str] = None,
-     ):
-         """Run experiment."""
-         self.status = Status.IN_PROGRESS
-         try:
-             logger.info(f'New experiment {self.name} for '
-                         f'collaborators {self.collaborators}')
- 
-             with ExperimentWorkspace(self.name, self.archive_path):
-                 aggregator_grpc_server = self._create_aggregator_grpc_server(
-                     tls=tls,
-                     root_certificate=root_certificate,
-                     private_key=private_key,
-                     certificate=certificate,
-                 )
-                 self.aggregator = aggregator_grpc_server.aggregator
-                 await self._run_aggregator_grpc_server(
-                     aggregator_grpc_server=aggregator_grpc_server,
-                 )
-             self.status = Status.FINISHED
-             logger.info(f'Experiment "{self.name}" was finished successfully.')
-         except Exception as e:
-             self.status = Status.FAILED
-             logger.exception(f'Experiment "{self.name}" was failed with error: {e}.')
- 
-     def _create_aggregator_grpc_server(
-             self, *,
-             tls: bool = True,
-             root_certificate: Union[Path, str] = None,
-             private_key: Union[Path, str] = None,
-             certificate: Union[Path, str] = None,
-     ) -> AggregatorGRPCServer:
-         plan = Plan.parse(plan_config_path=Path(self.plan_path))
-         plan.authorized_cols = list(self.collaborators)
- 
-         logger.info('🧿 Starting the Aggregator Service.')
-         aggregator_grpc_server = plan.interactive_api_get_server(
-             tensor_dict=self.init_tensor_dict,
-             root_certificate=root_certificate,
-             certificate=certificate,
-             private_key=private_key,
-             tls=tls,
-         )
-         return aggregator_grpc_server
- 
-     @staticmethod
-     async def _run_aggregator_grpc_server(aggregator_grpc_server: AggregatorGRPCServer) -> None:
-         """Run aggregator."""
-         logger.info('🧿 Starting the Aggregator Service.')
-         grpc_server = aggregator_grpc_server.get_server()
-         grpc_server.start()
-         logger.info('Starting Aggregator gRPC Server')
- 
-         try:
-             while not aggregator_grpc_server.aggregator.all_quit_jobs_sent():
-                 # Awaiting quit job sent to collaborators
-                 await asyncio.sleep(10)
-         except KeyboardInterrupt:
-             pass
-         finally:
-             grpc_server.stop(0)
-             # Temporary solution to free RAM used by TensorDB
-             aggregator_grpc_server.aggregator.tensor_db.clean_up(0)
- 
- 
- class ExperimentsRegistry:
-     """ExperimentsList class."""
- 
-     def __init__(self) -> None:
-         """Initialize an experiments list object."""
-         self.__active_experiment_name = None
-         self.__pending_experiments = []
-         self.__archived_experiments = []
-         self.__dict = {}
- 
-     @property
-     def active_experiment(self) -> Union[Experiment, None]:
-         """Get active experiment."""
-         if self.__active_experiment_name is None:
-             return None
-         return self.__dict[self.__active_experiment_name]
- 
-     @property
-     def pending_experiments(self) -> List[str]:
-         """Get queue of not started experiments."""
-         return self.__pending_experiments
- 
-     def add(self, experiment: Experiment) -> None:
-         """Add experiment to queue of not started experiments."""
-         self.__dict[experiment.name] = experiment
-         self.__pending_experiments.append(experiment.name)
- 
-     def remove(self, name: str) -> None:
-         """Remove experiment from everywhere."""
-         if self.__active_experiment_name == name:
-             self.__active_experiment_name = None
-         if name in self.__pending_experiments:
-             self.__pending_experiments.remove(name)
-         if name in self.__archived_experiments:
-             self.__archived_experiments.remove(name)
-         if name in self.__dict:
-             del self.__dict[name]
- 
-     def __getitem__(self, key: str) -> Experiment:
-         """Get experiment by name."""
-         return self.__dict[key]
- 
-     def get(self, key: str, default=None) -> Experiment:
-         """Get experiment by name."""
-         return self.__dict.get(key, default)
- 
-     def get_user_experiments(self, user: str) -> List[Experiment]:
-         """Get list of experiments for specific user."""
-         return [
-             exp
-             for exp in self.__dict.values()
-             if user in exp.users
-         ]
- 
-     def __contains__(self, key: str) -> bool:
-         """Check if experiment exists."""
-         return key in self.__dict
- 
-     def finish_active(self) -> None:
-         """Finish active experiment."""
-         self.__archived_experiments.insert(0, self.__active_experiment_name)
-         self.__active_experiment_name = None
- 
-     @asynccontextmanager
-     async def get_next_experiment(self):
-         """Context manager.
- 
-         On enter get experiment from pending_experiments.
-         On exit put finished experiment to archive_experiments.
-         """
-         while True:
-             if self.active_experiment is None and self.pending_experiments:
-                 break
-             await asyncio.sleep(10)
- 
-         try:
-             self.__active_experiment_name = self.pending_experiments.pop(0)
-             yield self.active_experiment
-         finally:
-             self.finish_active()
--- 0 ----
diff -crB --new-file ./openfl/openfl/component/director/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/director/__init__.py
*** ./openfl/openfl/component/director/__init__.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/director/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,11 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Director package."""
- 
- from .director import Director
- 
- 
- __all__ = [
-     'Director',
- ]
--- 0 ----
diff -crB --new-file ./openfl/openfl/component/envoy/envoy.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/envoy/envoy.py
*** ./openfl/openfl/component/envoy/envoy.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/envoy/envoy.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,182 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Envoy module."""
- 
- import logging
- import time
- import traceback
- import uuid
- from concurrent.futures import ThreadPoolExecutor
- from pathlib import Path
- from typing import Optional
- from typing import Type
- from typing import Union
- 
- from click import echo
- 
- from openfl.federated import Plan
- from openfl.interface.interactive_api.shard_descriptor import ShardDescriptor
- from openfl.plugins.processing_units_monitor.cuda_device_monitor import CUDADeviceMonitor
- from openfl.transport.grpc.director_client import ShardDirectorClient
- from openfl.utilities.workspace import ExperimentWorkspace
- 
- logger = logging.getLogger(__name__)
- 
- DEFAULT_RETRY_TIMEOUT_IN_SECONDS = 5
- 
- 
- class Envoy:
-     """Envoy class."""
- 
-     def __init__(
-             self, *,
-             shard_name: str,
-             director_host: str,
-             director_port: int,
-             shard_descriptor: Type[ShardDescriptor],
-             root_certificate: Optional[Union[Path, str]] = None,
-             private_key: Optional[Union[Path, str]] = None,
-             certificate: Optional[Union[Path, str]] = None,
-             tls: bool = True,
-             cuda_devices: Union[tuple, list] = (),
-             cuda_device_monitor: Optional[Type[CUDADeviceMonitor]] = None,
-     ) -> None:
-         """Initialize a envoy object."""
-         self.name = shard_name
-         self.root_certificate = Path(
-             root_certificate).absolute() if root_certificate is not None else None
-         self.private_key = Path(private_key).absolute() if root_certificate is not None else None
-         self.certificate = Path(certificate).absolute() if root_certificate is not None else None
-         self.director_client = ShardDirectorClient(
-             director_host=director_host,
-             director_port=director_port,
-             shard_name=shard_name,
-             tls=tls,
-             root_certificate=root_certificate,
-             private_key=private_key,
-             certificate=certificate
-         )
- 
-         self.shard_descriptor = shard_descriptor
-         self.cuda_devices = tuple(cuda_devices)
- 
-         # Optional plugins
-         self.cuda_device_monitor = cuda_device_monitor
- 
-         self.executor = ThreadPoolExecutor()
-         self.running_experiments = {}
-         self.is_experiment_running = False
-         self._health_check_future = None
- 
-     def run(self):
-         """Run of the envoy working cycle."""
-         while True:
-             try:
-                 # Workspace import should not be done by gRPC client!
-                 experiment_name = self.director_client.wait_experiment()
-                 data_stream = self.director_client.get_experiment_data(experiment_name)
-             except Exception as exc:
-                 logger.exception(f'Failed to get experiment: {exc}')
-                 time.sleep(DEFAULT_RETRY_TIMEOUT_IN_SECONDS)
-                 continue
-             data_file_path = self._save_data_stream_to_file(data_stream)
-             self.is_experiment_running = True
-             try:
-                 with ExperimentWorkspace(
-                         self.name + '_' + experiment_name,
-                         data_file_path,
-                         is_install_requirements=True
-                 ):
-                     self._run_collaborator()
-             except Exception as exc:
-                 logger.exception(f'Collaborator failed with error: {exc}:')
-                 self.director_client.set_experiment_failed(
-                     experiment_name,
-                     error_code=1,
-                     error_description=traceback.format_exc()
-                 )
-             finally:
-                 self.is_experiment_running = False
- 
-     @staticmethod
-     def _save_data_stream_to_file(data_stream):
-         data_file_path = Path(str(uuid.uuid4())).absolute()
-         with open(data_file_path, 'wb') as data_file:
-             for response in data_stream:
-                 if response.size == len(response.npbytes):
-                     data_file.write(response.npbytes)
-                 else:
-                     raise Exception('Broken archive')
-         return data_file_path
- 
-     def send_health_check(self):
-         """Send health check to the director."""
-         logger.info('The health check sender is started.')
-         while True:
-             cuda_devices_info = self._get_cuda_device_info()
-             timeout = self.director_client.send_health_check(
-                 envoy_name=self.name,
-                 is_experiment_running=self.is_experiment_running,
-                 cuda_devices_info=cuda_devices_info,
-             )
-             time.sleep(timeout)
- 
-     def _get_cuda_device_info(self):
-         cuda_devices_info = None
-         try:
-             if self.cuda_device_monitor is not None:
-                 cuda_devices_info = []
-                 cuda_driver_version = self.cuda_device_monitor.get_driver_version()
-                 cuda_version = self.cuda_device_monitor.get_cuda_version()
-                 for device_id in self.cuda_devices:
-                     memory_total = self.cuda_device_monitor.get_device_memory_total(device_id)
-                     memory_utilized = self.cuda_device_monitor.get_device_memory_utilized(
-                         device_id
-                     )
-                     device_utilization = self.cuda_device_monitor.get_device_utilization(device_id)
-                     device_name = self.cuda_device_monitor.get_device_name(device_id)
-                     cuda_devices_info.append({
-                         'index': device_id,
-                         'memory_total': memory_total,
-                         'memory_utilized': memory_utilized,
-                         'device_utilization': device_utilization,
-                         'cuda_driver_version': cuda_driver_version,
-                         'cuda_version': cuda_version,
-                         'name': device_name,
-                     })
-         except Exception as exc:
-             logger.exception(f'Failed to get cuda device info: {exc}. '
-                              f'Check your cuda device monitor plugin.')
-         return cuda_devices_info
- 
-     def _run_collaborator(self, plan='plan/plan.yaml'):
-         """Run the collaborator for the experiment running."""
-         plan = Plan.parse(plan_config_path=Path(plan))
- 
-         # TODO: Need to restructure data loader config file loader
-         echo(f'Data = {plan.cols_data_paths}')
-         logger.info('🧿 Starting a Collaborator Service.')
- 
-         col = plan.get_collaborator(self.name, self.root_certificate, self.private_key,
-                                     self.certificate, shard_descriptor=self.shard_descriptor)
-         col.set_available_devices(cuda=self.cuda_devices)
-         col.run()
- 
-     def start(self):
-         """Start the envoy."""
-         try:
-             is_accepted = self.director_client.report_shard_info(
-                 shard_descriptor=self.shard_descriptor,
-                 cuda_devices=self.cuda_devices)
-         except Exception as exc:
-             logger.exception(f'Failed to report shard info: {exc}')
-         else:
-             if is_accepted:
-                 # Shard accepted for participation in the federation
-                 logger.info('Shard accepted')
-                 self._health_check_future = self.executor.submit(self.send_health_check)
-                 self.run()
-             else:
-                 # Shut down
-                 logger.error('Report shard info was not accepted')
--- 0 ----
diff -crB --new-file ./openfl/openfl/component/envoy/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/envoy/__init__.py
*** ./openfl/openfl/component/envoy/__init__.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/envoy/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Envoy package."""
--- 0 ----
diff -crB --new-file ./openfl/openfl/component/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/__init__.py
*** ./openfl/openfl/component/__init__.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,18 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """openfl.component package."""
- 
- from .aggregator import Aggregator
- from .assigner import Assigner
- from .assigner import RandomGroupedAssigner
- from .assigner import StaticGroupedAssigner
- from .collaborator import Collaborator
- 
- __all__ = [
-     'Assigner',
-     'RandomGroupedAssigner',
-     'StaticGroupedAssigner',
-     'Aggregator',
-     'Collaborator'
- ]
--- 0 ----
diff -crB --new-file ./openfl/openfl/cryptography/ca.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/cryptography/ca.py
*** ./openfl/openfl/cryptography/ca.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/cryptography/ca.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,129 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Cryptography CA utilities."""
- 
- import datetime
- import uuid
- 
- from cryptography import x509
- from cryptography.hazmat.backends import default_backend
- from cryptography.hazmat.primitives import hashes
- from cryptography.hazmat.primitives.asymmetric import rsa
- from cryptography.x509.extensions import ExtensionNotFound
- from cryptography.x509.oid import ExtensionOID
- from cryptography.x509.oid import NameOID
- 
- 
- def generate_root_cert(days_to_expiration=365):
-     """Generate_root_certificate."""
-     now = datetime.datetime.utcnow()
-     expiration_delta = days_to_expiration * datetime.timedelta(1, 0, 0)
- 
-     # Generate private key
-     root_private_key = rsa.generate_private_key(
-         public_exponent=65537,
-         key_size=3072,
-         backend=default_backend()
-     )
- 
-     # Generate public key
-     root_public_key = root_private_key.public_key()
-     builder = x509.CertificateBuilder()
-     subject = x509.Name([
-         x509.NameAttribute(NameOID.DOMAIN_COMPONENT, u'org'),
-         x509.NameAttribute(NameOID.DOMAIN_COMPONENT, u'simple'),
-         x509.NameAttribute(NameOID.COMMON_NAME, u'Simple Root CA'),
-         x509.NameAttribute(NameOID.ORGANIZATION_NAME, u'Simple Inc'),
-         x509.NameAttribute(NameOID.ORGANIZATIONAL_UNIT_NAME, u'Simple Root CA'),
-     ])
-     issuer = subject
-     builder = builder.subject_name(subject)
-     builder = builder.issuer_name(issuer)
- 
-     builder = builder.not_valid_before(now)
-     builder = builder.not_valid_after(now + expiration_delta)
-     builder = builder.serial_number(int(uuid.uuid4()))
-     builder = builder.public_key(root_public_key)
-     builder = builder.add_extension(
-         x509.BasicConstraints(ca=True, path_length=None), critical=True,
-     )
- 
-     # Sign the CSR
-     certificate = builder.sign(
-         private_key=root_private_key, algorithm=hashes.SHA384(),
-         backend=default_backend()
-     )
- 
-     return root_private_key, certificate
- 
- 
- def generate_signing_csr():
-     """Generate signing CSR."""
-     # Generate private key
-     signing_private_key = rsa.generate_private_key(
-         public_exponent=65537,
-         key_size=3072,
-         backend=default_backend()
-     )
- 
-     builder = x509.CertificateSigningRequestBuilder()
-     subject = x509.Name([
-         x509.NameAttribute(NameOID.DOMAIN_COMPONENT, u'org'),
-         x509.NameAttribute(NameOID.DOMAIN_COMPONENT, u'simple'),
-         x509.NameAttribute(NameOID.COMMON_NAME, u'Simple Signing CA'),
-         x509.NameAttribute(NameOID.ORGANIZATION_NAME, u'Simple Inc'),
-         x509.NameAttribute(NameOID.ORGANIZATIONAL_UNIT_NAME, u'Simple Signing CA'),
-     ])
-     builder = builder.subject_name(subject)
-     builder = builder.add_extension(
-         x509.BasicConstraints(ca=True, path_length=None), critical=True,
-     )
- 
-     # Sign the CSR
-     csr = builder.sign(
-         private_key=signing_private_key, algorithm=hashes.SHA384(),
-         backend=default_backend()
-     )
- 
-     return signing_private_key, csr
- 
- 
- def sign_certificate(csr, issuer_private_key, issuer_name, days_to_expiration=365, ca=False):
-     """
-     Sign the incoming CSR request.
- 
-     Args:
-         csr                : Certificate Signing Request object
-         issuer_private_key : Root CA private key if the request is for the signing
-                              CA; Signing CA private key otherwise
-         issuer_name        : x509 Name
-         days_to_expiration : int (365 days by default)
-         ca                 : Is this a certificate authority
-     """
-     now = datetime.datetime.utcnow()
-     expiration_delta = days_to_expiration * datetime.timedelta(1, 0, 0)
- 
-     builder = x509.CertificateBuilder()
-     builder = builder.subject_name(csr.subject)
-     builder = builder.issuer_name(issuer_name)
-     builder = builder.not_valid_before(now)
-     builder = builder.not_valid_after(now + expiration_delta)
-     builder = builder.serial_number(int(uuid.uuid4()))
-     builder = builder.public_key(csr.public_key())
-     builder = builder.add_extension(
-         x509.BasicConstraints(ca=ca, path_length=None), critical=True,
-     )
-     try:
-         builder = builder.add_extension(
-             csr.extensions.get_extension_for_oid(
-                 ExtensionOID.SUBJECT_ALTERNATIVE_NAME
-             ).value, critical=False
-         )
-     except ExtensionNotFound:
-         pass  # Might not have alternative name
- 
-     signed_cert = builder.sign(
-         private_key=issuer_private_key, algorithm=hashes.SHA384(), backend=default_backend()
-     )
-     return signed_cert
--- 0 ----
diff -crB --new-file ./openfl/openfl/cryptography/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/cryptography/__init__.py
*** ./openfl/openfl/cryptography/__init__.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/cryptography/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """openfl.cryptography package."""
--- 0 ----
diff -crB --new-file ./openfl/openfl/cryptography/io.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/cryptography/io.py
*** ./openfl/openfl/cryptography/io.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/cryptography/io.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,101 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Cryptography IO utilities."""
- 
- from hashlib import sha384
- 
- from cryptography import x509
- from cryptography.hazmat.primitives import serialization
- from cryptography.hazmat.primitives.asymmetric import rsa
- from cryptography.hazmat.primitives.serialization import load_pem_private_key
- 
- 
- def read_key(path):
-     """
-     Read private key.
- 
-     Args:
-         path : Path (pathlib)
- 
-     Returns:
-         private_key
-     """
-     with open(path, 'rb') as f:
-         pem_data = f.read()
- 
-     signing_key = load_pem_private_key(pem_data, password=None)
-     assert(isinstance(signing_key, rsa.RSAPrivateKey))
-     return signing_key
- 
- 
- def write_key(key, path):
-     """
-     Write private key.
- 
-     Args:
-         key  : RSA private key object
-         path : Path (pathlib)
- 
-     """
-     with open(path, 'wb') as f:
-         f.write(key.private_bytes(
-             encoding=serialization.Encoding.PEM,
-             format=serialization.PrivateFormat.TraditionalOpenSSL,
-             encryption_algorithm=serialization.NoEncryption()
-         ))
- 
- 
- def read_crt(path):
-     """
-     Read signed TLS certificate.
- 
-     Args:
-         path : Path (pathlib)
- 
-     Returns:
-         Cryptography TLS Certificate object
-     """
-     with open(path, 'rb') as f:
-         pem_data = f.read()
- 
-     certificate = x509.load_pem_x509_certificate(pem_data)
-     assert(isinstance(certificate, x509.Certificate))
-     return certificate
- 
- 
- def write_crt(certificate, path):
-     """
-     Write cryptography certificate / csr.
- 
-     Args:
-         certificate : cryptography csr / certificate object
-         path : Path (pathlib)
- 
-     Returns:
-         Cryptography TLS Certificate object
-     """
-     with open(path, 'wb') as f:
-         f.write(certificate.public_bytes(
-             encoding=serialization.Encoding.PEM,
-         ))
- 
- 
- def read_csr(path):
-     """
-     Read certificate signing request.
- 
-     Args:
-         path : Path (pathlib)
- 
-     Returns:
-         Cryptography CSR object
-     """
-     hasher = sha384()
-     with open(path, 'rb') as f:
-         pem_data = f.read()
-         hasher.update(pem_data)
- 
-     csr = x509.load_pem_x509_csr(pem_data)
-     assert(isinstance(csr, x509.CertificateSigningRequest))
-     return csr, hasher.hexdigest()
--- 0 ----
diff -crB --new-file ./openfl/openfl/cryptography/participant.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/cryptography/participant.py
*** ./openfl/openfl/cryptography/participant.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/cryptography/participant.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,68 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Cryptography participant utilities."""
- 
- from cryptography import x509
- from cryptography.hazmat.backends import default_backend
- from cryptography.hazmat.primitives import hashes
- from cryptography.hazmat.primitives.asymmetric import rsa
- from cryptography.x509.oid import NameOID
- 
- 
- def generate_csr(common_name, server=False):
-     """Issue certificate signing request for server and client."""
-     # Generate private key
-     private_key = rsa.generate_private_key(
-         public_exponent=65537,
-         key_size=3072,
-         backend=default_backend()
-     )
- 
-     builder = x509.CertificateSigningRequestBuilder()
-     subject = x509.Name([
-         x509.NameAttribute(NameOID.COMMON_NAME, common_name),
-     ])
-     builder = builder.subject_name(subject)
-     builder = builder.add_extension(
-         x509.BasicConstraints(ca=False, path_length=None), critical=True,
-     )
-     if server:
-         builder = builder.add_extension(
-             x509.ExtendedKeyUsage([x509.ExtendedKeyUsageOID.SERVER_AUTH]),
-             critical=True
-         )
- 
-     else:
-         builder = builder.add_extension(
-             x509.ExtendedKeyUsage([x509.ExtendedKeyUsageOID.CLIENT_AUTH]),
-             critical=True
-         )
- 
-     builder = builder.add_extension(
-         x509.KeyUsage(
-             digital_signature=True,
-             key_encipherment=True,
-             data_encipherment=False,
-             key_agreement=False,
-             content_commitment=False,
-             key_cert_sign=False,
-             crl_sign=False,
-             encipher_only=False,
-             decipher_only=False
-         ),
-         critical=True
-     )
- 
-     builder = builder.add_extension(
-         x509.SubjectAlternativeName([x509.DNSName(common_name)]),
-         critical=False
-     )
- 
-     # Sign the CSR
-     csr = builder.sign(
-         private_key=private_key, algorithm=hashes.SHA384(),
-         backend=default_backend()
-     )
- 
-     return private_key, csr
--- 0 ----
diff -crB --new-file ./openfl/openfl/databases/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/databases/__init__.py
*** ./openfl/openfl/databases/__init__.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/databases/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,10 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Databases package."""
- 
- from .tensor_db import TensorDB
- 
- __all__ = [
-     'TensorDB',
- ]
--- 0 ----
diff -crB --new-file ./openfl/openfl/databases/tensor_db.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/databases/tensor_db.py
*** ./openfl/openfl/databases/tensor_db.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/databases/tensor_db.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,179 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """TensorDB Module."""
- 
- from threading import Lock
- 
- import numpy as np
- import pandas as pd
- 
- from openfl.utilities import LocalTensor
- from openfl.utilities import TensorKey
- 
- 
- class TensorDB:
-     """
-     The TensorDB stores a tensor key and the data that it corresponds to.
- 
-     It is built on top of a pandas dataframe
-     for it's easy insertion, retreival and aggregation capabilities. Each
-     collaborator and aggregator has its own TensorDB.
-     """
- 
-     def __init__(self):
-         """Initialize."""
-         self.tensor_db = pd.DataFrame([], columns=[
-             'tensor_name', 'origin', 'round', 'report', 'tags', 'nparray'
-         ])
-         self.mutex = Lock()
- 
-     def __repr__(self):
-         """Representation of the object."""
-         with pd.option_context('display.max_rows', None):
-             content = self.tensor_db[['tensor_name', 'origin', 'round', 'report', 'tags']]
-             return f'TensorDB contents:\n{content}'
- 
-     def __str__(self):
-         """Printable string representation."""
-         return self.__repr__()
- 
-     def clean_up(self, remove_older_than=1):
-         """Remove old entries from database preventing the db from becoming too large and slow."""
-         if remove_older_than < 0:
-             # Getting a negative argument calls off cleaning
-             return
-         current_round = int(self.tensor_db['round'].max())
-         self.tensor_db = self.tensor_db[
-             self.tensor_db['round'] > current_round - remove_older_than
-         ].reset_index(drop=True)
- 
-     def cache_tensor(self, tensor_key_dict):
-         """Insert tensor into TensorDB (dataframe).
- 
-         Args:
-             tensor_key_dict: The Tensor Key
- 
-         Returns:
-             None
-         """
-         entries_to_add = []
-         with self.mutex:
-             for tensor_key, nparray in tensor_key_dict.items():
-                 tensor_name, origin, fl_round, report, tags = tensor_key
-                 entries_to_add.append(
-                     pd.DataFrame([
-                         [tensor_name, origin, fl_round, report, tags, nparray]
-                     ],
-                         columns=[
-                             'tensor_name',
-                             'origin',
-                             'round',
-                             'report',
-                             'tags',
-                             'nparray']
-                     )
-                 )
- 
-             self.tensor_db = pd.concat(
-                 [self.tensor_db, *entries_to_add], ignore_index=True
-             )
- 
-     def get_tensor_from_cache(self, tensor_key):
-         """
-         Perform a lookup of the tensor_key in the TensorDB.
- 
-         Returns the nparray if it is available
-         Otherwise, it returns 'None'
-         """
-         tensor_name, origin, fl_round, report, tags = tensor_key
- 
-         # TODO come up with easy way to ignore compression
-         df = self.tensor_db[(self.tensor_db['tensor_name'] == tensor_name)
-                             & (self.tensor_db['origin'] == origin)
-                             & (self.tensor_db['round'] == fl_round)
-                             & (self.tensor_db['report'] == report)
-                             & (self.tensor_db['tags'] == tags)]
- 
-         if len(df) == 0:
-             return None
-         return np.array(df['nparray'].iloc[0])
- 
-     def get_aggregated_tensor(self, tensor_key, collaborator_weight_dict,
-                               aggregation_function):
-         """
-         Determine whether all of the collaborator tensors are present for a given tensor key.
- 
-         Returns their weighted average.
- 
-         Args:
-             tensor_key: The tensor key to be resolved. If origin 'agg_uuid' is
-                         present, can be returned directly. Otherwise must
-                         compute weighted average of all collaborators
-             collaborator_weight_dict: List of collaborator names in federation
-                                       and their respective weights
-             aggregation_function: Call the underlying numpy aggregation
-                                    function. Default is just the weighted
-                                    average.
-         Returns:
-             weighted_nparray if all collaborator values are present
-             None if not all values are present
- 
-         """
-         if len(collaborator_weight_dict) != 0:
-             assert np.abs(1.0 - sum(collaborator_weight_dict.values())) < 0.01, (
-                 f'Collaborator weights do not sum to 1.0: {collaborator_weight_dict}'
-             )
- 
-         collaborator_names = collaborator_weight_dict.keys()
-         agg_tensor_dict = {}
- 
-         # Check if the aggregated tensor is already present in TensorDB
-         tensor_name, origin, fl_round, report, tags = tensor_key
- 
-         raw_df = self.tensor_db[(self.tensor_db['tensor_name'] == tensor_name)
-                                 & (self.tensor_db['origin'] == origin)
-                                 & (self.tensor_db['round'] == fl_round)
-                                 & (self.tensor_db['report'] == report)
-                                 & (self.tensor_db['tags'] == tags)]['nparray']
-         if len(raw_df) > 0:
-             return np.array(raw_df.iloc[0]), {}
- 
-         for col in collaborator_names:
-             if type(tags) == str:
-                 new_tags = tuple([tags] + [col])
-             else:
-                 new_tags = tuple(list(tags) + [col])
-             raw_df = self.tensor_db[
-                 (self.tensor_db['tensor_name'] == tensor_name)
-                 & (self.tensor_db['origin'] == origin)
-                 & (self.tensor_db['round'] == fl_round)
-                 & (self.tensor_db['report'] == report)
-                 & (self.tensor_db['tags'] == new_tags)]['nparray']
-             if len(raw_df) == 0:
-                 tk = TensorKey(tensor_name, origin, report, fl_round, new_tags)
-                 print(f'No results for collaborator {col}, TensorKey={tk}')
-                 return None
-             else:
-                 agg_tensor_dict[col] = raw_df.iloc[0]
- 
-         local_tensors = [LocalTensor(col_name=col_name,
-                                      tensor=agg_tensor_dict[col_name],
-                                      weight=collaborator_weight_dict[col_name])
-                          for col_name in collaborator_names]
- 
-         db_iterator = self._iterate()
-         agg_nparray = aggregation_function(local_tensors,
-                                            db_iterator,
-                                            tensor_name,
-                                            fl_round,
-                                            tags)
-         self.cache_tensor({tensor_key: agg_nparray})
- 
-         return np.array(agg_nparray)
- 
-     def _iterate(self, order_by='round', ascending=False):
-         columns = ['round', 'nparray', 'tensor_name', 'tags']
-         rows = self.tensor_db[columns].sort_values(by=order_by, ascending=ascending).iterrows()
-         for _, row in rows:
-             yield row
--- 0 ----
diff -crB --new-file ./openfl/openfl/federated/data/federated_data.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/data/federated_data.py
*** ./openfl/openfl/federated/data/federated_data.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/data/federated_data.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,114 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """FederatedDataset module."""
- 
- import numpy as np
- 
- from openfl.utilities.data_splitters import EqualNumPyDataSplitter
- from openfl.utilities.data_splitters import NumPyDataSplitter
- from .loader_pt import PyTorchDataLoader
- 
- 
- class FederatedDataSet(PyTorchDataLoader):
-     """
-     Data Loader for in memory Numpy data.
- 
-     Args:
-         X_train: np.array
-             Training Features
-         y_train: np.array
-             Training labels
-         X_val: np.array
-             Validation features
-         y_val: np.array
-             Validation labels
-         batch_size : int
-             The batch size for the data loader
-         num_classes : int
-             The number of classes the model will be trained on
-         **kwargs: Additional arguments to pass to the function
- 
-     """
- 
-     train_splitter: NumPyDataSplitter
-     valid_splitter: NumPyDataSplitter
- 
-     def __init__(self, X_train, y_train, X_valid, y_valid,
-                  batch_size=1, num_classes=None, train_splitter=None, valid_splitter=None):
-         """
-         Initialize.
- 
-         Args:
-             X_train: np.array
-                 Training Features
-             y_train: np.array
-                 Training labels
-             X_val: np.array
-                 Validation features
-             y_val: np.array
-                 Validation labels
-             batch_size : int
-                 The batch size for the data loader
-             num_classes : int
-                 The number of classes the model will be trained on
-             train_splitter: NumPyDataSplitter
-                 Data splitter for train dataset.
-             valid_splitter: NumPyDataSplitter
-                 Data splitter for validation dataset.
-             **kwargs: Additional arguments to pass to the function
- 
-         """
-         super().__init__(batch_size)
- 
-         self.X_train = X_train
-         self.y_train = y_train
-         self.X_valid = X_valid
-         self.y_valid = y_valid
- 
-         if num_classes is None:
-             num_classes = np.unique(self.y_train).shape[0]
-             print(f'Inferred {num_classes} classes from the provided labels...')
-         self.num_classes = num_classes
-         self.train_splitter = self._get_splitter_or_default(train_splitter)
-         self.valid_splitter = self._get_splitter_or_default(valid_splitter)
- 
-     @staticmethod
-     def _get_splitter_or_default(value):
-         if value is None:
-             return EqualNumPyDataSplitter()
-         if isinstance(value, NumPyDataSplitter):
-             return value
-         else:
-             raise NotImplementedError(f'Data splitter {value} is not supported')
- 
-     def split(self, num_collaborators):
-         """Create a Federated Dataset for each of the collaborators.
- 
-         Args:
-             num_collaborators: int
-                 Collaborators to split the dataset between
-             shuffle: boolean
-                 Should the dataset be randomized?
-             equally: boolean
-                 Should each collaborator get the same amount of data?
- 
-         Returns:
-             list[FederatedDataSets]
-                 A dataset slice for each collaborator
-         """
-         train_idx = self.train_splitter.split(self.y_train, num_collaborators)
-         valid_idx = self.valid_splitter.split(self.y_valid, num_collaborators)
- 
-         return [
-             FederatedDataSet(
-                 self.X_train[train_idx[i]],
-                 self.y_train[train_idx[i]],
-                 self.X_valid[valid_idx[i]],
-                 self.y_valid[valid_idx[i]],
-                 batch_size=self.batch_size,
-                 num_classes=self.num_classes,
-                 train_splitter=self.train_splitter,
-                 valid_splitter=self.valid_splitter
-             ) for i in range(num_collaborators)
-         ]
--- 0 ----
diff -crB --new-file ./openfl/openfl/federated/data/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/data/__init__.py
*** ./openfl/openfl/federated/data/__init__.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/data/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,27 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Data package."""
- 
- import pkgutil
- from warnings import catch_warnings
- from warnings import simplefilter
- 
- with catch_warnings():
-     simplefilter(action='ignore', category=FutureWarning)
-     if pkgutil.find_loader('tensorflow'):
-         # ignore deprecation warnings in command-line interface
-         import tensorflow  # NOQA
- 
- from .loader import DataLoader  # NOQA
- 
- if pkgutil.find_loader('tensorflow'):
-     from .loader_tf import TensorFlowDataLoader  # NOQA
-     from .loader_keras import KerasDataLoader  # NOQA
-     from .federated_data import FederatedDataSet  # NOQA
- 
- if pkgutil.find_loader('torch'):
-     from .loader_pt import PyTorchDataLoader  # NOQA
-     from .federated_data import FederatedDataSet  # NOQA
- if pkgutil.find_loader('torch') and pkgutil.find_loader('tensorflow'):
-     from .loader_fe import FastEstimatorDataLoader  # NOQA
--- 0 ----
diff -crB --new-file ./openfl/openfl/federated/data/loader_fe.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/data/loader_fe.py
*** ./openfl/openfl/federated/data/loader_fe.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/data/loader_fe.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,60 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """FastEsitmatorDataLoader module."""
- 
- from .loader import DataLoader
- 
- 
- class FastEstimatorDataLoader(DataLoader):
-     """Federation Data Loader for FastEstimator."""
- 
-     def __init__(self, pipeline, **kwargs):
-         """
-         Instantiate the data object.
- 
-         Args:
-             batch_size: Size of batches used for all data loaders
-             kwargs: consumes all un-used kwargs
- 
-         Returns:
-             None
-         """
-         self.pipeline = pipeline
- 
-         self.batch_size = pipeline.batch_size
-         self.X_train = None
-         self.y_train = None
-         self.X_valid = None
-         self.y_valid = None
- 
-         # Child classes should have init signature:
-         # (self, batch_size, **kwargs), should call this __init__ and then
-         # define self.X_train, self.y_train, self.X_valid, and self.y_valid
- 
-     def get_train_data_size(self):
-         """
-         Get total number of training samples.
- 
-         Returns:
-             int: number of training samples
-         """
-         return len(self.pipeline.data['train'])
- 
-     def get_valid_data_size(self):
-         """
-         Get total number of validation samples.
- 
-         Returns:
-             int: number of validation samples
-         """
-         return len(self.pipeline.data['test'])
- 
-     def get_feature_shape(self):
-         """
-         Get feature shape.
- 
-         Returns:
-             tuple: shape of the input data.
-         """
-         return self.pipeline.data['train']['x'].shape[1:]
--- 0 ----
diff -crB --new-file ./openfl/openfl/federated/data/loader_keras.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/data/loader_keras.py
*** ./openfl/openfl/federated/data/loader_keras.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/data/loader_keras.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,123 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """KerasDataLoader module."""
- 
- import numpy as np
- 
- from .loader import DataLoader
- 
- 
- class KerasDataLoader(DataLoader):
-     """Federation Data Loader for TensorFlow Models."""
- 
-     def __init__(self, batch_size, **kwargs):
-         """
-         Instantiate the data object.
- 
-         Args:
-             batch_size: Size of batches used for all data loaders
-             kwargs: consumes all un-used kwargs
- 
-         Returns:
-             None
-         """
-         self.batch_size = batch_size
-         self.X_train = None
-         self.y_train = None
-         self.X_valid = None
-         self.y_valid = None
- 
-         # Child classes should have init signature:
-         # (self, batch_size, **kwargs), should call this __init__ and then
-         # define self.X_train, self.y_train, self.X_valid, and self.y_valid
- 
-     def get_feature_shape(self):
-         """Get the shape of an example feature array.
- 
-         Returns:
-             tuple: shape of an example feature array
-         """
-         return self.X_train[0].shape
- 
-     def get_train_loader(self, batch_size=None, num_batches=None):
-         """
-         Get training data loader.
- 
-         Returns
-         -------
-         loader object
-         """
-         return self._get_batch_generator(X=self.X_train, y=self.y_train, batch_size=batch_size,
-                                          num_batches=num_batches)
- 
-     def get_valid_loader(self, batch_size=None):
-         """
-         Get validation data loader.
- 
-         Returns:
-             loader object
-         """
-         return self._get_batch_generator(X=self.X_valid, y=self.y_valid, batch_size=batch_size)
- 
-     def get_train_data_size(self):
-         """
-         Get total number of training samples.
- 
-         Returns:
-             int: number of training samples
-         """
-         return self.X_train.shape[0]
- 
-     def get_valid_data_size(self):
-         """
-         Get total number of validation samples.
- 
-         Returns:
-             int: number of validation samples
-         """
-         return self.X_valid.shape[0]
- 
-     @staticmethod
-     def _batch_generator(X, y, idxs, batch_size, num_batches):
-         """
-         Generate batch of data.
- 
-         Args:
-             X: input data
-             y: label data
-             idxs: The index of the dataset
-             batch_size: The batch size for the data loader
-             num_batches: The number of batches
- 
-         Yields:
-             tuple: input data, label data
- 
-         """
-         for i in range(num_batches):
-             a = i * batch_size
-             b = a + batch_size
-             yield X[idxs[a:b]], y[idxs[a:b]]
- 
-     def _get_batch_generator(self, X, y, batch_size, num_batches=None):
-         """
-         Return the dataset generator.
- 
-         Args:
-             X: input data
-             y: label data
-             batch_size: The batch size for the data loader
- 
-         """
-         if batch_size is None:
-             batch_size = self.batch_size
- 
-         # shuffle data indices
-         idxs = np.random.permutation(np.arange(X.shape[0]))
- 
-         if num_batches is None:
-             # compute the number of batches
-             num_batches = int(np.ceil(X.shape[0] / batch_size))
- 
-         # build the generator and return it
-         return self._batch_generator(X, y, idxs, batch_size, num_batches)
--- 0 ----
diff -crB --new-file ./openfl/openfl/federated/data/loader_pt.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/data/loader_pt.py
*** ./openfl/openfl/federated/data/loader_pt.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/data/loader_pt.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,129 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """PyTorchDataLoader module."""
- 
- from math import ceil
- 
- import numpy as np
- 
- from .loader import DataLoader
- 
- 
- class PyTorchDataLoader(DataLoader):
-     """Federation Data Loader for TensorFlow Models."""
- 
-     def __init__(self, batch_size, random_seed=None, **kwargs):
-         """
-         Instantiate the data object.
- 
-         Args:
-             batch_size: Size of batches used for all data loaders
-             kwargs: consumes all un-used kwargs
- 
-         Returns:
-             None
-         """
-         self.batch_size = batch_size
-         self.X_train = None
-         self.y_train = None
-         self.X_valid = None
-         self.y_valid = None
-         self.random_seed = random_seed
- 
-         # Child classes should have init signature:
-         # (self, batch_size, **kwargs), should call this __init__ and then
-         # define self.X_train, self.y_train, self.X_valid, and self.y_valid
- 
-     def get_feature_shape(self):
-         """Get the shape of an example feature array.
- 
-         Returns:
-             tuple: shape of an example feature array
-         """
-         return self.X_train[0].shape
- 
-     def get_train_loader(self, batch_size=None, num_batches=None):
-         """
-         Get training data loader.
- 
-         Returns
-         -------
-         loader object
-         """
-         return self._get_batch_generator(
-             X=self.X_train, y=self.y_train, batch_size=batch_size, num_batches=num_batches)
- 
-     def get_valid_loader(self, batch_size=None):
-         """
-         Get validation data loader.
- 
-         Returns:
-             loader object
-         """
-         return self._get_batch_generator(X=self.X_valid, y=self.y_valid, batch_size=batch_size)
- 
-     def get_train_data_size(self):
-         """
-         Get total number of training samples.
- 
-         Returns:
-             int: number of training samples
-         """
-         return self.X_train.shape[0]
- 
-     def get_valid_data_size(self):
-         """
-         Get total number of validation samples.
- 
-         Returns:
-             int: number of validation samples
-         """
-         return self.X_valid.shape[0]
- 
-     @staticmethod
-     def _batch_generator(X, y, idxs, batch_size, num_batches):
-         """
-         Generate batch of data.
- 
-         Args:
-             X: input data
-             y: label data
-             idxs: The index of the dataset
-             batch_size: The batch size for the data loader
-             num_batches: The number of batches
- 
-         Yields:
-             tuple: input data, label data
- 
-         """
-         for i in range(num_batches):
-             a = i * batch_size
-             b = a + batch_size
-             yield X[idxs[a:b]], y[idxs[a:b]]
- 
-     def _get_batch_generator(self, X, y, batch_size, num_batches=None):
-         """
-         Return the dataset generator.
- 
-         Args:
-             X: input data
-             y: label data
-             batch_size: The batch size for the data loader
- 
-         """
-         if batch_size is None:
-             batch_size = self.batch_size
- 
-         # shuffle data indices
-         if self.random_seed is not None:
-             np.random.seed(self.random_seed)
- 
-         idxs = np.random.permutation(np.arange(X.shape[0]))
- 
-         # compute the number of batches
-         if num_batches is None:
-             num_batches = ceil(X.shape[0] / batch_size)
- 
-         # build the generator and return it
-         return self._batch_generator(X, y, idxs, batch_size, num_batches)
--- 0 ----
diff -crB --new-file ./openfl/openfl/federated/data/loader.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/data/loader.py
*** ./openfl/openfl/federated/data/loader.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/data/loader.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,72 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """DataLoader module."""
- 
- 
- class DataLoader:
-     """Federated Learning Data Loader Class."""
- 
-     def __init__(self, **kwargs):
-         """
-         Instantiate the data object.
- 
-         Returns:
-             None
-         """
-         pass
- 
-     def get_feature_shape(self):
-         """
-         Get the shape of an example feature array.
- 
-         Returns:
-             tuple: shape of an example feature array
-         """
-         raise NotImplementedError
- 
-     def get_train_loader(self, **kwargs):
-         """
-         Get training data loader.
- 
-         Returns:
-             loader object (class defined by inheritor)
-         """
-         raise NotImplementedError
- 
-     def get_valid_loader(self):
-         """
-         Get validation data loader.
- 
-         Returns:
-             loader object (class defined by inheritor)
-         """
-         raise NotImplementedError
- 
-     def get_infer_loader(self):
-         """
-         Get inferencing data loader.
- 
-         Returns
-         -------
-         loader object (class defined by inheritor)
-         """
-         return NotImplementedError
- 
-     def get_train_data_size(self):
-         """
-         Get total number of training samples.
- 
-         Returns:
-             int: number of training samples
-         """
-         raise NotImplementedError
- 
-     def get_valid_data_size(self):
-         """
-         Get total number of validation samples.
- 
-         Returns:
-             int: number of validation samples
-         """
-         raise NotImplementedError
--- 0 ----
diff -crB --new-file ./openfl/openfl/federated/data/loader_tf.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/data/loader_tf.py
*** ./openfl/openfl/federated/data/loader_tf.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/data/loader_tf.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,122 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """TensorflowDataLoader module."""
- 
- import numpy as np
- 
- from .loader import DataLoader
- 
- 
- class TensorFlowDataLoader(DataLoader):
-     """Federation Data Loader for TensorFlow Models."""
- 
-     def __init__(self, batch_size, **kwargs):
-         """
-         Instantiate the data object.
- 
-         Args:
-             batch_size: Size of batches used for all data loaders
-             kwargs: consumes all un-used kwargs
- 
-         Returns:
-             None
-         """
-         self.batch_size = batch_size
-         self.X_train = None
-         self.y_train = None
-         self.X_valid = None
-         self.y_valid = None
- 
-         # Child classes should have init signature:
-         # (self, batch_size, **kwargs), should call this __init__ and then
-         # define self.X_train, self.y_train, self.X_valid, and self.y_valid
- 
-     def get_feature_shape(self):
-         """
-         Get the shape of an example feature array.
- 
-         Returns:
-             tuple: shape of an example feature array
-         """
-         return self.X_train[0].shape
- 
-     def get_train_loader(self, batch_size=None):
-         """
-         Get training data loader.
- 
-         Returns
-         -------
-         loader object
-         """
-         return self._get_batch_generator(X=self.X_train, y=self.y_train, batch_size=batch_size)
- 
-     def get_valid_loader(self, batch_size=None):
-         """
-         Get validation data loader.
- 
-         Returns:
-             loader object
-         """
-         return self._get_batch_generator(X=self.X_valid, y=self.y_valid, batch_size=batch_size)
- 
-     def get_train_data_size(self):
-         """
-         Get total number of training samples.
- 
-         Returns:
-             int: number of training samples
-         """
-         return self.X_train.shape[0]
- 
-     def get_valid_data_size(self):
-         """
-         Get total number of validation samples.
- 
-         Returns:
-             int: number of validation samples
-         """
-         return self.X_valid.shape[0]
- 
-     @staticmethod
-     def _batch_generator(X, y, idxs, batch_size, num_batches):
-         """
-         Generate batch of data.
- 
-         Args:
-             X: input data
-             y: label data
-             idxs: The index of the dataset
-             batch_size: The batch size for the data loader
-             num_batches: The number of batches
- 
-         Yields:
-             tuple: input data, label data
- 
-         """
-         for i in range(num_batches):
-             a = i * batch_size
-             b = a + batch_size
-             yield X[idxs[a:b]], y[idxs[a:b]]
- 
-     def _get_batch_generator(self, X, y, batch_size):
-         """
-         Return the dataset generator.
- 
-         Args:
-             X: input data
-             y: label data
-             batch_size: The batch size for the data loader
- 
-         """
-         if batch_size is None:
-             batch_size = self.batch_size
- 
-         # shuffle data indices
-         idxs = np.random.permutation(np.arange(X.shape[0]))
- 
-         # compute the number of batches
-         num_batches = int(np.ceil(X.shape[0] / batch_size))
- 
-         # build the generator and return it
-         return self._batch_generator(X, y, idxs, batch_size, num_batches)
--- 0 ----
diff -crB --new-file ./openfl/openfl/federated/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/__init__.py
*** ./openfl/openfl/federated/__init__.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,19 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """openfl.federated package."""
- 
- import pkgutil
- from .plan import Plan  # NOQA
- from .task import TaskRunner  # NOQA
- from .data import DataLoader  # NOQA
- 
- if pkgutil.find_loader('tensorflow'):
-     from .task import TensorFlowTaskRunner, KerasTaskRunner, FederatedModel  # NOQA
-     from .data import TensorFlowDataLoader, KerasDataLoader, FederatedDataSet  # NOQA
- if pkgutil.find_loader('torch'):
-     from .task import PyTorchTaskRunner, FederatedModel  # NOQA
-     from .data import PyTorchDataLoader, FederatedDataSet  # NOQA
- if pkgutil.find_loader('torch') and pkgutil.find_loader('tensorflow'):
-     from .task import FastEstimatorTaskRunner  # NOQA
-     from .data import FastEstimatorDataLoader  # NOQA
--- 0 ----
diff -crB --new-file ./openfl/openfl/federated/plan/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/plan/__init__.py
*** ./openfl/openfl/federated/plan/__init__.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/plan/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,10 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Plan package."""
- 
- from .plan import Plan
- 
- __all__ = [
-     'Plan',
- ]
--- 0 ----
diff -crB --new-file ./openfl/openfl/federated/plan/plan.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/plan/plan.py
*** ./openfl/openfl/federated/plan/plan.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/plan/plan.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,575 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Plan module."""
- from hashlib import sha384
- from importlib import import_module
- from logging import getLogger
- from os.path import splitext
- from pathlib import Path
- 
- from yaml import dump
- from yaml import safe_load
- from yaml import SafeDumper
- 
- from openfl.component.aggregation_functions import AggregationFunction
- from openfl.component.aggregation_functions import WeightedAverage
- from openfl.component.assigner.custom_assigner import Assigner
- from openfl.interface.cli_helper import WORKSPACE
- from openfl.transport import AggregatorGRPCClient
- from openfl.transport import AggregatorGRPCServer
- from openfl.utilities.utils import getfqdn_env
- 
- SETTINGS = 'settings'
- TEMPLATE = 'template'
- DEFAULTS = 'defaults'
- AUTO = 'auto'
- 
- 
- class Plan:
-     """Federated Learning plan."""
- 
-     logger = getLogger(__name__)
- 
-     @staticmethod
-     def load(yaml_path: Path, default: dict = None):
-         """Load the plan from YAML file."""
-         if default is None:
-             default = {}
-         if yaml_path and yaml_path.exists():
-             return safe_load(yaml_path.read_text())
-         return default
- 
-     @staticmethod
-     def dump(yaml_path, config, freeze=False):
-         """Dump the plan config to YAML file."""
- 
-         class NoAliasDumper(SafeDumper):
- 
-             def ignore_aliases(self, data):
-                 return True
- 
-         if freeze:
-             plan = Plan()
-             plan.config = config
-             frozen_yaml_path = Path(
-                 f'{yaml_path.parent}/{yaml_path.stem}_{plan.hash[:8]}.yaml')
-             if frozen_yaml_path.exists():
-                 Plan.logger.info(f'{yaml_path.name} is already frozen')
-                 return
-             frozen_yaml_path.write_text(dump(config))
-             frozen_yaml_path.chmod(0o400)
-             Plan.logger.info(f'{yaml_path.name} frozen successfully')
-         else:
-             yaml_path.write_text(dump(config))
- 
-     @staticmethod
-     def parse(plan_config_path: Path, cols_config_path: Path = None,
-               data_config_path: Path = None, resolve=True):
-         """
-         Parse the Federated Learning plan.
- 
-         Args:
-             plan_config_path (string): The filepath to the federated learning
-                                        plan
-             cols_config_path (string): The filepath to the federation
-                                        collaborator list [optional]
-             data_config_path (string): The filepath to the federation
-                                        collaborator data configuration
-                                        [optional]
-         Returns:
-             A federated learning plan object
-         """
-         try:
- 
-             plan = Plan()
-             plan.config = Plan.load(plan_config_path)  # load plan configuration
-             plan.name = plan_config_path.name
-             plan.files = [plan_config_path]  # collect all the plan files
- 
-             # ensure 'settings' appears in each top-level section
-             for section in plan.config.keys():
- 
-                 if plan.config[section].get(SETTINGS) is None:
-                     plan.config[section][SETTINGS] = {}
- 
-             # walk the top level keys and load 'defaults' in sorted order
-             for section in sorted(plan.config.keys()):
-                 defaults = plan.config[section].pop(DEFAULTS, None)
- 
-                 if defaults is not None:
-                     defaults = WORKSPACE / 'workspace' / defaults
- 
-                     plan.files.append(defaults)
- 
-                     if resolve:
-                         Plan.logger.info(
-                             f'Loading DEFAULTS for section [red]{section}[/] '
-                             f'from file [red]{defaults}[/].',
-                             extra={'markup': True})
- 
-                     defaults = Plan.load(Path(defaults))
- 
-                     if SETTINGS in defaults:
-                         # override defaults with section settings
-                         defaults[SETTINGS].update(
-                             plan.config[section][SETTINGS])
-                         plan.config[section][SETTINGS] = defaults[SETTINGS]
- 
-                     defaults.update(plan.config[section])
- 
-                     plan.config[section] = defaults
- 
-             plan.authorized_cols = Plan.load(cols_config_path).get(
-                 'collaborators', []
-             )
- 
-             # TODO: Does this need to be a YAML file? Probably want to use key
-             #  value as the plan hash
-             plan.cols_data_paths = {}
-             if data_config_path is not None:
-                 data_config = open(data_config_path, 'r')
-                 for line in data_config:
-                     line = line.rstrip()
-                     if len(line) > 0:
-                         if line[0] != '#':
-                             collab, data_path = line.split(',', maxsplit=1)
-                             plan.cols_data_paths[collab] = data_path
- 
-             if resolve:
-                 plan.resolve()
- 
-                 Plan.logger.info(
-                     f'Parsing Federated Learning Plan : [green]SUCCESS[/] : '
-                     f'[blue]{plan_config_path}[/].',
-                     extra={'markup': True})
-                 Plan.logger.info(dump(plan.config))
- 
-             return plan
- 
-         except Exception:
-             Plan.logger.exception(f'Parsing Federated Learning Plan : '
-                                   f'[red]FAILURE[/] : [blue]{plan_config_path}[/].',
-                                   extra={'markup': True})
-             raise
- 
-     @staticmethod
-     def build(template, settings, **override):
-         """
-         Create an instance of a openfl Component or Federated DataLoader/TaskRunner.
- 
-         Args:
-             template: Fully qualified class template path
-             settings: Keyword arguments to class constructor
- 
-         Returns:
-             A Python object
-         """
-         class_name = splitext(template)[1].strip('.')
-         module_path = splitext(template)[0]
- 
-         Plan.logger.info(f'Building [red]🡆[/] Object [red]{class_name}[/] '
-                          f'from [red]{module_path}[/] Module.',
-                          extra={'markup': True})
-         Plan.logger.debug(f'Settings [red]🡆[/] {settings}',
-                           extra={'markup': True})
-         Plan.logger.debug(f'Override [red]🡆[/] {override}',
-                           extra={'markup': True})
- 
-         settings.update(**override)
- 
-         module = import_module(module_path)
-         instance = getattr(module, class_name)(**settings)
- 
-         return instance
- 
-     @staticmethod
-     def import_(template):
-         """
-         Import an instance of a openfl Component or Federated DataLoader/TaskRunner.
- 
-         Args:
-             template: Fully qualified object path
- 
-         Returns:
-             A Python object
-         """
-         class_name = splitext(template)[1].strip('.')
-         module_path = splitext(template)[0]
-         Plan.logger.info(f'Importing [red]🡆[/] Object [red]{class_name}[/] '
-                          f'from [red]{module_path}[/] Module.',
-                          extra={'markup': True})
-         module = import_module(module_path)
-         instance = getattr(module, class_name)
- 
-         return instance
- 
-     def __init__(self):
-         """Initialize."""
-         self.config = {}  # dictionary containing patched plan definition
-         self.authorized_cols = []  # authorized collaborator list
-         self.cols_data_paths = {}  # collaborator data paths dict
- 
-         self.collaborator_ = None  # collaborator object
-         self.aggregator_ = None  # aggregator object
-         self.assigner_ = None  # assigner object
- 
-         self.loader_ = None  # data loader object
-         self.runner_ = None  # task runner object
- 
-         self.server_ = None  # gRPC server object
-         self.client_ = None  # gRPC client object
- 
-         self.pipe_ = None  # compression pipeline object
- 
-         self.hash_ = None
-         self.name_ = None
-         self.serializer_ = None
- 
-     @property
-     def hash(self):  # NOQA
-         """Generate hash for this instance."""
-         self.hash_ = sha384(dump(self.config).encode('utf-8'))
-         Plan.logger.info(f'FL-Plan hash is [blue]{self.hash_.hexdigest()}[/]',
-                          extra={'markup': True})
- 
-         return self.hash_.hexdigest()
- 
-     def resolve(self):
-         """Resolve the federation settings."""
-         self.federation_uuid = f'{self.name}_{self.hash[:8]}'
-         self.aggregator_uuid = f'aggregator_{self.federation_uuid}'
- 
-         self.rounds_to_train = self.config['aggregator'][SETTINGS][
-             'rounds_to_train']
- 
-         if self.config['network'][SETTINGS]['agg_addr'] == AUTO:
-             self.config['network'][SETTINGS]['agg_addr'] = getfqdn_env()
- 
-         if self.config['network'][SETTINGS]['agg_port'] == AUTO:
-             self.config['network'][SETTINGS]['agg_port'] = int(
-                 self.hash[:8], 16
-             ) % (60999 - 49152) + 49152
- 
-     def get_assigner(self):
-         """Get the plan task assigner."""
-         aggregation_functions_by_task = None
-         assigner_function = None
-         try:
-             aggregation_functions_by_task = self.restore_object('aggregation_function_obj.pkl')
-             assigner_function = self.restore_object('task_assigner_obj.pkl')
-         except Exception as exc:
-             self.logger.error(f'Failed to load aggregation and assigner functions: {exc}')
-             self.logger.info('Using Task Runner API workflow')
-         if assigner_function:
-             self.assigner_ = Assigner(
-                 assigner_function=assigner_function,
-                 aggregation_functions_by_task=aggregation_functions_by_task,
-                 authorized_cols=self.authorized_cols,
-                 rounds_to_train=self.rounds_to_train,
-             )
-         else:
-             # Backward compatibility
-             defaults = self.config.get(
-                 'assigner',
-                 {
-                     TEMPLATE: 'openfl.component.Assigner',
-                     SETTINGS: {}
-                 }
-             )
- 
-             defaults[SETTINGS]['authorized_cols'] = self.authorized_cols
-             defaults[SETTINGS]['rounds_to_train'] = self.rounds_to_train
-             defaults[SETTINGS]['tasks'] = self.get_tasks()
- 
-             if self.assigner_ is None:
-                 self.assigner_ = Plan.build(**defaults)
- 
-         return self.assigner_
- 
-     def get_tasks(self):
-         """Get federation tasks."""
-         tasks = self.config.get('tasks', {})
-         tasks.pop(DEFAULTS, None)
-         tasks.pop(SETTINGS, None)
-         for task in tasks:
-             aggregation_type = tasks[task].get('aggregation_type')
-             if aggregation_type is None:
-                 aggregation_type = WeightedAverage()
-             elif isinstance(aggregation_type, dict):
-                 if SETTINGS not in aggregation_type:
-                     aggregation_type[SETTINGS] = {}
-                 aggregation_type = Plan.build(**aggregation_type)
-                 if not isinstance(aggregation_type, AggregationFunction):
-                     raise NotImplementedError(f'''{task} task aggregation type does not implement an interface:
-     openfl.component.aggregation_functions.AggregationFunction
-     ''')
-             tasks[task]['aggregation_type'] = aggregation_type
-         return tasks
- 
-     def get_aggregator(self, tensor_dict=None):
-         """Get federation aggregator."""
-         defaults = self.config.get('aggregator',
-                                    {
-                                        TEMPLATE: 'openfl.component.Aggregator',
-                                        SETTINGS: {}
-                                    })
- 
-         defaults[SETTINGS]['aggregator_uuid'] = self.aggregator_uuid
-         defaults[SETTINGS]['federation_uuid'] = self.federation_uuid
-         defaults[SETTINGS]['authorized_cols'] = self.authorized_cols
-         defaults[SETTINGS]['assigner'] = self.get_assigner()
-         defaults[SETTINGS]['compression_pipeline'] = self.get_tensor_pipe()
-         log_metric_callback = defaults[SETTINGS].get('log_metric_callback')
- 
-         if log_metric_callback:
-             if isinstance(log_metric_callback, dict):
-                 log_metric_callback = Plan.import_(**log_metric_callback)
-             elif not callable(log_metric_callback):
-                 raise TypeError(f'log_metric_callback should be callable object '
-                                 f'or be import from code part, get {log_metric_callback}')
- 
-         defaults[SETTINGS]['log_metric_callback'] = log_metric_callback
-         if self.aggregator_ is None:
-             self.aggregator_ = Plan.build(**defaults, initial_tensor_dict=tensor_dict)
- 
-         return self.aggregator_
- 
-     def get_tensor_pipe(self):
-         """Get data tensor pipeline."""
-         defaults = self.config.get(
-             'compression_pipeline',
-             {
-                 TEMPLATE: 'openfl.pipelines.NoCompressionPipeline',
-                 SETTINGS: {}
-             }
-         )
- 
-         if self.pipe_ is None:
-             self.pipe_ = Plan.build(**defaults)
- 
-         return self.pipe_
- 
-     # legacy api (TaskRunner subclassing)
-     def get_data_loader(self, collaborator_name):
-         """Get data loader."""
-         defaults = self.config.get('data_loader',
-                                    {
-                                        TEMPLATE: 'openfl.federation.DataLoader',
-                                        SETTINGS: {}
-                                    })
- 
-         defaults[SETTINGS]['data_path'] = self.cols_data_paths[
-             collaborator_name
-         ]
- 
-         if self.loader_ is None:
-             self.loader_ = Plan.build(**defaults)
- 
-         return self.loader_
- 
-     # Python interactive api
-     def initialize_data_loader(self, data_loader, shard_descriptor):
-         """Get data loader."""
-         data_loader.shard_descriptor = shard_descriptor
-         return data_loader
- 
-     # legacy api (TaskRunner subclassing)
-     def get_task_runner(self, data_loader):
-         """Get task runner."""
-         defaults = self.config.get('task_runner',
-                                    {
-                                        TEMPLATE: 'openfl.federation.TaskRunner',
-                                        SETTINGS: {}
-                                    })
- 
-         defaults[SETTINGS]['data_loader'] = data_loader
- 
-         if self.runner_ is None:
-             self.runner_ = Plan.build(**defaults)
- 
-         return self.runner_
- 
-     # Python interactive api
-     def get_core_task_runner(self, data_loader=None,
-                              model_provider=None,
-                              task_keeper=None):
-         """Get task runner."""
-         defaults = self.config.get(
-             'task_runner',
-             {
-                 TEMPLATE: 'openfl.federated.task.task_runner.CoreTaskRunner',
-                 SETTINGS: {}
-             })
- 
-         # We are importing a CoreTaskRunner instance!!!
-         if self.runner_ is None:
-             self.runner_ = Plan.build(**defaults)
- 
-         self.runner_.set_data_loader(data_loader)
- 
-         self.runner_.set_model_provider(model_provider)
-         self.runner_.set_task_provider(task_keeper)
- 
-         framework_adapter = Plan.build(
-             self.config['task_runner']['required_plugin_components']['framework_adapters'], {})
- 
-         # This step initializes tensorkeys
-         # Which have no sens if task provider is not set up
-         self.runner_.set_framework_adapter(framework_adapter)
- 
-         return self.runner_
- 
-     def get_collaborator(self, collaborator_name, root_certificate=None, private_key=None,
-                          certificate=None, task_runner=None, client=None, shard_descriptor=None):
-         """Get collaborator."""
-         defaults = self.config.get(
-             'collaborator',
-             {
-                 TEMPLATE: 'openfl.component.Collaborator',
-                 SETTINGS: {}
-             }
-         )
- 
-         defaults[SETTINGS]['collaborator_name'] = collaborator_name
-         defaults[SETTINGS]['aggregator_uuid'] = self.aggregator_uuid
-         defaults[SETTINGS]['federation_uuid'] = self.federation_uuid
- 
-         if task_runner is not None:
-             defaults[SETTINGS]['task_runner'] = task_runner
-         else:
-             # Here we support new interactive api as well as old task_runner subclassing interface
-             # If Task Runner class is placed incide openfl `task-runner` subpackage it is
-             # a part of the New API and it is a part of OpenFL kernel.
-             # If Task Runner is placed elsewhere, somewhere in user workspace, than it is
-             # a part of the old interface and we follow legacy initialization procedure.
-             if 'openfl.federated.task.task_runner' in self.config['task_runner']['template']:
-                 # Interactive API
-                 model_provider, task_keeper, data_loader = self.deserialize_interface_objects()
-                 data_loader = self.initialize_data_loader(data_loader, shard_descriptor)
-                 defaults[SETTINGS]['task_runner'] = self.get_core_task_runner(
-                     data_loader=data_loader,
-                     model_provider=model_provider,
-                     task_keeper=task_keeper)
-             else:
-                 # TaskRunner subclassing API
-                 data_loader = self.get_data_loader(collaborator_name)
-                 defaults[SETTINGS]['task_runner'] = self.get_task_runner(data_loader)
- 
-         defaults[SETTINGS]['compression_pipeline'] = self.get_tensor_pipe()
-         defaults[SETTINGS]['task_config'] = self.config.get('tasks', {})
-         if client is not None:
-             defaults[SETTINGS]['client'] = client
-         else:
-             defaults[SETTINGS]['client'] = self.get_client(
-                 collaborator_name,
-                 self.aggregator_uuid,
-                 self.federation_uuid,
-                 root_certificate,
-                 private_key,
-                 certificate
-             )
- 
-         if self.collaborator_ is None:
-             self.collaborator_ = Plan.build(**defaults)
- 
-         return self.collaborator_
- 
-     def get_client(self, collaborator_name, aggregator_uuid, federation_uuid,
-                    root_certificate=None, private_key=None, certificate=None):
-         """Get gRPC client for the specified collaborator."""
-         common_name = collaborator_name
-         if not root_certificate or not private_key or not certificate:
-             root_certificate = 'cert/cert_chain.crt'
-             certificate = f'cert/client/col_{common_name}.crt'
-             private_key = f'cert/client/col_{common_name}.key'
- 
-         client_args = self.config['network'][SETTINGS]
- 
-         # patch certificates
- 
-         client_args['root_certificate'] = root_certificate
-         client_args['certificate'] = certificate
-         client_args['private_key'] = private_key
- 
-         client_args['aggregator_uuid'] = aggregator_uuid
-         client_args['federation_uuid'] = federation_uuid
- 
-         if self.client_ is None:
-             self.client_ = AggregatorGRPCClient(**client_args)
- 
-         return self.client_
- 
-     def get_server(self, root_certificate=None, private_key=None, certificate=None, **kwargs):
-         """Get gRPC server of the aggregator instance."""
-         common_name = self.config['network'][SETTINGS]['agg_addr'].lower()
- 
-         if not root_certificate or not private_key or not certificate:
-             root_certificate = 'cert/cert_chain.crt'
-             certificate = f'cert/server/agg_{common_name}.crt'
-             private_key = f'cert/server/agg_{common_name}.key'
- 
-         server_args = self.config['network'][SETTINGS]
- 
-         # patch certificates
- 
-         server_args.update(kwargs)
-         server_args['root_certificate'] = root_certificate
-         server_args['certificate'] = certificate
-         server_args['private_key'] = private_key
- 
-         server_args['aggregator'] = self.get_aggregator()
- 
-         if self.server_ is None:
-             self.server_ = AggregatorGRPCServer(**server_args)
- 
-         return self.server_
- 
-     def interactive_api_get_server(self, *, tensor_dict, root_certificate, certificate,
-                                    private_key, tls):
-         """Get gRPC server of the aggregator instance."""
-         server_args = self.config['network'][SETTINGS]
- 
-         # patch certificates
-         server_args['root_certificate'] = root_certificate
-         server_args['certificate'] = certificate
-         server_args['private_key'] = private_key
-         server_args['tls'] = tls
- 
-         server_args['aggregator'] = self.get_aggregator(tensor_dict)
- 
-         if self.server_ is None:
-             self.server_ = AggregatorGRPCServer(**server_args)
- 
-         return self.server_
- 
-     def deserialize_interface_objects(self):
-         """Deserialize objects for TaskRunner."""
-         api_layer = self.config['api_layer']
-         filenames = [
-             'model_interface_file',
-             'tasks_interface_file',
-             'dataloader_interface_file'
-         ]
-         return (self.restore_object(api_layer['settings'][filename]) for filename in filenames)
- 
-     def get_serializer_plugin(self, **kwargs):
-         """Get serializer plugin.
- 
-         This plugin is used for serialization of interfaces in new interactive API
-         """
-         if self.serializer_ is None:
-             if 'api_layer' not in self.config:  # legacy API
-                 return None
-             required_plugin_components = self.config['api_layer']['required_plugin_components']
-             serializer_plugin = required_plugin_components['serializer_plugin']
-             self.serializer_ = Plan.build(serializer_plugin, kwargs)
-         return self.serializer_
- 
-     def restore_object(self, filename):
-         """Deserialize an object."""
-         serializer_plugin = self.get_serializer_plugin()
-         if serializer_plugin is None:
-             return None
-         obj = serializer_plugin.restore_object(filename)
-         return obj
--- 0 ----
diff -crB --new-file ./openfl/openfl/federated/task/fl_model.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/task/fl_model.py
*** ./openfl/openfl/federated/task/fl_model.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/task/fl_model.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,99 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """FederatedModel module."""
- 
- import inspect
- 
- from .runner import TaskRunner
- 
- 
- class FederatedModel(TaskRunner):
-     """
-     A wrapper that adapts to Tensorflow and Pytorch models to a federated context.
- 
-     Args:
-         model : tensorflow/keras (function) , pytorch (class)
-             For keras/tensorflow model, expects a function that returns the
-             model definition
-             For pytorch models, expects a class (not an instance) containing
-             the model definition and forward function
-         optimizer : lambda function (only required for pytorch)
-             The optimizer should be definied within a lambda function. This
-             allows the optimizer to be attached to the federated models spawned
-             for each collaborator.
-         loss_fn : pytorch loss_fun (only required for pytorch)
-     """
- 
-     def __init__(self, build_model, optimizer=None, loss_fn=None, **kwargs):
-         """Initialize.
- 
-         Args:
-             model:    build_model function
-             **kwargs: Additional parameters to pass to the function
- 
-         """
-         super().__init__(**kwargs)
- 
-         self.build_model = build_model
-         self.lambda_opt = None
-         # TODO pass params to model
-         if inspect.isclass(build_model):
-             self.model = build_model()
-             from .runner_pt import PyTorchTaskRunner
-             if optimizer is not None:
-                 self.optimizer = optimizer(self.model.parameters())
-             self.runner = PyTorchTaskRunner(**kwargs)
-             if hasattr(self.model, 'forward'):
-                 self.runner.forward = self.model.forward
-         else:
-             self.model = self.build_model(
-                 self.feature_shape, self.data_loader.num_classes)
-             from .runner_keras import KerasTaskRunner
-             self.runner = KerasTaskRunner(**kwargs)
-             self.optimizer = self.model.optimizer
-         self.lambda_opt = optimizer
-         if hasattr(self.model, 'validate'):
-             self.runner.validate = lambda *args, **kwargs: build_model.validate(
-                 self.runner, *args, **kwargs)
-         if hasattr(self.model, 'train_epoch'):
-             self.runner.train_epoch = lambda *args, **kwargs: build_model.train_epoch(
-                 self.runner, *args, **kwargs)
-         self.runner.model = self.model
-         self.runner.optimizer = self.optimizer
-         self.loss_fn = loss_fn
-         self.runner.loss_fn = self.loss_fn
-         self.tensor_dict_split_fn_kwargs = self.runner.tensor_dict_split_fn_kwargs
-         self.initialize_tensorkeys_for_functions()
- 
-     def __getattribute__(self, attr):
-         """Direct call into self.runner methods if necessary."""
-         if attr in ['reset_opt_vars', 'initialize_globals',
-                     'set_tensor_dict', 'get_tensor_dict',
-                     'get_required_tensorkeys_for_function',
-                     'initialize_tensorkeys_for_functions',
-                     'save_native', 'load_native', 'rebuild_model',
-                     'set_optimizer_treatment',
-                     'train', 'train_batches', 'validate']:
-             return self.runner.__getattribute__(attr)
-         return super(FederatedModel, self).__getattribute__(attr)
- 
-     def setup(self, num_collaborators, **kwargs):
-         """
-         Create new models for all of the collaborators in the experiment.
- 
-         Args:
-             num_collaborators:  Number of experiment collaborators
- 
-         Returns:
-             List of models
-         """
-         return [
-             FederatedModel(
-                 self.build_model,
-                 optimizer=self.lambda_opt,
-                 loss_fn=self.loss_fn,
-                 data_loader=data_slice,
-                 **kwargs
-             )
-             for data_slice in self.data_loader.split(num_collaborators)]
--- 0 ----
diff -crB --new-file ./openfl/openfl/federated/task/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/task/__init__.py
*** ./openfl/openfl/federated/task/__init__.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/task/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,27 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Task package."""
- 
- import pkgutil
- from warnings import catch_warnings
- from warnings import simplefilter
- 
- with catch_warnings():
-     simplefilter(action='ignore', category=FutureWarning)
-     if pkgutil.find_loader('tensorflow'):
-         # ignore deprecation warnings in command-line interface
-         import tensorflow  # NOQA
- 
- from .runner import TaskRunner  # NOQA
- 
- 
- if pkgutil.find_loader('tensorflow'):
-     from .runner_tf import TensorFlowTaskRunner  # NOQA
-     from .runner_keras import KerasTaskRunner  # NOQA
-     from .fl_model import FederatedModel  # NOQA
- if pkgutil.find_loader('torch'):
-     from .runner_pt import PyTorchTaskRunner  # NOQA
-     from .fl_model import FederatedModel  # NOQA
- if pkgutil.find_loader('torch') and pkgutil.find_loader('tensorflow'):
-     from .runner_fe import FastEstimatorTaskRunner  # NOQA
--- 0 ----
diff -crB --new-file ./openfl/openfl/federated/task/runner_fe.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/task/runner_fe.py
*** ./openfl/openfl/federated/task/runner_fe.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/task/runner_fe.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,318 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """FastEstimatorTaskRunner module."""
- 
- import numpy as np
- 
- from openfl.utilities import split_tensor_dict_for_holdouts
- from openfl.utilities import TensorKey
- from .runner import TaskRunner
- from .runner_keras import KerasTaskRunner
- from .runner_pt import PyTorchTaskRunner
- 
- 
- class FastEstimatorTaskRunner(TaskRunner):
-     """A wrapper for fastestimator.estimator."""
- 
-     def __init__(self, estimator, **kwargs):
-         """Initialize.
- 
-         Args:
-             estimator: object of type fastestimator.estimator
-         """
-         super().__init__(**kwargs)
-         import fastestimator as fe
- 
-         class ProgressLoader(fe.trace.Trace):
-             def __init__(self, get_progress) -> None:
-                 super().__init__(mode='train')
-                 self.get_progress = get_progress
- 
-             def on_begin(self, data) -> None:
-                 """Run once at the beginning of training or testing.
- 
-                 Args:
-                     data: A dictionary through which traces can communicate with
-                     each other or write values for logging.
-                 """
-                 progress = self.get_progress()
-                 self.system.epoch_idx = progress['epoch_idx']
-                 self.system.global_step = progress['global_step']
- 
-         estimator_kwargs = {}
-         for k, v in estimator.system.__dict__.items():
-             if k in ['pipeline', 'network', 'log_steps',
-                      'max_train_steps_per_epoch', 'max_eval_steps_per_epoch']:
-                 estimator_kwargs[k] = v
-             if k == 'traces':
-                 self.logger.debug(f'traces={estimator.system.traces}')
-                 estimator_kwargs[k] = v + [
-                     ProgressLoader(lambda: {
-                         'epoch_idx': self.epoch_idx,
-                         'global_step': self.global_step
-                     })]
-         estimator_kwargs.update({
-             'epochs': estimator.system.total_epochs,
-             'monitor_names': estimator.monitor_names
-         })
-         self.estimator = fe.Estimator(**estimator_kwargs)
-         assert (len(estimator.network.models) == 1), (
-             'Only one-model networks are currently supported')
-         if isinstance(estimator.network, fe.network.TorchNetwork):
-             impl = PyTorchTaskRunner
-         elif isinstance(estimator.network, fe.network.TFNetwork):
-             impl = KerasTaskRunner
-         self.model = self.estimator.network.models[0]
-         self.optimizer = self.model.optimizer
-         self.runner = impl(**kwargs)
-         self.runner.model = self.model
-         self.runner.optimizer = self.optimizer
-         self.required_tensorkeys_for_function = {}
-         self.tensor_dict_split_fn_kwargs = self.runner.tensor_dict_split_fn_kwargs
-         self.initialize_tensorkeys_for_functions()
-         self.epoch_idx = 0
-         self.global_step = None
-         self.total_epochs = self.estimator.system.total_epochs
- 
-     def train(self, col_name, round_num, input_tensor_dict, epochs, **kwargs):
-         """Perform training for a specified number of epochs."""
-         if 'metrics' not in kwargs:
-             raise KeyError('metrics must be included in kwargs')
-         param_metrics = kwargs['metrics']
- 
-         self.rebuild_model(round_num, input_tensor_dict)
- 
-         # Estimators need to be given an experiment name to produce an output
-         # summary
-         summary = self.estimator.fit('experiment', warmup=False)
-         self.epoch_idx = self.estimator.system.epoch_idx
-         self.global_step = self.estimator.system.global_step
-         self.estimator.system.total_epochs += self.total_epochs
-         # Define what the ouptut is to encapsulate in tensorkeys and return
-         # output metric tensors (scalar)
-         origin = col_name
-         tags = ('trained',)
-         output_metric_dict = {
-             TensorKey(
-                 metric, origin, round_num, True, ('metric',)
-             ): np.array(
-                 list(
-                     summary.history['train'][metric].values()
-                 )[-1]) for metric in param_metrics}
- 
-         # output model tensors (Doesn't include TensorKey)
-         output_model_dict = self.get_tensor_dict(with_opt_vars=True)
-         global_model_dict, local_model_dict = split_tensor_dict_for_holdouts(
-             self.logger, output_model_dict,
-             **self.tensor_dict_split_fn_kwargs
-         )
- 
-         # create global tensorkeys
-         global_tensorkey_model_dict = {
-             TensorKey(
-                 tensor_name, origin, round_num, False, tags
-             ): nparray for tensor_name, nparray in global_model_dict.items()
-         }
-         # create tensorkeys that should stay local
-         local_tensorkey_model_dict = {
-             TensorKey(
-                 tensor_name, origin, round_num, False, tags
-             ): nparray for tensor_name, nparray in local_model_dict.items()
-         }
-         # the train/validate aggregated function of the next round will look
-         # for the updated model parameters.
-         # this ensures they will be resolved locally
-         next_local_tensorkey_model_dict = {
-             TensorKey(
-                 tensor_name, origin, round_num + 1, False, ('model',)
-             ): nparray for tensor_name, nparray in local_model_dict.items()
-         }
- 
-         global_tensor_dict = {
-             **output_metric_dict,
-             **global_tensorkey_model_dict
-         }
-         local_tensor_dict = {
-             **local_tensorkey_model_dict,
-             **next_local_tensorkey_model_dict
-         }
- 
-         # update the required tensors if they need to be pulled from the
-         # aggregator
-         # TODO this logic can break if different collaborators have different
-         #  roles between rounds.
-         # for example, if a collaborator only performs validation in the first
-         # round but training in the second, it has no way of knowing the
-         # optimizer state tensor names to request from the aggregator
-         # because these are only created after training occurs.
-         # A work around could involve doing a single epoch of training
-         # on random data to get the optimizer names, and then throwing away
-         # the model.
-         if self.opt_treatment == 'CONTINUE_GLOBAL':
-             self.initialize_tensorkeys_for_functions(with_opt_vars=True)
- 
-         return global_tensor_dict, local_tensor_dict
- 
-     def validate(self, col_name, round_num, input_tensor_dict, **kwargs):
-         """
-         Run the trained model on validation data; report results.
- 
-         Parameters
-         ----------
-         input_tensor_dict : either the last aggregated or locally trained model
- 
-         Returns
-         -------
-         output_tensor_dict : {TensorKey: nparray} (these correspond to acc,
-          precision, f1_score, etc.)
-         """
-         self.rebuild_model(round_num, input_tensor_dict, validation=True)
-         param_metrics = kwargs['metrics']
- 
-         results = self.estimator.test('experiment')
-         ret_dict = {
-             metric: list(results.history['test'][metric].values())[-1]
-             for metric in param_metrics
-         }
- 
-         origin = col_name
-         suffix = 'validate'
-         if kwargs['apply'] == 'local':
-             suffix += '_local'
-         else:
-             suffix += '_agg'
-         tags = ('metric', suffix)
-         output_tensor_dict = {
-             TensorKey(
-                 metric, origin, round_num, True, tags
-             ): np.array(ret_dict[metric])
-             for metric in param_metrics
-         }
- 
-         return output_tensor_dict, {}
- 
-     def initialize_tensorkeys_for_functions(self, with_opt_vars=False):
-         """
-         Set the required tensors for all publicly accessible methods that could \
-             be called as part of a task.
- 
-         By default, this is just all of the layers and optimizer of the model.
-          Custom tensors should be added to this function
- 
-         Parameters
-         ----------
-         None
- 
-         Returns
-         -------
-         None
-         """
-         self.runner.initialize_tensorkeys_for_functions(with_opt_vars)
- 
-     def build_model(self):
-         """Abstract method."""
-         raise NotImplementedError
- 
-     def get_required_tensorkeys_for_function(self, func_name, **kwargs):
-         """
-         When running a task, a map of named tensorkeys must be provided to the \
-             function as dependencies.
- 
-         Returns:
-             list: (TensorKey(tensor_name, origin, round_number))
-         """
-         return self.runner.get_required_tensorkeys_for_function(
-             func_name, **kwargs)
- 
-     def get_tensor_dict(self, with_opt_vars):
-         """
-         Get the weights.
- 
-         Args:
-             with_opt_vars (bool): Specify if we also want to get the variables
-              of the optimizer.
- 
-         Returns:
-             dict: The weight dictionary {<tensor_name>: <value>}
-         """
-         return self.runner.get_tensor_dict(with_opt_vars)
- 
-     def set_tensor_dict(self, tensor_dict, with_opt_vars):
-         """
-         Set the model weights with a tensor dictionary: {<tensor_name>: <value>}.
- 
-         Args:
-             tensor_dict (dict): The model weights dictionary.
-             with_opt_vars (bool): Specify if we also want to set the variables
-             of the optimizer.
- 
-         Returns:
-             None
-         """
-         return self.runner.set_tensor_dict(tensor_dict, with_opt_vars)
- 
-     def reset_opt_vars(self):
-         """Reinitialize the optimizer variables."""
-         return self.runner.reset_opt_vars()
- 
-     def initialize_globals(self):
-         """
-         Initialize all global variables.
- 
-         Returns:
-             None
-         """
-         return self.runner.initialize_globals()
- 
-     def load_native(self, filepath, **kwargs):
-         """
-         Load model state from a filepath in ML-framework "native" format, \
-             e.g. PyTorch pickled models.
- 
-         May load from multiple files. Other filepaths may be derived from the
-         passed filepath, or they may be in the kwargs.
- 
-         Args:
-             filepath (string): Path to frame-work specific file to load. For
-                                frameworks that use multiple files, this string
-                                must be used to derive the other filepaths.
-             kwargs           : For future-proofing
- 
-         Returns:
-             None
-         """
-         return self.runner.load_native(filepath, **kwargs)
- 
-     def save_native(self, filepath, **kwargs):
-         """
-         Save model state in ML-framework "native" format, \
-             e.g. PyTorch pickled models.
- 
-         May save one file or multiple files, depending on the framework.
- 
-         Args:
-             filepath (string): If framework stores a single file, this should
-                                be a single file path.
-             Frameworks that store multiple files may need to derive the other
-             paths from this path.
-             kwargs           : For future-proofing
- 
-         Returns:
-             None
-         """
-         return self.runner.save_native(filepath, **kwargs)
- 
-     def rebuild_model(self, round_num, input_tensor_dict, validation=False):
-         """
-         Parse tensor names and update weights of model. Handles the optimizer treatment.
- 
-         Returns:
-             None
-         """
-         return self.runner.rebuild_model(
-             round_num, input_tensor_dict, validation)
- 
-     def set_optimizer_treatment(self, opt_treatment):
-         """Change treatment of current instance optimizer."""
-         super().set_optimizer_treatment(opt_treatment)
-         self.runner.opt_treatment = opt_treatment
--- 0 ----
diff -crB --new-file ./openfl/openfl/federated/task/runner_keras.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/task/runner_keras.py
*** ./openfl/openfl/federated/task/runner_keras.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/task/runner_keras.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,530 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """
- Base classes for developing a ke.Model() Federated Learning model.
- 
- You may copy this file as the starting point of your own keras model.
- """
- from warnings import catch_warnings
- from warnings import simplefilter
- 
- import numpy as np
- 
- from openfl.utilities import Metric
- from openfl.utilities import split_tensor_dict_for_holdouts
- from openfl.utilities import TensorKey
- from .runner import TaskRunner
- 
- with catch_warnings():
-     simplefilter(action='ignore')
-     import tensorflow as tf
-     import tensorflow.keras as ke
- 
- 
- class KerasTaskRunner(TaskRunner):
-     """The base model for Keras models in the federation."""
- 
-     def __init__(self, **kwargs):
-         """
-         Initialize.
- 
-         Args:
-             **kwargs: Additional parameters to pass to the function
-         """
-         super().__init__(**kwargs)
- 
-         self.model = ke.Model()
- 
-         self.model_tensor_names = []
- 
-         # this is a map of all of the required tensors for each of the public
-         # functions in KerasTaskRunner
-         self.required_tensorkeys_for_function = {}
-         ke.backend.clear_session()
- 
-     def rebuild_model(self, round_num, input_tensor_dict, validation=False):
-         """
-         Parse tensor names and update weights of model. Handles the optimizer treatment.
- 
-         Returns
-         -------
-         None
-         """
-         if self.opt_treatment == 'RESET':
-             self.reset_opt_vars()
-             self.set_tensor_dict(input_tensor_dict, with_opt_vars=False)
-         elif (round_num > 0 and self.opt_treatment == 'CONTINUE_GLOBAL'
-               and not validation):
-             self.set_tensor_dict(input_tensor_dict, with_opt_vars=True)
-         else:
-             self.set_tensor_dict(input_tensor_dict, with_opt_vars=False)
- 
-     def train(self, col_name, round_num, input_tensor_dict,
-               metrics, epochs=1, batch_size=1, **kwargs):
-         """
-         Perform the training.
- 
-         Is expected to perform draws randomly, without replacement until data is exausted.
-         Then data is replaced and shuffled and draws continue.
- 
-         Returns
-         -------
-         dict
-             'TensorKey: nparray'
-         """
-         if metrics is None:
-             raise KeyError('metrics must be defined')
- 
-         # rebuild model with updated weights
-         self.rebuild_model(round_num, input_tensor_dict)
-         for epoch in range(epochs):
-             self.logger.info(f'Run {epoch} epoch of {round_num} round')
-             results = self.train_iteration(self.data_loader.get_train_loader(batch_size),
-                                            metrics=metrics,
-                                            **kwargs)
- 
-         # output metric tensors (scalar)
-         origin = col_name
-         tags = ('trained',)
-         output_metric_dict = {
-             TensorKey(
-                 metric_name, origin, round_num, True, ('metric',)
-             ): metric_value
-             for (metric_name, metric_value) in results
-         }
- 
-         # output model tensors (Doesn't include TensorKey)
-         output_model_dict = self.get_tensor_dict(with_opt_vars=True)
-         global_model_dict, local_model_dict = split_tensor_dict_for_holdouts(
-             self.logger, output_model_dict,
-             **self.tensor_dict_split_fn_kwargs
-         )
- 
-         # create global tensorkeys
-         global_tensorkey_model_dict = {
-             TensorKey(tensor_name, origin, round_num, False, tags):
-                 nparray for tensor_name, nparray in global_model_dict.items()
-         }
-         # create tensorkeys that should stay local
-         local_tensorkey_model_dict = {
-             TensorKey(tensor_name, origin, round_num, False, tags):
-                 nparray for tensor_name, nparray in local_model_dict.items()
-         }
-         # the train/validate aggregated function of the next round will look
-         # for the updated model parameters.
-         # this ensures they will be resolved locally
-         next_local_tensorkey_model_dict = {
-             TensorKey(
-                 tensor_name, origin, round_num + 1, False, ('model',)
-             ): nparray for tensor_name, nparray in local_model_dict.items()
-         }
- 
-         global_tensor_dict = {
-             **output_metric_dict,
-             **global_tensorkey_model_dict
-         }
-         local_tensor_dict = {
-             **local_tensorkey_model_dict,
-             **next_local_tensorkey_model_dict
-         }
- 
-         # update the required tensors if they need to be pulled from the
-         # aggregator
-         # TODO this logic can break if different collaborators have different
-         # roles between rounds.
-         # for example, if a collaborator only performs validation in the first
-         # round but training in the second, it has no way of knowing the
-         # optimizer state tensor names to request from the aggregator because
-         # these are only created after training occurs. A work around could
-         # involve doing a single epoch of training on random data to get the
-         # optimizer names, and then throwing away the model.
-         if self.opt_treatment == 'CONTINUE_GLOBAL':
-             self.initialize_tensorkeys_for_functions(with_opt_vars=True)
- 
-         return global_tensor_dict, local_tensor_dict
- 
-     def train_iteration(self, batch_generator, metrics: list = None, **kwargs):
-         """Train single epoch.
- 
-         Override this function for custom training.
- 
-         Args:
-             batch_generator: Generator of training batches.
-                 Each batch is a tuple of N train images and N train labels
-                 where N is the batch size of the DataLoader of the current TaskRunner instance.
- 
-             epochs: Number of epochs to train.
-             metrics: Names of metrics to save.
-         """
-         if metrics is None:
-             metrics = []
-         # TODO Currently assuming that all metrics are defined at
-         #  initialization (build_model).
-         #  If metrics are added (i.e. not a subset of what was originally
-         #  defined) then the model must be recompiled.
-         model_metrics_names = self.model.metrics_names
- 
-         # TODO if there are new metrics in the flplan that were not included
-         #  in the originally
-         #  compiled model, that behavior is not currently handled.
-         for param in metrics:
-             if param not in model_metrics_names:
-                 raise ValueError(
-                     f'KerasTaskRunner does not support specifying new metrics. '
-                     f'Param_metrics = {metrics}, model_metrics_names = {model_metrics_names}'
-                 )
- 
-         history = self.model.fit(batch_generator,
-                                  verbose=1,
-                                  **kwargs)
-         results = []
-         for metric in metrics:
-             value = np.mean([history.history[metric]])
-             results.append(Metric(name=metric, value=np.array(value)))
-         return results
- 
-     def validate(self, col_name, round_num, input_tensor_dict, **kwargs):
-         """
-         Run the trained model on validation data; report results.
- 
-         Parameters
-         ----------
-         input_tensor_dict : either the last aggregated or locally trained model
- 
-         Returns
-         -------
-         output_tensor_dict : {TensorKey: nparray} (these correspond to acc,
-          precision, f1_score, etc.)
-         """
-         if 'batch_size' in kwargs:
-             batch_size = kwargs['batch_size']
-         else:
-             batch_size = 1
- 
-         self.rebuild_model(round_num, input_tensor_dict, validation=True)
-         param_metrics = kwargs['metrics']
- 
-         vals = self.model.evaluate(
-             self.data_loader.get_valid_loader(batch_size),
-             verbose=1
-         )
-         model_metrics_names = self.model.metrics_names
-         if type(vals) is not list:
-             vals = [vals]
-         ret_dict = dict(zip(model_metrics_names, vals))
- 
-         # TODO if there are new metrics in the flplan that were not included in
-         #  the originally compiled model, that behavior is not currently
-         #  handled.
-         for param in param_metrics:
-             if param not in model_metrics_names:
-                 raise ValueError(
-                     f'KerasTaskRunner does not support specifying new metrics. '
-                     f'Param_metrics = {param_metrics}, model_metrics_names = {model_metrics_names}'
-                 )
- 
-         origin = col_name
-         suffix = 'validate'
-         if kwargs['apply'] == 'local':
-             suffix += '_local'
-         else:
-             suffix += '_agg'
-         tags = ('metric', suffix)
-         output_tensor_dict = {
-             TensorKey(metric, origin, round_num, True, tags):
-                 np.array(ret_dict[metric])
-             for metric in param_metrics}
- 
-         return output_tensor_dict, {}
- 
-     def save_native(self, filepath):
-         """Save model."""
-         self.model.save(filepath)
- 
-     def load_native(self, filepath):
-         """Load model."""
-         self.model = ke.models.load_model(filepath)
- 
-     @staticmethod
-     def _get_weights_names(obj):
-         """
-         Get the list of weight names.
- 
-         Parameters
-         ----------
-         obj : Model or Optimizer
-             The target object that we want to get the weights.
- 
-         Returns
-         -------
-         dict
-             The weight name list
-         """
-         weight_names = [weight.name for weight in obj.weights]
-         return weight_names
- 
-     @staticmethod
-     def _get_weights_dict(obj, suffix=''):
-         """
-         Get the dictionary of weights.
- 
-         Parameters
-         ----------
-         obj : Model or Optimizer
-             The target object that we want to get the weights.
- 
-         Returns
-         -------
-         dict
-             The weight dictionary.
-         """
-         weights_dict = {}
-         weight_names = [weight.name for weight in obj.weights]
-         weight_values = obj.get_weights()
-         for name, value in zip(weight_names, weight_values):
-             weights_dict[name + suffix] = value
-         return weights_dict
- 
-     @staticmethod
-     def _set_weights_dict(obj, weights_dict):
-         """Set the object weights with a dictionary.
- 
-         The obj can be a model or an optimizer.
- 
-         Args:
-             obj (Model or Optimizer): The target object that we want to set
-             the weights.
-             weights_dict (dict): The weight dictionary.
- 
-         Returns:
-             None
-         """
-         weight_names = [weight.name for weight in obj.weights]
-         weight_values = [weights_dict[name] for name in weight_names]
-         obj.set_weights(weight_values)
- 
-     def get_tensor_dict(self, with_opt_vars, suffix=''):
-         """
-         Get the model weights as a tensor dictionary.
- 
-         Parameters
-         ----------
-         with_opt_vars : bool
-             If we should include the optimizer's status.
-         suffix : string
-             Universally
- 
-         Returns:
-             dict: The tensor dictionary.
-         """
-         model_weights = self._get_weights_dict(self.model, suffix)
- 
-         if with_opt_vars:
-             opt_weights = self._get_weights_dict(self.model.optimizer, suffix)
- 
-             model_weights.update(opt_weights)
-             if len(opt_weights) == 0:
-                 self.logger.debug(
-                     "WARNING: We didn't find variables for the optimizer.")
-         return model_weights
- 
-     def set_tensor_dict(self, tensor_dict, with_opt_vars):
-         """
-         Set the model weights with a tensor dictionary.
- 
-         Args:
-             tensor_dict: the tensor dictionary
-             with_opt_vars (bool): True = include the optimizer's status.
-         """
-         if with_opt_vars is False:
-             # It is possible to pass in opt variables from the input tensor dict
-             # This will make sure that the correct layers are updated
-             model_weight_names = [weight.name for weight in self.model.weights]
-             model_weights_dict = {
-                 name: tensor_dict[name] for name in model_weight_names
-             }
-             self._set_weights_dict(self.model, model_weights_dict)
-         else:
-             model_weight_names = [
-                 weight.name for weight in self.model.weights
-             ]
-             model_weights_dict = {
-                 name: tensor_dict[name] for name in model_weight_names
-             }
-             opt_weight_names = [
-                 weight.name for weight in self.model.optimizer.weights
-             ]
-             opt_weights_dict = {
-                 name: tensor_dict[name] for name in opt_weight_names
-             }
-             self._set_weights_dict(self.model, model_weights_dict)
-             self._set_weights_dict(self.model.optimizer, opt_weights_dict)
- 
-     def reset_opt_vars(self):
-         """
-         Reset optimizer variables.
- 
-         Resets the optimizer variables
- 
-         """
-         for var in self.model.optimizer.variables():
-             var.assign(tf.zeros_like(var))
-         self.logger.debug('Optimizer variables reset')
- 
-     def set_required_tensorkeys_for_function(self, func_name,
-                                              tensor_key, **kwargs):
-         """
-         Set the required tensors for specified function that could be called as part of a task.
- 
-         By default, this is just all of the layers and optimizer of the model.
-          Custom tensors should be added to this function
- 
-         Parameters
-         ----------
-         func_name: string
-         tensor_key: TensorKey (namedtuple)
-         **kwargs: Any function arguments {}
- 
-         Returns
-         -------
-         None
-         """
-         # TODO there should be a way to programmatically iterate through all
-         #  of the methods in the class and declare the tensors.
-         # For now this is done manually
- 
-         if func_name == 'validate':
-             # Should produce 'apply=global' or 'apply=local'
-             local_model = 'apply' + kwargs['apply']
-             self.required_tensorkeys_for_function[func_name][
-                 local_model].append(tensor_key)
-         else:
-             self.required_tensorkeys_for_function[func_name].append(tensor_key)
- 
-     def get_required_tensorkeys_for_function(self, func_name, **kwargs):
-         """
-         Get the required tensors for specified function that could be called as part of a task.
- 
-         By default, this is just all of the layers and optimizer of the model.
- 
-         Parameters
-         ----------
-         None
- 
-         Returns
-         -------
-         List
-             [TensorKey]
-         """
-         if func_name == 'validate':
-             local_model = 'apply=' + str(kwargs['apply'])
-             return self.required_tensorkeys_for_function[func_name][local_model]
-         else:
-             return self.required_tensorkeys_for_function[func_name]
- 
-     def update_tensorkeys_for_functions(self):
-         """
-         Update the required tensors for all publicly accessible methods \
-             that could be called as part of a task.
- 
-         By default, this is just all of the layers and optimizer of the model.
-         Custom tensors should be added to this function
- 
-         Parameters
-         ----------
-         None
- 
-         Returns
-         -------
-         None
-         """
-         # TODO complete this function. It is only needed for opt_treatment,
-         #  and making the model stateless
- 
-         # Minimal required tensors for train function
-         model_layer_names = self._get_weights_names(self.model)
-         opt_names = self._get_weights_names(self.model.optimizer)
-         tensor_names = model_layer_names + opt_names
-         self.logger.debug(f'Updating model tensor names: {tensor_names}')
-         self.required_tensorkeys_for_function['train'] = [
-             TensorKey(tensor_name, 'GLOBAL', 0, ('model',))
-             for tensor_name in tensor_names
-         ]
- 
-         # Validation may be performed on local or aggregated (global) model,
-         # so there is an extra lookup dimension for kwargs
-         self.required_tensorkeys_for_function['validate'] = {}
-         self.required_tensorkeys_for_function['validate']['local_model=True'] = [
-             TensorKey(tensor_name, 'LOCAL', 0, ('trained',))
-             for tensor_name in tensor_names
-         ]
-         self.required_tensorkeys_for_function['validate']['local_model=False'] = [
-             TensorKey(tensor_name, 'GLOBAL', 0, ('model',))
-             for tensor_name in tensor_names
-         ]
- 
-     def initialize_tensorkeys_for_functions(self, with_opt_vars=False):
-         """
-         Set the required tensors for all publicly accessible methods \
-             that could be called as part of a task.
- 
-         By default, this is just all of the layers and optimizer of the model.
-         Custom tensors should be added to this function
- 
-         Parameters
-         ----------
-         None
- 
-         Returns
-         -------
-         None
-         """
-         # TODO there should be a way to programmatically iterate through all
-         #  of the methods in the class and declare the tensors.
-         # For now this is done manually
- 
-         output_model_dict = self.get_tensor_dict(with_opt_vars=with_opt_vars)
-         global_model_dict, local_model_dict = split_tensor_dict_for_holdouts(
-             self.logger, output_model_dict,
-             **self.tensor_dict_split_fn_kwargs
-         )
-         if not with_opt_vars:
-             global_model_dict_val = global_model_dict
-             local_model_dict_val = local_model_dict
-         else:
-             output_model_dict = self.get_tensor_dict(with_opt_vars=False)
-             global_model_dict_val, local_model_dict_val = split_tensor_dict_for_holdouts(
-                 self.logger,
-                 output_model_dict,
-                 **self.tensor_dict_split_fn_kwargs
-             )
- 
-         self.required_tensorkeys_for_function['train'] = [
-             TensorKey(tensor_name, 'GLOBAL', 0, False, ('model',))
-             for tensor_name in global_model_dict
-         ]
-         self.required_tensorkeys_for_function['train'] += [
-             TensorKey(tensor_name, 'LOCAL', 0, False, ('model',))
-             for tensor_name in local_model_dict
-         ]
- 
-         # Validation may be performed on local or aggregated (global) model,
-         # so there is an extra lookup dimension for kwargs
-         self.required_tensorkeys_for_function['validate'] = {}
-         # TODO This is not stateless. The optimizer will not be
-         self.required_tensorkeys_for_function['validate']['apply=local'] = [
-             TensorKey(tensor_name, 'LOCAL', 0, False, ('trained',))
-             for tensor_name in {
-                 **global_model_dict_val,
-                 **local_model_dict_val
-             }
-         ]
-         self.required_tensorkeys_for_function['validate']['apply=global'] = [
-             TensorKey(tensor_name, 'GLOBAL', 0, False, ('model',))
-             for tensor_name in global_model_dict_val
-         ]
-         self.required_tensorkeys_for_function['validate']['apply=global'] += [
-             TensorKey(tensor_name, 'LOCAL', 0, False, ('model',))
-             for tensor_name in local_model_dict_val
-         ]
--- 0 ----
diff -crB --new-file ./openfl/openfl/federated/task/runner_pt.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/task/runner_pt.py
*** ./openfl/openfl/federated/task/runner_pt.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/task/runner_pt.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,670 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """PyTorchTaskRunner module."""
- 
- from copy import deepcopy
- from typing import Iterator
- from typing import Tuple
- 
- import numpy as np
- import torch as pt
- import torch.nn as nn
- import tqdm
- 
- from openfl.utilities import Metric
- from openfl.utilities import split_tensor_dict_for_holdouts
- from openfl.utilities import TensorKey
- from .runner import TaskRunner
- 
- 
- class PyTorchTaskRunner(nn.Module, TaskRunner):
-     """PyTorch Model class for Federated Learning."""
- 
-     def __init__(
-             self,
-             device: str = None,
-             loss_fn=None,
-             optimizer=None,
-             **kwargs
-     ):
-         """Initialize.
- 
-         Args:
-             device (string): Compute device (default="cpu")
-             **kwargs: Additional parameters to pass to the functions
-         """
-         super().__init__()
-         TaskRunner.__init__(self, **kwargs)
-         if device:
-             self.device = device
-         else:
-             self.device = pt.device('cuda' if pt.cuda.is_available() else 'cpu')
- 
-         # This is a map of all the required tensors for each of the public
-         # functions in PyTorchTaskRunner
-         self.required_tensorkeys_for_function = {}
- 
-         self.optimizer = optimizer
-         self.loss_fn = loss_fn
-         self.training_round_completed = False
- 
-         # overwrite attribute to account for one optimizer param (in every
-         # child model that does not overwrite get and set tensordict) that is
-         # not a numpy array
-         self.tensor_dict_split_fn_kwargs.update({
-             'holdout_tensor_names': ['__opt_state_needed']
-         })
- 
-     def rebuild_model(self, round_num, input_tensor_dict, validation=False):
-         """
-         Parse tensor names and update weights of model. Handles the optimizer treatment.
- 
-         Returns:
-             None
-         """
-         if self.opt_treatment == 'RESET':
-             self.reset_opt_vars()
-             self.set_tensor_dict(input_tensor_dict, with_opt_vars=False)
-         elif (self.training_round_completed
-               and self.opt_treatment == 'CONTINUE_GLOBAL' and not validation):
-             self.set_tensor_dict(input_tensor_dict, with_opt_vars=True)
-         else:
-             self.set_tensor_dict(input_tensor_dict, with_opt_vars=False)
- 
-     def validate(self, col_name, round_num, input_tensor_dict,
-                  use_tqdm=False, **kwargs):
-         """Validate.
- 
-         Run validation of the model on the local data.
- 
-         Args:
-             col_name:            Name of the collaborator
-             round_num:           What round is it
-             input_tensor_dict:   Required input tensors (for model)
-             use_tqdm (bool):     Use tqdm to print a progress bar (Default=True)
- 
-         Returns:
-             global_output_dict:  Tensors to send back to the aggregator
-             local_output_dict:   Tensors to maintain in the local TensorDB
- 
-         """
-         self.rebuild_model(round_num, input_tensor_dict, validation=True)
-         self.eval()
-         self.to(self.device)
-         val_score = 0
-         total_samples = 0
- 
-         loader = self.data_loader.get_valid_loader()
-         if use_tqdm:
-             loader = tqdm.tqdm(loader, desc='validate')
- 
-         with pt.no_grad():
-             for data, target in loader:
-                 samples = target.shape[0]
-                 total_samples += samples
-                 data, target = pt.tensor(data).to(self.device), pt.tensor(
-                     target).to(self.device, dtype=pt.int64)
-                 output = self(data)
-                 # get the index of the max log-probability
-                 pred = output.argmax(dim=1, keepdim=True)
-                 target_categorical = target.argmax(dim=1, keepdim=True)
-                 val_score += pred.eq(target_categorical).sum().cpu().numpy()
- 
-         origin = col_name
-         suffix = 'validate'
-         if kwargs['apply'] == 'local':
-             suffix += '_local'
-         else:
-             suffix += '_agg'
-         tags = ('metric', suffix)
-         # TODO figure out a better way to pass in metric for this pytorch
-         #  validate function
-         output_tensor_dict = {
-             TensorKey('acc', origin, round_num, True, tags):
-                 np.array(val_score / total_samples)
-         }
- 
-         # Empty list represents metrics that should only be stored locally
-         return output_tensor_dict, {}
- 
-     def train_batches(self, col_name, round_num, input_tensor_dict,
-                       use_tqdm=False, epochs=1, **kwargs):
-         """Train batches.
- 
-         Train the model on the requested number of batches.
- 
-         Args:
-             col_name:            Name of the collaborator
-             round_num:           What round is it
-             input_tensor_dict:   Required input tensors (for model)
-             use_tqdm (bool):     Use tqdm to print a progress bar (Default=True)
-             epochs:              The number of epochs to train
- 
-         Returns:
-             global_output_dict:  Tensors to send back to the aggregator
-             local_output_dict:   Tensors to maintain in the local TensorDB
-         """
-         self.rebuild_model(round_num, input_tensor_dict)
-         # set to "training" mode
-         self.train()
-         self.to(self.device)
-         for epoch in range(epochs):
-             self.logger.info(f'Run {epoch} epoch of {round_num} round')
-             loader = self.data_loader.get_train_loader()
-             if use_tqdm:
-                 loader = tqdm.tqdm(loader, desc='train epoch')
-             metric = self.train_epoch(loader)
-         # Output metric tensors (scalar)
-         origin = col_name
-         tags = ('trained',)
-         output_metric_dict = {
-             TensorKey(
-                 metric.name, origin, round_num, True, ('metric',)
-             ): metric.value
-         }
- 
-         # output model tensors (Doesn't include TensorKey)
-         output_model_dict = self.get_tensor_dict(with_opt_vars=True)
-         global_model_dict, local_model_dict = split_tensor_dict_for_holdouts(
-             self.logger, output_model_dict,
-             **self.tensor_dict_split_fn_kwargs
-         )
- 
-         # Create global tensorkeys
-         global_tensorkey_model_dict = {
-             TensorKey(tensor_name, origin, round_num, False, tags):
-                 nparray for tensor_name, nparray in global_model_dict.items()
-         }
-         # Create tensorkeys that should stay local
-         local_tensorkey_model_dict = {
-             TensorKey(tensor_name, origin, round_num, False, tags):
-                 nparray for tensor_name, nparray in local_model_dict.items()
-         }
-         # The train/validate aggregated function of the next round will look
-         # for the updated model parameters.
-         # This ensures they will be resolved locally
-         next_local_tensorkey_model_dict = {
-             TensorKey(tensor_name, origin, round_num + 1, False, ('model',)): nparray
-             for tensor_name, nparray in local_model_dict.items()}
- 
-         global_tensor_dict = {
-             **output_metric_dict,
-             **global_tensorkey_model_dict
-         }
-         local_tensor_dict = {
-             **local_tensorkey_model_dict,
-             **next_local_tensorkey_model_dict
-         }
- 
-         # Update the required tensors if they need to be pulled from the
-         # aggregator
-         # TODO this logic can break if different collaborators have different
-         # roles between rounds.
-         # For example, if a collaborator only performs validation in the first
-         # round but training in the second, it has no way of knowing the
-         # optimizer state tensor names to request from the aggregator because
-         # these are only created after training occurs. A work around could
-         # involve doing a single epoch of training on random data to get the
-         # optimizer names, and then throwing away the model.
-         if self.opt_treatment == 'CONTINUE_GLOBAL':
-             self.initialize_tensorkeys_for_functions(with_opt_vars=True)
- 
-         # This will signal that the optimizer values are now present,
-         # and can be loaded when the model is rebuilt
-         self.train_round_completed = True
- 
-         # Return global_tensor_dict, local_tensor_dict
-         return global_tensor_dict, local_tensor_dict
- 
-     def get_tensor_dict(self, with_opt_vars=False):
-         """Return the tensor dictionary.
- 
-         Args:
-             with_opt_vars (bool): Return the tensor dictionary including the
-                                   optimizer tensors (Default=False)
- 
-         Returns:
-             dict: Tensor dictionary {**dict, **optimizer_dict}
- 
-         """
-         # Gets information regarding tensor model layers and optimizer state.
-         # FIXME: self.parameters() instead? Unclear if load_state_dict() or
-         # simple assignment is better
-         # for now, state dict gives us names which is good
-         # FIXME: do both and sanity check each time?
- 
-         state = to_cpu_numpy(self.state_dict())
- 
-         if with_opt_vars:
-             opt_state = _get_optimizer_state(self.optimizer)
-             state = {**state, **opt_state}
- 
-         return state
- 
-     def _get_weights_names(self, with_opt_vars=False):
-         # Gets information regarding tensor model layers and optimizer state.
-         # FIXME: self.parameters() instead? Unclear if load_state_dict() or
-         # simple assignment is better
-         # for now, state dict gives us names which is good
-         # FIXME: do both and sanity check each time?
- 
-         state = self.state_dict().keys()
- 
-         if with_opt_vars:
-             opt_state = _get_optimizer_state(self.optimizer)
-             state += opt_state.keys()
- 
-         return state
- 
-     def set_tensor_dict(self, tensor_dict, with_opt_vars=False):
-         """Set the tensor dictionary.
- 
-         Args:
-             tensor_dict: The tensor dictionary
-             with_opt_vars (bool): Return the tensor dictionary including the
-                                   optimizer tensors (Default=False)
- 
-         """
-         # Sets tensors for model layers and optimizer state.
-         # FIXME: self.parameters() instead? Unclear if load_state_dict() or
-         #  simple assignment is better
-         # for now, state dict gives us names, which is good
-         # FIXME: do both and sanity check each time?
- 
-         # get device for correct placement of tensors
-         device = self.device
- 
-         new_state = {}
-         # Grabbing keys from model's state_dict helps to confirm we have
-         # everything
-         for k in self.state_dict():
-             new_state[k] = pt.from_numpy(tensor_dict.pop(k)).to(device)
- 
-         # set model state
-         self.load_state_dict(new_state)
- 
-         if with_opt_vars:
-             # see if there is state to restore first
-             if tensor_dict.pop('__opt_state_needed') == 'true':
-                 _set_optimizer_state(self.get_optimizer(), device, tensor_dict)
- 
-             # sanity check that we did not record any state that was not used
-             assert len(tensor_dict) == 0
- 
-     def get_optimizer(self):
-         """Get the optimizer of this instance."""
-         return self.optimizer
- 
-     def get_required_tensorkeys_for_function(self, func_name, **kwargs):
-         """
-         Get the required tensors for specified function that could be called \
-         as part of a task. By default, this is just all of the layers and \
-         optimizer of the model.
- 
-         Args:
-             func_name
- 
-         Returns:
-             list : [TensorKey]
-         """
-         if func_name == 'validate':
-             local_model = 'apply=' + str(kwargs['apply'])
-             return self.required_tensorkeys_for_function[func_name][local_model]
-         else:
-             return self.required_tensorkeys_for_function[func_name]
- 
-     def initialize_tensorkeys_for_functions(self, with_opt_vars=False):
-         """Set the required tensors for all publicly accessible task methods.
- 
-         By default, this is just all of the layers and optimizer of the model.
-         Custom tensors should be added to this function.
- 
-         Args:
-             None
- 
-         Returns:
-             None
-         """
-         # TODO there should be a way to programmatically iterate through
-         #  all of the methods in the class and declare the tensors.
-         # For now this is done manually
- 
-         output_model_dict = self.get_tensor_dict(with_opt_vars=with_opt_vars)
-         global_model_dict, local_model_dict = split_tensor_dict_for_holdouts(
-             self.logger, output_model_dict,
-             **self.tensor_dict_split_fn_kwargs
-         )
-         if not with_opt_vars:
-             global_model_dict_val = global_model_dict
-             local_model_dict_val = local_model_dict
-         else:
-             output_model_dict = self.get_tensor_dict(with_opt_vars=False)
-             global_model_dict_val, local_model_dict_val = split_tensor_dict_for_holdouts(
-                 self.logger,
-                 output_model_dict,
-                 **self.tensor_dict_split_fn_kwargs
-             )
- 
-         self.required_tensorkeys_for_function['train_batches'] = [
-             TensorKey(tensor_name, 'GLOBAL', 0, False, ('model',))
-             for tensor_name in global_model_dict]
-         self.required_tensorkeys_for_function['train_batches'] += [
-             TensorKey(tensor_name, 'LOCAL', 0, False, ('model',))
-             for tensor_name in local_model_dict]
- 
-         self.required_tensorkeys_for_function['train'] = [
-             TensorKey(
-                 tensor_name, 'GLOBAL', 0, False, ('model',)
-             ) for tensor_name in global_model_dict
-         ]
-         self.required_tensorkeys_for_function['train'] += [
-             TensorKey(
-                 tensor_name, 'LOCAL', 0, False, ('model',)
-             ) for tensor_name in local_model_dict
-         ]
- 
-         # Validation may be performed on local or aggregated (global) model,
-         # so there is an extra lookup dimension for kwargs
-         self.required_tensorkeys_for_function['validate'] = {}
-         # TODO This is not stateless. The optimizer will not be
-         self.required_tensorkeys_for_function['validate']['apply=local'] = [
-             TensorKey(tensor_name, 'LOCAL', 0, False, ('trained',))
-             for tensor_name in {
-                 **global_model_dict_val,
-                 **local_model_dict_val
-             }]
-         self.required_tensorkeys_for_function['validate']['apply=global'] = [
-             TensorKey(tensor_name, 'GLOBAL', 0, False, ('model',))
-             for tensor_name in global_model_dict_val
-         ]
-         self.required_tensorkeys_for_function['validate']['apply=global'] += [
-             TensorKey(tensor_name, 'LOCAL', 0, False, ('model',))
-             for tensor_name in local_model_dict_val
-         ]
- 
-     def load_native(self, filepath, model_state_dict_key='model_state_dict',
-                     optimizer_state_dict_key='optimizer_state_dict', **kwargs):
-         """
-         Load model and optimizer states from a pickled file specified by \
-         filepath. model_/optimizer_state_dict args can be specified if needed. \
-         Uses pt.load().
- 
-         Args:
-             filepath (string)                 : Path to pickle file created
-                                                 by pt.save().
-             model_state_dict_key (string)     : key for model state dict
-                                                 in pickled file.
-             optimizer_state_dict_key (string) : key for optimizer state dict
-                                                 in picked file.
-             kwargs                            : unused
- 
-         Returns:
-             None
-         """
-         pickle_dict = pt.load(filepath)
-         self.load_state_dict(pickle_dict[model_state_dict_key])
-         self.optimizer.load_state_dict(pickle_dict[optimizer_state_dict_key])
- 
-     def save_native(self, filepath, model_state_dict_key='model_state_dict',
-                     optimizer_state_dict_key='optimizer_state_dict', **kwargs):
-         """
-         Save model and optimizer states in a picked file specified by the \
-         filepath. model_/optimizer_state_dicts are stored in the keys provided. \
-         Uses pt.save().
- 
-         Args:
-             filepath (string)                 : Path to pickle file to be
-                                                 created by pt.save().
-             model_state_dict_key (string)     : key for model state dict
-                                                 in pickled file.
-             optimizer_state_dict_key (string) : key for optimizer state
-                                                 dict in picked file.
-             kwargs                            : unused
- 
-         Returns:
-             None
-         """
-         pickle_dict = {
-             model_state_dict_key: self.state_dict(),
-             optimizer_state_dict_key: self.optimizer.state_dict()
-         }
-         pt.save(pickle_dict, filepath)
- 
-     def reset_opt_vars(self):
-         """
-         Reset optimizer variables.
- 
-         Resets the optimizer variables
- 
-         """
-         pass
- 
-     def train_epoch(self, batch_generator: Iterator[Tuple[np.ndarray, np.ndarray]]) -> Metric:
-         """Train single epoch.
- 
-         Override this function in order to use custom training.
- 
-         Args:
-             batch_generator: Train dataset batch generator. Yields (samples, targets) tuples of
-             size = `self.data_loader.batch_size`.
-         Returns:
-             Metric: An object containing name and np.ndarray value.
-         """
-         losses = []
-         for data, target in batch_generator:
-             data, target = pt.tensor(data).to(self.device), pt.tensor(
-                 target).to(self.device)
-             self.optimizer.zero_grad()
-             output = self(data)
-             loss = self.loss_fn(output=output, target=target)
-             loss.backward()
-             self.optimizer.step()
-             losses.append(loss.detach().cpu().numpy())
-         loss = np.mean(losses)
-         return Metric(name=self.loss_fn.__name__, value=np.array(loss))
- 
- 
- def _derive_opt_state_dict(opt_state_dict):
-     """Separate optimizer tensors from the tensor dictionary.
- 
-     Flattens the optimizer state dict so as to have key, value pairs with
-     values as numpy arrays.
-     The keys have sufficient info to restore opt_state_dict using
-     expand_derived_opt_state_dict.
- 
-     Args:
-         opt_state_dict: The optimizer state dictionary
- 
-     """
-     derived_opt_state_dict = {}
- 
-     # Determine if state is needed for this optimizer.
-     if len(opt_state_dict['state']) == 0:
-         derived_opt_state_dict['__opt_state_needed'] = 'false'
-         return derived_opt_state_dict
- 
-     derived_opt_state_dict['__opt_state_needed'] = 'true'
- 
-     # Using one example state key, we collect keys for the corresponding
-     # dictionary value.
-     example_state_key = opt_state_dict['param_groups'][0]['params'][0]
-     example_state_subkeys = set(
-         opt_state_dict['state'][example_state_key].keys()
-     )
- 
-     # We assume that the state collected for all params in all param groups is
-     # the same.
-     # We also assume that whether or not the associated values to these state
-     # subkeys is a tensor depends only on the subkey.
-     # Using assert statements to break the routine if these assumptions are
-     # incorrect.
-     for state_key in opt_state_dict['state'].keys():
-         assert example_state_subkeys == set(opt_state_dict['state'][state_key].keys())
-         for state_subkey in example_state_subkeys:
-             assert (isinstance(
-                 opt_state_dict['state'][example_state_key][state_subkey],
-                 pt.Tensor)
-                 == isinstance(
-                     opt_state_dict['state'][state_key][state_subkey],
-                     pt.Tensor))
- 
-     state_subkeys = list(opt_state_dict['state'][example_state_key].keys())
- 
-     # Tags will record whether the value associated to the subkey is a
-     # tensor or not.
-     state_subkey_tags = []
-     for state_subkey in state_subkeys:
-         if isinstance(
-                 opt_state_dict['state'][example_state_key][state_subkey],
-                 pt.Tensor
-         ):
-             state_subkey_tags.append('istensor')
-         else:
-             state_subkey_tags.append('')
-     state_subkeys_and_tags = list(zip(state_subkeys, state_subkey_tags))
- 
-     # Forming the flattened dict, using a concatenation of group index,
-     # subindex, tag, and subkey inserted into the flattened dict key -
-     # needed for reconstruction.
-     nb_params_per_group = []
-     for group_idx, group in enumerate(opt_state_dict['param_groups']):
-         for idx, param_id in enumerate(group['params']):
-             for subkey, tag in state_subkeys_and_tags:
-                 if tag == 'istensor':
-                     new_v = opt_state_dict['state'][param_id][
-                         subkey].cpu().numpy()
-                 else:
-                     new_v = np.array(
-                         [opt_state_dict['state'][param_id][subkey]]
-                     )
-                 derived_opt_state_dict[f'__opt_state_{group_idx}_{idx}_{tag}_{subkey}'] = new_v
-         nb_params_per_group.append(idx + 1)
-     # group lengths are also helpful for reconstructing
-     # original opt_state_dict structure
-     derived_opt_state_dict['__opt_group_lengths'] = np.array(
-         nb_params_per_group
-     )
- 
-     return derived_opt_state_dict
- 
- 
- def expand_derived_opt_state_dict(derived_opt_state_dict, device):
-     """Expand the optimizer state dictionary.
- 
-     Takes a derived opt_state_dict and creates an opt_state_dict suitable as
-     input for load_state_dict for restoring optimizer state.
- 
-     Reconstructing state_subkeys_and_tags using the example key
-     prefix, "__opt_state_0_0_", certain to be present.
- 
-     Args:
-         derived_opt_state_dict: Optimizer state dictionary
- 
-     Returns:
-         dict: Optimizer state dictionary
-     """
-     state_subkeys_and_tags = []
-     for key in derived_opt_state_dict:
-         if key.startswith('__opt_state_0_0_'):
-             stripped_key = key[16:]
-             if stripped_key.startswith('istensor_'):
-                 this_tag = 'istensor'
-                 subkey = stripped_key[9:]
-             else:
-                 this_tag = ''
-                 subkey = stripped_key[1:]
-             state_subkeys_and_tags.append((subkey, this_tag))
- 
-     opt_state_dict = {'param_groups': [], 'state': {}}
-     nb_params_per_group = list(
-         derived_opt_state_dict.pop('__opt_group_lengths').astype(np.int)
-     )
- 
-     # Construct the expanded dict.
-     for group_idx, nb_params in enumerate(nb_params_per_group):
-         these_group_ids = [f'{group_idx}_{idx}' for idx in range(nb_params)]
-         opt_state_dict['param_groups'].append({'params': these_group_ids})
-         for this_id in these_group_ids:
-             opt_state_dict['state'][this_id] = {}
-             for subkey, tag in state_subkeys_and_tags:
-                 flat_key = f'__opt_state_{this_id}_{tag}_{subkey}'
-                 if tag == 'istensor':
-                     new_v = pt.from_numpy(derived_opt_state_dict.pop(flat_key))
-                 else:
-                     # Here (for currrently supported optimizers) the subkey
-                     # should be 'step' and the length of array should be one.
-                     assert subkey == 'step'
-                     assert len(derived_opt_state_dict[flat_key]) == 1
-                     new_v = int(derived_opt_state_dict.pop(flat_key))
-                 opt_state_dict['state'][this_id][subkey] = new_v
- 
-     # sanity check that we did not miss any optimizer state
-     assert len(derived_opt_state_dict) == 0
- 
-     return opt_state_dict
- 
- 
- def _get_optimizer_state(optimizer):
-     """Return the optimizer state.
- 
-     Args:
-         optimizer
-     """
-     opt_state_dict = deepcopy(optimizer.state_dict())
- 
-     # Optimizer state might not have some parts representing frozen parameters
-     # So we do not synchronize them
-     param_keys_with_state = set(opt_state_dict['state'].keys())
-     for group in opt_state_dict['param_groups']:
-         local_param_set = set(group['params'])
-         params_to_sync = local_param_set & param_keys_with_state
-         group['params'] = sorted(params_to_sync)
- 
-     derived_opt_state_dict = _derive_opt_state_dict(opt_state_dict)
- 
-     return derived_opt_state_dict
- 
- 
- def _set_optimizer_state(optimizer, device, derived_opt_state_dict):
-     """Set the optimizer state.
- 
-     Args:
-         optimizer:
-         device:
-         derived_opt_state_dict:
- 
-     """
-     temp_state_dict = expand_derived_opt_state_dict(
-         derived_opt_state_dict, device)
- 
-     # FIXME: Figure out whether or not this breaks learning rate
-     #  scheduling and the like.
-     # Setting default values.
-     # All optimizer.defaults are considered as not changing over course of
-     # training.
-     for group in temp_state_dict['param_groups']:
-         for k, v in optimizer.defaults.items():
-             group[k] = v
- 
-     optimizer.load_state_dict(temp_state_dict)
- 
- 
- def to_cpu_numpy(state):
-     """Send data to CPU as Numpy array.
- 
-     Args:
-         state
- 
-     """
-     # deep copy so as to decouple from active model
-     state = deepcopy(state)
- 
-     for k, v in state.items():
-         # When restoring, we currently assume all values are tensors.
-         if not pt.is_tensor(v):
-             raise ValueError('We do not currently support non-tensors '
-                              'coming from model.state_dict()')
-         # get as a numpy array, making sure is on cpu
-         state[k] = v.cpu().numpy()
-     return state
--- 0 ----
diff -crB --new-file ./openfl/openfl/federated/task/runner.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/task/runner.py
*** ./openfl/openfl/federated/task/runner.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/task/runner.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,215 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """
- Mixin class for FL models. No default implementation.
- 
- Each framework will likely have its own baseclass implementation (e.g.
- TensorflowTaskRunner) that uses this mixin.
- 
- You may copy use this file or the appropriate framework-specific base-class to
- port your own models.
- """
- 
- from logging import getLogger
- 
- 
- class TaskRunner:
-     """Federated Learning Task Runner Class."""
- 
-     def __init__(self, data_loader, tensor_dict_split_fn_kwargs: dict = None, **kwargs):
-         """
-         Intialize.
- 
-         Args:
-             data_loader: The data_loader object
-             tensor_dict_split_fn_kwargs: (Default=None)
-             **kwargs: Additional parameters to pass to the function
-         """
-         self.data_loader = data_loader
-         self.feature_shape = self.data_loader.get_feature_shape()
-         # TODO: Should this comment a path of the doc string?
-         # key word arguments for determining which parameters to hold out from
-         # aggregation.
-         # If set to none, an empty dict will be passed, currently resulting in
-         # the defaults:
-         # be held out
-         # holdout_tensor_names=[]     # params with these names will be held out  # NOQA:E800
-         # TODO: params are restored from protobufs as float32 numpy arrays, so
-         # non-floats arrays and non-arrays are not currently supported for
-         # passing to and from protobuf (and as a result for aggregation) - for
-         # such params in current examples, aggregation does not make sense
-         # anyway, but if this changes support should be added.
-         if tensor_dict_split_fn_kwargs is None:
-             tensor_dict_split_fn_kwargs = {}
-         self.tensor_dict_split_fn_kwargs = tensor_dict_split_fn_kwargs
-         self.set_logger()
- 
-     def set_logger(self):
-         """Set up the log object."""
-         self.logger = getLogger(__name__)
- 
-     def set_optimizer_treatment(self, opt_treatment):
-         """Change the treatment of current instance optimizer."""
-         self.opt_treatment = opt_treatment
- 
-     def get_data_loader(self):
-         """
-         Get the data_loader object.
- 
-         Serves up batches and provides info regarding data_loader.
- 
-         Returns:
-             data_loader object
-         """
-         return self.data_loader
- 
-     def set_data_loader(self, data_loader):
-         """Set data_loader object.
- 
-         Args:
-             data_loader: data_loader object to set
-         Returns:
-             None
-         """
-         if data_loader.get_feature_shape() != self.data_loader.get_feature_shape():
-             raise ValueError(
-                 'The data_loader feature shape is not compatible with model.')
- 
-         self.data_loader = data_loader
- 
-     def get_train_data_size(self):
-         """
-         Get the number of training examples.
- 
-         It will be used for weighted averaging in aggregation.
- 
-         Returns:
-             int: The number of training examples.
-         """
-         return self.data_loader.get_train_data_size()
- 
-     def get_valid_data_size(self):
-         """
-         Get the number of examples.
- 
-         It will be used for weighted averaging in aggregation.
- 
-         Returns:
-             int: The number of validation examples.
-         """
-         return self.data_loader.get_valid_data_size()
- 
-     def train_batches(self, num_batches=None, use_tqdm=False):
-         """
-         Perform the training for a specified number of batches.
- 
-         Is expected to perform draws randomly, without
-         replacement until data is exausted. Then data is replaced and
-         shuffled and draws continue.
- 
-         Args:
-             num_batches: Number of batches to train
-             use_tdqm (bool): True = use tqdm progress bar (Default=False)
- 
-         Returns:
-             dict: {<metric>: <value>}
-         """
-         raise NotImplementedError
- 
-     def validate(self):
-         """
-         Run validation.
- 
-         Returns:
-             dict: {<metric>: <value>}
-         """
-         raise NotImplementedError
- 
-     def get_required_tensorkeys_for_function(self, func_name, **kwargs):
-         """
-         When running a task, a map of named tensorkeys \
-             must be provided to the function as dependencies.
- 
-         Returns:
-             list: (TensorKey(tensor_name, origin, round_number))
-         """
-         raise NotImplementedError
- 
-     def get_tensor_dict(self, with_opt_vars):
-         """
-         Get the weights.
- 
-         Args:
-             with_opt_vars (bool): Specify if we also want to get the variables
-                                   of the optimizer.
- 
-         Returns:
-             dict: The weight dictionary {<tensor_name>: <value>}
-         """
-         raise NotImplementedError
- 
-     def set_tensor_dict(self, tensor_dict, with_opt_vars):
-         """
-         Set the model weights with a tensor dictionary:\
-         {<tensor_name>: <value>}.
- 
-         Args:
-             tensor_dict (dict): The model weights dictionary.
-             with_opt_vars (bool): Specify if we also want to set the variables
-                                   of the optimizer.
- 
-         Returns:
-             None
-         """
-         raise NotImplementedError
- 
-     def reset_opt_vars(self):
-         """Reinitialize the optimizer variables."""
-         raise NotImplementedError
- 
-     def initialize_globals(self):
-         """
-         Initialize all global variables.
- 
-         Returns:
-             None
-         """
-         raise NotImplementedError
- 
-     def load_native(self, filepath, **kwargs):
-         """
-         Load model state from a filepath in ML-framework "native" format, \
-             e.g. PyTorch pickled models.
- 
-         May load from multiple files. Other filepaths may be derived from the
-         passed filepath, or they may be in the kwargs.
- 
-         Args:
-             filepath (string): Path to frame-work specific file to load. For
-             frameworks that use multiple files, this string must be used to
-             derive the other filepaths.
-             kwargs           : For future-proofing
- 
-         Returns:
-             None
-         """
-         raise NotImplementedError
- 
-     def save_native(self, filepath, **kwargs):
-         """
-         Save model state in ML-framework "native" format, e.g. PyTorch pickled models.
- 
-         May save one file or multiple files, depending on the framework.
- 
-         Args:
-             filepath (string): If framework stores a single file, this should
-                                be a single file path.
-             Frameworks that store multiple files may need to derive the other
-             paths from this path.
-             kwargs           : For future-proofing
- 
-         Returns:
-             None
-         """
-         raise NotImplementedError
--- 0 ----
diff -crB --new-file ./openfl/openfl/federated/task/runner_tf.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/task/runner_tf.py
*** ./openfl/openfl/federated/task/runner_tf.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/task/runner_tf.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,445 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """TensorFlowTaskRunner module."""
- 
- import numpy as np
- import tensorflow.compat.v1 as tf
- from tqdm import tqdm
- 
- from openfl.utilities import split_tensor_dict_for_holdouts
- from openfl.utilities import TensorKey
- from .runner import TaskRunner
- 
- 
- class TensorFlowTaskRunner(TaskRunner):
-     """
-     Base class for TensorFlow models in the Federated Learning solution.
- 
-         child classes should have __init__ function signature (self, data, kwargs),
-         and should overwrite at least the following while defining the model
-     """
- 
-     def __init__(self, **kwargs):
-         """
-         Initialize.
- 
-         Args:
-             **kwargs: Additional parameters to pass to the function
-         """
-         tf.disable_v2_behavior()
- 
-         super().__init__(**kwargs)
- 
-         self.assign_ops = None
-         self.placeholders = None
- 
-         self.tvar_assign_ops = None
-         self.tvar_placeholders = None
- 
-         # construct the shape needed for the input features
-         self.input_shape = (None,) + self.data_loader.get_feature_shape()
- 
-         # Required tensorkeys for all public functions in TensorFlowTaskRunner
-         self.required_tensorkeys_for_function = {}
- 
-         # Required tensorkeys for all public functions in TensorFlowTaskRunner
-         self.required_tensorkeys_for_function = {}
- 
-         # tensorflow session
-         self.sess = None
-         # input featrures to the model
-         self.X = None
-         # input labels to the model
-         self.y = None
-         # optimizer train step operation
-         self.train_step = None
-         # model loss function
-         self.loss = None
-         # model output tensor
-         self.output = None
-         # function used to validate the model outputs against labels
-         self.validation_metric = None
-         # tensorflow trainable variables
-         self.tvars = None
-         # self.optimizer.variables() once self.optimizer is defined
-         self.opt_vars = None
-         # self.tvars + self.opt_vars
-         self.fl_vars = None
- 
-     def rebuild_model(self, round_num, input_tensor_dict, validation=False):
-         """
-         Parse tensor names and update weights of model. Handles the optimizer treatment.
- 
-         Returns:
-             None
-         """
-         if self.opt_treatment == 'RESET':
-             self.reset_opt_vars()
-             self.set_tensor_dict(input_tensor_dict, with_opt_vars=False)
-         elif (round_num > 0 and self.opt_treatment == 'CONTINUE_GLOBAL'
-               and not validation):
-             self.set_tensor_dict(input_tensor_dict, with_opt_vars=True)
-         else:
-             self.set_tensor_dict(input_tensor_dict, with_opt_vars=False)
- 
-     def train_batches(self, col_name, round_num, input_tensor_dict,
-                       epochs=1, use_tqdm=False, **kwargs):
-         """
-         Perform the training.
- 
-         Is expected to perform draws randomly, without replacement until data is exausted. Then
-         data is replaced and shuffled and draws continue.
- 
-         Args:
-             use_tqdm (bool): True = use tqdm to print a progress
-              bar (Default=False)
-             epochs (int): Number of epochs to train
-         Returns:
-             float: loss metric
-         """
-         batch_size = self.data_loader.batch_size
- 
-         if kwargs['batch_size']:
-             batch_size = kwargs['batch_size']
- 
-         # rebuild model with updated weights
-         self.rebuild_model(round_num, input_tensor_dict)
- 
-         tf.keras.backend.set_learning_phase(True)
-         losses = []
- 
-         for epoch in range(epochs):
-             self.logger.info(f'Run {epoch} epoch of {round_num} round')
-             # get iterator for batch draws (shuffling happens here)
-             gen = self.data_loader.get_train_loader(batch_size)
-             if use_tqdm:
-                 gen = tqdm.tqdm(gen, desc='training epoch')
- 
-             for (X, y) in gen:
-                 losses.append(self.train_batch(X, y))
- 
-         # Output metric tensors (scalar)
-         origin = col_name
-         tags = ('trained',)
-         output_metric_dict = {
-             TensorKey(
-                 self.loss_name, origin, round_num, True, ('metric',)
-             ): np.array(np.mean(losses))
-         }
- 
-         # output model tensors (Doesn't include TensorKey)
-         output_model_dict = self.get_tensor_dict(with_opt_vars=True)
-         global_model_dict, local_model_dict = split_tensor_dict_for_holdouts(
-             self.logger, output_model_dict,
-             **self.tensor_dict_split_fn_kwargs
-         )
- 
-         # Create global tensorkeys
-         global_tensorkey_model_dict = {
-             TensorKey(tensor_name, origin, round_num, False, tags):
-                 nparray for tensor_name, nparray in global_model_dict.items()
-         }
-         # Create tensorkeys that should stay local
-         local_tensorkey_model_dict = {
-             TensorKey(tensor_name, origin, round_num, False, tags):
-                 nparray for tensor_name, nparray in local_model_dict.items()
-         }
-         # The train/validate aggregated function of the next round will
-         # look for the updated model parameters.
-         # This ensures they will be resolved locally
-         next_local_tensorkey_model_dict = {
-             TensorKey(
-                 tensor_name, origin, round_num + 1, False, ('model',)
-             ): nparray for tensor_name, nparray in local_model_dict.items()}
- 
-         global_tensor_dict = {
-             **output_metric_dict,
-             **global_tensorkey_model_dict
-         }
-         local_tensor_dict = {
-             **local_tensorkey_model_dict,
-             **next_local_tensorkey_model_dict
-         }
- 
-         # Update the required tensors if they need to be pulled from
-         # the aggregator
-         # TODO this logic can break if different collaborators have different
-         #  roles between rounds.
-         # For example, if a collaborator only performs validation in the first
-         # round but training in the second, it has no way of knowing the
-         # optimizer state tensor names to request from the aggregator because
-         # these are only created after training occurs. A work around could
-         # involve doing a single epoch of training on random data to get the
-         # optimizer names, and then throwing away the model.
-         if self.opt_treatment == 'CONTINUE_GLOBAL':
-             self.initialize_tensorkeys_for_functions(with_opt_vars=True)
- 
-         return global_tensor_dict, local_tensor_dict
- 
-     def train_batch(self, X, y):
-         """
-         Train the model on a single batch.
- 
-         Args:
-             X: Input to the model
-             y: Ground truth label to the model
- 
-         Returns:
-             float: loss metric
-         """
-         feed_dict = {self.X: X, self.y: y}
- 
-         # run the train step and return the loss
-         _, loss = self.sess.run([self.train_step, self.loss], feed_dict=feed_dict)
- 
-         return loss
- 
-     def validate(self, col_name, round_num,
-                  input_tensor_dict, use_tqdm=False, **kwargs):
-         """
-         Run validation.
- 
-         Returns:
-             dict: {<metric>: <value>}
-         """
-         batch_size = self.data_loader.batch_size
- 
-         if kwargs['batch_size']:
-             batch_size = kwargs['batch_size']
- 
-         self.rebuild_model(round_num, input_tensor_dict, validation=True)
- 
-         tf.keras.backend.set_learning_phase(False)
- 
-         score = 0
- 
-         gen = self.data_loader.get_valid_loader(batch_size)
-         if use_tqdm:
-             gen = tqdm.tqdm(gen, desc='validating')
- 
-         for X, y in gen:
-             weight = X.shape[0] / self.data_loader.get_valid_data_size()
-             _, s = self.validate_batch(X, y)
-             score += s * weight
- 
-         origin = col_name
-         suffix = 'validate'
-         if kwargs['apply'] == 'local':
-             suffix += '_local'
-         else:
-             suffix += '_agg'
-         tags = ('metric', suffix)
-         output_tensor_dict = {
-             TensorKey(
-                 self.validation_metric_name, origin, round_num, True, tags
-             ): np.array(score)}
- 
-         # return empty dict for local metrics
-         return output_tensor_dict, {}
- 
-     def validate_batch(self, X, y):
-         """Validate the model on a single local batch.
- 
-         Args:
-             X: Input to the model
-             y: Ground truth label to the model
- 
-         Returns:
-             float: loss metric
- 
-         """
-         feed_dict = {self.X: X, self.y: y}
- 
-         return self.sess.run(
-             [self.output, self.validation_metric], feed_dict=feed_dict)
- 
-     def get_tensor_dict(self, with_opt_vars=True):
-         """Get the dictionary weights.
- 
-         Get the weights from the tensor
- 
-         Args:
-             with_opt_vars (bool): Specify if we also want to get the variables
-              of the optimizer
- 
-         Returns:
-             dict: The weight dictionary {<tensor_name>: <value>}
- 
-         """
-         if with_opt_vars is True:
-             variables = self.fl_vars
-         else:
-             variables = self.tvars
- 
-         # FIXME: do this in one call?
-         return {var.name: val for var, val in zip(
-             variables, self.sess.run(variables))}
- 
-     def set_tensor_dict(self, tensor_dict, with_opt_vars):
-         """Set the tensor dictionary.
- 
-         Set the model weights with a tensor
-          dictionary: {<tensor_name>: <value>}.
- 
-         Args:
-             tensor_dict (dict): The model weights dictionary
-             with_opt_vars (bool): Specify if we also want to set the variables
-              of the optimizer
- 
-         Returns:
-             None
-         """
-         if with_opt_vars:
-             self.assign_ops, self.placeholders = tf_set_tensor_dict(
-                 tensor_dict, self.sess, self.fl_vars,
-                 self.assign_ops, self.placeholders
-             )
-         else:
-             self.tvar_assign_ops, self.tvar_placeholders = tf_set_tensor_dict(
-                 tensor_dict,
-                 self.sess,
-                 self.tvars,
-                 self.tvar_assign_ops,
-                 self.tvar_placeholders
-             )
- 
-     def reset_opt_vars(self):
-         """Reinitialize the optimizer variables."""
-         for v in self.opt_vars:
-             v.initializer.run(session=self.sess)
- 
-     def initialize_globals(self):
-         """Initialize Global Variables.
- 
-         Initialize all global variables
- 
-         Returns:
-             None
-         """
-         self.sess.run(tf.global_variables_initializer())
- 
-     def _get_weights_names(self, with_opt_vars=True):
-         """Get the weights.
- 
-         Args:
-             with_opt_vars (bool): Specify if we also want to get the variables
-              of the optimizer.
- 
-         Returns:
-             list : The weight names list
-         """
-         if with_opt_vars is True:
-             variables = self.fl_vars
-         else:
-             variables = self.tvars
- 
-         return [var.name for var in variables]
- 
-     def get_required_tensorkeys_for_function(self, func_name, **kwargs):
-         """
-         Get the required tensors for specified function that could be called as part of a task.
- 
-         By default, this is just all of the layers and optimizer of the model.
- 
-         Returns:
-             list : [TensorKey]
-         """
-         if func_name == 'validate':
-             local_model = 'apply=' + str(kwargs['apply'])
-             return self.required_tensorkeys_for_function[func_name][local_model]
-         else:
-             return self.required_tensorkeys_for_function[func_name]
- 
-     def initialize_tensorkeys_for_functions(self, with_opt_vars=False):
-         """
-         Set the required tensors for all publicly accessible methods \
-             that could be called as part of a task.
- 
-         By default, this is just all of the layers and optimizer of the model.
-         Custom tensors should be added to this function
- 
-         """
-         # TODO there should be a way to programmatically iterate through
-         #  all of the methods in the class and declare the tensors.
-         # For now this is done manually
- 
-         output_model_dict = self.get_tensor_dict(with_opt_vars=with_opt_vars)
-         global_model_dict, local_model_dict = split_tensor_dict_for_holdouts(
-             self.logger, output_model_dict,
-             **self.tensor_dict_split_fn_kwargs
-         )
-         if not with_opt_vars:
-             global_model_dict_val = global_model_dict
-             local_model_dict_val = local_model_dict
-         else:
-             output_model_dict = self.get_tensor_dict(with_opt_vars=False)
-             global_model_dict_val, local_model_dict_val = split_tensor_dict_for_holdouts(
-                 self.logger,
-                 output_model_dict,
-                 **self.tensor_dict_split_fn_kwargs
-             )
- 
-         self.required_tensorkeys_for_function['train_batches'] = [
-             TensorKey(tensor_name, 'GLOBAL', 0, False, ('model',))
-             for tensor_name in global_model_dict]
-         self.required_tensorkeys_for_function['train_batches'] += [
-             TensorKey(tensor_name, 'LOCAL', 0, False, ('model',))
-             for tensor_name in local_model_dict]
- 
-         # Validation may be performed on local or aggregated (global)
-         # model, so there is an extra lookup dimension for kwargs
-         self.required_tensorkeys_for_function['validate'] = {}
-         # TODO This is not stateless. The optimizer will not be
-         self.required_tensorkeys_for_function['validate']['apply=local'] = [
-             TensorKey(tensor_name, 'LOCAL', 0, False, ('trained',))
-             for tensor_name in {
-                 **global_model_dict_val,
-                 **local_model_dict_val
-             }
-         ]
-         self.required_tensorkeys_for_function['validate']['apply=global'] = [
-             TensorKey(tensor_name, 'GLOBAL', 0, False, ('model',))
-             for tensor_name in global_model_dict_val
-         ]
-         self.required_tensorkeys_for_function['validate']['apply=global'] += [
-             TensorKey(tensor_name, 'LOCAL', 0, False, ('model',))
-             for tensor_name in local_model_dict_val
-         ]
- 
- 
- # FIXME: what's a nicer construct than this? ugly interface. Perhaps we
- #  get an object with an assumed interface that lets is set/get these?
- # Note that this will return the assign_ops and placeholder nodes it uses
- # if called with None, it will create them.
- # to avoid inflating the graph, caller should keep these and pass them back
- # What if we want to set a different group of vars in the middle?
- # It is good if it is the subset of the original variables.
- def tf_set_tensor_dict(tensor_dict, session, variables,
-                        assign_ops=None, placeholders=None):
-     """Tensorflow set tensor dictionary.
- 
-     Args:
-         tensor_dict: Dictionary of tensors
-         session: TensorFlow session
-         variables: TensorFlow variables
-         assign_ops: TensorFlow operations (Default=None)
-         placeholders: TensorFlow placeholders (Default=None)
- 
-     Returns:
-         assign_ops, placeholders
- 
-     """
-     if placeholders is None:
-         placeholders = {
-             v.name: tf.placeholder(v.dtype, shape=v.shape) for v in variables
-         }
-     if assign_ops is None:
-         assign_ops = {
-             v.name: tf.assign(v, placeholders[v.name]) for v in variables
-         }
- 
-     for k, v in tensor_dict.items():
-         session.run(assign_ops[k], feed_dict={placeholders[k]: v})
- 
-     return assign_ops, placeholders
--- 0 ----
diff -crB --new-file ./openfl/openfl/federated/task/task_runner.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/task/task_runner.py
*** ./openfl/openfl/federated/task/task_runner.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/task/task_runner.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,381 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Interactive API package."""
- 
- from logging import getLogger
- 
- import numpy as np
- 
- from openfl.utilities import split_tensor_dict_for_holdouts
- from openfl.utilities import TensorKey
- 
- 
- class CoreTaskRunner:
-     """Federated Learning Task Runner Class."""
- 
-     def _prepare_tensorkeys_for_agggregation(self, metric_dict, validation_flag,
-                                              col_name, round_num):
-         """
-         Prepare tensorkeys for aggregation.
- 
-         Returns (global_tensor_dict, local_tensor_dict)
-         """
-         global_tensor_dict, local_tensor_dict = {}, {}
-         origin = col_name
-         if not validation_flag:
-             # Output metric tensors (scalar)
-             tags = ('trained',)
- 
-             # output model tensors (Doesn't include TensorKey)
-             output_model_dict = self.get_tensor_dict(with_opt_vars=True)
-             global_model_dict, local_model_dict = split_tensor_dict_for_holdouts(
-                 self.logger, output_model_dict,
-                 **self.tensor_dict_split_fn_kwargs
-             )
- 
-             # Create global tensorkeys
-             global_tensorkey_model_dict = {
-                 TensorKey(tensor_name, origin, round_num, False, tags):
-                     nparray for tensor_name, nparray in global_model_dict.items()}
-             # Create tensorkeys that should stay local
-             local_tensorkey_model_dict = {
-                 TensorKey(tensor_name, origin, round_num, False, tags):
-                     nparray for tensor_name, nparray in local_model_dict.items()}
-             # The train/validate aggregated function of the next
-             # round will look for the updated model parameters.
-             # This ensures they will be resolved locally
-             next_local_tensorkey_model_dict = {TensorKey(
-                 tensor_name, origin, round_num + 1, False, ('model',)): nparray
-                 for tensor_name, nparray in local_model_dict.items()}
- 
-             global_tensor_dict = global_tensorkey_model_dict
-             local_tensor_dict = {**local_tensorkey_model_dict, **next_local_tensorkey_model_dict}
- 
-             # Update the required tensors if they need to be
-             # pulled from the aggregator
-             # TODO this logic can break if different collaborators
-             #  have different roles between rounds.
-             # For example, if a collaborator only performs validation
-             # in the first round but training
-             # in the second, it has no way of knowing the optimizer
-             # state tensor names to request from the aggregator
-             # because these are only created after training occurs.
-             # A work around could involve doing a single epoch of training
-             # on random data to get the optimizer names,
-             # and then throwing away the model.
-             if self.opt_treatment == 'CONTINUE_GLOBAL':
-                 self.initialize_tensorkeys_for_functions(with_opt_vars=True)
- 
-             # This will signal that the optimizer values are now present,
-             # and can be loaded when the model is rebuilt
-             self.training_round_completed = True
- 
-         else:
-             suffix = 'validate' + validation_flag
-             tags = (suffix,)
-         tags = ('metric', *tags)
-         metric_dict = {
-             TensorKey(metric, origin, round_num, True, tags):
-                 np.array(value) for metric, value in metric_dict.items()
-         }
-         global_tensor_dict = {**global_tensor_dict, **metric_dict}
- 
-         return global_tensor_dict, local_tensor_dict
- 
-     def adapt_tasks(self):
-         """
-         Prepare tasks for the collaborator.
- 
-         Using functions from a task provider (deserialized interface object) and
-         registered task contracts prepares callable tasks to be invoked by the collaborator.
- 
-         Preparing includes conditional model rebuilding and filling output dicts
-         with tensors for aggregation and storing in local DB.
- 
-         There is an assumption that any training task accepts optimizer as one
-         of the arguments, thus the model should be aggregated after such tasks.
-         """
- 
-         def task_binder(task_name, callable_task):
-             def collaborator_adapted_task(col_name, round_num, input_tensor_dict, **kwargs):
-                 task_contract = self.task_provider.task_contract[task_name]
-                 # Validation flag can be [False, '_local', '_agg']
-                 validation_flag = True if task_contract['optimizer'] is None else False
-                 task_settings = self.task_provider.task_settings[task_name]
- 
-                 device = kwargs.get('device', 'cpu')
- 
-                 self.rebuild_model(input_tensor_dict, validation=validation_flag, device=device)
-                 task_kwargs = {}
-                 if validation_flag:
-                     loader = self.data_loader.get_valid_loader()
-                     if kwargs['apply'] == 'local':
-                         validation_flag = '_local'
-                     else:
-                         validation_flag = '_agg'
-                 else:
-                     loader = self.data_loader.get_train_loader()
-                     # If train task we also pass optimizer
-                     task_kwargs[task_contract['optimizer']] = self.optimizer
- 
-                 if task_contract['round_num'] is not None:
-                     task_kwargs[task_contract['round_num']] = round_num
- 
-                 for en_name, entity in zip(['model', 'data_loader', 'device'],
-                                            [self.model, loader, device]):
-                     task_kwargs[task_contract[en_name]] = entity
- 
-                 # Add task settings to the keyword arguments
-                 task_kwargs.update(task_settings)
- 
-                 # Here is the training metod call
-                 metric_dict = callable_task(**task_kwargs)
- 
-                 return self._prepare_tensorkeys_for_agggregation(
-                     metric_dict, validation_flag, col_name, round_num)
- 
-             return collaborator_adapted_task
- 
-         for task_name, callable_task in self.task_provider.task_registry.items():
-             self.TASK_REGISTRY[task_name] = task_binder(task_name, callable_task)
- 
-     def __init__(self, **kwargs):
-         """
-         Initialize Task Runner.
- 
-         This class is a part of the Interactive python API release.
-         It is no longer a user interface entity that should be subclassed
-         but a part of OpenFL kernel.
-         """
-         self.set_logger()
- 
-         self.kwargs = kwargs
- 
-         self.TASK_REGISTRY = {}
- 
-         # Why is it here
-         self.opt_treatment = 'RESET'
-         self.tensor_dict_split_fn_kwargs = {}
-         self.required_tensorkeys_for_function = {}
- 
-         # Complete hell below
-         self.training_round_completed = False
-         # overwrite attribute to account for one optimizer param (in every
-         # child model that does not overwrite get and set tensordict) that is
-         # not a numpy array
-         self.tensor_dict_split_fn_kwargs.update({
-             'holdout_tensor_names': ['__opt_state_needed']
-         })
- 
-     def set_task_provider(self, task_provider):
-         """
-         Set task registry.
- 
-         This method recieves Task Interface object as an argument
-         and uses provided callables and information to prepare
-         tasks that may be called by the collaborator component.
-         """
-         if task_provider is None:
-             return
-         self.task_provider = task_provider
-         self.adapt_tasks()
- 
-     def set_data_loader(self, data_loader):
-         """Register a data loader initialized with local data path."""
-         self.data_loader = data_loader
- 
-     def set_model_provider(self, model_provider):
-         """Retrieve a model and an optimizer from the interface object."""
-         self.model_provider = model_provider
-         self.model = self.model_provider.provide_model()
-         self.optimizer = self.model_provider.provide_optimizer()
- 
-     def set_framework_adapter(self, framework_adapter):
-         """
-         Set framework adapter.
- 
-         Setting a framework adapter allows first extraction of the weigths
-         of the model with the purpose to make a list of parameters to be aggregated.
-         """
-         self.framework_adapter = framework_adapter
-         if self.opt_treatment == 'CONTINUE_GLOBAL':
-             aggregate_optimizer_parameters = True
-         else:
-             aggregate_optimizer_parameters = False
-         self.initialize_tensorkeys_for_functions(with_opt_vars=aggregate_optimizer_parameters)
- 
-     def set_logger(self):
-         """Set up the log object."""
-         self.logger = getLogger(__name__)
- 
-     def set_optimizer_treatment(self, opt_treatment):
-         # SHould be removed! We have this info at the initialization time
-         # and do not change this one during training.
-         """Change the treatment of current instance optimizer."""
-         self.opt_treatment = opt_treatment
- 
-     def rebuild_model(self, input_tensor_dict, validation=False, device='cpu'):
-         """
-         Parse tensor names and update weights of model. Handles the optimizer treatment.
- 
-         Returns:
-             None
-         """
-         if self.opt_treatment == 'RESET':
-             self.reset_opt_vars()
-             self.set_tensor_dict(input_tensor_dict, with_opt_vars=False, device=device)
-         elif (self.training_round_completed
-               and self.opt_treatment == 'CONTINUE_GLOBAL' and not validation):
-             self.set_tensor_dict(input_tensor_dict, with_opt_vars=True, device=device)
-         else:
-             self.set_tensor_dict(input_tensor_dict, with_opt_vars=False, device=device)
- 
-     def get_required_tensorkeys_for_function(self, func_name, **kwargs):
-         """
-         Get the required tensors for specified function that could be called as part of a task.
- 
-         By default, this is just all of the layers and optimizer of the model.
- 
-         Parameters
-         ----------
-         None
- 
-         Returns
-         -------
-         List
-             [TensorKey]
-         """
-         # We rely on validation type tasks parameter `apply`
-         # In the interface layer we add those parameters automatically
-         if 'apply' not in kwargs:
-             return [
-                 TensorKey(tensor_name, 'GLOBAL', 0, False, ('model',))
-                 for tensor_name in self.required_tensorkeys_for_function['global_model_dict']
-             ] + [
-                 TensorKey(tensor_name, 'LOCAL', 0, False, ('model',))
-                 for tensor_name in self.required_tensorkeys_for_function['local_model_dict']
-             ]
- 
-         if kwargs['apply'] == 'local':
-             return [
-                 TensorKey(tensor_name, 'LOCAL', 0, False, ('trained',))
-                 for tensor_name in {
-                     **self.required_tensorkeys_for_function['local_model_dict_val'],
-                     **self.required_tensorkeys_for_function['global_model_dict_val']
-                 }
-             ]
- 
-         elif kwargs['apply'] == 'global':
-             return [
-                 TensorKey(tensor_name, 'GLOBAL', 0, False, ('model',))
-                 for tensor_name in self.required_tensorkeys_for_function['global_model_dict_val']
-             ] + [
-                 TensorKey(tensor_name, 'LOCAL', 0, False, ('model',))
-                 for tensor_name in self.required_tensorkeys_for_function['local_model_dict_val']
-             ]
- 
-     def initialize_tensorkeys_for_functions(self, with_opt_vars=False):
-         """Set the required tensors for all publicly accessible task methods.
- 
-         By default, this is just all of the layers and optimizer of the model.
-         Custom tensors should be added to this function.
- 
-         Args:
-             None
- 
-         Returns:
-             None
-         """
-         # TODO: Framework adapters should have separate methods for dealing with optimizer
-         # Set model dict for validation tasks
-         output_model_dict = self.get_tensor_dict(with_opt_vars=False)
-         global_model_dict_val, local_model_dict_val = split_tensor_dict_for_holdouts(
-             self.logger,
-             output_model_dict,
-             **self.tensor_dict_split_fn_kwargs
-         )
-         # Now set model dict for training tasks
-         if with_opt_vars:
-             output_model_dict = self.get_tensor_dict(with_opt_vars=True)
-             global_model_dict, local_model_dict = split_tensor_dict_for_holdouts(
-                 self.logger, output_model_dict,
-                 **self.tensor_dict_split_fn_kwargs
-             )
-         else:
-             global_model_dict = global_model_dict_val
-             local_model_dict = local_model_dict_val
- 
-         self.required_tensorkeys_for_function['global_model_dict'] = global_model_dict
-         self.required_tensorkeys_for_function['local_model_dict'] = local_model_dict
-         self.required_tensorkeys_for_function['global_model_dict_val'] = global_model_dict_val
-         self.required_tensorkeys_for_function['local_model_dict_val'] = local_model_dict_val
- 
-     def reset_opt_vars(self):
-         """
-         Reset optimizer variables.
- 
-         Resets the optimizer variables
- 
-         """
-         self.optimizer = self.model_provider.provide_optimizer()
- 
-     def get_train_data_size(self):
-         """
-         Get the number of training examples.
- 
-         It will be used for weighted averaging in aggregation.
- 
-         Returns:
-             int: The number of training examples.
-         """
-         return self.data_loader.get_train_data_size()
- 
-     def get_valid_data_size(self):
-         """
-         Get the number of examples.
- 
-         It will be used for weighted averaging in aggregation.
- 
-         Returns:
-             int: The number of validation examples.
-         """
-         return self.data_loader.get_valid_data_size()
- 
-     def get_tensor_dict(self, with_opt_vars=False):
-         """Return the tensor dictionary.
- 
-         Args:
-             with_opt_vars (bool): Return the tensor dictionary including the
-                                   optimizer tensors (Default=False)
- 
-         Returns:
-             dict: Tensor dictionary {**dict, **optimizer_dict}
- 
-         """
-         args = [self.model]
-         if with_opt_vars:
-             args.append(self.optimizer)
- 
-         return self.framework_adapter.get_tensor_dict(*args)
- 
-     def set_tensor_dict(self, tensor_dict, with_opt_vars=False, device='cpu'):
-         """Set the tensor dictionary.
- 
-         Args:
-             tensor_dict: The tensor dictionary
-             with_opt_vars (bool): Return the tensor dictionary including the
-                                   optimizer tensors (Default=False)
- 
-         """
-         # Sets tensors for model layers and optimizer state.
-         # FIXME: self.parameters() instead? Unclear if load_state_dict() or
-         #  simple assignment is better
-         # for now, state dict gives us names, which is good
-         # FIXME: do both and sanity check each time?
-         args = [self.model, tensor_dict]
-         if with_opt_vars:
-             args.append(self.optimizer)
- 
-         kwargs = {'device': device, }
- 
-         return self.framework_adapter.set_tensor_dict(*args, **kwargs)
--- 0 ----
diff -crB --new-file ./openfl/openfl/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/__init__.py
*** ./openfl/openfl/__init__.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,5 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """openfl base package."""
- # flake8: noqa
- from .__version__ import __version__
--- 0 ----
diff -crB --new-file ./openfl/openfl/interface/aggregator.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/aggregator.py
*** ./openfl/openfl/interface/aggregator.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/aggregator.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,193 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Aggregator module."""
- 
- import sys
- from logging import getLogger
- 
- from click import echo
- from click import group
- from click import option
- from click import pass_context
- from click import Path as ClickPath
- from click import style
- 
- from openfl.utilities import click_types
- from openfl.utilities.path_check import is_directory_traversal
- from openfl.utilities.utils import getfqdn_env
- 
- logger = getLogger(__name__)
- 
- 
- @group()
- @pass_context
- def aggregator(context):
-     """Manage Federated Learning Aggregator."""
-     context.obj['group'] = 'aggregator'
- 
- 
- @aggregator.command(name='start')
- @option('-p', '--plan', required=False,
-         help='Federated learning plan [plan/plan.yaml]',
-         default='plan/plan.yaml',
-         type=ClickPath(exists=True))
- @option('-c', '--authorized_cols', required=False,
-         help='Authorized collaborator list [plan/cols.yaml]',
-         default='plan/cols.yaml', type=ClickPath(exists=True))
- @option('-s', '--secure', required=False,
-         help='Enable Intel SGX Enclave', is_flag=True, default=False)
- def start_(plan, authorized_cols, secure):
-     """Start the aggregator service."""
-     from pathlib import Path
- 
-     from openfl.federated import Plan
- 
-     if is_directory_traversal(plan):
-         echo('Federated learning plan path is out of the openfl workspace scope.')
-         sys.exit(1)
-     if is_directory_traversal(authorized_cols):
-         echo('Authorized collaborator list file path is out of the openfl workspace scope.')
-         sys.exit(1)
- 
-     plan = Plan.parse(plan_config_path=Path(plan).absolute(),
-                       cols_config_path=Path(authorized_cols).absolute())
- 
-     logger.info('🧿 Starting the Aggregator Service.')
- 
-     plan.get_server().serve()
- 
- 
- @aggregator.command(name='generate-cert-request')
- @option('--fqdn', required=False, type=click_types.FQDN,
-         help=f'The fully qualified domain name of'
-              f' aggregator node [{getfqdn_env()}]',
-         default=getfqdn_env())
- def _generate_cert_request(fqdn):
-     generate_cert_request(fqdn)
- 
- 
- def generate_cert_request(fqdn):
-     """Create aggregator certificate key pair."""
-     from openfl.cryptography.participant import generate_csr
-     from openfl.cryptography.io import write_crt
-     from openfl.cryptography.io import write_key
-     from openfl.interface.cli_helper import CERT_DIR
- 
-     if fqdn is None:
-         fqdn = getfqdn_env()
- 
-     common_name = f'{fqdn}'.lower()
-     subject_alternative_name = f'DNS:{common_name}'
-     file_name = f'agg_{common_name}'
- 
-     echo(f'Creating AGGREGATOR certificate key pair with following settings: '
-          f'CN={style(common_name, fg="red")},'
-          f' SAN={style(subject_alternative_name, fg="red")}')
- 
-     server_private_key, server_csr = generate_csr(common_name, server=True)
- 
-     (CERT_DIR / 'server').mkdir(parents=True, exist_ok=True)
- 
-     echo('  Writing AGGREGATOR certificate key pair to: ' + style(
-         f'{CERT_DIR}/server', fg='green'))
- 
-     # Write aggregator csr and key to disk
-     write_crt(server_csr, CERT_DIR / 'server' / f'{file_name}.csr')
-     write_key(server_private_key, CERT_DIR / 'server' / f'{file_name}.key')
- 
- 
- # TODO: function not used
- def find_certificate_name(file_name):
-     """Search the CRT for the actual aggregator name."""
-     # This loop looks for the collaborator name in the key
-     with open(file_name, 'r') as f:
-         for line in f:
-             if 'Subject: CN=' in line:
-                 col_name = line.split('=')[-1].strip()
-                 break
-     return col_name
- 
- 
- @aggregator.command(name='certify')
- @option('-n', '--fqdn', type=click_types.FQDN,
-         help=f'The fully qualified domain name of aggregator node [{getfqdn_env()}]',
-         default=getfqdn_env())
- @option('-s', '--silent', help='Do not prompt', is_flag=True)
- def _certify(fqdn, silent):
-     certify(fqdn, silent)
- 
- 
- def certify(fqdn, silent):
-     """Sign/certify the aggregator certificate key pair."""
-     from pathlib import Path
- 
-     from click import confirm
- 
-     from openfl.cryptography.ca import sign_certificate
-     from openfl.cryptography.io import read_crt
-     from openfl.cryptography.io import read_csr
-     from openfl.cryptography.io import read_key
-     from openfl.cryptography.io import write_crt
-     from openfl.interface.cli_helper import CERT_DIR
- 
-     if fqdn is None:
-         fqdn = getfqdn_env()
- 
-     common_name = f'{fqdn}'.lower()
-     file_name = f'agg_{common_name}'
-     cert_name = f'server/{file_name}'
-     signing_key_path = 'ca/signing-ca/private/signing-ca.key'
-     signing_crt_path = 'ca/signing-ca.crt'
- 
-     # Load CSR
-     csr_path_absolute_path = Path(CERT_DIR / f'{cert_name}.csr').absolute()
-     if not csr_path_absolute_path.exists():
-         echo(style('Aggregator certificate signing request not found.', fg='red')
-              + ' Please run `fx aggregator generate-cert-request`'
-                ' to generate the certificate request.')
- 
-     csr, csr_hash = read_csr(csr_path_absolute_path)
- 
-     # Load private signing key
-     private_sign_key_absolute_path = Path(CERT_DIR / signing_key_path).absolute()
-     if not private_sign_key_absolute_path.exists():
-         echo(style('Signing key not found.', fg='red')
-              + ' Please run `fx workspace certify`'
-                ' to initialize the local certificate authority.')
- 
-     signing_key = read_key(private_sign_key_absolute_path)
- 
-     # Load signing cert
-     signing_crt_absolute_path = Path(CERT_DIR / signing_crt_path).absolute()
-     if not signing_crt_absolute_path.exists():
-         echo(style('Signing certificate not found.', fg='red')
-              + ' Please run `fx workspace certify`'
-                ' to initialize the local certificate authority.')
- 
-     signing_crt = read_crt(signing_crt_absolute_path)
- 
-     echo('The CSR Hash for file '
-          + style(f'{cert_name}.csr', fg='green')
-          + ' = '
-          + style(f'{csr_hash}', fg='red'))
- 
-     crt_path_absolute_path = Path(CERT_DIR / f'{cert_name}.crt').absolute()
- 
-     if silent:
- 
-         echo(' Signing AGGREGATOR certificate')
-         signed_agg_cert = sign_certificate(csr, signing_key, signing_crt.subject)
-         write_crt(signed_agg_cert, crt_path_absolute_path)
- 
-     else:
- 
-         if confirm('Do you want to sign this certificate?'):
- 
-             echo(' Signing AGGREGATOR certificate')
-             signed_agg_cert = sign_certificate(csr, signing_key, signing_crt.subject)
-             write_crt(signed_agg_cert, crt_path_absolute_path)
- 
-         else:
-             echo(style('Not signing certificate.', fg='red')
-                  + ' Please check with this AGGREGATOR to get the correct'
-                    ' certificate for this federation.')
--- 0 ----
diff -crB --new-file ./openfl/openfl/interface/cli_helper.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/cli_helper.py
*** ./openfl/openfl/interface/cli_helper.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/cli_helper.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,225 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Module with auxiliary CLI helper functions."""
- 
- from itertools import islice
- from os import environ
- from os import stat
- from pathlib import Path
- from sys import argv
- 
- from click import echo
- from click import style
- from yaml import FullLoader
- from yaml import load
- 
- FX = argv[0]
- 
- SITEPACKS = Path(__file__).parent.parent.parent
- WORKSPACE = SITEPACKS / 'openfl-workspace'
- TUTORIALS = SITEPACKS / 'openfl-tutorials'
- OPENFL_USERDIR = Path.home() / '.openfl'
- CERT_DIR = Path('cert').absolute()
- 
- 
- def pretty(o):
-     """Pretty-print the dictionary given."""
-     m = max(map(len, o.keys()))
- 
-     for k, v in o.items():
-         echo(style(f'{k:<{m}} : ', fg='blue') + style(f'{v}', fg='cyan'))
- 
- 
- def tree(path):
-     """Print current directory file tree."""
-     echo(f'+ {path}')
- 
-     for path in sorted(path.rglob('*')):
- 
-         depth = len(path.relative_to(path).parts)
-         space = '    ' * depth
- 
-         if path.is_file():
-             echo(f'{space}f {path.name}')
-         else:
-             echo(f'{space}d {path.name}')
- 
- 
- def print_tree(dir_path: Path, level: int = -1,
-                limit_to_directories: bool = False,
-                length_limit: int = 1000):
-     """Given a directory Path object print a visual tree structure."""
-     space = '    '
-     branch = '│   '
-     tee = '├── '
-     last = '└── '
- 
-     echo('\nNew workspace directory structure:')
- 
-     dir_path = Path(dir_path)  # accept string coerceable to Path
-     files = 0
-     directories = 0
- 
-     def inner(dir_path: Path, prefix: str = '', level=-1):
-         nonlocal files, directories
-         if not level:
-             return  # 0, stop iterating
-         if limit_to_directories:
-             contents = [d for d in dir_path.iterdir() if d.is_dir()]
-         else:
-             contents = list(dir_path.iterdir())
-         pointers = [tee] * (len(contents) - 1) + [last]
-         for pointer, path in zip(pointers, contents):
-             if path.is_dir():
-                 yield prefix + pointer + path.name
-                 directories += 1
-                 extension = branch if pointer == tee else space
-                 yield from inner(path, prefix=prefix + extension,
-                                  level=level - 1)
-             elif not limit_to_directories:
-                 yield prefix + pointer + path.name
-                 files += 1
- 
-     echo(dir_path.name)
-     iterator = inner(dir_path, level=level)
-     for line in islice(iterator, length_limit):
-         echo(line)
-     if next(iterator, None):
-         echo(f'... length_limit, {length_limit}, reached, counted:')
-     echo(f'\n{directories} directories' + (f', {files} files' if files else ''))
- 
- 
- def copytree(src, dst, symlinks=False, ignore=None,
-              ignore_dangling_symlinks=False, dirs_exist_ok=False):
-     """From Python 3.8 'shutil' which include 'dirs_exist_ok' option."""
-     import os
-     import shutil
- 
-     with os.scandir(src) as itr:
-         entries = list(itr)
- 
-     copy_function = shutil.copy2
- 
-     def _copytree():
- 
-         if ignore is not None:
-             ignored_names = ignore(os.fspath(src), [x.name for x in entries])
-         else:
-             ignored_names = set()
- 
-         os.makedirs(dst, exist_ok=dirs_exist_ok)
-         errors = []
-         use_srcentry = copy_function is shutil.copy2 or copy_function is shutil.copy
- 
-         for srcentry in entries:
-             if srcentry.name in ignored_names:
-                 continue
-             srcname = os.path.join(src, srcentry.name)
-             dstname = os.path.join(dst, srcentry.name)
-             srcobj = srcentry if use_srcentry else srcname
-             try:
-                 is_symlink = srcentry.is_symlink()
-                 if is_symlink and os.name == 'nt':
-                     lstat = srcentry.stat(follow_symlinks=False)
-                     if lstat.st_reparse_tag == stat.IO_REPARSE_TAG_MOUNT_POINT:
-                         is_symlink = False
-                 if is_symlink:
-                     linkto = os.readlink(srcname)
-                     if symlinks:
-                         os.symlink(linkto, dstname)
-                         shutil.copystat(srcobj, dstname,
-                                         follow_symlinks=not symlinks)
-                     else:
-                         if (not os.path.exists(linkto)
-                                 and ignore_dangling_symlinks):
-                             continue
-                         if srcentry.is_dir():
-                             copytree(srcobj, dstname, symlinks, ignore,
-                                      dirs_exist_ok=dirs_exist_ok)
-                         else:
-                             copy_function(srcobj, dstname)
-                 elif srcentry.is_dir():
-                     copytree(srcobj, dstname, symlinks, ignore,
-                              dirs_exist_ok=dirs_exist_ok)
-                 else:
-                     copy_function(srcobj, dstname)
-             except OSError as why:
-                 errors.append((srcname, dstname, str(why)))
-             except Exception as err:
-                 errors.extend(err.args[0])
-         try:
-             shutil.copystat(src, dst)
-         except OSError as why:
-             if getattr(why, 'winerror', None) is None:
-                 errors.append((src, dst, str(why)))
-         if errors:
-             raise Exception(errors)
-         return dst
- 
-     return _copytree()
- 
- 
- def get_workspace_parameter(name):
-     """Get a parameter from the workspace config file (.workspace)."""
-     # Update the .workspace file to show the current workspace plan
-     workspace_file = '.workspace'
- 
-     with open(workspace_file, 'r') as f:
-         doc = load(f, Loader=FullLoader)
- 
-     if not doc:  # YAML is not correctly formatted
-         doc = {}  # Create empty dictionary
- 
-     if name not in doc.keys() or not doc[name]:  # List doesn't exist
-         return ''
-     else:
-         return doc[name]
- 
- 
- def check_varenv(env: str = '', args: dict = None):
-     """Update "args" (dictionary) with <env: env_value> if env has a defined value in the host."""
-     if args is None:
-         args = {}
-     env_val = environ.get(env)
-     if env and (env_val is not None):
-         args[env] = env_val
- 
-     return args
- 
- 
- def get_fx_path(curr_path=''):
-     """Return the absolute path to fx binary."""
-     import re
-     import os
- 
-     match = re.search('lib', curr_path)
-     idx = match.end()
-     path_prefix = curr_path[0:idx]
-     bin_path = re.sub('lib', 'bin', path_prefix)
-     fx_path = os.path.join(bin_path, 'fx')
- 
-     return fx_path
- 
- 
- def remove_line_from_file(pkg, filename):
-     """Remove line that contains `pkg` from the `filename` file."""
-     with open(filename, 'r+') as f:
-         d = f.readlines()
-         f.seek(0)
-         for i in d:
-             if pkg not in i:
-                 f.write(i)
-         f.truncate()
- 
- 
- def replace_line_in_file(line, line_num_to_replace, filename):
-     """Replace line at `line_num_to_replace` with `line`."""
-     with open(filename, 'r+') as f:
-         d = f.readlines()
-         f.seek(0)
-         for idx, i in enumerate(d):
-             if idx == line_num_to_replace:
-                 f.write(line)
-             else:
-                 f.write(i)
-         f.truncate()
--- 0 ----
diff -crB --new-file ./openfl/openfl/interface/cli.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/cli.py
*** ./openfl/openfl/interface/cli.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/cli.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,218 ****
- #!/usr/bin/env python
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """CLI module."""
- 
- from click import argument
- from click import command
- from click import echo
- from click import Group
- from click import group
- from click import option
- from click import pass_context
- from click import style
- 
- from openfl.utilities import add_log_level
- 
- 
- def setup_logging(level='info', log_file=None):
-     """Initialize logging settings."""
-     import logging
-     from logging import basicConfig
- 
-     from rich.console import Console
-     from rich.logging import RichHandler
- 
-     metric = 25
-     add_log_level('METRIC', metric)
- 
-     if isinstance(level, str):
-         level = level.upper()
- 
-     handlers = []
-     if log_file:
-         fh = logging.FileHandler(log_file)
-         formatter = logging.Formatter(
-             '%(asctime)s %(levelname)s %(message)s %(filename)s:%(lineno)d'
-         )
-         fh.setFormatter(formatter)
-         handlers.append(fh)
- 
-     console = Console(width=160)
-     handlers.append(RichHandler(console=console))
-     basicConfig(level=level, format='%(message)s',
-                 datefmt='[%X]', handlers=handlers)
- 
- 
- def disable_warnings():
-     """Disables CUDA warnings."""
-     import os
- 
-     os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
- 
- 
- class CLI(Group):
-     """CLI class."""
- 
-     def __init__(self, name=None, commands=None, **kwargs):
-         """Initialize."""
-         super(CLI, self).__init__(name, commands, **kwargs)
-         self.commands = commands or {}
- 
-     def list_commands(self, ctx):
-         """Display all available commands."""
-         return self.commands
- 
-     def format_help(self, ctx, formatter):
-         """Dislpay user-friendly help."""
-         show_header()
-         uses = [
-             f'{ctx.command_path}',
-             '[options]',
-             style('[command]', fg='blue'),
-             style('[subcommand]', fg='cyan'),
-             '[args]'
-         ]
- 
-         formatter.write(style('BASH COMPLETE ACTIVATION\n\n', bold=True, fg='bright_black'))
-         formatter.write(
-             'Run in terminal:\n'
-             '   _FX_COMPLETE=bash_source fx > ~/.fx-autocomplete.sh\n'
-             '   source ~/.fx-autocomplete.sh\n'
-             'If ~/.fx-autocomplete.sh has already exist:\n'
-             '   source ~/.fx-autocomplete.sh\n\n'
-         )
- 
-         formatter.write(style('CORRECT USAGE\n\n', bold=True, fg='bright_black'))
-         formatter.write(' '.join(uses) + '\n')
- 
-         opts = []
-         for param in self.get_params(ctx):
-             rv = param.get_help_record(ctx)
-             if rv is not None:
-                 opts.append(rv)
- 
-         formatter.write(style(
-             '\nGLOBAL OPTIONS\n\n', bold=True, fg='bright_black'))
-         formatter.write_dl(opts)
- 
-         cmds = []
-         for cmd in self.list_commands(ctx):
-             cmd = self.get_command(ctx, cmd)
-             cmds.append((cmd.name, cmd, 0))
- 
-             for sub in cmd.list_commands(ctx):
-                 sub = cmd.get_command(ctx, sub)
-                 cmds.append((sub.name, sub, 1))
- 
-         formatter.write(style(
-             '\nAVAILABLE COMMANDS\n', bold=True, fg='bright_black'))
- 
-         for name, cmd, level in cmds:
-             help_str = cmd.get_short_help_str()
-             if level == 0:
-                 formatter.write(
-                     f'\n{style(name, fg="blue", bold=True):<30}'
-                     f' {style(help_str, bold=True)}' + '\n')
-                 formatter.write('─' * 80 + '\n')
-             if level == 1:
-                 formatter.write(
-                     f'  {style("*", fg="green")}'
-                     f' {style(name, fg="cyan"):<21} {help_str}' + '\n')
- 
- 
- @group(cls=CLI)
- @option('-l', '--log-level', default='info', help='Logging verbosity level.')
- @pass_context
- def cli(context, log_level):
-     """Command-line Interface."""
-     import os
-     from sys import argv
- 
-     context.ensure_object(dict)
-     context.obj['log_level'] = log_level
-     context.obj['fail'] = False
-     context.obj['script'] = argv[0]
-     context.obj['arguments'] = argv[1:]
- 
-     log_file = os.getenv('LOG_FILE')
-     setup_logging(log_level, log_file)
- 
- 
- @cli.result_callback()
- @pass_context
- def end(context, result, **kwargs):
-     """Print the result of the operation."""
-     if context.obj['fail']:
-         echo('\n ❌ :(')
-     else:
-         echo('\n ✔️ OK')
- 
- 
- @command(name='help')
- @pass_context
- @argument('subcommand', required=False)
- def help_(context, subcommand):
-     """Display help."""
-     pass
- 
- 
- def error_handler(error):
-     """Handle the error."""
-     if 'cannot import' in str(error):
-         if 'TensorFlow' in str(error):
-             echo(style('EXCEPTION', fg='red', bold=True) + ' : ' + style(
-                 'Tensorflow must be installed prior to running this command',
-                 fg='red'))
-         if 'PyTorch' in str(error):
-             echo(style('EXCEPTION', fg='red', bold=True) + ' : ' + style(
-                 'Torch must be installed prior to running this command',
-                 fg='red'))
-     echo(style('EXCEPTION', fg='red', bold=True)
-          + ' : ' + style(f'{error}', fg='red'))
-     raise error
- 
- 
- def show_header():
-     """Show header."""
-     banner = 'OpenFL - Open Federated Learning'
-     echo(style(f'{banner:<80}', bold=True, bg='bright_blue'))
-     echo()
- 
- 
- def entry():
-     """Entry point of the Command-Line Interface."""
-     from importlib import import_module
-     from pathlib import Path
-     from sys import path
- 
-     file = Path(__file__).resolve()
-     root = file.parent.resolve()  # interface root, containing command modules
-     work = Path.cwd().resolve()
-     path.append(str(root))
-     path.insert(0, str(work))
- 
-     # Setup logging immediately to suppress unnecessary warnings on import
-     # This will be overridden later with user selected debugging level
-     disable_warnings()
- 
-     for module in root.glob('*.py'):  # load command modules
- 
-         package = module.parent
-         module = module.name.split('.')[0]
- 
-         if module.count('__init__') or module.count('cli'):
-             continue
- 
-         command_group = import_module(module, package)
- 
-         cli.add_command(command_group.__getattribute__(module))
- 
-     try:
-         cli()
-     except Exception as e:
-         error_handler(e)
- 
- 
- if __name__ == '__main__':
-     entry()
--- 0 ----
diff -crB --new-file ./openfl/openfl/interface/collaborator.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/collaborator.py
*** ./openfl/openfl/interface/collaborator.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/collaborator.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,391 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Collaborator module."""
- 
- import sys
- from logging import getLogger
- 
- from click import echo
- from click import group
- from click import option
- from click import pass_context
- from click import Path as ClickPath
- from click import style
- 
- from openfl.utilities.path_check import is_directory_traversal
- 
- logger = getLogger(__name__)
- 
- 
- @group()
- @pass_context
- def collaborator(context):
-     """Manage Federated Learning Collaborators."""
-     context.obj['group'] = 'service'
- 
- 
- @collaborator.command(name='start')
- @option('-p', '--plan', required=False,
-         help='Federated learning plan [plan/plan.yaml]',
-         default='plan/plan.yaml',
-         type=ClickPath(exists=True))
- @option('-d', '--data_config', required=False,
-         help='The data set/shard configuration file [plan/data.yaml]',
-         default='plan/data.yaml', type=ClickPath(exists=True))
- @option('-n', '--collaborator_name', required=True,
-         help='The certified common name of the collaborator')
- @option('-s', '--secure', required=False,
-         help='Enable Intel SGX Enclave', is_flag=True, default=False)
- def start_(plan, collaborator_name, data_config, secure):
-     """Start a collaborator service."""
-     from pathlib import Path
- 
-     from openfl.federated import Plan
- 
-     if plan and is_directory_traversal(plan):
-         echo('Federated learning plan path is out of the openfl workspace scope.')
-         sys.exit(1)
-     if data_config and is_directory_traversal(data_config):
-         echo('The data set/shard configuration file path is out of the openfl workspace scope.')
-         sys.exit(1)
- 
-     plan = Plan.parse(plan_config_path=Path(plan).absolute(),
-                       data_config_path=Path(data_config).absolute())
- 
-     # TODO: Need to restructure data loader config file loader
- 
-     echo(f'Data = {plan.cols_data_paths}')
-     logger.info('🧿 Starting a Collaborator Service.')
- 
-     plan.get_collaborator(collaborator_name).run()
- 
- 
- def register_data_path(collaborator_name, data_path=None, silent=False):
-     """Register dataset path in the plan/data.yaml file.
- 
-     Args:
-         collaborator_name (str): The collaborator whose data path to be defined
-         data_path (str)        : Data path (optional)
-         silent (bool)          : Silent operation (don't prompt)
-     """
-     from click import prompt
-     from os.path import isfile
- 
-     if data_path and is_directory_traversal(data_path):
-         echo('Data path is out of the openfl workspace scope.')
-         sys.exit(1)
- 
-     # Ask for the data directory
-     default_data_path = f'data/{collaborator_name}'
-     if not silent and data_path is None:
-         dir_path = prompt('\nWhere is the data (or what is the rank)'
-                           ' for collaborator '
-                           + style(f'{collaborator_name}', fg='green')
-                           + ' ? ', default=default_data_path)
-     elif data_path is not None:
-         dir_path = data_path
-     else:
-         # TODO: Need to figure out the default for this.
-         dir_path = default_data_path
- 
-     # Read the data.yaml file
-     d = {}
-     data_yaml = 'plan/data.yaml'
-     separator = ','
-     if isfile(data_yaml):
-         with open(data_yaml, 'r') as f:
-             for line in f:
-                 if separator in line:
-                     key, val = line.split(separator, maxsplit=1)
-                     d[key] = val.strip()
- 
-     d[collaborator_name] = dir_path
- 
-     # Write the data.yaml
-     with open(data_yaml, 'w') as f:
-         for key, val in d.items():
-             f.write(f'{key}{separator}{val}\n')
- 
- 
- @collaborator.command(name='generate-cert-request')
- @option('-n', '--collaborator_name', required=True,
-         help='The certified common name of the collaborator')
- @option('-d', '--data_path',
-         help='The data path to be associated with the collaborator')
- @option('-s', '--silent', help='Do not prompt', is_flag=True)
- @option('-x', '--skip-package',
-         help='Do not package the certificate signing request for export',
-         is_flag=True)
- def generate_cert_request_(collaborator_name,
-                            data_path, silent, skip_package):
-     """Generate certificate request for the collaborator."""
-     if data_path and is_directory_traversal(data_path):
-         echo('Data path is out of the openfl workspace scope.')
-         sys.exit(1)
-     generate_cert_request(collaborator_name, data_path, silent, skip_package)
- 
- 
- def generate_cert_request(collaborator_name, data_path, silent, skip_package):
-     """
-     Create collaborator certificate key pair.
- 
-     Then create a package with the CSR to send for signing.
-     """
-     from openfl.cryptography.participant import generate_csr
-     from openfl.cryptography.io import write_crt
-     from openfl.cryptography.io import write_key
-     from openfl.interface.cli_helper import CERT_DIR
- 
-     common_name = f'{collaborator_name}'.lower()
-     subject_alternative_name = f'DNS:{common_name}'
-     file_name = f'col_{common_name}'
- 
-     echo(f'Creating COLLABORATOR certificate key pair with following settings: '
-          f'CN={style(common_name, fg="red")},'
-          f' SAN={style(subject_alternative_name, fg="red")}')
- 
-     client_private_key, client_csr = generate_csr(common_name, server=False)
- 
-     (CERT_DIR / 'client').mkdir(parents=True, exist_ok=True)
- 
-     echo('  Moving COLLABORATOR certificate to: ' + style(
-         f'{CERT_DIR}/{file_name}', fg='green'))
- 
-     # Write collaborator csr and key to disk
-     write_crt(client_csr, CERT_DIR / 'client' / f'{file_name}.csr')
-     write_key(client_private_key, CERT_DIR / 'client' / f'{file_name}.key')
- 
-     if not skip_package:
-         from shutil import copytree
-         from shutil import ignore_patterns
-         from shutil import make_archive
-         from tempfile import mkdtemp
-         from os.path import basename
-         from os.path import join
-         from os import remove
-         from glob import glob
- 
-         archive_type = 'zip'
-         archive_name = f'col_{common_name}_to_agg_cert_request'
-         archive_file_name = archive_name + '.' + archive_type
- 
-         # Collaborator certificate signing request
-         tmp_dir = join(mkdtemp(), 'openfl', archive_name)
- 
-         ignore = ignore_patterns('__pycache__', '*.key', '*.srl', '*.pem')
-         # Copy the current directory into the temporary directory
-         copytree(f'{CERT_DIR}/client', tmp_dir, ignore=ignore)
- 
-         for f in glob(f'{tmp_dir}/*'):
-             if common_name not in basename(f):
-                 remove(f)
- 
-         # Create Zip archive of directory
-         make_archive(archive_name, archive_type, tmp_dir)
- 
-         echo(f'Archive {archive_file_name} with certificate signing'
-              f' request created')
-         echo('This file should be sent to the certificate authority'
-              ' (typically hosted by the aggregator) for signing')
- 
-     # TODO: There should be some association with the plan made here as well
-     register_data_path(common_name, data_path=data_path, silent=silent)
- 
- 
- def find_certificate_name(file_name):
-     """Parse the collaborator name."""
-     col_name = str(file_name).split('/')[-1].split('.')[0][4:]
-     return col_name
- 
- 
- def register_collaborator(file_name):
-     """Register the collaborator name in the cols.yaml list.
- 
-     Args:
-         file_name (str): The name of the collaborator in this federation
- 
-     """
-     from os.path import isfile
-     from yaml import dump
-     from yaml import FullLoader
-     from yaml import load
-     from pathlib import Path
- 
-     col_name = find_certificate_name(file_name)
- 
-     cols_file = Path('plan/cols.yaml').absolute()
- 
-     if not isfile(cols_file):
-         cols_file.touch()
-     with open(cols_file, 'r') as f:
-         doc = load(f, Loader=FullLoader)
- 
-     if not doc:  # YAML is not correctly formatted
-         doc = {}  # Create empty dictionary
- 
-     # List doesn't exist
-     if 'collaborators' not in doc.keys() or not doc['collaborators']:
-         doc['collaborators'] = []  # Create empty list
- 
-     if col_name in doc['collaborators']:
- 
-         echo('\nCollaborator '
-              + style(f'{col_name}', fg='green')
-              + ' is already in the '
-              + style(f'{cols_file}', fg='green'))
- 
-     else:
- 
-         doc['collaborators'].append(col_name)
-         with open(cols_file, 'w') as f:
-             dump(doc, f)
- 
-         echo('\nRegistering '
-              + style(f'{col_name}', fg='green')
-              + ' in '
-              + style(f'{cols_file}', fg='green'))
- 
- 
- @collaborator.command(name='certify')
- @option('-n', '--collaborator_name',
-         help='The certified common name of the collaborator. This is only'
-              ' needed for single node expiriments')
- @option('-s', '--silent', help='Do not prompt', is_flag=True)
- @option('-r', '--request-pkg', type=ClickPath(exists=True),
-         help='The archive containing the certificate signing'
-              ' request (*.zip) for a collaborator')
- @option('-i', '--import', 'import_', type=ClickPath(exists=True),
-         help='Import the archive containing the collaborator\'s'
-              ' certificate (signed by the CA)')
- def certify_(collaborator_name, silent, request_pkg, import_):
-     """Certify the collaborator."""
-     certify(collaborator_name, silent, request_pkg, import_)
- 
- 
- def certify(collaborator_name, silent, request_pkg=None, import_=False):
-     """Sign/certify collaborator certificate key pair."""
-     from click import confirm
-     from pathlib import Path
-     from shutil import copy
-     from shutil import make_archive
-     from shutil import unpack_archive
-     from glob import glob
-     from os.path import basename
-     from os.path import join
-     from os.path import splitext
-     from os import remove
-     from tempfile import mkdtemp
-     from openfl.cryptography.ca import sign_certificate
-     from openfl.cryptography.io import read_crt
-     from openfl.cryptography.io import read_csr
-     from openfl.cryptography.io import read_key
-     from openfl.cryptography.io import write_crt
-     from openfl.interface.cli_helper import CERT_DIR
- 
-     common_name = f'{collaborator_name}'.lower()
- 
-     if not import_:
-         if request_pkg:
-             Path(f'{CERT_DIR}/client').mkdir(parents=True, exist_ok=True)
-             unpack_archive(request_pkg, extract_dir=f'{CERT_DIR}/client')
-             csr = glob(f'{CERT_DIR}/client/*.csr')[0]
-         else:
-             if collaborator_name is None:
-                 echo('collaborator_name can only be omitted if signing\n'
-                      'a zipped request package.\n'
-                      '\n'
-                      'Example: fx collaborator certify --request-pkg '
-                      'col_one_to_agg_cert_request.zip')
-                 return
-             csr = glob(f'{CERT_DIR}/client/col_{common_name}.csr')[0]
-             copy(csr, CERT_DIR)
-         cert_name = splitext(csr)[0]
-         file_name = basename(cert_name)
-         signing_key_path = 'ca/signing-ca/private/signing-ca.key'
-         signing_crt_path = 'ca/signing-ca.crt'
- 
-         # Load CSR
-         if not Path(f'{cert_name}.csr').exists():
-             echo(style('Collaborator certificate signing request not found.', fg='red')
-                  + ' Please run `fx collaborator generate-cert-request`'
-                    ' to generate the certificate request.')
- 
-         csr, csr_hash = read_csr(f'{cert_name}.csr')
- 
-         # Load private signing key
-         if not Path(CERT_DIR / signing_key_path).exists():
-             echo(style('Signing key not found.', fg='red')
-                  + ' Please run `fx workspace certify`'
-                    ' to initialize the local certificate authority.')
- 
-         signing_key = read_key(CERT_DIR / signing_key_path)
- 
-         # Load signing cert
-         if not Path(CERT_DIR / signing_crt_path).exists():
-             echo(style('Signing certificate not found.', fg='red')
-                  + ' Please run `fx workspace certify`'
-                    ' to initialize the local certificate authority.')
- 
-         signing_crt = read_crt(CERT_DIR / signing_crt_path)
- 
-         echo('The CSR Hash for file '
-              + style(f'{file_name}.csr', fg='green')
-              + ' = '
-              + style(f'{csr_hash}', fg='red'))
- 
-         if silent:
- 
-             echo(' Signing COLLABORATOR certificate')
-             signed_col_cert = sign_certificate(csr, signing_key, signing_crt.subject)
-             write_crt(signed_col_cert, f'{cert_name}.crt')
-             register_collaborator(CERT_DIR / 'client' / f'{file_name}.crt')
- 
-         else:
- 
-             if confirm('Do you want to sign this certificate?'):
- 
-                 echo(' Signing COLLABORATOR certificate')
-                 signed_col_cert = sign_certificate(csr, signing_key, signing_crt.subject)
-                 write_crt(signed_col_cert, f'{cert_name}.crt')
-                 register_collaborator(CERT_DIR / 'client' / f'{file_name}.crt')
- 
-             else:
-                 echo(style('Not signing certificate.', fg='red')
-                      + ' Please check with this collaborator to get the'
-                        ' correct certificate for this federation.')
-                 return
- 
-         if len(common_name) == 0:
-             # If the collaborator name is provided, the collaborator and
-             # certificate does not need to be exported
-             return
- 
-         # Remove unneeded CSR
-         remove(f'{cert_name}.csr')
- 
-         archive_type = 'zip'
-         archive_name = f'agg_to_{file_name}_signed_cert'
- 
-         # Collaborator certificate signing request
-         tmp_dir = join(mkdtemp(), 'openfl', archive_name)
- 
-         Path(f'{tmp_dir}/client').mkdir(parents=True, exist_ok=True)
-         # Copy the signed cert to the temporary directory
-         copy(f'{CERT_DIR}/client/{file_name}.crt', f'{tmp_dir}/client/')
-         # Copy the CA certificate chain to the temporary directory
-         copy(f'{CERT_DIR}/cert_chain.crt', tmp_dir)
- 
-         # Create Zip archive of directory
-         make_archive(archive_name, archive_type, tmp_dir)
- 
-     else:
-         # Copy the signed certificate and cert chain into PKI_DIR
-         previous_crts = glob(f'{CERT_DIR}/client/*.crt')
-         unpack_archive(import_, extract_dir=CERT_DIR)
-         updated_crts = glob(f'{CERT_DIR}/client/*.crt')
-         cert_difference = list(set(updated_crts) - set(previous_crts))
-         if len(cert_difference) != 0:
-             crt = basename(cert_difference[0])
-             echo(f'Certificate {crt} installed to PKI directory')
-         else:
-             echo('Certificate updated in the PKI directory')
--- 0 ----
diff -crB --new-file ./openfl/openfl/interface/director.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/director.py
*** ./openfl/openfl/interface/director.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/director.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,118 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Director CLI."""
- 
- import logging
- import shutil
- import sys
- from pathlib import Path
- 
- import click
- from click import group
- from click import option
- from click import pass_context
- from click import Path as ClickPath
- from dynaconf import Validator
- 
- from openfl.component.director import Director
- from openfl.interface.cli_helper import WORKSPACE
- from openfl.transport import DirectorGRPCServer
- from openfl.utilities import merge_configs
- from openfl.utilities.path_check import is_directory_traversal
- 
- logger = logging.getLogger(__name__)
- 
- 
- @group()
- @pass_context
- def director(context):
-     """Manage Federated Learning Director."""
-     context.obj['group'] = 'director'
- 
- 
- @director.command(name='start')
- @option('-c', '--director-config-path', default='director.yaml',
-         help='The director config file path', type=ClickPath(exists=True))
- @option('--tls/--disable-tls', default=True,
-         is_flag=True, help='Use TLS or not (By default TLS is enabled)')
- @option('-rc', '--root-cert-path', 'root_certificate', required=False,
-         type=ClickPath(exists=True), default=None,
-         help='Path to a root CA cert')
- @option('-pk', '--private-key-path', 'private_key', required=False,
-         type=ClickPath(exists=True), default=None,
-         help='Path to a private key')
- @option('-oc', '--public-cert-path', 'certificate', required=False,
-         type=ClickPath(exists=True), default=None,
-         help='Path to a signed certificate')
- def start(director_config_path, tls, root_certificate, private_key, certificate):
-     """Start the director service."""
-     director_config_path = Path(director_config_path).absolute()
-     logger.info('🧿 Starting the Director Service.')
-     if is_directory_traversal(director_config_path):
-         click.echo('The director config file path is out of the openfl workspace scope.')
-         sys.exit(1)
-     config = merge_configs(
-         settings_files=director_config_path,
-         overwrite_dict={
-             'root_certificate': root_certificate,
-             'private_key': private_key,
-             'certificate': certificate,
-         },
-         validators=[
-             Validator('settings.listen_host', default='localhost'),
-             Validator('settings.listen_port', default=50051, gte=1024, lte=65535),
-             Validator('settings.sample_shape', default=[]),
-             Validator('settings.target_shape', default=[]),
-             Validator('settings.envoy_health_check_period', gte=1, lte=24 * 60 * 60),
-         ],
-         value_transform=[
-             ('settings.sample_shape', lambda x: list(map(str, x))),
-             ('settings.target_shape', lambda x: list(map(str, x))),
-         ],
-     )
- 
-     logger.info(
-         f'Sample shape: {config.settings.sample_shape}, '
-         f'target shape: {config.settings.target_shape}'
-     )
- 
-     if config.root_certificate:
-         config.root_certificate = Path(config.root_certificate).absolute()
- 
-     if config.private_key:
-         config.private_key = Path(config.private_key).absolute()
- 
-     if config.certificate:
-         config.certificate = Path(config.certificate).absolute()
- 
-     director_server = DirectorGRPCServer(
-         director_cls=Director,
-         tls=tls,
-         sample_shape=config.settings.sample_shape,
-         target_shape=config.settings.target_shape,
-         root_certificate=config.root_certificate,
-         private_key=config.private_key,
-         certificate=config.certificate,
-         settings=config.settings,
-         listen_host=config.settings.listen_host,
-         listen_port=config.settings.listen_port,
-     )
-     director_server.start()
- 
- 
- @director.command(name='create-workspace')
- @option('-p', '--director-path', required=True,
-         help='The director path', type=ClickPath())
- def create(director_path):
-     """Create a director workspace."""
-     if is_directory_traversal(director_path):
-         click.echo('The director path is out of the openfl workspace scope.')
-         sys.exit(1)
-     director_path = Path(director_path).absolute()
-     if director_path.exists():
-         if not click.confirm('Director workspace already exists. Recreate?', default=True):
-             sys.exit(1)
-         shutil.rmtree(director_path)
-     (director_path / 'cert').mkdir(parents=True, exist_ok=True)
-     (director_path / 'logs').mkdir(parents=True, exist_ok=True)
-     shutil.copyfile(WORKSPACE / 'default/director.yaml', director_path / 'director.yaml')
--- 0 ----
diff -crB --new-file ./openfl/openfl/interface/envoy.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/envoy.py
*** ./openfl/openfl/interface/envoy.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/envoy.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,152 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Envoy CLI."""
- 
- import logging
- import shutil
- import sys
- from importlib import import_module
- from pathlib import Path
- 
- import click
- from click import group
- from click import option
- from click import pass_context
- from click import Path as ClickPath
- from dynaconf import Validator
- 
- from openfl.component.envoy.envoy import Envoy
- from openfl.interface.cli_helper import WORKSPACE
- from openfl.utilities import click_types
- from openfl.utilities import merge_configs
- from openfl.utilities.path_check import is_directory_traversal
- 
- logger = logging.getLogger(__name__)
- 
- 
- @group()
- @pass_context
- def envoy(context):
-     """Manage Federated Learning Envoy."""
-     context.obj['group'] = 'envoy'
- 
- 
- @envoy.command(name='start')
- @option('-n', '--shard-name', required=True,
-         help='Current shard name')
- @option('-dh', '--director-host', required=True,
-         help='The FQDN of the federation director', type=click_types.FQDN)
- @option('-dp', '--director-port', required=True,
-         help='The federation director port', type=click.IntRange(1, 65535))
- @option('--tls/--disable-tls', default=True,
-         is_flag=True, help='Use TLS or not (By default TLS is enabled)')
- @option('-ec', '--envoy-config-path', default='envoy_config.yaml',
-         help='The envoy config path', type=ClickPath(exists=True))
- @option('-rc', '--root-cert-path', 'root_certificate', default=None,
-         help='Path to a root CA cert', type=ClickPath(exists=True))
- @option('-pk', '--private-key-path', 'private_key', default=None,
-         help='Path to a private key', type=ClickPath(exists=True))
- @option('-oc', '--public-cert-path', 'certificate', default=None,
-         help='Path to a signed certificate', type=ClickPath(exists=True))
- def start_(shard_name, director_host, director_port, tls, envoy_config_path,
-            root_certificate, private_key, certificate):
-     """Start the Envoy."""
-     logger.info('🧿 Starting the Envoy.')
-     if is_directory_traversal(envoy_config_path):
-         click.echo('The shard config path is out of the openfl workspace scope.')
-         sys.exit(1)
- 
-     config = merge_configs(
-         settings_files=envoy_config_path,
-         overwrite_dict={
-             'root_certificate': root_certificate,
-             'private_key': private_key,
-             'certificate': certificate,
-         },
-         validators=[
-             Validator('shard_descriptor.template', required=True),
-             Validator('params.cuda_devices', default=[]),
-         ],
-     )
- 
-     if config.root_certificate:
-         config.root_certificate = Path(config.root_certificate).absolute()
-     if config.private_key:
-         config.private_key = Path(config.private_key).absolute()
-     if config.certificate:
-         config.certificate = Path(config.certificate).absolute()
- 
-     # Parse envoy parameters
-     envoy_params = config.get('params', {})
- 
-     # Build optional plugin components
-     optional_plugins_section = config.get('optional_plugin_components')
-     if optional_plugins_section is not None:
-         for plugin_name, plugin_settings in optional_plugins_section.items():
-             template = plugin_settings.get('template')
-             if not template:
-                 raise Exception('You should put a template'
-                                 f'for plugin {plugin_name}')
-             module_path, _, class_name = template.rpartition('.')
-             plugin_params = plugin_settings.get('params', {})
- 
-             module = import_module(module_path)
-             instance = getattr(module, class_name)(**plugin_params)
-             envoy_params[plugin_name] = instance
- 
-     # Instantiate Shard Descriptor
-     shard_descriptor = shard_descriptor_from_config(config.get('shard_descriptor', {}))
-     envoy = Envoy(
-         shard_name=shard_name,
-         director_host=director_host,
-         director_port=director_port,
-         tls=tls,
-         shard_descriptor=shard_descriptor,
-         root_certificate=config.root_certificate,
-         private_key=config.private_key,
-         certificate=config.certificate,
-         **envoy_params
-     )
- 
-     envoy.start()
- 
- 
- @envoy.command(name='create-workspace')
- @option('-p', '--envoy-path', required=True,
-         help='The Envoy path', type=ClickPath())
- def create(envoy_path):
-     """Create an envoy workspace."""
-     if is_directory_traversal(envoy_path):
-         click.echo('The Envoy path is out of the openfl workspace scope.')
-         sys.exit(1)
-     envoy_path = Path(envoy_path).absolute()
-     if envoy_path.exists():
-         if not click.confirm('Envoy workspace already exists. Recreate?',
-                              default=True):
-             sys.exit(1)
-         shutil.rmtree(envoy_path)
-     (envoy_path / 'cert').mkdir(parents=True, exist_ok=True)
-     (envoy_path / 'logs').mkdir(parents=True, exist_ok=True)
-     (envoy_path / 'data').mkdir(parents=True, exist_ok=True)
-     shutil.copyfile(WORKSPACE / 'default/envoy_config.yaml',
-                     envoy_path / 'envoy_config.yaml')
-     shutil.copyfile(WORKSPACE / 'default/shard_descriptor.py',
-                     envoy_path / 'shard_descriptor.py')
-     shutil.copyfile(WORKSPACE / 'default/requirements.txt',
-                     envoy_path / 'requirements.txt')
- 
- 
- def shard_descriptor_from_config(shard_config: dict):
-     """Build a shard descriptor from config."""
-     template = shard_config.get('template')
-     if not template:
-         raise Exception('You should define a shard '
-                         'descriptor template in the envoy config')
-     class_name = template.split('.')[-1]
-     module_path = '.'.join(template.split('.')[:-1])
-     params = shard_config.get('params', {})
- 
-     module = import_module(module_path)
-     instance = getattr(module, class_name)(**params)
- 
-     return instance
--- 0 ----
diff -crB --new-file ./openfl/openfl/interface/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/__init__.py
*** ./openfl/openfl/interface/__init__.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """openfl.interface package."""
--- 0 ----
diff -crB --new-file ./openfl/openfl/interface/interactive_api/experiment.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/interactive_api/experiment.py
*** ./openfl/openfl/interface/interactive_api/experiment.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/interactive_api/experiment.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,643 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Python low-level API module."""
- import os
- import time
- from collections import defaultdict
- from copy import deepcopy
- from logging import getLogger
- from pathlib import Path
- from typing import Dict
- from typing import Tuple
- 
- from tensorboardX import SummaryWriter
- 
- from openfl.component.aggregation_functions import AggregationFunction
- from openfl.component.aggregation_functions import WeightedAverage
- from openfl.component.assigner.tasks import Task
- from openfl.component.assigner.tasks import TrainTask
- from openfl.component.assigner.tasks import ValidateTask
- from openfl.federated import Plan
- from openfl.interface.cli import setup_logging
- from openfl.interface.cli_helper import WORKSPACE
- from openfl.utilities import split_tensor_dict_for_holdouts
- from openfl.utilities.workspace import dump_requirements_file
- 
- 
- class ModelStatus:
-     """Model statuses."""
- 
-     INITIAL = 'initial'
-     BEST = 'best'
-     LAST = 'last'
-     RESTORED = 'restored'
- 
- 
- class FLExperiment:
-     """Central class for FL experiment orchestration."""
- 
-     def __init__(
-             self,
-             federation,
-             experiment_name: str = None,
-             serializer_plugin: str = 'openfl.plugins.interface_serializer.'
-                                      'cloudpickle_serializer.CloudpickleSerializer'
-     ) -> None:
-         """
-         Initialize an experiment inside a federation.
- 
-         Experiment makes sense in a scope of some machine learning problem.
-         Information about the data on collaborators is contained on the federation level.
-         """
-         self.federation = federation
-         self.experiment_name = experiment_name or 'test-' + time.strftime('%Y%m%d-%H%M%S')
-         self.summary_writer = None
-         self.serializer_plugin = serializer_plugin
- 
-         self.experiment_accepted = False
- 
-         self.is_validate_task_exist = False
- 
-         self.logger = getLogger(__name__)
-         setup_logging()
- 
-     def _assert_experiment_accepted(self):
-         """Assure experiment is sent to director."""
-         if not self.experiment_accepted:
-             self.logger.error('The experiment has not been accepted by director')
-             self.logger.error(
-                 'Report the experiment first: '
-                 'use the Experiment.start() method.')
-             raise Exception
- 
-     def get_best_model(self):
-         """Retrieve the model with the best score."""
-         self._assert_experiment_accepted()
-         tensor_dict = self.federation.dir_client.get_best_model(
-             experiment_name=self.experiment_name)
- 
-         return self._rebuild_model(tensor_dict, upcoming_model_status=ModelStatus.BEST)
- 
-     def get_last_model(self):
-         """Retrieve the aggregated model after the last round."""
-         self._assert_experiment_accepted()
-         tensor_dict = self.federation.dir_client.get_last_model(
-             experiment_name=self.experiment_name)
- 
-         return self._rebuild_model(tensor_dict, upcoming_model_status=ModelStatus.LAST)
- 
-     def _rebuild_model(self, tensor_dict, upcoming_model_status=ModelStatus.BEST):
-         """Use tensor dict to update model weights."""
-         if len(tensor_dict) == 0:
-             warning_msg = ('No tensors received from director\n'
-                            'Possible reasons:\n'
-                            '\t1. Aggregated model is not ready\n'
-                            '\t2. Experiment data removed from director')
- 
-             if upcoming_model_status == ModelStatus.BEST and not self.is_validate_task_exist:
-                 warning_msg += '\n\t3. No validation tasks are provided'
- 
-             warning_msg += f'\nReturn {self.current_model_status} model'
- 
-             self.logger.warning(warning_msg)
- 
-         else:
-             self.task_runner_stub.rebuild_model(tensor_dict, validation=True, device='cpu')
-             self.current_model_status = upcoming_model_status
- 
-         return deepcopy(self.task_runner_stub.model)
- 
-     def stream_metrics(self, tensorboard_logs: bool = True) -> None:
-         """Stream metrics."""
-         self._assert_experiment_accepted()
-         for metric_message_dict in self.federation.dir_client.stream_metrics(self.experiment_name):
-             self.logger.metric(
-                 f'Round {metric_message_dict["round"]}, '
-                 f'collaborator {metric_message_dict["metric_origin"]} '
-                 f'{metric_message_dict["task_name"]} result '
-                 f'{metric_message_dict["metric_name"]}:\t{metric_message_dict["metric_value"]:f}')
- 
-             if tensorboard_logs:
-                 self.write_tensorboard_metric(metric_message_dict)
- 
-     def write_tensorboard_metric(self, metric: dict) -> None:
-         """Write metric callback."""
-         if not self.summary_writer:
-             self.summary_writer = SummaryWriter(f'./logs/{self.experiment_name}', flush_secs=5)
- 
-         self.summary_writer.add_scalar(
-             f'{metric["metric_origin"]}/{metric["task_name"]}/{metric["metric_name"]}',
-             metric['metric_value'], metric['round'])
- 
-     def remove_experiment_data(self):
-         """Remove experiment data."""
-         self._assert_experiment_accepted()
-         log_message = 'Removing experiment data '
-         if self.federation.dir_client.remove_experiment_data(
-                 name=self.experiment_name
-         ):
-             log_message += 'succeed.'
-             self.experiment_accepted = False
-         else:
-             log_message += 'failed.'
- 
-         self.logger.info(log_message)
- 
-     def prepare_workspace_distribution(self, model_provider, task_keeper, data_loader,
-                                        task_assigner,
-                                        pip_install_options: Tuple[str] = ()):
-         """Prepare an archive from a user workspace."""
-         # Save serialized python objects to disc
-         self._serialize_interface_objects(model_provider, task_keeper, data_loader, task_assigner)
-         # Save the prepared plan
-         Plan.dump(Path(f'./plan/{self.plan.name}'), self.plan.config, freeze=False)
- 
-         # PACK the WORKSPACE!
-         # Prepare requirements file to restore python env
-         dump_requirements_file(keep_original_prefixes=True,
-                                prefixes=pip_install_options)
- 
-         # Compress te workspace to restore it on collaborator
-         self.arch_path = self._pack_the_workspace()
- 
-     def start(self, *, model_provider, task_keeper, data_loader,
-               rounds_to_train: int,
-               task_assigner=None,
-               delta_updates: bool = False,
-               opt_treatment: str = 'RESET',
-               device_assignment_policy: str = 'CPU_ONLY',
-               pip_install_options: Tuple[str] = ()) -> None:
-         """
-         Prepare workspace distribution and send to Director.
- 
-         A successful call of this function will result in sending the experiment workspace
-         to the Director service and experiment start.
- 
-         Parameters:
-         model_provider - Model Interface instance.
-         task_keeper - Task Interface instance.
-         data_loader - Data Interface instance.
-         rounds_to_train - required number of training rounds for the experiment.
-         delta_updates - [bool] Tells if collaborators should send delta updates
-             for the locally tuned models. If set to False, whole checkpoints will be sent.
-         opt_treatment - Optimizer state treatment policy.
-             Valid options: 'RESET' - reinitialize optimizer for every round,
-             'CONTINUE_LOCAL' - keep local optimizer state,
-             'CONTINUE_GLOBAL' - aggregate optimizer state.
-         device_assignment_policy - device assignment policy.
-             Valid options: 'CPU_ONLY' - device parameter passed to tasks
-             will always be 'cpu',
-             'CUDA_PREFERRED' - enable passing CUDA device identifiers to tasks
-             by collaborators, works with cuda-device-monitor plugin equipped Envoys.
-         pip_install_options - tuple of options for the remote `pip install` calls,
-             example: ('-f some.website', '--no-index')
-         """
-         if not task_assigner:
-             task_assigner = self.define_task_assigner(task_keeper, rounds_to_train)
- 
-         self._prepare_plan(model_provider, data_loader,
-                            rounds_to_train,
-                            delta_updates=delta_updates, opt_treatment=opt_treatment,
-                            device_assignment_policy=device_assignment_policy,
-                            model_interface_file='model_obj.pkl',
-                            tasks_interface_file='tasks_obj.pkl',
-                            dataloader_interface_file='loader_obj.pkl')
- 
-         self.prepare_workspace_distribution(
-             model_provider, task_keeper, data_loader,
-             task_assigner,
-             pip_install_options
-         )
- 
-         self.logger.info('Starting experiment!')
-         self.plan.resolve()
-         initial_tensor_dict = self._get_initial_tensor_dict(model_provider)
-         try:
-             response = self.federation.dir_client.set_new_experiment(
-                 name=self.experiment_name,
-                 col_names=self.plan.authorized_cols,
-                 arch_path=self.arch_path,
-                 initial_tensor_dict=initial_tensor_dict
-             )
-         finally:
-             self.remove_workspace_archive()
- 
-         if response.accepted:
-             self.logger.info('Experiment was accepted and launched.')
-             self.experiment_accepted = True
-         else:
-             self.logger.info('Experiment was not accepted or failed.')
- 
-     def define_task_assigner(self, task_keeper, rounds_to_train):
-         """Define task assigner by registered tasks."""
-         tasks = task_keeper.get_registered_tasks()
-         is_train_task_exist = False
-         self.is_validate_task_exist = False
-         for task in tasks.values():
-             if task.task_type == 'train':
-                 is_train_task_exist = True
-             if task.task_type == 'validate':
-                 self.is_validate_task_exist = True
- 
-         if not is_train_task_exist and rounds_to_train != 1:
-             # Since we have only validation tasks, we do not have to train it multiple times
-             raise Exception('Variable rounds_to_train must be equal 1, '
-                             'because only validation tasks were given')
-         if is_train_task_exist and self.is_validate_task_exist:
-             def assigner(collaborators, round_number, **kwargs):
-                 tasks_by_collaborator = {}
-                 for collaborator in collaborators:
-                     tasks_by_collaborator[collaborator] = [
-                         tasks['train'],
-                         tasks['locally_tuned_model_validate'],
-                         tasks['aggregated_model_validate'],
-                     ]
-                 return tasks_by_collaborator
-             return assigner
-         elif not is_train_task_exist and self.is_validate_task_exist:
-             def assigner(collaborators, round_number, **kwargs):
-                 tasks_by_collaborator = {}
-                 for collaborator in collaborators:
-                     tasks_by_collaborator[collaborator] = [
-                         tasks['aggregated_model_validate'],
-                     ]
-                 return tasks_by_collaborator
-             return assigner
-         elif is_train_task_exist and not self.is_validate_task_exist:
-             raise Exception('You should define validate task!')
-         else:
-             raise Exception('You should define train and validate tasks!')
- 
-     def restore_experiment_state(self, model_provider):
-         """Restore accepted experiment object."""
-         self.task_runner_stub = self.plan.get_core_task_runner(model_provider=model_provider)
-         self.current_model_status = ModelStatus.RESTORED
-         self.experiment_accepted = True
- 
-     @staticmethod
-     def _pack_the_workspace():
-         """Packing the archive."""
-         from shutil import copytree
-         from shutil import ignore_patterns
-         from shutil import make_archive
-         from shutil import rmtree
-         from os import getcwd
-         from os import makedirs
-         from os.path import basename
- 
-         archive_type = 'zip'
-         archive_name = basename(getcwd())
- 
-         tmp_dir = 'temp_' + archive_name
-         makedirs(tmp_dir, exist_ok=True)
- 
-         ignore = ignore_patterns(
-             '__pycache__', 'data', 'cert', tmp_dir, '*.crt', '*.key',
-             '*.csr', '*.srl', '*.pem', '*.pbuf', '*zip')
- 
-         copytree('./', tmp_dir + '/workspace', ignore=ignore)
- 
-         arch_path = make_archive(archive_name, archive_type, tmp_dir + '/workspace')
- 
-         rmtree(tmp_dir)
- 
-         return arch_path
- 
-     def remove_workspace_archive(self):
-         """Remove the workspace archive."""
-         os.remove(self.arch_path)
-         del self.arch_path
- 
-     def _get_initial_tensor_dict(self, model_provider):
-         """Extract initial weights from the model."""
-         self.task_runner_stub = self.plan.get_core_task_runner(model_provider=model_provider)
-         self.current_model_status = ModelStatus.INITIAL
-         tensor_dict, _ = split_tensor_dict_for_holdouts(
-             self.logger,
-             self.task_runner_stub.get_tensor_dict(False),
-             **self.task_runner_stub.tensor_dict_split_fn_kwargs
-         )
-         return tensor_dict
- 
-     def _prepare_plan(self, model_provider, data_loader,
-                       rounds_to_train,
-                       delta_updates, opt_treatment,
-                       device_assignment_policy,
-                       model_interface_file='model_obj.pkl', tasks_interface_file='tasks_obj.pkl',
-                       dataloader_interface_file='loader_obj.pkl',
-                       aggregation_function_interface_file='aggregation_function_obj.pkl',
-                       task_assigner_file='task_assigner_obj.pkl'):
-         """Fill plan.yaml file using provided setting."""
-         # Create a folder to store plans
-         os.makedirs('./plan', exist_ok=True)
-         os.makedirs('./save', exist_ok=True)
-         # Load the default plan
-         base_plan_path = WORKSPACE / 'workspace/plan/plans/default/base_plan_interactive_api.yaml'
-         plan = Plan.parse(base_plan_path, resolve=False)
-         # Change plan name to default one
-         plan.name = 'plan.yaml'
- 
-         # Seems like we still need to fill authorized_cols list
-         # So aggregator know when to start sending tasks
-         # We also could change the aggregator logic so it will send tasks to aggregator
-         # as soon as it connects. This change should be a part of a bigger PR
-         # brining in fault tolerance changes
- 
-         shard_registry = self.federation.get_shard_registry()
-         plan.authorized_cols = [
-             name for name, info in shard_registry.items() if info['is_online']
-         ]
-         # Network part of the plan
-         # We keep in mind that an aggregator FQND will be the same as the directors FQDN
-         # We just choose a port randomly from plan hash
-         director_fqdn = self.federation.director_node_fqdn.split(':')[0]  # We drop the port
-         plan.config['network']['settings']['agg_addr'] = director_fqdn
-         plan.config['network']['settings']['tls'] = self.federation.tls
- 
-         # Aggregator part of the plan
-         plan.config['aggregator']['settings']['rounds_to_train'] = rounds_to_train
- 
-         # Collaborator part
-         plan.config['collaborator']['settings']['delta_updates'] = delta_updates
-         plan.config['collaborator']['settings']['opt_treatment'] = opt_treatment
-         plan.config['collaborator']['settings'][
-             'device_assignment_policy'] = device_assignment_policy
- 
-         # DataLoader part
-         for setting, value in data_loader.kwargs.items():
-             plan.config['data_loader']['settings'][setting] = value
- 
-         # TaskRunner framework plugin
-         # ['required_plugin_components'] should be already in the default plan with all the fields
-         # filled with the default values
-         plan.config['task_runner']['required_plugin_components'] = {
-             'framework_adapters': model_provider.framework_plugin
-         }
- 
-         # API layer
-         plan.config['api_layer'] = {
-             'required_plugin_components': {
-                 'serializer_plugin': self.serializer_plugin
-             },
-             'settings': {
-                 'model_interface_file': model_interface_file,
-                 'tasks_interface_file': tasks_interface_file,
-                 'dataloader_interface_file': dataloader_interface_file,
-                 'aggregation_function_interface_file': aggregation_function_interface_file,
-                 'task_assigner_file': task_assigner_file
-             }
-         }
- 
-         self.plan = deepcopy(plan)
- 
-     def _serialize_interface_objects(
-             self,
-             model_provider,
-             task_keeper,
-             data_loader,
-             task_assigner
-     ):
-         """Save python objects to be restored on collaborators."""
-         serializer = self.plan.build(
-             self.plan.config['api_layer']['required_plugin_components']['serializer_plugin'], {})
-         framework_adapter = Plan.build(model_provider.framework_plugin, {})
-         # Model provider serialization may need preprocessing steps
-         framework_adapter.serialization_setup()
- 
-         obj_dict = {
-             'model_interface_file': model_provider,
-             'tasks_interface_file': task_keeper,
-             'dataloader_interface_file': data_loader,
-             'aggregation_function_interface_file': task_keeper.aggregation_functions,
-             'task_assigner_file': task_assigner
-         }
- 
-         for filename, object_ in obj_dict.items():
-             serializer.serialize(object_, self.plan.config['api_layer']['settings'][filename])
- 
- 
- class TaskKeeper:
-     """
-     Task keeper class.
- 
-     Task should accept the following entities that exist on collaborator nodes:
-     1. model - will be rebuilt with relevant weights for every task by `TaskRunner`
-     2. data_loader - data loader equipped with `repository adapter` that provides local data
-     3. device - a device to be used on collaborator machines
-     4. optimizer (optional)
- 
-     Task returns a dictionary {metric name: metric value for this task}
-     """
- 
-     def __init__(self) -> None:
-         """Initialize task registry."""
-         # Mapping 'task name' -> callable
-         self.task_registry = {}
-         # Mapping 'task name' -> arguments
-         self.task_contract = {}
-         # Mapping 'task name' -> arguments
-         self.task_settings = defaultdict(dict)
-         # Mapping 'task name' -> callable
-         self.aggregation_functions = defaultdict(WeightedAverage)
-         # Mapping 'task_alias' -> Task
-         self._tasks: Dict[str, Task] = {}
- 
-     def register_fl_task(self, model, data_loader, device, optimizer=None, round_num=None):
-         """
-         Register FL tasks.
- 
-         The task contract should be set up by providing variable names:
-         [model, data_loader, device] - necessarily
-         and optimizer - optionally
- 
-         All tasks should accept contract entities to be run on collaborator node.
-         Moreover we ask users return dict{'metric':value} in every task
-         `
-         TI = TaskInterface()
- 
-         task_settings = {
-             'batch_size': 32,
-             'some_arg': 228,
-         }
-         @TI.add_kwargs(**task_settings)
-         @TI.register_fl_task(model='my_model', data_loader='train_loader',
-                 device='device', optimizer='my_Adam_opt')
-         def foo_task(my_model, train_loader, my_Adam_opt, device, batch_size, some_arg=356)
-             ...
-             return {'metric_name': metric, 'metric_name_2': metric_2,}
-         `
-         """
-         # The highest level wrapper for allowing arguments for the decorator
-         def decorator_with_args(training_method):
-             # We could pass hooks to the decorator
-             # @functools.wraps(training_method)
- 
-             def wrapper_decorator(**task_keywords):
-                 metric_dict = training_method(**task_keywords)
-                 return metric_dict
- 
-             # Saving the task and the contract for later serialization
-             function_name = training_method.__name__
-             self.task_registry[function_name] = wrapper_decorator
-             contract = {'model': model, 'data_loader': data_loader,
-                         'device': device, 'optimizer': optimizer, 'round_num': round_num}
-             self.task_contract[function_name] = contract
-             # define tasks
-             if optimizer:
-                 self._tasks['train'] = TrainTask(
-                     name='train',
-                     function_name=function_name,
-                 )
-             else:
-                 self._tasks['locally_tuned_model_validate'] = ValidateTask(
-                     name='locally_tuned_model_validate',
-                     function_name=function_name,
-                     apply_local=True,
-                 )
-                 self._tasks['aggregated_model_validate'] = ValidateTask(
-                     name='aggregated_model_validate',
-                     function_name=function_name,
-                 )
-             # We do not alter user environment
- 
-             return training_method
- 
-         return decorator_with_args
- 
-     def add_kwargs(self, **task_kwargs):
-         """
-         Register tasks settings.
- 
-         Warning! We do not actually need to register additional kwargs,
-         we ust serialize them.
-         This one is a decorator because we need task name and
-         to be consistent with the main registering method
-         """
-         # The highest level wrapper for allowing arguments for the decorator
-         def decorator_with_args(training_method):
-             # Saving the task's settings to be written in plan
-             self.task_settings[training_method.__name__] = task_kwargs
- 
-             return training_method
- 
-         return decorator_with_args
- 
-     def set_aggregation_function(self, aggregation_function: AggregationFunction):
-         """Set aggregation function for the task.
- 
-         To be serialized and sent to aggregator node.
- 
-         There is no support for aggregation functions
-         containing logic from workspace-related libraries
-         that are not present on director yet.
- 
-         Args:
-             aggregation_function: Aggregation function.
- 
-         You might need to override default FedAvg aggregation with built-in aggregation types:
-             - openfl.component.aggregation_functions.GeometricMedian
-             - openfl.component.aggregation_functions.Median
-         or define your own AggregationFunction subclass.
-         See more details on `Overriding the aggregation function`_ documentation page.
-         .. _Overriding the aggregation function:
-             https://openfl.readthedocs.io/en/latest/overriding_agg_fn.html
-         """
-         def decorator_with_args(training_method):
-             if not isinstance(aggregation_function, AggregationFunction):
-                 raise Exception('aggregation_function must implement '
-                                 'AggregationFunction interface.')
-             self.aggregation_functions[training_method.__name__] = aggregation_function
-             return training_method
-         return decorator_with_args
- 
-     def get_registered_tasks(self) -> Dict[str, Task]:
-         """Return registered tasks."""
-         return self._tasks
- 
- 
- # Backward compatibility
- TaskInterface = TaskKeeper
- 
- 
- class ModelInterface:
-     """
-     Registers model graph and optimizer.
- 
-     To be serialized and sent to collaborator nodes
- 
-     This is the place to determine correct framework adapter
-         as they are needed to fill the model graph with trained tensors.
- 
-     There is no support for several models / optimizers yet.
-     """
- 
-     def __init__(self, model, optimizer, framework_plugin) -> None:
-         """
-         Initialize model keeper.
- 
-         Tensors in provided graphs will be used for
-         initialization of the global model.
- 
-         Arguments:
-         model: Union[tuple, graph]
-         optimizer: Union[tuple, optimizer]
-         """
-         self.model = model
-         self.optimizer = optimizer
-         self.framework_plugin = framework_plugin
- 
-     def provide_model(self):
-         """Retrieve model."""
-         return self.model
- 
-     def provide_optimizer(self):
-         """Retrieve optimizer."""
-         return self.optimizer
- 
- 
- class DataInterface:
-     """
-     The class to define dataloaders.
- 
-     In the future users will have to adapt `unified data interface hook`
-         in their dataloaders.
-     For now, we can provide `data_path` variable on every collaborator node
-         at initialization time for dataloader customization
-     """
- 
-     def __init__(self, **kwargs):
-         """Initialize DataLoader."""
-         self.kwargs = kwargs
- 
-     @property
-     def shard_descriptor(self):
-         """Return shard descriptor."""
-         return self._shard_descriptor
- 
-     @shard_descriptor.setter
-     def shard_descriptor(self, shard_descriptor):
-         """
-         Describe per-collaborator procedures or sharding.
- 
-         This method will be called during a collaborator initialization.
-         Local shard_descriptor  will be set by Envoy.
-         """
-         self._shard_descriptor = shard_descriptor
-         raise NotImplementedError
- 
-     def get_train_loader(self, **kwargs):
-         """Output of this method will be provided to tasks with optimizer in contract."""
-         raise NotImplementedError
- 
-     def get_valid_loader(self, **kwargs):
-         """Output of this method will be provided to tasks without optimizer in contract."""
-         raise NotImplementedError
- 
-     def get_train_data_size(self):
-         """Information for aggregation."""
-         raise NotImplementedError
- 
-     def get_valid_data_size(self):
-         """Information for aggregation."""
-         raise NotImplementedError
--- 0 ----
diff -crB --new-file ./openfl/openfl/interface/interactive_api/federation.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/interactive_api/federation.py
*** ./openfl/openfl/interface/interactive_api/federation.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/interactive_api/federation.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,66 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Federation API module."""
- 
- from openfl.transport.grpc.director_client import DirectorClient
- from openfl.utilities.utils import getfqdn_env
- from .shard_descriptor import DummyShardDescriptor
- 
- 
- class Federation:
-     """
-     Federation class.
- 
-     Federation entity exists to keep information about collaborator related settings,
-     their local data and network setting to enable communication in federation.
-     """
- 
-     def __init__(self, client_id=None, director_node_fqdn=None, director_port=None, tls=True,
-                  cert_chain=None, api_cert=None, api_private_key=None) -> None:
-         """
-         Initialize federation.
- 
-         Federation API class should be initialized with the Director node FQDN
-         and encryption settings. One may disable mTLS in trusted environments or
-         provide paths to a certificate chain to CA, API certificate and
-         pricate key to enable mTLS.
- 
-         Args:
-         - client_id: name of created Frontend API instance.
-             The same name user certify.
-         - director_node_fqdn: Address and port a director's service is running on.
-             User passes here an address with a port.
-         """
-         if director_node_fqdn is None:
-             self.director_node_fqdn = getfqdn_env()
-         else:
-             self.director_node_fqdn = director_node_fqdn
- 
-         self.tls = tls
- 
-         self.cert_chain = cert_chain
-         self.api_cert = api_cert
-         self.api_private_key = api_private_key
- 
-         # Create Director client
-         self.dir_client = DirectorClient(
-             client_id=client_id,
-             director_host=director_node_fqdn,
-             director_port=director_port,
-             tls=tls,
-             root_certificate=cert_chain,
-             private_key=api_private_key,
-             certificate=api_cert
-         )
- 
-         # Request sample and target shapes from Director.
-         # This is an internal method for finding out dataset properties in a Federation.
-         self.sample_shape, self.target_shape = self.dir_client.get_dataset_info()
- 
-     def get_dummy_shard_descriptor(self, size):
-         """Return a dummy shard descriptor."""
-         return DummyShardDescriptor(self.sample_shape, self.target_shape, size)
- 
-     def get_shard_registry(self):
-         """Return a shard registry."""
-         return self.dir_client.get_envoys()
--- 0 ----
diff -crB --new-file ./openfl/openfl/interface/interactive_api/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/interactive_api/__init__.py
*** ./openfl/openfl/interface/interactive_api/__init__.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/interactive_api/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Interactive API package."""
--- 0 ----
diff -crB --new-file ./openfl/openfl/interface/interactive_api/shard_descriptor.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/interactive_api/shard_descriptor.py
*** ./openfl/openfl/interface/interactive_api/shard_descriptor.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/interactive_api/shard_descriptor.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,104 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Shard descriptor."""
- 
- from typing import Iterable
- from typing import List
- 
- import numpy as np
- 
- 
- class ShardDataset:
-     """Shard dataset class."""
- 
-     def __len__(self) -> int:
-         """Return the len of the shard dataset."""
-         raise NotImplementedError
- 
-     def __getitem__(self, index: int):
-         """Return an item by the index."""
-         raise NotImplementedError
- 
- 
- class ShardDescriptor:
-     """Shard descriptor class."""
- 
-     def get_dataset(self, dataset_type: str) -> ShardDataset:
-         """Return a shard dataset by type."""
-         raise NotImplementedError
- 
-     @property
-     def sample_shape(self) -> List[int]:
-         """Return the sample shape info."""
-         raise NotImplementedError
- 
-     @property
-     def target_shape(self) -> List[int]:
-         """Return the target shape info."""
-         raise NotImplementedError
- 
-     @property
-     def dataset_description(self) -> str:
-         """Return the dataset description."""
-         return ''
- 
- 
- class DummyShardDataset(ShardDataset):
-     """Dummy shard dataset class."""
- 
-     def __init__(
-             self, *,
-             size: int,
-             sample_shape: List[int],
-             target_shape: List[int]
-     ):
-         """Initialize DummyShardDataset."""
-         self.size = size
-         self.samples = np.random.randint(0, 255, (self.size, *sample_shape), np.uint8)
-         self.targets = np.random.randint(0, 255, (self.size, *target_shape), np.uint8)
- 
-     def __len__(self) -> int:
-         """Return the len of the dataset."""
-         return self.size
- 
-     def __getitem__(self, index: int):
-         """Return a item by the index."""
-         return self.samples[index], self.targets[index]
- 
- 
- class DummyShardDescriptor(ShardDescriptor):
-     """Dummy shard descriptor class."""
- 
-     def __init__(
-             self,
-             sample_shape: Iterable[str],
-             target_shape: Iterable[str],
-             size: int
-     ) -> None:
-         """Initialize DummyShardDescriptor."""
-         self._sample_shape = [int(dim) for dim in sample_shape]
-         self._target_shape = [int(dim) for dim in target_shape]
-         self.size = size
- 
-     def get_dataset(self, dataset_type: str) -> ShardDataset:
-         """Return a shard dataset by type."""
-         return DummyShardDataset(
-             size=self.size,
-             sample_shape=self._sample_shape,
-             target_shape=self._target_shape
-         )
- 
-     @property
-     def sample_shape(self) -> List[int]:
-         """Return the sample shape info."""
-         return self._sample_shape
- 
-     @property
-     def target_shape(self) -> List[int]:
-         """Return the target shape info."""
-         return self._target_shape
- 
-     @property
-     def dataset_description(self) -> str:
-         """Return the dataset description."""
-         return 'Dummy shard descriptor'
--- 0 ----
diff -crB --new-file ./openfl/openfl/interface/pki.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/pki.py
*** ./openfl/openfl/interface/pki.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/pki.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,110 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """PKI CLI."""
- 
- import logging
- import os
- from pathlib import Path
- 
- from click import group
- from click import option
- from click import pass_context
- from click import password_option
- from click import Path as ClickPath
- 
- from openfl.component.ca.ca import CA_CONFIG_JSON
- from openfl.component.ca.ca import CA_PASSWORD_FILE
- from openfl.component.ca.ca import CA_PKI_DIR
- from openfl.component.ca.ca import CA_STEP_CONFIG_DIR
- from openfl.component.ca.ca import certify
- from openfl.component.ca.ca import get_ca_bin_paths
- from openfl.component.ca.ca import get_token
- from openfl.component.ca.ca import install
- from openfl.component.ca.ca import remove_ca
- from openfl.component.ca.ca import run_ca
- 
- logger = logging.getLogger(__name__)
- 
- CA_URL = 'localhost:9123'
- 
- 
- @group()
- @pass_context
- def pki(context):
-     """Manage Step-ca PKI."""
-     context.obj['group'] = 'pki'
- 
- 
- @pki.command(name='run')
- @option('-p', '--ca-path', required=True,
-         help='The ca path', type=ClickPath())
- def run(ca_path):
-     """Run CA server."""
-     ca_path = Path(ca_path).absolute()
-     step_config_dir = ca_path / CA_STEP_CONFIG_DIR
-     pki_dir = ca_path / CA_PKI_DIR
-     password_file = pki_dir / CA_PASSWORD_FILE
-     ca_json = step_config_dir / CA_CONFIG_JSON
-     _, step_ca_path = get_ca_bin_paths(ca_path)
-     if (not os.path.exists(step_config_dir) or not os.path.exists(pki_dir)
-             or not os.path.exists(password_file) or not os.path.exists(ca_json)
-             or not os.path.exists(step_ca_path)):
-         logger.warning('CA is not installed or corrupted, please install it first')
-         return
-     run_ca(step_ca_path, password_file, ca_json)
- 
- 
- @pki.command(name='install')
- @option('-p', '--ca-path', required=True,
-         help='The ca path', type=ClickPath())
- @password_option(prompt='The password will encrypt some ca files \nEnter the password')
- @option('--ca-url', required=False, default=CA_URL)
- def install_(ca_path, password, ca_url):
-     """Create a ca workspace."""
-     ca_path = Path(ca_path).absolute()
-     install(ca_path, ca_url, password)
- 
- 
- @pki.command(name='uninstall')
- @option('-p', '--ca-path', required=True,
-         help='The CA path', type=ClickPath())
- def uninstall(ca_path):
-     """Remove step-CA."""
-     ca_path = Path(ca_path).absolute()
-     remove_ca(ca_path)
- 
- 
- @pki.command(name='get-token')
- @option('-n', '--name', required=True)
- @option('--ca-url', required=False, default=CA_URL)
- @option('-p', '--ca-path', default='.',
-         help='The CA path', type=ClickPath(exists=True))
- def get_token_(name, ca_url, ca_path):
-     """
-     Create authentication token.
- 
-     Args:
-         name: common name for following certificate
-                     (aggregator fqdn or collaborator name)
-         ca_url: full url of CA server
-         ca_path: the path to CA binaries
-     """
-     ca_path = Path(ca_path).absolute()
-     token = get_token(name, ca_url, ca_path)
-     print('Token:')
-     print(token)
- 
- 
- @pki.command(name='certify')
- @option('-n', '--name', required=True)
- @option('-t', '--token', 'token_with_cert', required=True)
- @option('-c', '--certs-path', required=False, default=Path('.') / 'cert',
-         help='The path where certificates will be stored', type=ClickPath())
- @option('-p', '--ca-path', default='.', help='The path to CA client',
-         type=ClickPath(exists=True), required=False)
- def certify_(name, token_with_cert, certs_path, ca_path):
-     """Create an envoy workspace."""
-     certs_path = Path(certs_path).absolute()
-     ca_path = Path(ca_path).absolute()
-     certs_path.mkdir(parents=True, exist_ok=True)
-     certify(name, certs_path, token_with_cert, ca_path)
--- 0 ----
diff -crB --new-file ./openfl/openfl/interface/plan.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/plan.py
*** ./openfl/openfl/interface/plan.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/plan.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,253 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Plan module."""
- 
- import sys
- from logging import getLogger
- 
- from click import echo
- from click import group
- from click import option
- from click import pass_context
- from click import Path as ClickPath
- 
- from openfl.utilities.path_check import is_directory_traversal
- 
- logger = getLogger(__name__)
- 
- 
- @group()
- @pass_context
- def plan(context):
-     """Manage Federated Learning Plans."""
-     context.obj['group'] = 'plan'
- 
- 
- @plan.command()
- @pass_context
- @option('-p', '--plan_config', required=False,
-         help='Federated learning plan [plan/plan.yaml]',
-         default='plan/plan.yaml', type=ClickPath(exists=True))
- @option('-c', '--cols_config', required=False,
-         help='Authorized collaborator list [plan/cols.yaml]',
-         default='plan/cols.yaml', type=ClickPath(exists=True))
- @option('-d', '--data_config', required=False,
-         help='The data set/shard configuration file [plan/data.yaml]',
-         default='plan/data.yaml', type=ClickPath(exists=True))
- @option('-a', '--aggregator_address', required=False,
-         help='The FQDN of the federation agregator')
- @option('-f', '--feature_shape', required=False,
-         help='The input shape to the model')
- def initialize(context, plan_config, cols_config, data_config,
-                aggregator_address, feature_shape):
-     """
-     Initialize Data Science plan.
- 
-     Create a protocol buffer file of the initial model weights for
-      the federation.
-     """
-     from pathlib import Path
- 
-     from openfl.federated import Plan
-     from openfl.protocols import utils
-     from openfl.utilities import split_tensor_dict_for_holdouts
-     from openfl.utilities.utils import getfqdn_env
- 
-     for p in [plan_config, cols_config, data_config]:
-         if is_directory_traversal(p):
-             echo(f'{p} is out of the openfl workspace scope.')
-             sys.exit(1)
- 
-     plan_config = Path(plan_config).absolute()
-     cols_config = Path(cols_config).absolute()
-     data_config = Path(data_config).absolute()
- 
-     plan = Plan.parse(plan_config_path=plan_config,
-                       cols_config_path=cols_config,
-                       data_config_path=data_config)
- 
-     init_state_path = plan.config['aggregator']['settings']['init_state_path']
- 
-     # TODO:  Is this part really needed?  Why would we need to collaborator
-     #  name to know the input shape to the model?
- 
-     # if  feature_shape is None:
-     #     if  cols_config is None:
-     #         exit('You must specify either a feature
-     #         shape or authorized collaborator
-     #         list in order for the script to determine the input layer shape')
-     print(plan.cols_data_paths)
- 
-     collaborator_cname = list(plan.cols_data_paths)[0]
- 
-     data_loader = plan.get_data_loader(collaborator_cname)
-     task_runner = plan.get_task_runner(data_loader)
-     tensor_pipe = plan.get_tensor_pipe()
- 
-     tensor_dict, holdout_params = split_tensor_dict_for_holdouts(
-         logger,
-         task_runner.get_tensor_dict(False),
-         **task_runner.tensor_dict_split_fn_kwargs
-     )
- 
-     logger.warn(f'Following parameters omitted from global initial model, '
-                 f'local initialization will determine'
-                 f' values: {list(holdout_params.keys())}')
- 
-     model_snap = utils.construct_model_proto(tensor_dict=tensor_dict,
-                                              round_number=0,
-                                              tensor_pipe=tensor_pipe)
- 
-     logger.info(f'Creating Initial Weights File    🠆 {init_state_path}')
- 
-     utils.dump_proto(model_proto=model_snap, fpath=init_state_path)
- 
-     plan_origin = Plan.parse(plan_config, resolve=False).config
- 
-     if (plan_origin['network']['settings']['agg_addr'] == 'auto'
-             or aggregator_address):
-         plan_origin['network']['settings']['agg_addr'] = aggregator_address or getfqdn_env()
- 
-         logger.warn(f'Patching Aggregator Addr in Plan'
-                     f" 🠆 {plan_origin['network']['settings']['agg_addr']}")
- 
-         Plan.dump(plan_config, plan_origin)
- 
-     plan.config = plan_origin
- 
-     # Record that plan with this hash has been initialized
-     if 'plans' not in context.obj:
-         context.obj['plans'] = []
-     context.obj['plans'].append(f'{plan_config.stem}_{plan.hash[:8]}')
-     logger.info(f"{context.obj['plans']}")
- 
- 
- # TODO: looks like Plan.method
- def freeze_plan(plan_config):
-     """Dump the plan to YAML file."""
-     from pathlib import Path
- 
-     from openfl.federated import Plan
- 
-     plan = Plan()
-     plan.config = Plan.parse(Path(plan_config), resolve=False).config
- 
-     init_state_path = plan.config['aggregator']['settings']['init_state_path']
- 
-     if not Path(init_state_path).exists():
-         logger.info("Plan has not been initialized! Run 'fx plan"
-                     " initialize' before proceeding")
-         return
- 
-     Plan.dump(Path(plan_config), plan.config, freeze=True)
- 
- 
- @plan.command(name='freeze')
- @option('-p', '--plan_config', required=False,
-         help='Federated learning plan [plan/plan.yaml]',
-         default='plan/plan.yaml', type=ClickPath(exists=True))
- def freeze(plan_config):
-     """
-     Finalize the Data Science plan.
- 
-     Create a new plan file that embeds its hash in the file name
-     (plan.yaml -> plan_{hash}.yaml) and changes the permissions to read only
-     """
-     if is_directory_traversal(plan_config):
-         echo('Plan config path is out of the openfl workspace scope.')
-         sys.exit(1)
-     freeze_plan(plan_config)
- 
- 
- def switch_plan(name):
-     """Switch the FL plan to this one."""
-     from shutil import copyfile
-     from os.path import isfile
- 
-     from yaml import dump
-     from yaml import FullLoader
-     from yaml import load
- 
-     plan_file = f'plan/plans/{name}/plan.yaml'
-     if isfile(plan_file):
- 
-         echo(f'Switch plan to {name}')
- 
-         # Copy the new plan.yaml file to the top directory
-         copyfile(plan_file, 'plan/plan.yaml')
- 
-         # Update the .workspace file to show the current workspace plan
-         workspace_file = '.workspace'
- 
-         with open(workspace_file, 'r') as f:
-             doc = load(f, Loader=FullLoader)
- 
-         if not doc:  # YAML is not correctly formatted
-             doc = {}  # Create empty dictionary
- 
-         doc['current_plan_name'] = f'{name}'  # Switch with new plan name
- 
-         # Rewrite updated workspace file
-         with open(workspace_file, 'w') as f:
-             dump(doc, f)
- 
-     else:
-         echo(f'Error: Plan {name} not found in plan/plans/{name}')
- 
- 
- @plan.command(name='switch')
- @option('-n', '--name', required=False,
-         help='Name of the Federated learning plan',
-         default='default', type=str)
- def switch_(name):
-     """Switch the current plan to this plan."""
-     switch_plan(name)
- 
- 
- @plan.command(name='save')
- @option('-n', '--name', required=False,
-         help='Name of the Federated learning plan',
-         default='default', type=str)
- def save_(name):
-     """Save the current plan to this plan and switch."""
-     from os import makedirs
-     from shutil import copyfile
- 
-     echo(f'Saving plan to {name}')
-     # TODO: How do we get the prefix path? What happens if this gets executed
-     #  outside of the workspace top directory?
- 
-     makedirs(f'plan/plans/{name}', exist_ok=True)
-     copyfile('plan/plan.yaml', f'plan/plans/{name}/plan.yaml')
- 
-     switch_plan(name)  # Swtich the context
- 
- 
- @plan.command(name='remove')
- @option('-n', '--name', required=False,
-         help='Name of the Federated learning plan',
-         default='default', type=str)
- def remove_(name):
-     """Remove this plan."""
-     from shutil import rmtree
- 
-     if name != 'default':
-         echo(f'Removing plan {name}')
-         # TODO: How do we get the prefix path? What happens if
-         #  this gets executed outside of the workspace top directory?
- 
-         rmtree(f'plan/plans/{name}')
- 
-         switch_plan('default')  # Swtich the context back to the default
- 
-     else:
-         echo("ERROR: Can't remove default plan")
- 
- 
- @plan.command(name='print')
- def print_():
-     """Print the current plan."""
-     from openfl.interface.cli_helper import get_workspace_parameter
- 
-     current_plan_name = get_workspace_parameter('current_plan_name')
-     echo(f'The current plan is: {current_plan_name}')
--- 0 ----
diff -crB --new-file ./openfl/openfl/interface/tutorial.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/tutorial.py
*** ./openfl/openfl/interface/tutorial.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/tutorial.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,51 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Tutorial module."""
- 
- from logging import getLogger
- 
- from click import group
- from click import IntRange
- from click import option
- from click import pass_context
- 
- from openfl.utilities import click_types
- 
- logger = getLogger(__name__)
- 
- 
- @group()
- @pass_context
- def tutorial(context):
-     """Manage Jupyter notebooks."""
-     context.obj['group'] = 'tutorial'
- 
- 
- @tutorial.command()
- @option('-ip', '--ip', required=False, type=click_types.IP_ADDRESS,
-         help='IP address the Jupyter Lab that should start')
- @option('-port', '--port', required=False, type=IntRange(1, 65535),
-         help='The port the Jupyter Lab server will listen on')
- def start(ip, port):
-     """Start the Jupyter Lab from the tutorials directory."""
-     from os import environ
-     from subprocess import check_call
-     from sys import executable
- 
-     from openfl.interface.cli_helper import TUTORIALS
- 
-     if 'VIRTUAL_ENV' in environ:
-         venv = environ['VIRTUAL_ENV'].split('/')[-1]
-         check_call([
-             executable, '-m', 'ipykernel', 'install',
-             '--user', '--name', f'{venv}'
-         ], shell=False)
- 
-     jupyter_command = ['jupyter', 'lab', '--notebook-dir', f'{TUTORIALS}']
- 
-     if ip is not None:
-         jupyter_command += ['--ip', f'{ip}']
-     if port is not None:
-         jupyter_command += ['--port', f'{port}']
- 
-     check_call(jupyter_command)
--- 0 ----
diff -crB --new-file ./openfl/openfl/interface/workspace.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/workspace.py
*** ./openfl/openfl/interface/workspace.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/workspace.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,531 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Workspace module."""
- 
- import os
- import subprocess
- import sys
- from pathlib import Path
- from typing import Tuple
- 
- from click import Choice
- from click import confirm
- from click import echo
- from click import group
- from click import option
- from click import pass_context
- from click import Path as ClickPath
- 
- from openfl.utilities.path_check import is_directory_traversal
- from openfl.utilities.workspace import dump_requirements_file
- 
- 
- @group()
- @pass_context
- def workspace(context):
-     """Manage Federated Learning Workspaces."""
-     context.obj['group'] = 'workspace'
- 
- 
- def create_dirs(prefix):
-     """Create workspace directories."""
-     from shutil import copyfile
- 
-     from openfl.interface.cli_helper import WORKSPACE
- 
-     echo('Creating Workspace Directories')
- 
-     (prefix / 'cert').mkdir(parents=True, exist_ok=True)  # certifications
-     (prefix / 'data').mkdir(parents=True, exist_ok=True)  # training data
-     (prefix / 'logs').mkdir(parents=True, exist_ok=True)  # training logs
-     (prefix / 'save').mkdir(parents=True, exist_ok=True)  # model weight saves / initialization
-     (prefix / 'src').mkdir(parents=True, exist_ok=True)  # model code
- 
-     copyfile(WORKSPACE / 'workspace' / '.workspace', prefix / '.workspace')
- 
- 
- def create_temp(prefix, template):
-     """Create workspace templates."""
-     from shutil import ignore_patterns
- 
-     from openfl.interface.cli_helper import copytree
-     from openfl.interface.cli_helper import WORKSPACE
- 
-     echo('Creating Workspace Templates')
- 
-     copytree(src=WORKSPACE / template, dst=prefix, dirs_exist_ok=True,
-              ignore=ignore_patterns('__pycache__'))  # from template workspace
-     apply_template_plan(prefix, template)
- 
- 
- def get_templates():
-     """Grab the default templates from the distribution."""
-     from openfl.interface.cli_helper import WORKSPACE
- 
-     return [d.name for d in WORKSPACE.glob('*') if d.is_dir()
-             and d.name not in ['__pycache__', 'workspace']]
- 
- 
- @workspace.command(name='create')
- @option('--prefix', required=True,
-         help='Workspace name or path', type=ClickPath())
- @option('--template', required=True, type=Choice(get_templates()))
- def create_(prefix, template):
-     """Create the workspace."""
-     if is_directory_traversal(prefix):
-         echo('Workspace name or path is out of the openfl workspace scope.')
-         sys.exit(1)
-     create(prefix, template)
- 
- 
- def create(prefix, template):
-     """Create federated learning workspace."""
-     from os.path import isfile
-     from subprocess import check_call
-     from sys import executable
- 
-     from openfl.interface.cli_helper import print_tree
-     from openfl.interface.cli_helper import OPENFL_USERDIR
- 
-     if not OPENFL_USERDIR.exists():
-         OPENFL_USERDIR.mkdir()
- 
-     prefix = Path(prefix).absolute()
- 
-     create_dirs(prefix)
-     create_temp(prefix, template)
- 
-     requirements_filename = 'requirements.txt'
- 
-     if isfile(f'{str(prefix)}/{requirements_filename}'):
-         check_call([
-             executable, '-m', 'pip', 'install', '-r',
-             f'{prefix}/requirements.txt'], shell=False)
-         echo(f'Successfully installed packages from {prefix}/requirements.txt.')
-     else:
-         echo('No additional requirements for workspace defined. Skipping...')
-     prefix_hash = _get_dir_hash(str(prefix.absolute()))
-     with open(OPENFL_USERDIR / f'requirements.{prefix_hash}.txt', 'w') as f:
-         check_call([executable, '-m', 'pip', 'freeze'], shell=False, stdout=f)
- 
-     print_tree(prefix, level=3)
- 
- 
- @workspace.command(name='export')
- @option('-o', '--pip-install-options', required=False,
-         type=str, multiple=True, default=tuple,
-         help='Options for remote pip install. '
-              'You may pass several options in quotation marks alongside with arguments, '
-              'e.g. -o "--find-links source.site"')
- def export_(pip_install_options: Tuple[str]):
-     """Export federated learning workspace."""
-     from os import getcwd
-     from os import makedirs
-     from os.path import basename
-     from os.path import join
-     from shutil import copy2
-     from shutil import copytree
-     from shutil import ignore_patterns
-     from shutil import make_archive
-     from tempfile import mkdtemp
- 
-     from plan import freeze_plan
-     from openfl.interface.cli_helper import WORKSPACE
- 
-     plan_file = Path('plan/plan.yaml').absolute()
-     try:
-         freeze_plan(plan_file)
-     except Exception:
-         echo(f'Plan file "{plan_file}" not found. No freeze performed.')
- 
-     # Dump requirements.txt
-     dump_requirements_file(prefixes=pip_install_options, keep_original_prefixes=True)
- 
-     archive_type = 'zip'
-     archive_name = basename(getcwd())
-     archive_file_name = archive_name + '.' + archive_type
- 
-     # Aggregator workspace
-     tmp_dir = join(mkdtemp(), 'openfl', archive_name)
- 
-     ignore = ignore_patterns(
-         '__pycache__', '*.crt', '*.key', '*.csr', '*.srl', '*.pem', '*.pbuf')
- 
-     # We only export the minimum required files to set up a collaborator
-     makedirs(f'{tmp_dir}/save', exist_ok=True)
-     makedirs(f'{tmp_dir}/logs', exist_ok=True)
-     makedirs(f'{tmp_dir}/data', exist_ok=True)
-     copytree('./src', f'{tmp_dir}/src', ignore=ignore)  # code
-     copytree('./plan', f'{tmp_dir}/plan', ignore=ignore)  # plan
-     copy2('./requirements.txt', f'{tmp_dir}/requirements.txt')  # requirements
- 
-     try:
-         copy2('.workspace', tmp_dir)  # .workspace
-     except FileNotFoundError:
-         echo('\'.workspace\' file not found.')
-         if confirm('Create a default \'.workspace\' file?'):
-             copy2(WORKSPACE / 'workspace' / '.workspace', tmp_dir)
-         else:
-             echo('To proceed, you must have a \'.workspace\' '
-                  'file in the current directory.')
-             raise
- 
-     # Create Zip archive of directory
-     echo('\n 🗜️ Preparing workspace distribution zip file')
-     make_archive(archive_name, archive_type, tmp_dir)
- 
-     echo(f'\n ✔️ Workspace exported to archive: {archive_file_name}')
- 
- 
- @workspace.command(name='import')
- @option('--archive', required=True,
-         help='Zip file containing workspace to import',
-         type=ClickPath(exists=True))
- def import_(archive):
-     """Import federated learning workspace."""
-     from os import chdir
-     from os.path import basename
-     from os.path import isfile
-     from shutil import unpack_archive
-     from subprocess import check_call
-     from sys import executable
- 
-     archive = Path(archive).absolute()
- 
-     dir_path = basename(archive).split('.')[0]
-     unpack_archive(archive, extract_dir=dir_path)
-     chdir(dir_path)
- 
-     requirements_filename = 'requirements.txt'
- 
-     if isfile(requirements_filename):
-         check_call([
-             executable, '-m', 'pip', 'install', '--upgrade', 'pip'],
-             shell=False)
-         check_call([
-             executable, '-m', 'pip', 'install', '-r', 'requirements.txt'],
-             shell=False)
-     else:
-         echo('No ' + requirements_filename + ' file found.')
- 
-     echo(f'Workspace {archive} has been imported.')
-     echo('You may need to copy your PKI certificates to join the federation.')
- 
- 
- @workspace.command(name='certify')
- def certify_():
-     """Create certificate authority for federation."""
-     certify()
- 
- 
- def certify():
-     """Create certificate authority for federation."""
-     from cryptography.hazmat.primitives import serialization
- 
-     from openfl.cryptography.ca import generate_root_cert
-     from openfl.cryptography.ca import generate_signing_csr
-     from openfl.cryptography.ca import sign_certificate
-     from openfl.interface.cli_helper import CERT_DIR
- 
-     echo('Setting Up Certificate Authority...\n')
- 
-     echo('1.  Create Root CA')
-     echo('1.1 Create Directories')
- 
-     (CERT_DIR / 'ca/root-ca/private').mkdir(
-         parents=True, exist_ok=True, mode=0o700)
-     (CERT_DIR / 'ca/root-ca/db').mkdir(parents=True, exist_ok=True)
- 
-     echo('1.2 Create Database')
- 
-     with open(CERT_DIR / 'ca/root-ca/db/root-ca.db', 'w') as f:
-         pass  # write empty file
-     with open(CERT_DIR / 'ca/root-ca/db/root-ca.db.attr', 'w') as f:
-         pass  # write empty file
- 
-     with open(CERT_DIR / 'ca/root-ca/db/root-ca.crt.srl', 'w') as f:
-         f.write('01')  # write file with '01'
-     with open(CERT_DIR / 'ca/root-ca/db/root-ca.crl.srl', 'w') as f:
-         f.write('01')  # write file with '01'
- 
-     echo('1.3 Create CA Request and Certificate')
- 
-     root_crt_path = 'ca/root-ca.crt'
-     root_key_path = 'ca/root-ca/private/root-ca.key'
- 
-     root_private_key, root_cert = generate_root_cert()
- 
-     # Write root CA certificate to disk
-     with open(CERT_DIR / root_crt_path, 'wb') as f:
-         f.write(root_cert.public_bytes(
-             encoding=serialization.Encoding.PEM,
-         ))
- 
-     with open(CERT_DIR / root_key_path, 'wb') as f:
-         f.write(root_private_key.private_bytes(
-             encoding=serialization.Encoding.PEM,
-             format=serialization.PrivateFormat.TraditionalOpenSSL,
-             encryption_algorithm=serialization.NoEncryption()
-         ))
- 
-     echo('2.  Create Signing Certificate')
-     echo('2.1 Create Directories')
- 
-     (CERT_DIR / 'ca/signing-ca/private').mkdir(
-         parents=True, exist_ok=True, mode=0o700)
-     (CERT_DIR / 'ca/signing-ca/db').mkdir(parents=True, exist_ok=True)
- 
-     echo('2.2 Create Database')
- 
-     with open(CERT_DIR / 'ca/signing-ca/db/signing-ca.db', 'w') as f:
-         pass  # write empty file
-     with open(CERT_DIR / 'ca/signing-ca/db/signing-ca.db.attr', 'w') as f:
-         pass  # write empty file
- 
-     with open(CERT_DIR / 'ca/signing-ca/db/signing-ca.crt.srl', 'w') as f:
-         f.write('01')  # write file with '01'
-     with open(CERT_DIR / 'ca/signing-ca/db/signing-ca.crl.srl', 'w') as f:
-         f.write('01')  # write file with '01'
- 
-     echo('2.3 Create Signing Certificate CSR')
- 
-     signing_csr_path = 'ca/signing-ca.csr'
-     signing_crt_path = 'ca/signing-ca.crt'
-     signing_key_path = 'ca/signing-ca/private/signing-ca.key'
- 
-     signing_private_key, signing_csr = generate_signing_csr()
- 
-     # Write Signing CA CSR to disk
-     with open(CERT_DIR / signing_csr_path, 'wb') as f:
-         f.write(signing_csr.public_bytes(
-             encoding=serialization.Encoding.PEM,
-         ))
- 
-     with open(CERT_DIR / signing_key_path, 'wb') as f:
-         f.write(signing_private_key.private_bytes(
-             encoding=serialization.Encoding.PEM,
-             format=serialization.PrivateFormat.TraditionalOpenSSL,
-             encryption_algorithm=serialization.NoEncryption()
-         ))
- 
-     echo('2.4 Sign Signing Certificate CSR')
- 
-     signing_cert = sign_certificate(signing_csr, root_private_key, root_cert.subject, ca=True)
- 
-     with open(CERT_DIR / signing_crt_path, 'wb') as f:
-         f.write(signing_cert.public_bytes(
-             encoding=serialization.Encoding.PEM,
-         ))
- 
-     echo('3   Create Certificate Chain')
- 
-     # create certificate chain file by combining root-ca and signing-ca
-     with open(CERT_DIR / 'cert_chain.crt', 'w') as d:
-         with open(CERT_DIR / 'ca/root-ca.crt') as s:
-             d.write(s.read())
-         with open(CERT_DIR / 'ca/signing-ca.crt') as s:
-             d.write(s.read())
- 
-     echo('\nDone.')
- 
- 
- def _get_requirements_dict(txtfile):
-     with open(txtfile, 'r') as snapshot:
-         snapshot_dict = {}
-         for line in snapshot:
-             try:
-                 # 'pip freeze' generates requirements with exact versions
-                 k, v = line.split('==')
-                 snapshot_dict[k] = v
-             except ValueError:
-                 snapshot_dict[line] = None
-         return snapshot_dict
- 
- 
- def _get_dir_hash(path):
-     from hashlib import sha256
-     hash_ = sha256()
-     hash_.update(path.encode('utf-8'))
-     hash_ = hash_.hexdigest()
-     return hash_
- 
- 
- @workspace.command(name='dockerize')
- @option('-b', '--base_image', required=False,
-         help='The tag for openfl base image',
-         default='openfl')
- @option('--save/--no-save',
-         required=False,
-         help='Save the Docker image into the workspace',
-         default=True)
- @pass_context
- def dockerize_(context, base_image, save):
-     """
-     Pack the workspace as a Docker image.
- 
-     This command is the alternative to `workspace export`.
-     It should be called after plan initialization from the workspace dir.
- 
-     User is expected to be in docker group.
-     If your machine is behind a proxy, make sure you set it up in ~/.docker/config.json.
-     """
-     import docker
-     import sys
-     from shutil import copyfile
- 
-     from openfl.interface.cli_helper import SITEPACKS
- 
-     # Specify the Dockerfile.workspace loaction
-     openfl_docker_dir = os.path.join(SITEPACKS, 'openfl-docker')
-     dockerfile_workspace = 'Dockerfile.workspace'
-     # Apparently, docker's python package does not support
-     # scenarios when the dockerfile is placed outside the build context
-     copyfile(os.path.join(openfl_docker_dir, dockerfile_workspace), dockerfile_workspace)
- 
-     workspace_path = os.getcwd()
-     workspace_name = os.path.basename(workspace_path)
- 
-     # Exporting the workspace
-     context.invoke(export_)
-     workspace_archive = workspace_name + '.zip'
- 
-     build_args = {
-         'WORKSPACE_NAME': workspace_name,
-         'BASE_IMAGE': base_image
-     }
- 
-     client = docker.from_env(timeout=3600)
-     echo('Building the Docker image')
-     try:
-         client.images.build(
-             path=str(workspace_path),
-             tag=workspace_name,
-             buildargs=build_args,
-             dockerfile=dockerfile_workspace
-         )
-     except docker.errors.BuildError as e:
-         for log in e.build_log:
-             msg = log.get('stream')
-             if msg:
-                 echo(msg)
-         echo('Failed to build the image\n' + str(e) + '\n')
-         sys.exit(1)
-     finally:
-         os.remove(workspace_archive)
-         os.remove(dockerfile_workspace)
-     echo('The workspace image has been built successfully!')
- 
-     # Saving the image to a tarball
-     if save:
-         workspace_image_tar = workspace_name + '_image.tar'
-         echo('Saving the Docker image...')
-         image = client.images.get(f'{workspace_name}')
-         resp = image.save(named=True)
-         with open(workspace_image_tar, 'wb') as f:
-             for chunk in resp:
-                 f.write(chunk)
-         echo(f'{workspace_name} image saved to {workspace_path}/{workspace_image_tar}')
- 
- 
- @workspace.command(name='graminize')
- @option('-s', '--signing-key', required=False,
-         type=lambda p: Path(p).absolute(), default='/',
-         help='A 3072-bit RSA private key (PEM format) is required for signing the manifest.\n'
-              'If a key is passed the gramine-sgx manifest fill be prepared.\n'
-              'In option is ignored this command will build an image that can only run '
-              'with gramine-direct (not in enclave).',
-         )
- @option('-o', '--pip-install-options', required=False,
-         type=str, multiple=True, default=tuple,
-         help='Options for remote pip install. '
-              'You may pass several options in quotation marks alongside with arguments, '
-              'e.g. -o "--find-links source.site"')
- @option('--save/--no-save', required=False,
-         default=True, type=bool,
-         help='Dump the Docker image to an archive')
- @option('--rebuild', help='Build images with `--no-cache`', is_flag=True)
- @pass_context
- def graminize_(context, signing_key: Path, pip_install_options: Tuple[str],
-                save: bool, rebuild: bool) -> None:
-     """
-     Build gramine app inside a docker image.
- 
-     This command is the alternative to `workspace export`.
-     It should be called after `fx plan initialize` inside the workspace dir.
- 
-     User is expected to be in docker group.
-     If your machine is behind a proxy, make sure you set it up in ~/.docker/config.json.
- 
-     TODO:
-     1. gramine-direct, check if a key is provided
-     2. make a standalone function with `export` parametr
-     """
-     def open_pipe(command: str):
-         echo(f'\n 📦 Executing command:\n{command}\n')
-         process = subprocess.Popen(
-             command,
-             shell=True, stderr=subprocess.STDOUT,
-             stdout=subprocess.PIPE)
-         for line in process.stdout:
-             echo(line)
-         _ = process.communicate()  # pipe is already empty, used to get `returncode`
-         if process.returncode != 0:
-             raise Exception('\n ❌ Execution failed\n')
- 
-     from openfl.interface.cli_helper import SITEPACKS
- 
-     # We can build for gramine-sgx and run with gramine-direct,
-     # but not vice versa.
-     sgx_build = signing_key.is_file()
-     if sgx_build:
-         echo('\n Building SGX-ready applecation')
-     else:
-         echo('\n Building gramine-direct applecation')
-     rebuild_option = '--no-cache' if rebuild else ''
- 
-     os.environ['DOCKER_BUILDKIT'] = '1'
- 
-     echo('\n 🐋 Building base gramine-openfl image...')
-     base_dockerfile = SITEPACKS / 'openfl-gramine' / 'Dockerfile.gramine'
-     base_build_command = f'docker build {rebuild_option} -t gramine_openfl -f {base_dockerfile} .'
-     open_pipe(base_build_command)
-     echo('\n ✔️ DONE: Building base gramine-openfl image')
- 
-     workspace_path = Path.cwd()
-     workspace_name = workspace_path.name
-     context.invoke(export_, pip_install_options=pip_install_options)
-     workspace_archive = workspace_path / f'{workspace_name}.zip'
- 
-     grainized_ws_dockerfile = SITEPACKS / 'openfl-gramine' / 'Dockerfile.graminized.workspace'
- 
-     echo('\n 🐋 Building graminized workspace image...')
-     signing_key = f'--secret id=signer-key,src={signing_key} ' if sgx_build else ''
-     graminized_build_command = (
-         f'docker build -t {workspace_name} {rebuild_option} '
-         '--build-arg BASE_IMAGE=gramine_openfl '
-         f'--build-arg WORKSPACE_ARCHIVE={workspace_archive.relative_to(workspace_path)} '
-         f'--build-arg SGX_BUILD={int(sgx_build)} '
-         f'{signing_key}'
-         f'-f {grainized_ws_dockerfile} {workspace_path}')
-     open_pipe(graminized_build_command)
-     echo('\n ✔️ DONE: Building graminized workspace image')
- 
-     if save:
-         echo('\n 💾 Saving the graminized workspace image...')
-         save_image_command = f'docker save {workspace_name} | gzip > {workspace_name}.tar.gz'
-         open_pipe(save_image_command)
-         echo(f'\n ✔️ The image saved to file: {workspace_name}.tar.gz')
- 
- 
- def apply_template_plan(prefix, template):
-     """Copy plan file from template folder.
- 
-     This function unfolds default values from template plan configuration
-     and writes the configuration to the current workspace.
-     """
-     from openfl.federated.plan import Plan
-     from openfl.interface.cli_helper import WORKSPACE
- 
-     template_plan = Plan.parse(WORKSPACE / template / 'plan' / 'plan.yaml')
- 
-     Plan.dump(prefix / 'plan' / 'plan.yaml', template_plan.config)
--- 0 ----
diff -crB --new-file ./openfl/openfl/native/fastestimator.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/native/fastestimator.py
*** ./openfl/openfl/native/fastestimator.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/native/fastestimator.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,188 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """FederatedFastEstimator module."""
- 
- import os
- from logging import getLogger
- from pathlib import Path
- 
- import openfl.native as fx
- from openfl.federated import Plan
- from openfl.federated.data import FastEstimatorDataLoader
- from openfl.federated.task import FastEstimatorTaskRunner
- from openfl.protocols import utils
- from openfl.utilities import split_tensor_dict_for_holdouts
- 
- 
- class FederatedFastEstimator:
-     """A wrapper for fastestimator.estimator that allows running in federated mode."""
- 
-     def __init__(self, estimator, override_config: dict = None, **kwargs):
-         """Initialize."""
-         self.estimator = estimator
-         self.logger = getLogger(__name__)
-         fx.init(**kwargs)
-         if override_config:
-             fx.update_plan(override_config)
- 
-     def fit(self):
-         """Run the estimator."""
-         import fastestimator as fe
-         from fastestimator.trace.io.best_model_saver import BestModelSaver
-         from sys import path
- 
-         file = Path(__file__).resolve()
-         # interface root, containing command modules
-         root = file.parent.resolve()
-         work = Path.cwd().resolve()
- 
-         path.append(str(root))
-         path.insert(0, str(work))
- 
-         # TODO: Fix this implementation. The full plan parsing is reused here,
-         # but the model and data will be overwritten based on
-         # user specifications
-         plan_config = (Path(fx.WORKSPACE_PREFIX) / 'plan' / 'plan.yaml')
-         cols_config = (Path(fx.WORKSPACE_PREFIX) / 'plan' / 'cols.yaml')
-         data_config = (Path(fx.WORKSPACE_PREFIX) / 'plan' / 'data.yaml')
- 
-         plan = Plan.parse(plan_config_path=plan_config,
-                           cols_config_path=cols_config,
-                           data_config_path=data_config)
- 
-         self.rounds = plan.config['aggregator']['settings']['rounds_to_train']
-         data_loader = FastEstimatorDataLoader(self.estimator.pipeline)
-         runner = FastEstimatorTaskRunner(
-             self.estimator, data_loader=data_loader)
-         # Overwrite plan values
-         tensor_pipe = plan.get_tensor_pipe()
-         # Initialize model weights
-         init_state_path = plan.config['aggregator']['settings'][
-             'init_state_path']
-         tensor_dict, holdout_params = split_tensor_dict_for_holdouts(
-             self.logger, runner.get_tensor_dict(False))
- 
-         model_snap = utils.construct_model_proto(tensor_dict=tensor_dict,
-                                                  round_number=0,
-                                                  tensor_pipe=tensor_pipe)
- 
-         self.logger.info(f'Creating Initial Weights File'
-                          f'    🠆 {init_state_path}')
- 
-         utils.dump_proto(model_proto=model_snap, fpath=init_state_path)
- 
-         self.logger.info('Starting Experiment...')
- 
-         aggregator = plan.get_aggregator()
- 
-         model_states = {
-             collaborator: None for collaborator in plan.authorized_cols
-         }
-         runners = {}
-         save_dir = {}
-         data_path = 1
-         for col in plan.authorized_cols:
-             data = self.estimator.pipeline.data
-             train_data, eval_data, test_data = split_data(
-                 data['train'], data['eval'], data['test'],
-                 data_path, len(plan.authorized_cols))
-             pipeline_kwargs = {}
-             for k, v in self.estimator.pipeline.__dict__.items():
-                 if k in ['batch_size', 'ops', 'num_process',
-                          'drop_last', 'pad_value', 'collate_fn']:
-                     pipeline_kwargs[k] = v
-             pipeline_kwargs.update({
-                 'train_data': train_data,
-                 'eval_data': eval_data,
-                 'test_data': test_data
-             })
-             pipeline = fe.Pipeline(**pipeline_kwargs)
- 
-             data_loader = FastEstimatorDataLoader(pipeline)
-             self.estimator.system.pipeline = pipeline
- 
-             runners[col] = FastEstimatorTaskRunner(
-                 estimator=self.estimator, data_loader=data_loader)
-             runners[col].set_optimizer_treatment('CONTINUE_LOCAL')
- 
-             for trace in runners[col].estimator.system.traces:
-                 if isinstance(trace, BestModelSaver):
-                     save_dir_path = f'{trace.save_dir}/{col}'
-                     os.makedirs(save_dir_path, exist_ok=True)
-                     save_dir[col] = save_dir_path
- 
-             data_path += 1
- 
-         # Create the collaborators
-         collaborators = {collaborator: fx.create_collaborator(
-             plan, collaborator, runners[collaborator], aggregator)
-             for collaborator in plan.authorized_cols}
- 
-         model = None
-         for round_num in range(self.rounds):
-             for col in plan.authorized_cols:
- 
-                 collaborator = collaborators[col]
- 
-                 if round_num != 0:
-                     # For FastEstimator Jupyter notebook, models must be
-                     # saved in different directories (i.e. path must be
-                     # reset here)
- 
-                     runners[col].estimator.system.load_state(
-                         f'save/{col}_state')
-                     runners[col].rebuild_model(round_num, model_states[col])
- 
-                 # Reset the save directory if BestModelSaver is present
-                 # in traces
-                 for trace in runners[col].estimator.system.traces:
-                     if isinstance(trace, BestModelSaver):
-                         trace.save_dir = save_dir[col]
- 
-                 collaborator.run_simulation()
- 
-                 model_states[col] = runners[col].get_tensor_dict(
-                     with_opt_vars=True)
-                 model = runners[col].model
-                 runners[col].estimator.system.save_state(f'save/{col}_state')
- 
-         # TODO This will return the model from the last collaborator,
-         #  NOT the final aggregated model (though they should be similar).
-         # There should be a method added to the aggregator that will load
-         # the best model from disk and return it
-         return model
- 
- 
- def split_data(train, eva, test, rank, collaborator_count):
-     """Split data into N parts, where N is the collaborator count."""
-     if collaborator_count == 1:
-         return train, eva, test
- 
-     fraction = [1.0 / float(collaborator_count)]
-     fraction *= (collaborator_count - 1)
- 
-     # Expand the split list into individual parameters
-     train_split = train.split(*fraction)
-     eva_split = eva.split(*fraction)
-     test_split = test.split(*fraction)
- 
-     train = [train]
-     eva = [eva]
-     test = [test]
- 
-     if type(train_split) is not list:
-         train.append(train_split)
-         eva.append(eva_split)
-         test.append(test_split)
-     else:
-         # Combine all partitions into a single list
-         train = [train] + train_split
-         eva = [eva] + eva_split
-         test = [test] + test_split
- 
-     # Extract the right shard
-     train = train[rank - 1]
-     eva = eva[rank - 1]
-     test = test[rank - 1]
- 
-     return train, eva, test
--- 0 ----
diff -crB --new-file ./openfl/openfl/native/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/native/__init__.py
*** ./openfl/openfl/native/__init__.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/native/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,5 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """openfl.native package."""
- 
- from .native import *  # NOQA
--- 0 ----
diff -crB --new-file ./openfl/openfl/native/native.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/native/native.py
*** ./openfl/openfl/native/native.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/native/native.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,297 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """openfl Native functions module.
- 
- This file defines openfl entrypoints to be used directly through python (not CLI)
- """
- 
- import logging
- import os
- from copy import copy
- from logging import getLogger
- from pathlib import Path
- 
- from flatten_json import flatten_preserve_lists
- 
- import openfl.interface.aggregator as aggregator
- import openfl.interface.collaborator as collaborator
- import openfl.interface.workspace as workspace
- from openfl.federated import Plan
- from openfl.protocols import utils
- from openfl.utilities import add_log_level
- from openfl.utilities import split_tensor_dict_for_holdouts
- 
- logger = getLogger(__name__)
- 
- WORKSPACE_PREFIX = os.path.join(os.path.expanduser('~'), '.local', 'workspace')
- 
- 
- def setup_plan(log_level='CRITICAL'):
-     """
-     Dump the plan with all defaults + overrides set.
- 
-     Args:
-         save : bool (default=True)
-             Whether to save the plan to disk
- 
-     Returns:
-         plan : Plan object
-     """
-     plan_config = 'plan/plan.yaml'
-     cols_config = 'plan/cols.yaml'
-     data_config = 'plan/data.yaml'
- 
-     current_level = logging.root.level
-     getLogger().setLevel(log_level)
-     plan = Plan.parse(plan_config_path=Path(plan_config),
-                       cols_config_path=Path(cols_config),
-                       data_config_path=Path(data_config),
-                       resolve=False)
-     getLogger().setLevel(current_level)
- 
-     return plan
- 
- 
- def flatten(config, return_complete=False):
-     """Flatten nested config."""
-     flattened_config = flatten_preserve_lists(config, '.')[0]
-     if not return_complete:
-         keys_to_remove = [
-             k for k, v in flattened_config.items()
-             if ('defaults' in k or v is None)]
-     else:
-         keys_to_remove = [k for k, v in flattened_config.items() if v is None]
-     for k in keys_to_remove:
-         del flattened_config[k]
- 
-     return flattened_config
- 
- 
- def update_plan(override_config):
-     """
-     Update the plan with the provided override and save it to disk.
- 
-     For a list of available override options, call `fx.get_plan()`
- 
-     Args:
-         override_config : dict {"COMPONENT.settings.variable" : value}
- 
-     Returns:
-         None
-     """
-     plan = setup_plan()
-     flat_plan_config = flatten(plan.config, return_complete=True)
-     for k, v in override_config.items():
-         if k in flat_plan_config:
-             logger.info(f'Updating {k} to {v}... ')
-         else:
-             # TODO: We probably need to validate the new key somehow
-             logger.warn(f'Did not find {k} in config. Make sure it should exist. Creating...')
-         flat_plan_config[k] = v
-     plan.config = unflatten(flat_plan_config, '.')
-     plan.resolve()
-     return plan
- 
- 
- def unflatten(config, separator='.'):
-     """Unfold `config` settings that have `separator` in their names."""
-     keys_to_separate = [k for k in config if separator in k]
-     if len(keys_to_separate) > 0:
-         for key in keys_to_separate:
-             prefix = separator.join(key.split(separator)[:-1])
-             suffix = key.split(separator)[-1]
-             if prefix in config:
-                 temp = {**config[prefix], suffix: config[key]}
-                 config[prefix] = temp
-             else:
-                 config[prefix] = {suffix: config[key]}
-             del config[key]
-         unflatten(config, separator)
-     return config
- 
- 
- def setup_logging(level='INFO', log_file=None):
-     """Initialize logging settings."""
-     # Setup logging
-     from logging import basicConfig
-     from rich.console import Console
-     from rich.logging import RichHandler
-     import pkgutil
-     if True if pkgutil.find_loader('tensorflow') else False:
-         import tensorflow as tf
-         tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)
-     metric = 25
-     add_log_level('METRIC', metric)
- 
-     if isinstance(level, str):
-         level = level.upper()
- 
-     handlers = []
-     if log_file:
-         fh = logging.FileHandler(log_file)
-         formatter = logging.Formatter(
-             '%(asctime)s %(levelname)s %(message)s %(filename)s:%(lineno)d'
-         )
-         fh.setFormatter(formatter)
-         handlers.append(fh)
- 
-     console = Console(width=160)
-     handlers.append(RichHandler(console=console))
-     basicConfig(level=level, format='%(message)s',
-                 datefmt='[%X]', handlers=handlers)
- 
- 
- def init(workspace_template: str = 'default', log_level: str = 'INFO',
-          log_file: str = None, agg_fqdn: str = None, col_names=None):
-     """
-     Initialize the openfl package.
- 
-     It performs the following tasks:
- 
-          1. Creates a workspace in ~/.local/workspace (Equivalent to `fx
-          workspace create --prefix ~/.local/workspace --template
-          $workspace_template)
-          2. Setup certificate authority (equivalent to `fx workspace certify`)
-          3. Setup aggregator PKI (equivalent to `fx aggregator
-          generate-cert-request` followed by `fx aggregator certify`)
-          4. Setup list of collaborators (col_names) and their PKI. (Equivalent
-          to running `fx collaborator generate-cert-request` followed by `fx
-          collaborator certify` for each of the collaborators in col_names)
-          5. Setup logging
- 
-     Args:
-         workspace_template : str (default='default')
-             The template that should be used as the basis for the experiment.
-             Other options include are any of the template names [
-             keras_cnn_mnist, tf_2dunet, tf_cnn_histology, mtorch_cnn_histology,
-             torch_cnn_mnist]
-         log_level : str
-             Log level for logging. METRIC level is available
-         log_file : str
-             Name of the file in which the log will be duplicated
-         agg_fqdn : str
-            The local node's fully qualified domain name (if it can't be
-            resolved automatically)
-         col_names: list[str]
-            The names of the collaborators that will be created. These
-            collaborators will be set up to participate in the experiment, but
-            are not required to
- 
-     Returns:
-         None
-     """
-     if col_names is None:
-         col_names = ['one', 'two']
-     workspace.create(WORKSPACE_PREFIX, workspace_template)
-     os.chdir(WORKSPACE_PREFIX)
-     workspace.certify()
-     aggregator.generate_cert_request(agg_fqdn)
-     aggregator.certify(agg_fqdn, silent=True)
-     data_path = 1
-     for col_name in col_names:
-         collaborator.generate_cert_request(
-             col_name, str(data_path), silent=True, skip_package=True)
-         collaborator.certify(col_name, silent=True)
-         data_path += 1
- 
-     setup_logging(level=log_level, log_file=log_file)
- 
- 
- def create_collaborator(plan, name, model, aggregator):
-     """
-     Create the collaborator.
- 
-     Using the same plan object to create multiple collaborators leads to
-     identical collaborator objects. This function can be removed once
-     collaborator generation is fixed in openfl/federated/plan/plan.py
-     """
-     plan = copy(plan)
- 
-     return plan.get_collaborator(name, task_runner=model, client=aggregator)
- 
- 
- def run_experiment(collaborator_dict: dict, override_config: dict = None):
-     """
-     Core function that executes the FL Plan.
- 
-     Args:
-         collaborator_dict : dict {collaborator_name(str): FederatedModel}
-             This dictionary defines which collaborators will participate in the
-             experiment, as well as a reference to that collaborator's
-             federated model.
-         override_config : dict {flplan.key : flplan.value}
-             Override any of the plan parameters at runtime using this
-             dictionary. To get a list of the available options, execute
-             `fx.get_plan()`
- 
-     Returns:
-         final_federated_model : FederatedModel
-             The final model resulting from the federated learning experiment
-     """
-     from sys import path
- 
-     if override_config is None:
-         override_config = {}
- 
-     file = Path(__file__).resolve()
-     root = file.parent.resolve()  # interface root, containing command modules
-     work = Path.cwd().resolve()
- 
-     path.append(str(root))
-     path.insert(0, str(work))
- 
-     # Update the plan if necessary
-     plan = update_plan(override_config)
-     # Overwrite plan values
-     plan.authorized_cols = list(collaborator_dict)
-     tensor_pipe = plan.get_tensor_pipe()
- 
-     # This must be set to the final index of the list (this is the last
-     # tensorflow session to get created)
-     plan.runner_ = list(collaborator_dict.values())[-1]
-     model = plan.runner_
- 
-     # Initialize model weights
-     init_state_path = plan.config['aggregator']['settings']['init_state_path']
-     rounds_to_train = plan.config['aggregator']['settings']['rounds_to_train']
-     tensor_dict, holdout_params = split_tensor_dict_for_holdouts(
-         logger,
-         model.get_tensor_dict(False)
-     )
- 
-     model_snap = utils.construct_model_proto(tensor_dict=tensor_dict,
-                                              round_number=0,
-                                              tensor_pipe=tensor_pipe)
- 
-     logger.info(f'Creating Initial Weights File    🠆 {init_state_path}')
- 
-     utils.dump_proto(model_proto=model_snap, fpath=init_state_path)
- 
-     logger.info('Starting Experiment...')
- 
-     aggregator = plan.get_aggregator()
- 
-     # Create the collaborators
-     collaborators = {
-         collaborator: create_collaborator(
-             plan, collaborator, collaborator_dict[collaborator], aggregator
-         ) for collaborator in plan.authorized_cols
-     }
- 
-     for _ in range(rounds_to_train):
-         for col in plan.authorized_cols:
-             collaborator = collaborators[col]
-             collaborator.run_simulation()
- 
-     # Set the weights for the final model
-     model.rebuild_model(
-         rounds_to_train - 1, aggregator.last_tensor_dict, validation=True)
-     return model
- 
- 
- def get_plan(indent=4, sort_keys=True):
-     """Get string representation of current Plan."""
-     import json
-     plan = setup_plan()
-     flat_plan_config = flatten(plan.config)
-     return json.dumps(flat_plan_config, indent=indent, sort_keys=sort_keys)
--- 0 ----
diff -crB --new-file ./openfl/openfl/pipelines/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/pipelines/__init__.py
*** ./openfl/openfl/pipelines/__init__.py	2022-11-18 11:08:33.047181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/pipelines/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,19 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """openfl.pipelines module."""
- 
- from .kc_pipeline import KCPipeline
- from .no_compression_pipeline import NoCompressionPipeline
- from .random_shift_pipeline import RandomShiftPipeline
- from .skc_pipeline import SKCPipeline
- from .stc_pipeline import STCPipeline
- from .tensor_codec import TensorCodec
- 
- __all__ = [
-     'NoCompressionPipeline',
-     'RandomShiftPipeline',
-     'STCPipeline',
-     'SKCPipeline',
-     'KCPipeline',
-     'TensorCodec',
- ]
--- 0 ----
diff -crB --new-file ./openfl/openfl/pipelines/kc_pipeline.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/pipelines/kc_pipeline.py
*** ./openfl/openfl/pipelines/kc_pipeline.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/pipelines/kc_pipeline.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,159 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """KCPipeline module."""
- 
- 
- import copy as co
- import gzip as gz
- 
- import numpy as np
- from sklearn import cluster
- 
- from .pipeline import TransformationPipeline
- from .pipeline import Transformer
- 
- 
- class KmeansTransformer(Transformer):
-     """A K-means transformer class to quantize input data."""
- 
-     def __init__(self, n_cluster=6):
-         """Class initializer.
- 
-         Args:
-             n_cluster (int): Number of clusters for the K-means
-         """
-         self.lossy = True
-         self.n_cluster = n_cluster
- 
-     def forward(self, data, **kwargs):
-         """
-         Quantize data into n_cluster levels of values.
- 
-         Args:
-             data: an numpy array from the model tensor_dict
-             data: an numpy array being quantized
-             **kwargs: Variable arguments to pass
-         """
-         metadata = {'int_list': list(data.shape)}
-         # clustering
-         k_means = cluster.KMeans(n_clusters=self.n_cluster, n_init=self.n_cluster)
-         data = data.reshape((-1, 1))
-         if data.shape[0] >= self.n_cluster:
-             k_means = cluster.KMeans(
-                 n_clusters=self.n_cluster, n_init=self.n_cluster)
-             k_means.fit(data)
-             quantized_values = k_means.cluster_centers_.squeeze()
-             indices = k_means.labels_
-             quant_array = np.choose(indices, quantized_values)
-         else:
-             quant_array = data
- 
-         int_array, int2float_map = self._float_to_int(quant_array)
-         metadata['int_to_float'] = int2float_map
- 
-         return int_array, metadata
- 
-     def backward(self, data, metadata, **kwargs):
-         """Recover data array back to the original numerical type and the shape.
- 
-         Args:
-             data: an flattened numpy array
-             metadata: dictionary to contain information for recovering ack to original data array
- 
-         Returns:
-             data: Numpy array with original numerical type and shape
-         """
-         # convert back to float
-         # TODO
-         data = co.deepcopy(data)
-         int2float_map = metadata['int_to_float']
-         for key in int2float_map:
-             indices = data == key
-             data[indices] = int2float_map[key]
-         data_shape = list(metadata['int_list'])
-         data = data.reshape(data_shape)
-         return data
- 
-     @staticmethod
-     def _float_to_int(np_array):
-         """Create look-up table for conversion between floating and integer types.
- 
-         Args:
-             np_array: A Numpy array
- 
-         Returns:
-             int_array: The input Numpy float array converted to an integer array
-             int_to_float_map
-         """
-         flatten_array = np_array.reshape(-1)
-         unique_value_array = np.unique(flatten_array)
-         int_array = np.zeros(flatten_array.shape, dtype=np.int)
-         int_to_float_map = {}
-         float_to_int_map = {}
-         # create table
-         for idx, u_value in enumerate(unique_value_array):
-             int_to_float_map.update({idx: u_value})
-             float_to_int_map.update({u_value: idx})
-             # assign to the integer array
-             indices = np.where(flatten_array == u_value)
-             int_array[indices] = idx
-         int_array = int_array.reshape(np_array.shape)
-         return int_array, int_to_float_map
- 
- 
- class GZIPTransformer(Transformer):
-     """A GZIP transformer class to losslessly compress data."""
- 
-     def __init__(self):
-         """Initialize."""
-         self.lossy = False
- 
-     def forward(self, data, **kwargs):
-         """Compress data into bytes.
- 
-         Args:
-             data: A Numpy array
- 
-         Returns:
-             GZIP compressed data object
-         """
-         bytes_ = data.astype(np.float32).tobytes()
-         compressed_bytes_ = gz.compress(bytes_)
-         metadata = {}
-         return compressed_bytes_, metadata
- 
-     def backward(self, data, metadata, **kwargs):
-         """Decompress data into numpy of float32.
- 
-         Args:
-             data: Compressed GZIP data
-             metadata:
-             **kwargs: Additional parameters to pass to the function
- 
-         Returns:
-             data: Numpy array
-         """
-         decompressed_bytes_ = gz.decompress(data)
-         data = np.frombuffer(decompressed_bytes_, dtype=np.float32)
-         return data
- 
- 
- class KCPipeline(TransformationPipeline):
-     """A pipeline class to compress data lossly using k-means and GZIP methods."""
- 
-     def __init__(self, p_sparsity=0.01, n_clusters=6, **kwargs):
-         """Initialize a pipeline of transformers.
- 
-         Args:
-             p_sparsity (float): Amount of sparsity for compression (Default = 0.01)
-             n_clusters (int): Number of K-mean cluster
- 
-         Return:
-             Transformer class object
-         """
-         # instantiate each transformer
-         self.p = p_sparsity
-         self.n_cluster = n_clusters
-         transformers = [KmeansTransformer(self.n_cluster), GZIPTransformer()]
-         super(KCPipeline, self).__init__(transformers=transformers, **kwargs)
--- 0 ----
diff -crB --new-file ./openfl/openfl/pipelines/no_compression_pipeline.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/pipelines/no_compression_pipeline.py
*** ./openfl/openfl/pipelines/no_compression_pipeline.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/pipelines/no_compression_pipeline.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,16 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """NoCompressionPipeline module."""
- 
- from .pipeline import Float32NumpyArrayToBytes
- from .pipeline import TransformationPipeline
- 
- 
- class NoCompressionPipeline(TransformationPipeline):
-     """The data pipeline without any compression."""
- 
-     def __init__(self, **kwargs):
-         """Initialize."""
-         super(NoCompressionPipeline, self).__init__(
-             transformers=[Float32NumpyArrayToBytes()], **kwargs)
--- 0 ----
diff -crB --new-file ./openfl/openfl/pipelines/pipeline.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/pipelines/pipeline.py
*** ./openfl/openfl/pipelines/pipeline.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/pipelines/pipeline.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,157 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Pipeline module."""
- 
- import numpy as np
- 
- 
- class Transformer:
-     """Data transformation class."""
- 
-     def forward(self, data, **kwargs):
-         """Forward pass data transformation.
- 
-         Implement the data transformation.
- 
-         Args:
-             data:
-             **kwargs: Additional parameters to pass to the function
- 
-         Returns:
-             transformed_data
-             metadata
-         """
-         raise NotImplementedError
- 
-     def backward(self, data, metadata, **kwargs):
-         """Backward pass data transformation.
- 
-         Implement the data transformation needed when going the opposite
-         direction to the forward method.
- 
-         Args:
-             data:
-             metadata:
-             **kwargs: Additional parameters to pass to the function
- 
-         Returns:
-             transformed_data
-         """
-         raise NotImplementedError
- 
- 
- class Float32NumpyArrayToBytes(Transformer):
-     """Converts float32 Numpy array to Bytes array."""
- 
-     def __init__(self):
-         """Initialize."""
-         self.lossy = False
- 
-     def forward(self, data, **kwargs):
-         """Forward pass.
- 
-         Args:
-             data:
-             **kwargs: Additional arguments to pass to the function
- 
-         Returns:
-             data_bytes:
-             metadata:
-         """
-         # TODO: Warn when this casting is being performed.
-         if data.dtype != np.float32:
-             data = data.astype(np.float32)
-         array_shape = data.shape
-         # Better call it array_shape?
-         metadata = {'int_list': list(array_shape)}
-         data_bytes = data.tobytes(order='C')
-         return data_bytes, metadata
- 
-     def backward(self, data, metadata, **kwargs):
-         """Backward pass.
- 
-         Args:
-             data:
-             metadata:
- 
-         Returns:
-             Numpy Array
- 
-         """
-         array_shape = tuple(metadata['int_list'])
-         flat_array = np.frombuffer(data, dtype=np.float32)
-         # For integer parameters we probably should unpack arrays
-         # with shape (1,)
-         return np.reshape(flat_array, newshape=array_shape, order='C')
- 
- 
- class TransformationPipeline:
-     """Data Transformer Pipeline Class.
- 
-     A sequential pipeline to transform (e.x. compress) data (e.x. layer of
-     model_weights) as well as return metadata (if needed) for the
-     reconstruction process carried out by the backward method.
-     """
- 
-     def __init__(self, transformers, **kwargs):
-         """Initialize.
- 
-         Args:
-             transformers:
-             **kwargs: Additional parameters to pass to the function
-         """
-         self.transformers = transformers
- 
-     def forward(self, data, **kwargs):
-         """Forward pass of pipeline data transformer.
- 
-         Args:
-             data: Data to transform
-             **kwargs: Additional parameters to pass to the function
- 
-         Returns:
-             data:
-             transformer_metadata:
- 
-         """
-         transformer_metadata = []
- 
-         # dataformat::numpy::float.32
-         # model proto:: a collection of tensor_dict proto
-         # protobuff::-> a layer of weights
-         # input::tensor_dict:{"layer1":np.array(float32, [128,3,28,28]),
-         # "layer2": np.array()}
-         # output::meta data::numpy::int array
-         # (data, transformer_metadata)::(float32, dictionary o
-         # key+float32 vlues)
-         # input:: numpy_data (float32)
-         # input:: (data(bytes), transformer_metadata_list::a list of dictionary
-         # from int to float)
- 
-         data = data.copy()
-         for transformer in self.transformers:
-             data, metadata = transformer.forward(data=data, **kwargs)
-             transformer_metadata.append(metadata)
-         return data, transformer_metadata
- 
-     def backward(self, data, transformer_metadata, **kwargs):
-         """Backward pass of pipeline data transformer.
- 
-         Args:
-             data: Data to transform
-             transformer_metadata:
-             **kwargs: Additional parameters to pass to the function
- 
-         Returns:
-             data:
- 
-         """
-         for transformer in self.transformers[::-1]:
-             data = transformer.backward(
-                 data=data, metadata=transformer_metadata.pop(), **kwargs)
-         return data
- 
-     def is_lossy(self):
-         """If any of the transformers are lossy, then the pipeline is lossy."""
-         return any([transformer.lossy for transformer in self.transformers])
--- 0 ----
diff -crB --new-file ./openfl/openfl/pipelines/random_shift_pipeline.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/pipelines/random_shift_pipeline.py
*** ./openfl/openfl/pipelines/random_shift_pipeline.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/pipelines/random_shift_pipeline.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,80 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """RandomShiftPipeline module."""
- 
- import numpy as np
- 
- from .pipeline import Float32NumpyArrayToBytes
- from .pipeline import TransformationPipeline
- from .pipeline import Transformer
- 
- 
- class RandomShiftTransformer(Transformer):
-     """Random Shift Transformer."""
- 
-     def __init__(self):
-         """Initialize."""
-         self.lossy = False
- 
-         return
- 
-     def forward(self, data, **kwargs):
-         """Forward pass - compress data.
- 
-         Implement the data transformation.
- 
-         Args:
-             data: an array value from a model tensor_dict
- 
-         Returns:
-             transformed_data:
-             metadata:
- 
-         """
-         shape = data.shape
-         random_shift = np.random.uniform(
-             low=-20, high=20, size=shape).astype(np.float32)
-         transformed_data = data + random_shift
- 
-         # construct metadata
-         metadata = {'int_to_float': {}, 'int_list': list(shape)}
-         for idx, val in enumerate(random_shift.flatten(order='C')):
-             metadata['int_to_float'][idx] = val
- 
-         return transformed_data, metadata
- 
-     def backward(self, data, metadata, **kwargs):
-         """Backward pass - Decompress data.
- 
-         Implement the data transformation needed when going the oppposite
-         direction to the forward method.
- 
-         Args:
-             data:
-             metadata:
- 
-         Returns:
-             transformed_data:
-         """
-         shape = tuple(metadata['int_list'])
-         # this is an awkward use of the metadata into to float dict, usually
-         # it will trully be treated as a dict. Here (and in 'forward' above)
-         # we use it essentially as an array.
-         shift = np.reshape(
-             np.array([
-                 metadata['int_to_float'][idx]
-                 for idx in range(len(metadata['int_to_float']))]),
-             newshape=shape,
-             order='C'
-         )
-         return data - shift
- 
- 
- class RandomShiftPipeline(TransformationPipeline):
-     """Random Shift Pipeline."""
- 
-     def __init__(self, **kwargs):
-         """Initialize."""
-         transformers = [RandomShiftTransformer(), Float32NumpyArrayToBytes()]
-         super(RandomShiftPipeline, self).__init__(transformers=transformers)
--- 0 ----
diff -crB --new-file ./openfl/openfl/pipelines/skc_pipeline.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/pipelines/skc_pipeline.py
*** ./openfl/openfl/pipelines/skc_pipeline.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/pipelines/skc_pipeline.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,226 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """SKCPipeline module."""
- 
- import copy as co
- import gzip as gz
- 
- import numpy as np
- from sklearn import cluster
- 
- from .pipeline import TransformationPipeline
- from .pipeline import Transformer
- 
- 
- class SparsityTransformer(Transformer):
-     """A transformer class to sparsify input data."""
- 
-     def __init__(self, p=0.01):
-         """Initialize.
- 
-         Args:
-             p (float): sparsity ratio (Default=0.01)
-         """
-         self.lossy = True
-         self.p = p
- 
-     def forward(self, data, **kwargs):
-         """
-         Sparsify data and pass over only non-sparsified elements by reducing the array size.
- 
-         Args:
-             data: an numpy array from the model tensor_dict.
- 
-         Returns:
-             sparse_data: a flattened, sparse representation of the input tensor
-             metadata: dictionary to store a list of meta information.
-         """
-         metadata = {'int_list': list(data.shape)}
-         # sparsification
-         data = data.astype(np.float32)
-         flatten_data = data.flatten()
-         n_elements = flatten_data.shape[0]
-         k_op = int(np.ceil(n_elements * self.p))
-         topk, topk_indices = self._topk_func(flatten_data, k_op)
-         sparse_data = np.zeros(flatten_data.shape)
-         sparse_data[topk_indices] = topk
-         return sparse_data, metadata
- 
-     def backward(self, data, metadata, **kwargs):
-         """Recover data array with the right shape and numerical type.
- 
-         Args:
-             data: an numpy array with non-zero values.
-             metadata: dictionary to contain information for recovering back
-              to original data array.
- 
-         Returns:
-             recovered_data: an numpy array with original shape.
-         """
-         data = data.astype(np.float32)
-         data_shape = metadata['int_list']
-         recovered_data = data.reshape(data_shape)
-         return recovered_data
- 
-     @staticmethod
-     def _topk_func(x, k):
-         """Select top k values.
- 
-         Args:
-             x: an numpy array to be sorted out for top-k components.
-             k: k most maximum values.
- 
-         Returns:
-             topk_mag: components with top-k values.
-             indices: indices of the top-k components.
-         """
-         # quick sort as default on magnitude
-         idx = np.argsort(np.abs(x))
-         # sorted order, the right most is the largest magnitude
-         length = x.shape[0]
-         start_idx = length - k
-         # get the top k magnitude
-         topk_mag = np.asarray(x[idx[start_idx:]])
-         indices = np.asarray(idx[start_idx:])
-         if min(topk_mag) - 0 < 10e-8:  # avoid zeros
-             topk_mag = topk_mag + 10e-8
-         return topk_mag, indices
- 
- 
- class KmeansTransformer(Transformer):
-     """A transformer class to quantize input data."""
- 
-     def __init__(self, n_cluster=6):
-         """Initialize."""
-         self.n_cluster = n_cluster
-         self.lossy = True
- 
-     def forward(self, data, **kwargs):
-         """Quantize data into n_cluster levels of values.
- 
-         Args:
-             data: an flattened numpy array.
- 
-         Returns:
-             int_data: an numpy array being quantized.
-             metadata: dictionary to store a list of meta information.
-         """
-         # clustering
-         data = data.reshape((-1, 1))
-         if data.shape[0] >= self.n_cluster:
-             k_means = cluster.KMeans(
-                 n_clusters=self.n_cluster, n_init=self.n_cluster)
-             k_means.fit(data)
-             quantized_values = k_means.cluster_centers_.squeeze()
-             indices = k_means.labels_
-             quant_array = np.choose(indices, quantized_values)
-         else:
-             quant_array = data
-         int_array, int2float_map = self._float_to_int(quant_array)
-         metadata = {'int_to_float': int2float_map}
-         int_array = int_array.reshape(-1)
-         return int_array, metadata
- 
-     def backward(self, data, metadata, **kwargs):
-         """Recover data array back to the original numerical type.
- 
-         Args:
-             data: an numpy array with non-zero values
-             metadata: dictionary to contain information for recovering back
-              to original data array
- 
-         Returns:
-             data: an numpy array with original numerical type
-         """
-         # convert back to float
-         data = co.deepcopy(data)
-         int2float_map = metadata['int_to_float']
-         for key in int2float_map:
-             indices = data == key
-             data[indices] = int2float_map[key]
-         return data
- 
-     @staticmethod
-     def _float_to_int(np_array):
-         """
-          Create look-up table for conversion between floating and integer types.
- 
-         Args:
-             np_array
- 
-         Returns:
-             int_array, int_to_float_map
-         """
-         flatten_array = np_array.reshape(-1)
-         unique_value_array = np.unique(flatten_array)
-         int_array = np.zeros(flatten_array.shape, dtype=np.int)
-         int_to_float_map = {}
-         float_to_int_map = {}
-         # create table
-         for idx, u_value in enumerate(unique_value_array):
-             int_to_float_map.update({idx: u_value})
-             float_to_int_map.update({u_value: idx})
-             # assign to the integer array
-             indices = np.where(flatten_array == u_value)
-             int_array[indices] = idx
-         int_array = int_array.reshape(np_array.shape)
-         return int_array, int_to_float_map
- 
- 
- class GZIPTransformer(Transformer):
-     """A transformer class to losslessly compress data."""
- 
-     def __init__(self):
-         """Initialize."""
-         self.lossy = False
- 
-     def forward(self, data, **kwargs):
-         """Compress data into bytes.
- 
-         Args:
-             data: an numpy array with non-zero values
-         """
-         bytes_ = data.astype(np.float32).tobytes()
-         compressed_bytes_ = gz.compress(bytes_)
-         metadata = {}
-         return compressed_bytes_, metadata
- 
-     def backward(self, data, metadata, **kwargs):
-         """Decompress data into numpy of float32.
- 
-         Args:
-             data: an numpy array with non-zero values
-             metadata: dictionary to contain information for recovering back
-              to original data array
- 
-         Returns:
-             data:
-         """
-         decompressed_bytes_ = gz.decompress(data)
-         data = np.frombuffer(decompressed_bytes_, dtype=np.float32)
-         return data
- 
- 
- class SKCPipeline(TransformationPipeline):
-     """A pipeline class to compress data lossly using sparsity and k-means methods."""
- 
-     def __init__(self, p_sparsity=0.1, n_clusters=6, **kwargs):
-         """Initialize a pipeline of transformers.
- 
-         Args:
-             p_sparsity (float): Sparsity factor (Default=0.1)
-             n_cluster (int): Number of K-Means clusters (Default=6)
- 
-         Returns:
-             Data compression transformer pipeline object
-         """
-         # instantiate each transformer
-         self.p = p_sparsity
-         self.n_cluster = n_clusters
-         transformers = [
-             SparsityTransformer(self.p),
-             KmeansTransformer(self.n_cluster),
-             GZIPTransformer()
-         ]
-         super(SKCPipeline, self).__init__(transformers=transformers, **kwargs)
--- 0 ----
diff -crB --new-file ./openfl/openfl/pipelines/stc_pipeline.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/pipelines/stc_pipeline.py
*** ./openfl/openfl/pipelines/stc_pipeline.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/pipelines/stc_pipeline.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,215 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """STCPipelinemodule."""
- 
- import gzip as gz
- 
- import numpy as np
- 
- from .pipeline import TransformationPipeline
- from .pipeline import Transformer
- 
- 
- class SparsityTransformer(Transformer):
-     """A transformer class to sparsify input data."""
- 
-     def __init__(self, p=0.01):
-         """Initialize.
- 
-         Args:
-             p (float): sparsity ratio (Default=0.01)
-         """
-         self.lossy = True
-         self.p = p
- 
-     def forward(self, data, **kwargs):
-         """
-         Sparsify data and pass over only non-sparsified elements by reducing the array size.
- 
-         Args:
-             data: an numpy array from the model tensor_dict.
- 
-         Returns:
-             sparse_data: a flattened, sparse representation of the input tensor
-             metadata: dictionary to store a list of meta information.
-         """
-         metadata = {'int_list': list(data.shape)}
-         # sparsification
-         data = data.astype(np.float32)
-         flatten_data = data.flatten()
-         n_elements = flatten_data.shape[0]
-         k_op = int(np.ceil(n_elements * self.p))
-         topk, topk_indices = self._topk_func(flatten_data, k_op)
-         sparse_data = np.zeros(flatten_data.shape)
-         sparse_data[topk_indices] = topk
-         return sparse_data, metadata
- 
-     def backward(self, data, metadata, **kwargs):
-         """Recover data array with the right shape and numerical type.
- 
-         Args:
-             data: an numpy array with non-zero values.
-             metadata: dictionary to contain information for recovering back
-              to original data array.
- 
-         Returns:
-             recovered_data: an numpy array with original shape.
-         """
-         data = data.astype(np.float32)
-         data_shape = metadata['int_list']
-         recovered_data = data.reshape(data_shape)
-         return recovered_data
- 
-     @staticmethod
-     def _topk_func(x, k):
-         """Select top k values.
- 
-         Args:
-             x: an numpy array to be sorted out for top-k components.
-             k: k most maximum values.
- 
-         Returns:
-             topk_mag: components with top-k values.
-             indices: indices of the top-k components.
-         """
-         # quick sort as default on magnitude
-         idx = np.argsort(np.abs(x))
-         # sorted order, the right most is the largest magnitude
-         length = x.shape[0]
-         start_idx = length - k
-         # get the top k magnitude
-         topk_mag = np.asarray(x[idx[start_idx:]])
-         indices = np.asarray(idx[start_idx:])
-         if min(topk_mag) - 0 < 10e-8:  # avoid zeros
-             topk_mag = topk_mag + 10e-8
-         return topk_mag, indices
- 
- 
- class TernaryTransformer(Transformer):
-     """A transformer class to ternerize input data."""
- 
-     def __init__(self):
-         """Initialize."""
-         self.lossy = True
- 
-     def forward(self, data, **kwargs):
-         """Ternerize data into positive mean value, negative mean value and zero value.
- 
-         Args:
-             data: an flattened numpy array
- 
-         Returns:
-             int_data: an numpy array being terneraized.
-             metadata: dictionary to store a list of meta information.
-         """
-         # ternarization, data is sparse and flattened
-         mean_topk = np.mean(np.abs(data))
-         out_ = np.where(data > 0.0, mean_topk, 0.0)
-         out = np.where(data < 0.0, -mean_topk, out_)
-         int_array, int2float_map = self._float_to_int(out)
-         metadata = {'int_to_float': int2float_map}
-         return int_array, metadata
- 
-     def backward(self, data, metadata, **kwargs):
-         """Recover data array back to the original numerical type.
- 
-         Args:
-             data: an numpy array with non-zero values.
- 
-         Returns:
-             metadata: dictionary to contain information for recovering back to original data array.
-             data (return): an numpy array with original numerical type.
-         """
-         # TODO
-         import copy
-         data = copy.deepcopy(data)
-         int2float_map = metadata['int_to_float']
-         for key in int2float_map:
-             indices = data == key
-             data[indices] = int2float_map[key]
-         return data
- 
-     @staticmethod
-     def _float_to_int(np_array):
-         """Create look-up table for conversion between floating and integer types.
- 
-         Args:
-             np_array:
- 
-         Returns:
-             int_array:
-             int_to_float_map:
- 
-         """
-         flatten_array = np_array.reshape(-1)
-         unique_value_array = np.unique(flatten_array)
-         int_array = np.zeros(flatten_array.shape, dtype=np.int)
-         int_to_float_map = {}
-         float_to_int_map = {}
-         # create table
-         for idx, u_value in enumerate(unique_value_array):
-             int_to_float_map.update({idx: u_value})
-             float_to_int_map.update({u_value: idx})
-             # assign to the integer array
-             indices = np.where(flatten_array == u_value)
-             int_array[indices] = idx
-         int_array = int_array.reshape(np_array.shape)
-         return int_array, int_to_float_map
- 
- 
- class GZIPTransformer(Transformer):
-     """A transformer class to losslessly compress data."""
- 
-     def __init__(self):
-         """Initialize."""
-         self.lossy = False
- 
-     def forward(self, data, **kwargs):
-         """Compress data into numpy of float32.
- 
-         Args:
-             data: an numpy array with non-zero values
- 
-         Returns:
-             compressed_bytes :
-             metadata: dictionary to contain information for recovering back to original data array
- 
-         """
-         bytes_ = data.astype(np.float32).tobytes()
-         compressed_bytes = gz.compress(bytes_)
-         metadata = {}
-         return compressed_bytes, metadata
- 
-     def backward(self, data, metadata, **kwargs):
-         """Decompress data into numpy of float32.
- 
-         Args:
-             data: an numpy array with non-zero values
-             metadata: dictionary to contain information for recovering back to original data array
- 
-         Returns:
-             data:
-         """
-         decompressed_bytes_ = gz.decompress(data)
-         data = np.frombuffer(decompressed_bytes_, dtype=np.float32)
-         return data
- 
- 
- class STCPipeline(TransformationPipeline):
-     """A pipeline class to compress data lossly using sparsity and ternerization methods."""
- 
-     def __init__(self, p_sparsity=0.1, n_clusters=6, **kwargs):
-         """Initialize a pipeline of transformers.
- 
-         Args:
-             p_sparsity (float): Sparsity factor (Default=0.01)
-             n_cluster (int): Number of K-Means clusters (Default=6)
- 
-         Returns:
-             Data compression transformer pipeline object
-         """
-         # instantiate each transformer
-         self.p = p_sparsity
-         transformers = [SparsityTransformer(self.p), TernaryTransformer(), GZIPTransformer()]
-         super(STCPipeline, self).__init__(transformers=transformers, **kwargs)
--- 0 ----
diff -crB --new-file ./openfl/openfl/pipelines/tensor_codec.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/pipelines/tensor_codec.py
*** ./openfl/openfl/pipelines/tensor_codec.py	2022-11-18 11:08:33.047181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/pipelines/tensor_codec.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,247 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """TensorCodec module."""
- 
- import numpy as np
- 
- from openfl.pipelines import NoCompressionPipeline
- from openfl.utilities import TensorKey
- 
- 
- class TensorCodec:
-     """TensorCodec is responsible for the following.
- 
-     1. Tracking the compression/decompression related dependencies of a given tensor
-     2. Acting as a TensorKey aware wrapper for the compression_pipeline functionality
-     """
- 
-     def __init__(self, compression_pipeline):
-         """Initialize."""
-         self.compression_pipeline = compression_pipeline
-         if self.compression_pipeline.is_lossy():
-             self.lossless_pipeline = NoCompressionPipeline()
-         else:
-             self.lossless_pipeline = compression_pipeline
- 
-     def set_lossless_pipeline(self, lossless_pipeline):
-         """Set lossless pipeline."""
-         assert lossless_pipeline.is_lossy() is False, (
-             'The provided pipeline is not lossless')
-         self.lossless_pipeline = lossless_pipeline
- 
-     def compress(self, tensor_key, data, require_lossless=False, **kwargs):
-         """
-         Function-wrapper around the tensor_pipeline.forward function.
- 
-         It also keeps track of the tensorkeys associated with the compressed nparray
- 
-         Args:
-             tensor_key:             TensorKey is provided to verify it should
-                                     be compressed, and new TensorKeys returned
-                                     will be derivatives of the existing
-                                     tensor_name
- 
-             data:                   (uncompressed) numpy array associated with
-                                     the tensor_key
- 
-             require_lossless:       boolean. Does tensor require
-                                     compression
- 
-         Returns:
-             compressed_tensor_key:  Tensorkey corresponding to the decompressed
-                                     tensor
- 
-             compressed_nparray:     The compressed tensor
- 
-             metadata:               metadata associated with compressed tensor
- 
-         """
-         if require_lossless:
-             compressed_nparray, metadata = self.lossless_pipeline.forward(
-                 data, **kwargs)
-         else:
-             compressed_nparray, metadata = self.compression_pipeline.forward(
-                 data, **kwargs)
-         # Define the compressed tensorkey that should be
-         # returned ('trained.delta'->'trained.delta.lossy_compressed')
-         tensor_name, origin, round_number, report, tags = tensor_key
-         if not self.compression_pipeline.is_lossy() or require_lossless:
-             new_tags = tuple(list(tags) + ['compressed'])
-         else:
-             new_tags = tuple(list(tags) + ['lossy_compressed'])
-         compressed_tensor_key = TensorKey(
-             tensor_name, origin, round_number, report, new_tags)
-         return compressed_tensor_key, compressed_nparray, metadata
- 
-     def decompress(self, tensor_key, data, transformer_metadata,
-                    require_lossless=False, **kwargs):
-         """
-         Function-wrapper around the tensor_pipeline.backward function.
- 
-         It also keeps track of the tensorkeys associated with the decompressed nparray
- 
-         Args:
-             tensor_key:             TensorKey is provided to verify it should
-                                     be decompressed, and new TensorKeys
-                                     returned will be derivatives of the
-                                     existing tensor_name
- 
-             data:                   (compressed) numpy array associated with
-                                     the tensor_key
- 
-             transformer_metadata:   metadata associated with the compressed
-                                     tensor
- 
-             require_lossless:       boolean, does data require lossless
-                                     decompression
- 
-         Returns:
-             decompressed_tensor_key:    Tensorkey corresponding to the
-                                         decompressed tensor
- 
-             decompressed_nparray:       The decompressed tensor
- 
-         """
-         tensor_name, origin, round_number, report, tags = tensor_key
- 
-         assert (len(transformer_metadata) > 0), (
-             'metadata must be included for decompression')
-         assert (('compressed' in tags) or ('lossy_compressed' in tags)), (
-             'Cannot decompress an uncompressed tensor')
-         if require_lossless:
-             assert ('compressed' in tags), (
-                 'Cannot losslessly decompress lossy tensor')
- 
-         if require_lossless or 'compressed' in tags:
-             decompressed_nparray = self.lossless_pipeline.backward(
-                 data, transformer_metadata, **kwargs)
-         else:
-             decompressed_nparray = self.compression_pipeline.backward(
-                 data, transformer_metadata, **kwargs)
-         # Define the decompressed tensorkey that should be returned
-         if 'lossy_compressed' in tags:
-             lc_idx = tags.index('lossy_compressed')
-             new_tags = list(tags)
-             new_tags[lc_idx] = 'lossy_decompressed'
-             decompressed_tensor_key = TensorKey(
-                 tensor_name, origin, round_number, report, tuple(new_tags))
-         elif 'compressed' in tags:
-             # 'compressed' == lossless compression; no need for
-             # compression related tag after decompression
-             new_tags = list(tags)
-             new_tags.remove('compressed')
-             decompressed_tensor_key = TensorKey(
-                 tensor_name, origin, round_number, report, tuple(new_tags))
-         else:
-             raise NotImplementedError(
-                 'Decompression is only supported on compressed data')
- 
-         return decompressed_tensor_key, decompressed_nparray
- 
-     @staticmethod
-     def generate_delta(tensor_key, nparray, base_model_nparray):
-         """
-         Create delta from the updated layer and base layer.
- 
-         Args:
-             tensor_key:         This is the tensor_key associated with the
-                                 nparray.
-                                 Should have a tag of 'trained' or 'aggregated'
- 
-             nparray:            The nparray that corresponds to the tensorkey
- 
-             base_model_nparray: The base model tensor that will be subtracted
-                                 from the new weights
- 
-         Returns:
-             delta_tensor_key:   Tensorkey that corresponds to the delta weight
-                                 array
- 
-             delta:              Difference between the provided tensors
- 
-         """
-         tensor_name, origin, round_number, report, tags = tensor_key
-         if not np.isscalar(nparray):
-             assert nparray.shape == base_model_nparray.shape, (
-                 f'Shape of updated layer ({nparray.shape}) is not equal to base '
-                 f'layer shape of ({base_model_nparray.shape})'
-             )
-         assert 'model' not in tags, (
-             'The tensorkey should be provided '
-             'from the layer with new weights, not the base model')
-         if type(tags) == str:
-             new_tags = tuple([tensor_key[3]] + ['delta'])
-         else:
-             new_tags = tuple(list(tags) + ['delta'])
-         delta_tensor_key = TensorKey(
-             tensor_name, origin, round_number, report, new_tags)
-         return delta_tensor_key, nparray - base_model_nparray
- 
-     @staticmethod
-     def apply_delta(tensor_key, delta, base_model_nparray, creates_model=False):
-         """
-         Add delta to the nparray.
- 
-         Args:
-             tensor_key:             This is the tensor_key associated with the
-                                     delta. Should have a tag of 'trained' or
-                                     'aggregated'
-             delta:                  Weight delta between the new model and
-                                     old model
-             base_model_nparray:     The nparray that corresponds to the prior
-                                     weights
-             creates_model:          If flag is set, the tensorkey returned
-                                     will correspond to the aggregator model
- 
-         Returns:
-             new_model_tensor_key:   Latest model layer tensorkey
-             new_model_nparray:      Latest layer weights
- 
-         """
-         tensor_name, origin, round_number, report, tags = tensor_key
-         if not np.isscalar(base_model_nparray):
-             assert (delta.shape == base_model_nparray.shape), (
-                 f'Shape of delta ({delta.shape}) is not equal to shape of model'
-                 f' layer ({base_model_nparray.shape})'
-             )
-         # assert('model' in tensor_key[3]), 'The tensorkey should be provided
-         # from the base model'
-         # Aggregator UUID has the prefix 'aggregator'
-         if 'aggregator' in origin and not creates_model:
-             tags = list(tags)
-             tags.remove('delta')
-             new_tags = tuple(tags)
-             new_model_tensor_key = TensorKey(
-                 tensor_name, origin, round_number, report, new_tags)
-         else:
-             new_model_tensor_key = TensorKey(
-                 tensor_name, origin, round_number, report, ('model',))
- 
-         return new_model_tensor_key, base_model_nparray + delta
- 
-     def find_dependencies(self, tensor_key, send_model_deltas):
-         """Resolve the tensors required to do the specified operation."""
-         tensor_key_dependencies = []
- 
-         tensor_name, origin, round_number, report, tags = tensor_key
- 
-         if 'model' in tags and send_model_deltas:
-             if round_number >= 1:
-                 # The new model can be generated by previous model + delta
-                 tensor_key_dependencies.append(
-                     TensorKey(
-                         tensor_name, origin, round_number - 1, report, tags
-                     )
-                 )
-                 if self.compression_pipeline.is_lossy():
-                     new_tags = ('aggregated', 'delta', 'lossy_compressed')
-                 else:
-                     new_tags = ('aggregated', 'delta', 'compressed')
-                 tensor_key_dependencies.append(
-                     TensorKey(
-                         tensor_name, origin, round_number, report, new_tags
-                     )
-                 )
- 
-         return tensor_key_dependencies
--- 0 ----
diff -crB --new-file ./openfl/openfl/plugins/frameworks_adapters/framework_adapter_interface.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/plugins/frameworks_adapters/framework_adapter_interface.py
*** ./openfl/openfl/plugins/frameworks_adapters/framework_adapter_interface.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/plugins/frameworks_adapters/framework_adapter_interface.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,36 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Framework Adapter plugin interface."""
- 
- 
- class FrameworkAdapterPluginInterface:
-     """Framework adapter plugin class."""
- 
-     def __init__(self) -> None:
-         """Initialize framework adapter."""
-         pass
- 
-     @staticmethod
-     def serialization_setup():
-         """Prepare model for serialization (optional)."""
-         pass
- 
-     @staticmethod
-     def get_tensor_dict(model, optimizer=None) -> dict:
-         """
-         Extract tensor dict from a model and an optimizer.
- 
-         Returns:
-         dict {weight name: numpy ndarray}
-         """
-         raise NotImplementedError
- 
-     @staticmethod
-     def set_tensor_dict(model, tensor_dict, optimizer=None, device='cpu'):
-         """
-         Set tensor dict from a model and an optimizer.
- 
-         Given a dict {weight name: numpy ndarray} sets weights to
-         the model and optimizer objects inplace.
-         """
-         raise NotImplementedError
--- 0 ----
diff -crB --new-file ./openfl/openfl/plugins/frameworks_adapters/keras_adapter.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/plugins/frameworks_adapters/keras_adapter.py
*** ./openfl/openfl/plugins/frameworks_adapters/keras_adapter.py	2022-11-18 11:08:33.047181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/plugins/frameworks_adapters/keras_adapter.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,132 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Keras Framework Adapter plugin."""
- from .framework_adapter_interface import FrameworkAdapterPluginInterface
- 
- 
- class FrameworkAdapterPlugin(FrameworkAdapterPluginInterface):
-     """Framework adapter plugin class."""
- 
-     def __init__(self) -> None:
-         """Initialize framework adapter."""
-         pass
- 
-     @staticmethod
-     def serialization_setup():
-         """Prepare model for serialization (optional)."""
-         # Source: https://github.com/tensorflow/tensorflow/issues/34697
-         from tensorflow.keras.models import Model
-         from tensorflow.python.keras.layers import deserialize
-         from tensorflow.python.keras.layers import serialize
-         from tensorflow.python.keras.saving import saving_utils
- 
-         def unpack(model, training_config, weights):
-             restored_model = deserialize(model)
-             if training_config is not None:
-                 restored_model.compile(
-                     **saving_utils.compile_args_from_training_config(
-                         training_config
-                     )
-                 )
-             restored_model.set_weights(weights)
-             return restored_model
- 
-         # Hotfix function
-         def make_keras_picklable():
- 
-             def __reduce__(self):  # NOQA:N807
-                 model_metadata = saving_utils.model_metadata(self)
-                 training_config = model_metadata.get('training_config', None)
-                 model = serialize(self)
-                 weights = self.get_weights()
-                 return (unpack, (model, training_config, weights))
- 
-             cls = Model
-             cls.__reduce__ = __reduce__
- 
-         # Run the function
-         make_keras_picklable()
- 
-     @staticmethod
-     def get_tensor_dict(model, optimizer=None, suffix=''):
-         """
-         Extract tensor dict from a model and an optimizer.
- 
-         Returns:
-         dict {weight name: numpy ndarray}
-         """
-         model_weights = _get_weights_dict(model, suffix)
- 
-         if optimizer is not None:
-             opt_weights = _get_weights_dict(optimizer, suffix)
- 
-             model_weights.update(opt_weights)
-             if len(opt_weights) == 0:
-                 # ToDo: warn user somehow
-                 pass
- 
-         return model_weights
- 
-     @staticmethod
-     def set_tensor_dict(model, tensor_dict, optimizer=None, device='cpu'):
-         """
-         Set the model weights with a tensor dictionary.
- 
-         Args:
-             tensor_dict: the tensor dictionary
-             with_opt_vars (bool): True = include the optimizer's status.
-         """
-         model_weight_names = [weight.name for weight in model.weights]
-         model_weights_dict = {
-             name: tensor_dict[name] for name in model_weight_names
-         }
-         _set_weights_dict(model, model_weights_dict)
- 
-         if optimizer is not None:
-             opt_weight_names = [
-                 weight.name for weight in optimizer.weights
-             ]
-             opt_weights_dict = {
-                 name: tensor_dict[name] for name in opt_weight_names
-             }
-             _set_weights_dict(optimizer, opt_weights_dict)
- 
- 
- def _get_weights_dict(obj, suffix=''):
-     """
-     Get the dictionary of weights.
- 
-     Parameters
-     ----------
-     obj : Model or Optimizer
-         The target object that we want to get the weights.
- 
-     Returns
-     -------
-     dict
-         The weight dictionary.
-     """
-     weights_dict = {}
-     weight_names = [weight.name for weight in obj.weights]
-     weight_values = obj.get_weights()
-     for name, value in zip(weight_names, weight_values):
-         weights_dict[name + suffix] = value
-     return weights_dict
- 
- 
- def _set_weights_dict(obj, weights_dict):
-     """Set the object weights with a dictionary.
- 
-     The obj can be a model or an optimizer.
- 
-     Args:
-         obj (Model or Optimizer): The target object that we want to set
-         the weights.
-         weights_dict (dict): The weight dictionary.
- 
-     Returns:
-         None
-     """
-     weight_names = [weight.name for weight in obj.weights]
-     weight_values = [weights_dict[name] for name in weight_names]
-     obj.set_weights(weight_values)
--- 0 ----
diff -crB --new-file ./openfl/openfl/plugins/frameworks_adapters/pytorch_adapter.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/plugins/frameworks_adapters/pytorch_adapter.py
*** ./openfl/openfl/plugins/frameworks_adapters/pytorch_adapter.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/plugins/frameworks_adapters/pytorch_adapter.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,264 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Pytorch Framework Adapter plugin."""
- from copy import deepcopy
- 
- import numpy as np
- import torch as pt
- 
- from .framework_adapter_interface import FrameworkAdapterPluginInterface
- 
- 
- class FrameworkAdapterPlugin(FrameworkAdapterPluginInterface):
-     """Framework adapter plugin class."""
- 
-     def __init__(self) -> None:
-         """Initialize framework adapter."""
-         pass
- 
-     @staticmethod
-     def get_tensor_dict(model, optimizer=None):
-         """
-         Extract tensor dict from a model and an optimizer.
- 
-         Returns:
-         dict {weight name: numpy ndarray}
-         """
-         state = to_cpu_numpy(model.state_dict())
- 
-         if optimizer is not None:
-             opt_state = _get_optimizer_state(optimizer)
-             state = {**state, **opt_state}
- 
-         return state
- 
-     @staticmethod
-     def set_tensor_dict(model, tensor_dict, optimizer=None, device='cpu'):
-         """
-         Set tensor dict from a model and an optimizer.
- 
-         Given a dict {weight name: numpy ndarray} sets weights to
-         the model and optimizer objects inplace.
-         """
-         new_state = {}
-         # Grabbing keys from model's state_dict helps to confirm we have
-         # everything
-         for k in model.state_dict():
-             new_state[k] = pt.from_numpy(tensor_dict.pop(k)).to(device)
- 
-         # set model state
-         model.load_state_dict(new_state)
- 
-         if optimizer is not None:
-             # see if there is state to restore first
-             if tensor_dict.pop('__opt_state_needed') == 'true':
-                 _set_optimizer_state(optimizer, device, tensor_dict)
- 
-             # sanity check that we did not record any state that was not used
-             assert len(tensor_dict) == 0
- 
- 
- def _set_optimizer_state(optimizer, device, derived_opt_state_dict):
-     """Set the optimizer state.
- 
-     Args:
-         optimizer:
-         device:
-         derived_opt_state_dict:
- 
-     """
-     temp_state_dict = expand_derived_opt_state_dict(
-         derived_opt_state_dict, device)
- 
-     # Setting other items from the param_groups
-     # getting them from the local optimizer
-     # (expand_derived_opt_state_dict sets only 'params')
-     for i, group in enumerate(optimizer.param_groups):
-         for k, v in group.items():
-             if k not in temp_state_dict['param_groups'][i]:
-                 temp_state_dict['param_groups'][i][k] = v
- 
-     optimizer.load_state_dict(temp_state_dict)
- 
- 
- def _get_optimizer_state(optimizer):
-     """Return the optimizer state.
- 
-     Args:
-         optimizer
-     """
-     opt_state_dict = deepcopy(optimizer.state_dict())
- 
-     # Optimizer state might not have some parts representing frozen parameters
-     # So we do not synchronize them
-     param_keys_with_state = set(opt_state_dict['state'].keys())
-     for group in opt_state_dict['param_groups']:
-         local_param_set = set(group['params'])
-         params_to_sync = local_param_set & param_keys_with_state
-         group['params'] = sorted(params_to_sync)
- 
-     derived_opt_state_dict = _derive_opt_state_dict(opt_state_dict)
- 
-     return derived_opt_state_dict
- 
- 
- def _derive_opt_state_dict(opt_state_dict):
-     """Separate optimizer tensors from the tensor dictionary.
- 
-     Flattens the optimizer state dict so as to have key, value pairs with
-     values as numpy arrays.
-     The keys have sufficient info to restore opt_state_dict using
-     expand_derived_opt_state_dict.
- 
-     Args:
-         opt_state_dict: The optimizer state dictionary
- 
-     """
-     derived_opt_state_dict = {}
- 
-     # Determine if state is needed for this optimizer.
-     if len(opt_state_dict['state']) == 0:
-         derived_opt_state_dict['__opt_state_needed'] = 'false'
-         return derived_opt_state_dict
- 
-     derived_opt_state_dict['__opt_state_needed'] = 'true'
- 
-     # Using one example state key, we collect keys for the corresponding
-     # dictionary value.
-     example_state_key = opt_state_dict['param_groups'][0]['params'][0]
-     example_state_subkeys = set(
-         opt_state_dict['state'][example_state_key].keys()
-     )
- 
-     # We assume that the state collected for all params in all param groups is
-     # the same.
-     # We also assume that whether or not the associated values to these state
-     # subkeys is a tensor depends only on the subkey.
-     # Using assert statements to break the routine if these assumptions are
-     # incorrect.
-     for state_key in opt_state_dict['state'].keys():
-         assert example_state_subkeys == set(opt_state_dict['state'][state_key].keys())
-         for state_subkey in example_state_subkeys:
-             assert (isinstance(
-                 opt_state_dict['state'][example_state_key][state_subkey],
-                 pt.Tensor)
-                 == isinstance(
-                     opt_state_dict['state'][state_key][state_subkey],
-                     pt.Tensor))
- 
-     state_subkeys = list(opt_state_dict['state'][example_state_key].keys())
- 
-     # Tags will record whether the value associated to the subkey is a
-     # tensor or not.
-     state_subkey_tags = []
-     for state_subkey in state_subkeys:
-         if isinstance(
-                 opt_state_dict['state'][example_state_key][state_subkey],
-                 pt.Tensor
-         ):
-             state_subkey_tags.append('istensor')
-         else:
-             state_subkey_tags.append('')
-     state_subkeys_and_tags = list(zip(state_subkeys, state_subkey_tags))
- 
-     # Forming the flattened dict, using a concatenation of group index,
-     # subindex, tag, and subkey inserted into the flattened dict key -
-     # needed for reconstruction.
-     nb_params_per_group = []
-     for group_idx, group in enumerate(opt_state_dict['param_groups']):
-         for idx, param_id in enumerate(group['params']):
-             for subkey, tag in state_subkeys_and_tags:
-                 if tag == 'istensor':
-                     new_v = opt_state_dict['state'][param_id][
-                         subkey].cpu().numpy()
-                 else:
-                     new_v = np.array(
-                         [opt_state_dict['state'][param_id][subkey]]
-                     )
-                 derived_opt_state_dict[f'__opt_state_{group_idx}_{idx}_{tag}_{subkey}'] = new_v
-         nb_params_per_group.append(idx + 1)
-     # group lengths are also helpful for reconstructing
-     # original opt_state_dict structure
-     derived_opt_state_dict['__opt_group_lengths'] = np.array(
-         nb_params_per_group
-     )
- 
-     return derived_opt_state_dict
- 
- 
- def expand_derived_opt_state_dict(derived_opt_state_dict, device):
-     """Expand the optimizer state dictionary.
- 
-     Takes a derived opt_state_dict and creates an opt_state_dict suitable as
-     input for load_state_dict for restoring optimizer state.
- 
-     Reconstructing state_subkeys_and_tags using the example key
-     prefix, "__opt_state_0_0_", certain to be present.
- 
-     Args:
-         derived_opt_state_dict: Optimizer state dictionary
- 
-     Returns:
-         dict: Optimizer state dictionary
-     """
-     state_subkeys_and_tags = []
-     for key in derived_opt_state_dict:
-         if key.startswith('__opt_state_0_0_'):
-             stripped_key = key[16:]
-             if stripped_key.startswith('istensor_'):
-                 this_tag = 'istensor'
-                 subkey = stripped_key[9:]
-             else:
-                 this_tag = ''
-                 subkey = stripped_key[1:]
-             state_subkeys_and_tags.append((subkey, this_tag))
- 
-     opt_state_dict = {'param_groups': [], 'state': {}}
-     nb_params_per_group = list(
-         derived_opt_state_dict.pop('__opt_group_lengths').astype(np.int)
-     )
- 
-     # Construct the expanded dict.
-     for group_idx, nb_params in enumerate(nb_params_per_group):
-         these_group_ids = [
-             f'{group_idx}_{idx}' for idx in range(nb_params)
-         ]
-         opt_state_dict['param_groups'].append({'params': these_group_ids})
-         for this_id in these_group_ids:
-             opt_state_dict['state'][this_id] = {}
-             for subkey, tag in state_subkeys_and_tags:
-                 flat_key = f'__opt_state_{this_id}_{tag}_{subkey}'
-                 if tag == 'istensor':
-                     new_v = pt.from_numpy(derived_opt_state_dict.pop(flat_key))
-                 else:
-                     # Here (for currrently supported optimizers) the subkey
-                     # should be 'step' and the length of array should be one.
-                     assert subkey == 'step'
-                     assert len(derived_opt_state_dict[flat_key]) == 1
-                     new_v = int(derived_opt_state_dict.pop(flat_key))
-                 opt_state_dict['state'][this_id][subkey] = new_v
- 
-     # sanity check that we did not miss any optimizer state
-     assert len(derived_opt_state_dict) == 0, str(derived_opt_state_dict)
- 
-     return opt_state_dict
- 
- 
- def to_cpu_numpy(state):
-     """Send data to CPU as Numpy array.
- 
-     Args:
-         state
- 
-     """
-     # deep copy so as to decouple from active model
-     state = deepcopy(state)
- 
-     for k, v in state.items():
-         # When restoring, we currently assume all values are tensors.
-         if not pt.is_tensor(v):
-             raise ValueError('We do not currently support non-tensors '
-                              'coming from model.state_dict()')
-         # get as a numpy array, making sure is on cpu
-         state[k] = v.cpu().numpy()
-     return state
--- 0 ----
diff -crB --new-file ./openfl/openfl/plugins/interface_serializer/cloudpickle_serializer.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/plugins/interface_serializer/cloudpickle_serializer.py
*** ./openfl/openfl/plugins/interface_serializer/cloudpickle_serializer.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/plugins/interface_serializer/cloudpickle_serializer.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,27 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Cloudpickle serializer plugin."""
- 
- import cloudpickle
- 
- from .serializer_interface import Serializer
- 
- 
- class CloudpickleSerializer(Serializer):
-     """Serializer API plugin."""
- 
-     def __init__(self) -> None:
-         """Initialize serializer."""
-         super().__init__()
- 
-     @staticmethod
-     def serialize(object_, filename):
-         """Serialize an object and save to disk."""
-         with open(filename, 'wb') as f:
-             cloudpickle.dump(object_, f)
- 
-     @staticmethod
-     def restore_object(filename):
-         """Load and deserialize an object."""
-         with open(filename, 'rb') as f:
-             return cloudpickle.load(f)
--- 0 ----
diff -crB --new-file ./openfl/openfl/plugins/interface_serializer/dill_serializer.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/plugins/interface_serializer/dill_serializer.py
*** ./openfl/openfl/plugins/interface_serializer/dill_serializer.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/plugins/interface_serializer/dill_serializer.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,27 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Dill serializer plugin."""
- 
- import dill
- 
- from .serializer_interface import Serializer
- 
- 
- class DillSerializer(Serializer):
-     """Serializer API plugin."""
- 
-     def __init__(self) -> None:
-         """Initialize serializer."""
-         super().__init__()
- 
-     @staticmethod
-     def serialize(object_, filename):
-         """Serialize an object and save to disk."""
-         with open(filename, 'wb') as f:
-             dill.dump(object_, f, recurse=True)
- 
-     @staticmethod
-     def restore_object(filename):
-         """Load and deserialize an object."""
-         with open(filename, 'rb') as f:
-             return dill.load(f)
--- 0 ----
diff -crB --new-file ./openfl/openfl/plugins/interface_serializer/serializer_interface.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/plugins/interface_serializer/serializer_interface.py
*** ./openfl/openfl/plugins/interface_serializer/serializer_interface.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/plugins/interface_serializer/serializer_interface.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,21 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Serializer plugin interface."""
- 
- 
- class Serializer:
-     """Serializer API plugin."""
- 
-     def __init__(self) -> None:
-         """Initialize serializer."""
-         pass
- 
-     @staticmethod
-     def serialize(object_, filename):
-         """Serialize an object and save to disk."""
-         raise NotImplementedError
- 
-     @staticmethod
-     def restore_object(filename):
-         """Load and deserialize an object."""
-         raise NotImplementedError
--- 0 ----
diff -crB --new-file ./openfl/openfl/plugins/processing_units_monitor/cuda_device_monitor.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/plugins/processing_units_monitor/cuda_device_monitor.py
*** ./openfl/openfl/plugins/processing_units_monitor/cuda_device_monitor.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/plugins/processing_units_monitor/cuda_device_monitor.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,37 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """CUDA Device monitor plugin module."""
- 
- from .device_monitor import DeviceMonitor
- 
- 
- class CUDADeviceMonitor(DeviceMonitor):
-     """CUDA Device monitor plugin."""
- 
-     def get_driver_version(self) -> str:
-         """Get CUDA driver version."""
-         raise NotImplementedError
- 
-     def get_device_memory_total(self, index: int) -> int:
-         """Get total memory available on the device."""
-         raise NotImplementedError
- 
-     def get_device_memory_utilized(self, index: int) -> int:
-         """Get utilized memory on the device."""
-         raise NotImplementedError
- 
-     def get_device_utilization(self, index: int) -> str:
-         """
-         Get device utilization.
- 
-         It is just a general method that returns a string that may be shown to the frontend user.
-         """
-         raise NotImplementedError
- 
-     def get_device_name(self, index: int) -> str:
-         """Get device name."""
-         raise NotImplementedError
- 
-     def get_cuda_version(self) -> str:
-         """Get CUDA driver version."""
-         raise NotImplementedError
--- 0 ----
diff -crB --new-file ./openfl/openfl/plugins/processing_units_monitor/device_monitor.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/plugins/processing_units_monitor/device_monitor.py
*** ./openfl/openfl/plugins/processing_units_monitor/device_monitor.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/plugins/processing_units_monitor/device_monitor.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,19 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Device monitor plugin module."""
- 
- 
- class DeviceMonitor:
-     """Device monitor plugin interface."""
- 
-     def get_driver_version(self) -> str:
-         """Get device's driver version."""
-         raise NotImplementedError
- 
-     def get_device_utilization(self, index: int) -> str:
-         """
-         Get device utilization method.
- 
-         It is just a general method that returns a string that may be shown to the frontend user.
-         """
-         raise NotImplementedError
--- 0 ----
diff -crB --new-file ./openfl/openfl/plugins/processing_units_monitor/pynvml_monitor.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/plugins/processing_units_monitor/pynvml_monitor.py
*** ./openfl/openfl/plugins/processing_units_monitor/pynvml_monitor.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/plugins/processing_units_monitor/pynvml_monitor.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,66 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """
- pynvml CUDA Device monitor plugin module.
- 
- Required package: pynvml
- """
- 
- import pynvml
- 
- from .cuda_device_monitor import CUDADeviceMonitor
- 
- pynvml.nvmlInit()
- 
- 
- class PynvmlCUDADeviceMonitor(CUDADeviceMonitor):
-     """CUDA Device monitor plugin using pynvml lib."""
- 
-     def __init__(self) -> None:
-         """Initialize pynvml plugin."""
-         super().__init__()
- 
-     def get_driver_version(self) -> str:
-         """Get Nvidia driver version."""
-         return pynvml.nvmlSystemGetDriverVersion().decode('utf-8')
- 
-     def get_device_memory_total(self, index: int) -> int:
-         """Get total memory available on the device."""
-         handle = pynvml.nvmlDeviceGetHandleByIndex(index)
-         info = pynvml.nvmlDeviceGetMemoryInfo(handle)
-         return info.total
- 
-     def get_device_memory_utilized(self, index: int) -> int:
-         """Get utilized memory on the device."""
-         handle = pynvml.nvmlDeviceGetHandleByIndex(index)
-         info = pynvml.nvmlDeviceGetMemoryInfo(handle)
-         return info.used
- 
-     def get_device_utilization(self, index: int) -> str:
-         """
-         Get device utilization.
- 
-         It is just a general method that returns a string that may be shown to the frontend user.
-         """
-         handle = pynvml.nvmlDeviceGetHandleByIndex(index)
-         info_utilization = pynvml.nvmlDeviceGetUtilizationRates(handle)
-         return f'{info_utilization.gpu}%'
- 
-     def get_device_name(self, index: int) -> str:
-         """Get device utilization method."""
-         handle = pynvml.nvmlDeviceGetHandleByIndex(index)
-         device_name = pynvml.nvmlDeviceGetName(handle)
-         return device_name
- 
-     def get_cuda_version(self) -> str:
-         """
-         Get CUDA driver version.
- 
-         The CUDA version is specified as (1000 * major + 10 * minor),
-         so CUDA 11.2 should be specified as 11020.
-         https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__DRIVER__ENTRY__POINT.html
-         """
-         cuda_version = pynvml.nvmlSystemGetCudaDriverVersion()
-         major_version = int(cuda_version / 1000)
-         minor_version = int(cuda_version % 1000 / 10)
-         return f'{major_version}.{minor_version}'
--- 0 ----
diff -crB --new-file ./openfl/openfl/protocols/aggregator_pb2_grpc.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols/aggregator_pb2_grpc.py
*** ./openfl/openfl/protocols/aggregator_pb2_grpc.py	2022-11-18 11:08:33.047181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols/aggregator_pb2_grpc.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,232 ****
- # Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
- """Client and server classes corresponding to protobuf-defined services."""
- import grpc
- 
- from openfl.protocols import aggregator_pb2 as openfl_dot_protocols_dot_aggregator__pb2
- from openfl.protocols import base_pb2 as openfl_dot_protocols_dot_base__pb2
- 
- 
- class AggregatorStub(object):
-     """Missing associated documentation comment in .proto file."""
- 
-     def __init__(self, channel):
-         """Constructor.
- 
-         Args:
-             channel: A grpc.Channel.
-         """
-         self.GetTasks = channel.unary_unary(
-                 '/openfl.aggregator.Aggregator/GetTasks',
-                 request_serializer=openfl_dot_protocols_dot_aggregator__pb2.GetTasksRequest.SerializeToString,
-                 response_deserializer=openfl_dot_protocols_dot_aggregator__pb2.GetTasksResponse.FromString,
-                 )
-         self.GetAggregatedTensor = channel.unary_unary(
-                 '/openfl.aggregator.Aggregator/GetAggregatedTensor',
-                 request_serializer=openfl_dot_protocols_dot_aggregator__pb2.GetAggregatedTensorRequest.SerializeToString,
-                 response_deserializer=openfl_dot_protocols_dot_aggregator__pb2.GetAggregatedTensorResponse.FromString,
-                 )
-         self.SendLocalTaskResults = channel.stream_unary(
-                 '/openfl.aggregator.Aggregator/SendLocalTaskResults',
-                 request_serializer=openfl_dot_protocols_dot_base__pb2.DataStream.SerializeToString,
-                 response_deserializer=openfl_dot_protocols_dot_aggregator__pb2.SendLocalTaskResultsResponse.FromString,
-                 )
-         self.GetMetricStream = channel.unary_stream(
-                 '/openfl.aggregator.Aggregator/GetMetricStream',
-                 request_serializer=openfl_dot_protocols_dot_aggregator__pb2.GetMetricStreamRequest.SerializeToString,
-                 response_deserializer=openfl_dot_protocols_dot_aggregator__pb2.GetMetricStreamResponse.FromString,
-                 )
-         self.GetTrainedModel = channel.unary_unary(
-                 '/openfl.aggregator.Aggregator/GetTrainedModel',
-                 request_serializer=openfl_dot_protocols_dot_aggregator__pb2.GetTrainedModelRequest.SerializeToString,
-                 response_deserializer=openfl_dot_protocols_dot_aggregator__pb2.TrainedModelResponse.FromString,
-                 )
-         self.GetExperimentDescription = channel.unary_unary(
-                 '/openfl.aggregator.Aggregator/GetExperimentDescription',
-                 request_serializer=openfl_dot_protocols_dot_aggregator__pb2.GetExperimentDescriptionRequest.SerializeToString,
-                 response_deserializer=openfl_dot_protocols_dot_aggregator__pb2.GetExperimentDescriptionResponse.FromString,
-                 )
- 
- 
- class AggregatorServicer(object):
-     """Missing associated documentation comment in .proto file."""
- 
-     def GetTasks(self, request, context):
-         """Missing associated documentation comment in .proto file."""
-         context.set_code(grpc.StatusCode.UNIMPLEMENTED)
-         context.set_details('Method not implemented!')
-         raise NotImplementedError('Method not implemented!')
- 
-     def GetAggregatedTensor(self, request, context):
-         """Missing associated documentation comment in .proto file."""
-         context.set_code(grpc.StatusCode.UNIMPLEMENTED)
-         context.set_details('Method not implemented!')
-         raise NotImplementedError('Method not implemented!')
- 
-     def SendLocalTaskResults(self, request_iterator, context):
-         """Missing associated documentation comment in .proto file."""
-         context.set_code(grpc.StatusCode.UNIMPLEMENTED)
-         context.set_details('Method not implemented!')
-         raise NotImplementedError('Method not implemented!')
- 
-     def GetMetricStream(self, request, context):
-         """Missing associated documentation comment in .proto file."""
-         context.set_code(grpc.StatusCode.UNIMPLEMENTED)
-         context.set_details('Method not implemented!')
-         raise NotImplementedError('Method not implemented!')
- 
-     def GetTrainedModel(self, request, context):
-         """Missing associated documentation comment in .proto file."""
-         context.set_code(grpc.StatusCode.UNIMPLEMENTED)
-         context.set_details('Method not implemented!')
-         raise NotImplementedError('Method not implemented!')
- 
-     def GetExperimentDescription(self, request, context):
-         """Missing associated documentation comment in .proto file."""
-         context.set_code(grpc.StatusCode.UNIMPLEMENTED)
-         context.set_details('Method not implemented!')
-         raise NotImplementedError('Method not implemented!')
- 
- 
- def add_AggregatorServicer_to_server(servicer, server):
-     rpc_method_handlers = {
-             'GetTasks': grpc.unary_unary_rpc_method_handler(
-                     servicer.GetTasks,
-                     request_deserializer=openfl_dot_protocols_dot_aggregator__pb2.GetTasksRequest.FromString,
-                     response_serializer=openfl_dot_protocols_dot_aggregator__pb2.GetTasksResponse.SerializeToString,
-             ),
-             'GetAggregatedTensor': grpc.unary_unary_rpc_method_handler(
-                     servicer.GetAggregatedTensor,
-                     request_deserializer=openfl_dot_protocols_dot_aggregator__pb2.GetAggregatedTensorRequest.FromString,
-                     response_serializer=openfl_dot_protocols_dot_aggregator__pb2.GetAggregatedTensorResponse.SerializeToString,
-             ),
-             'SendLocalTaskResults': grpc.stream_unary_rpc_method_handler(
-                     servicer.SendLocalTaskResults,
-                     request_deserializer=openfl_dot_protocols_dot_base__pb2.DataStream.FromString,
-                     response_serializer=openfl_dot_protocols_dot_aggregator__pb2.SendLocalTaskResultsResponse.SerializeToString,
-             ),
-             'GetMetricStream': grpc.unary_stream_rpc_method_handler(
-                     servicer.GetMetricStream,
-                     request_deserializer=openfl_dot_protocols_dot_aggregator__pb2.GetMetricStreamRequest.FromString,
-                     response_serializer=openfl_dot_protocols_dot_aggregator__pb2.GetMetricStreamResponse.SerializeToString,
-             ),
-             'GetTrainedModel': grpc.unary_unary_rpc_method_handler(
-                     servicer.GetTrainedModel,
-                     request_deserializer=openfl_dot_protocols_dot_aggregator__pb2.GetTrainedModelRequest.FromString,
-                     response_serializer=openfl_dot_protocols_dot_aggregator__pb2.TrainedModelResponse.SerializeToString,
-             ),
-             'GetExperimentDescription': grpc.unary_unary_rpc_method_handler(
-                     servicer.GetExperimentDescription,
-                     request_deserializer=openfl_dot_protocols_dot_aggregator__pb2.GetExperimentDescriptionRequest.FromString,
-                     response_serializer=openfl_dot_protocols_dot_aggregator__pb2.GetExperimentDescriptionResponse.SerializeToString,
-             ),
-     }
-     generic_handler = grpc.method_handlers_generic_handler(
-             'openfl.aggregator.Aggregator', rpc_method_handlers)
-     server.add_generic_rpc_handlers((generic_handler,))
- 
- 
-  # This class is part of an EXPERIMENTAL API.
- class Aggregator(object):
-     """Missing associated documentation comment in .proto file."""
- 
-     @staticmethod
-     def GetTasks(request,
-             target,
-             options=(),
-             channel_credentials=None,
-             call_credentials=None,
-             insecure=False,
-             compression=None,
-             wait_for_ready=None,
-             timeout=None,
-             metadata=None):
-         return grpc.experimental.unary_unary(request, target, '/openfl.aggregator.Aggregator/GetTasks',
-             openfl_dot_protocols_dot_aggregator__pb2.GetTasksRequest.SerializeToString,
-             openfl_dot_protocols_dot_aggregator__pb2.GetTasksResponse.FromString,
-             options, channel_credentials,
-             insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
- 
-     @staticmethod
-     def GetAggregatedTensor(request,
-             target,
-             options=(),
-             channel_credentials=None,
-             call_credentials=None,
-             insecure=False,
-             compression=None,
-             wait_for_ready=None,
-             timeout=None,
-             metadata=None):
-         return grpc.experimental.unary_unary(request, target, '/openfl.aggregator.Aggregator/GetAggregatedTensor',
-             openfl_dot_protocols_dot_aggregator__pb2.GetAggregatedTensorRequest.SerializeToString,
-             openfl_dot_protocols_dot_aggregator__pb2.GetAggregatedTensorResponse.FromString,
-             options, channel_credentials,
-             insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
- 
-     @staticmethod
-     def SendLocalTaskResults(request_iterator,
-             target,
-             options=(),
-             channel_credentials=None,
-             call_credentials=None,
-             insecure=False,
-             compression=None,
-             wait_for_ready=None,
-             timeout=None,
-             metadata=None):
-         return grpc.experimental.stream_unary(request_iterator, target, '/openfl.aggregator.Aggregator/SendLocalTaskResults',
-             openfl_dot_protocols_dot_base__pb2.DataStream.SerializeToString,
-             openfl_dot_protocols_dot_aggregator__pb2.SendLocalTaskResultsResponse.FromString,
-             options, channel_credentials,
-             insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
- 
-     @staticmethod
-     def GetMetricStream(request,
-             target,
-             options=(),
-             channel_credentials=None,
-             call_credentials=None,
-             insecure=False,
-             compression=None,
-             wait_for_ready=None,
-             timeout=None,
-             metadata=None):
-         return grpc.experimental.unary_stream(request, target, '/openfl.aggregator.Aggregator/GetMetricStream',
-             openfl_dot_protocols_dot_aggregator__pb2.GetMetricStreamRequest.SerializeToString,
-             openfl_dot_protocols_dot_aggregator__pb2.GetMetricStreamResponse.FromString,
-             options, channel_credentials,
-             insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
- 
-     @staticmethod
-     def GetTrainedModel(request,
-             target,
-             options=(),
-             channel_credentials=None,
-             call_credentials=None,
-             insecure=False,
-             compression=None,
-             wait_for_ready=None,
-             timeout=None,
-             metadata=None):
-         return grpc.experimental.unary_unary(request, target, '/openfl.aggregator.Aggregator/GetTrainedModel',
-             openfl_dot_protocols_dot_aggregator__pb2.GetTrainedModelRequest.SerializeToString,
-             openfl_dot_protocols_dot_aggregator__pb2.TrainedModelResponse.FromString,
-             options, channel_credentials,
-             insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
- 
-     @staticmethod
-     def GetExperimentDescription(request,
-             target,
-             options=(),
-             channel_credentials=None,
-             call_credentials=None,
-             insecure=False,
-             compression=None,
-             wait_for_ready=None,
-             timeout=None,
-             metadata=None):
-         return grpc.experimental.unary_unary(request, target, '/openfl.aggregator.Aggregator/GetExperimentDescription',
-             openfl_dot_protocols_dot_aggregator__pb2.GetExperimentDescriptionRequest.SerializeToString,
-             openfl_dot_protocols_dot_aggregator__pb2.GetExperimentDescriptionResponse.FromString,
-             options, channel_credentials,
-             insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
--- 0 ----
diff -crB --new-file ./openfl/openfl/protocols/aggregator_pb2.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols/aggregator_pb2.py
*** ./openfl/openfl/protocols/aggregator_pb2.py	2022-11-18 11:08:33.047181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols/aggregator_pb2.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,889 ****
- # -*- coding: utf-8 -*-
- # Generated by the protocol buffer compiler.  DO NOT EDIT!
- # source: openfl/protocols/aggregator.proto
- """Generated protocol buffer code."""
- from google.protobuf import descriptor as _descriptor
- from google.protobuf import message as _message
- from google.protobuf import reflection as _reflection
- from google.protobuf import symbol_database as _symbol_database
- # @@protoc_insertion_point(imports)
- 
- _sym_db = _symbol_database.Default()
- 
- 
- from openfl.protocols import base_pb2 as openfl_dot_protocols_dot_base__pb2
- 
- 
- DESCRIPTOR = _descriptor.FileDescriptor(
-   name='openfl/protocols/aggregator.proto',
-   package='openfl.aggregator',
-   syntax='proto3',
-   serialized_options=None,
-   create_key=_descriptor._internal_create_key,
-   serialized_pb=b'\n!openfl/protocols/aggregator.proto\x12\x11openfl.aggregator\x1a\x1bopenfl/protocols/base.proto\"o\n\rMessageHeader\x12\x0e\n\x06sender\x18\x01 \x01(\t\x12\x10\n\x08receiver\x18\x02 \x01(\t\x12\x17\n\x0f\x66\x65\x64\x65ration_uuid\x18\x03 \x01(\t\x12#\n\x1bsingle_col_cert_common_name\x18\x04 \x01(\t\"C\n\x0fGetTasksRequest\x12\x30\n\x06header\x18\x01 \x01(\x0b\x32 .openfl.aggregator.MessageHeader\"S\n\x04Task\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x15\n\rfunction_name\x18\x02 \x01(\t\x12\x11\n\ttask_type\x18\x03 \x01(\t\x12\x13\n\x0b\x61pply_local\x18\x04 \x01(\x08\"\xa4\x01\n\x10GetTasksResponse\x12\x30\n\x06header\x18\x01 \x01(\x0b\x32 .openfl.aggregator.MessageHeader\x12\x14\n\x0cround_number\x18\x02 \x01(\x05\x12&\n\x05tasks\x18\x03 \x03(\x0b\x32\x17.openfl.aggregator.Task\x12\x12\n\nsleep_time\x18\x04 \x01(\x05\x12\x0c\n\x04quit\x18\x05 \x01(\x08\"\xb1\x01\n\x1aGetAggregatedTensorRequest\x12\x30\n\x06header\x18\x01 \x01(\x0b\x32 .openfl.aggregator.MessageHeader\x12\x13\n\x0btensor_name\x18\x02 \x01(\t\x12\x14\n\x0cround_number\x18\x03 \x01(\x05\x12\x0e\n\x06report\x18\x04 \x01(\x08\x12\x0c\n\x04tags\x18\x05 \x03(\t\x12\x18\n\x10require_lossless\x18\x06 \x01(\x08\"\x83\x01\n\x1bGetAggregatedTensorResponse\x12\x30\n\x06header\x18\x01 \x01(\x0b\x32 .openfl.aggregator.MessageHeader\x12\x14\n\x0cround_number\x18\x02 \x01(\x05\x12\x1c\n\x06tensor\x18\x03 \x01(\x0b\x32\x0c.NamedTensor\"\x9a\x01\n\x0bTaskResults\x12\x30\n\x06header\x18\x01 \x01(\x0b\x32 .openfl.aggregator.MessageHeader\x12\x14\n\x0cround_number\x18\x02 \x01(\x05\x12\x11\n\ttask_name\x18\x03 \x01(\t\x12\x11\n\tdata_size\x18\x04 \x01(\x05\x12\x1d\n\x07tensors\x18\x05 \x03(\x0b\x32\x0c.NamedTensor\"P\n\x1cSendLocalTaskResultsResponse\x12\x30\n\x06header\x18\x01 \x01(\x0b\x32 .openfl.aggregator.MessageHeader\"1\n\x16GetMetricStreamRequest\x12\x17\n\x0f\x65xperiment_name\x18\x01 \x01(\t\"}\n\x17GetMetricStreamResponse\x12\x15\n\rmetric_origin\x18\x01 \x01(\t\x12\x11\n\ttask_name\x18\x02 \x01(\t\x12\x13\n\x0bmetric_name\x18\x03 \x01(\t\x12\x14\n\x0cmetric_value\x18\x04 \x01(\x02\x12\r\n\x05round\x18\x05 \x01(\r\"\xa7\x01\n\x16GetTrainedModelRequest\x12\x17\n\x0f\x65xperiment_name\x18\x02 \x01(\t\x12G\n\nmodel_type\x18\x03 \x01(\x0e\x32\x33.openfl.aggregator.GetTrainedModelRequest.ModelType\"+\n\tModelType\x12\x0e\n\nBEST_MODEL\x10\x00\x12\x0e\n\nLAST_MODEL\x10\x01\"8\n\x14TrainedModelResponse\x12 \n\x0bmodel_proto\x18\x01 \x01(\x0b\x32\x0b.ModelProto\"/\n\x1fGetExperimentDescriptionRequest\x12\x0c\n\x04name\x18\x01 \x01(\t\"N\n GetExperimentDescriptionResponse\x12*\n\nexperiment\x18\x01 \x01(\x0b\x32\x16.ExperimentDescription2\x94\x05\n\nAggregator\x12U\n\x08GetTasks\x12\".openfl.aggregator.GetTasksRequest\x1a#.openfl.aggregator.GetTasksResponse\"\x00\x12v\n\x13GetAggregatedTensor\x12-.openfl.aggregator.GetAggregatedTensorRequest\x1a..openfl.aggregator.GetAggregatedTensorResponse\"\x00\x12X\n\x14SendLocalTaskResults\x12\x0b.DataStream\x1a/.openfl.aggregator.SendLocalTaskResultsResponse\"\x00(\x01\x12l\n\x0fGetMetricStream\x12).openfl.aggregator.GetMetricStreamRequest\x1a*.openfl.aggregator.GetMetricStreamResponse\"\x00\x30\x01\x12g\n\x0fGetTrainedModel\x12).openfl.aggregator.GetTrainedModelRequest\x1a\'.openfl.aggregator.TrainedModelResponse\"\x00\x12\x85\x01\n\x18GetExperimentDescription\x12\x32.openfl.aggregator.GetExperimentDescriptionRequest\x1a\x33.openfl.aggregator.GetExperimentDescriptionResponse\"\x00\x62\x06proto3'
-   ,
-   dependencies=[openfl_dot_protocols_dot_base__pb2.DESCRIPTOR,])
- 
- 
- 
- _GETTRAINEDMODELREQUEST_MODELTYPE = _descriptor.EnumDescriptor(
-   name='ModelType',
-   full_name='openfl.aggregator.GetTrainedModelRequest.ModelType',
-   filename=None,
-   file=DESCRIPTOR,
-   create_key=_descriptor._internal_create_key,
-   values=[
-     _descriptor.EnumValueDescriptor(
-       name='BEST_MODEL', index=0, number=0,
-       serialized_options=None,
-       type=None,
-       create_key=_descriptor._internal_create_key),
-     _descriptor.EnumValueDescriptor(
-       name='LAST_MODEL', index=1, number=1,
-       serialized_options=None,
-       type=None,
-       create_key=_descriptor._internal_create_key),
-   ],
-   containing_type=None,
-   serialized_options=None,
-   serialized_start=1375,
-   serialized_end=1418,
- )
- _sym_db.RegisterEnumDescriptor(_GETTRAINEDMODELREQUEST_MODELTYPE)
- 
- 
- _MESSAGEHEADER = _descriptor.Descriptor(
-   name='MessageHeader',
-   full_name='openfl.aggregator.MessageHeader',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='sender', full_name='openfl.aggregator.MessageHeader.sender', index=0,
-       number=1, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='receiver', full_name='openfl.aggregator.MessageHeader.receiver', index=1,
-       number=2, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='federation_uuid', full_name='openfl.aggregator.MessageHeader.federation_uuid', index=2,
-       number=3, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='single_col_cert_common_name', full_name='openfl.aggregator.MessageHeader.single_col_cert_common_name', index=3,
-       number=4, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=85,
-   serialized_end=196,
- )
- 
- 
- _GETTASKSREQUEST = _descriptor.Descriptor(
-   name='GetTasksRequest',
-   full_name='openfl.aggregator.GetTasksRequest',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='header', full_name='openfl.aggregator.GetTasksRequest.header', index=0,
-       number=1, type=11, cpp_type=10, label=1,
-       has_default_value=False, default_value=None,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=198,
-   serialized_end=265,
- )
- 
- 
- _TASK = _descriptor.Descriptor(
-   name='Task',
-   full_name='openfl.aggregator.Task',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='name', full_name='openfl.aggregator.Task.name', index=0,
-       number=1, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='function_name', full_name='openfl.aggregator.Task.function_name', index=1,
-       number=2, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='task_type', full_name='openfl.aggregator.Task.task_type', index=2,
-       number=3, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='apply_local', full_name='openfl.aggregator.Task.apply_local', index=3,
-       number=4, type=8, cpp_type=7, label=1,
-       has_default_value=False, default_value=False,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=267,
-   serialized_end=350,
- )
- 
- 
- _GETTASKSRESPONSE = _descriptor.Descriptor(
-   name='GetTasksResponse',
-   full_name='openfl.aggregator.GetTasksResponse',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='header', full_name='openfl.aggregator.GetTasksResponse.header', index=0,
-       number=1, type=11, cpp_type=10, label=1,
-       has_default_value=False, default_value=None,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='round_number', full_name='openfl.aggregator.GetTasksResponse.round_number', index=1,
-       number=2, type=5, cpp_type=1, label=1,
-       has_default_value=False, default_value=0,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='tasks', full_name='openfl.aggregator.GetTasksResponse.tasks', index=2,
-       number=3, type=11, cpp_type=10, label=3,
-       has_default_value=False, default_value=[],
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='sleep_time', full_name='openfl.aggregator.GetTasksResponse.sleep_time', index=3,
-       number=4, type=5, cpp_type=1, label=1,
-       has_default_value=False, default_value=0,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='quit', full_name='openfl.aggregator.GetTasksResponse.quit', index=4,
-       number=5, type=8, cpp_type=7, label=1,
-       has_default_value=False, default_value=False,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=353,
-   serialized_end=517,
- )
- 
- 
- _GETAGGREGATEDTENSORREQUEST = _descriptor.Descriptor(
-   name='GetAggregatedTensorRequest',
-   full_name='openfl.aggregator.GetAggregatedTensorRequest',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='header', full_name='openfl.aggregator.GetAggregatedTensorRequest.header', index=0,
-       number=1, type=11, cpp_type=10, label=1,
-       has_default_value=False, default_value=None,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='tensor_name', full_name='openfl.aggregator.GetAggregatedTensorRequest.tensor_name', index=1,
-       number=2, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='round_number', full_name='openfl.aggregator.GetAggregatedTensorRequest.round_number', index=2,
-       number=3, type=5, cpp_type=1, label=1,
-       has_default_value=False, default_value=0,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='report', full_name='openfl.aggregator.GetAggregatedTensorRequest.report', index=3,
-       number=4, type=8, cpp_type=7, label=1,
-       has_default_value=False, default_value=False,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='tags', full_name='openfl.aggregator.GetAggregatedTensorRequest.tags', index=4,
-       number=5, type=9, cpp_type=9, label=3,
-       has_default_value=False, default_value=[],
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='require_lossless', full_name='openfl.aggregator.GetAggregatedTensorRequest.require_lossless', index=5,
-       number=6, type=8, cpp_type=7, label=1,
-       has_default_value=False, default_value=False,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=520,
-   serialized_end=697,
- )
- 
- 
- _GETAGGREGATEDTENSORRESPONSE = _descriptor.Descriptor(
-   name='GetAggregatedTensorResponse',
-   full_name='openfl.aggregator.GetAggregatedTensorResponse',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='header', full_name='openfl.aggregator.GetAggregatedTensorResponse.header', index=0,
-       number=1, type=11, cpp_type=10, label=1,
-       has_default_value=False, default_value=None,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='round_number', full_name='openfl.aggregator.GetAggregatedTensorResponse.round_number', index=1,
-       number=2, type=5, cpp_type=1, label=1,
-       has_default_value=False, default_value=0,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='tensor', full_name='openfl.aggregator.GetAggregatedTensorResponse.tensor', index=2,
-       number=3, type=11, cpp_type=10, label=1,
-       has_default_value=False, default_value=None,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=700,
-   serialized_end=831,
- )
- 
- 
- _TASKRESULTS = _descriptor.Descriptor(
-   name='TaskResults',
-   full_name='openfl.aggregator.TaskResults',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='header', full_name='openfl.aggregator.TaskResults.header', index=0,
-       number=1, type=11, cpp_type=10, label=1,
-       has_default_value=False, default_value=None,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='round_number', full_name='openfl.aggregator.TaskResults.round_number', index=1,
-       number=2, type=5, cpp_type=1, label=1,
-       has_default_value=False, default_value=0,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='task_name', full_name='openfl.aggregator.TaskResults.task_name', index=2,
-       number=3, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='data_size', full_name='openfl.aggregator.TaskResults.data_size', index=3,
-       number=4, type=5, cpp_type=1, label=1,
-       has_default_value=False, default_value=0,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='tensors', full_name='openfl.aggregator.TaskResults.tensors', index=4,
-       number=5, type=11, cpp_type=10, label=3,
-       has_default_value=False, default_value=[],
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=834,
-   serialized_end=988,
- )
- 
- 
- _SENDLOCALTASKRESULTSRESPONSE = _descriptor.Descriptor(
-   name='SendLocalTaskResultsResponse',
-   full_name='openfl.aggregator.SendLocalTaskResultsResponse',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='header', full_name='openfl.aggregator.SendLocalTaskResultsResponse.header', index=0,
-       number=1, type=11, cpp_type=10, label=1,
-       has_default_value=False, default_value=None,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=990,
-   serialized_end=1070,
- )
- 
- 
- _GETMETRICSTREAMREQUEST = _descriptor.Descriptor(
-   name='GetMetricStreamRequest',
-   full_name='openfl.aggregator.GetMetricStreamRequest',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='experiment_name', full_name='openfl.aggregator.GetMetricStreamRequest.experiment_name', index=0,
-       number=1, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=1072,
-   serialized_end=1121,
- )
- 
- 
- _GETMETRICSTREAMRESPONSE = _descriptor.Descriptor(
-   name='GetMetricStreamResponse',
-   full_name='openfl.aggregator.GetMetricStreamResponse',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='metric_origin', full_name='openfl.aggregator.GetMetricStreamResponse.metric_origin', index=0,
-       number=1, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='task_name', full_name='openfl.aggregator.GetMetricStreamResponse.task_name', index=1,
-       number=2, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='metric_name', full_name='openfl.aggregator.GetMetricStreamResponse.metric_name', index=2,
-       number=3, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='metric_value', full_name='openfl.aggregator.GetMetricStreamResponse.metric_value', index=3,
-       number=4, type=2, cpp_type=6, label=1,
-       has_default_value=False, default_value=float(0),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='round', full_name='openfl.aggregator.GetMetricStreamResponse.round', index=4,
-       number=5, type=13, cpp_type=3, label=1,
-       has_default_value=False, default_value=0,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=1123,
-   serialized_end=1248,
- )
- 
- 
- _GETTRAINEDMODELREQUEST = _descriptor.Descriptor(
-   name='GetTrainedModelRequest',
-   full_name='openfl.aggregator.GetTrainedModelRequest',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='experiment_name', full_name='openfl.aggregator.GetTrainedModelRequest.experiment_name', index=0,
-       number=2, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='model_type', full_name='openfl.aggregator.GetTrainedModelRequest.model_type', index=1,
-       number=3, type=14, cpp_type=8, label=1,
-       has_default_value=False, default_value=0,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-     _GETTRAINEDMODELREQUEST_MODELTYPE,
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=1251,
-   serialized_end=1418,
- )
- 
- 
- _TRAINEDMODELRESPONSE = _descriptor.Descriptor(
-   name='TrainedModelResponse',
-   full_name='openfl.aggregator.TrainedModelResponse',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='model_proto', full_name='openfl.aggregator.TrainedModelResponse.model_proto', index=0,
-       number=1, type=11, cpp_type=10, label=1,
-       has_default_value=False, default_value=None,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=1420,
-   serialized_end=1476,
- )
- 
- 
- _GETEXPERIMENTDESCRIPTIONREQUEST = _descriptor.Descriptor(
-   name='GetExperimentDescriptionRequest',
-   full_name='openfl.aggregator.GetExperimentDescriptionRequest',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='name', full_name='openfl.aggregator.GetExperimentDescriptionRequest.name', index=0,
-       number=1, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=1478,
-   serialized_end=1525,
- )
- 
- 
- _GETEXPERIMENTDESCRIPTIONRESPONSE = _descriptor.Descriptor(
-   name='GetExperimentDescriptionResponse',
-   full_name='openfl.aggregator.GetExperimentDescriptionResponse',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='experiment', full_name='openfl.aggregator.GetExperimentDescriptionResponse.experiment', index=0,
-       number=1, type=11, cpp_type=10, label=1,
-       has_default_value=False, default_value=None,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=1527,
-   serialized_end=1605,
- )
- 
- _GETTASKSREQUEST.fields_by_name['header'].message_type = _MESSAGEHEADER
- _GETTASKSRESPONSE.fields_by_name['header'].message_type = _MESSAGEHEADER
- _GETTASKSRESPONSE.fields_by_name['tasks'].message_type = _TASK
- _GETAGGREGATEDTENSORREQUEST.fields_by_name['header'].message_type = _MESSAGEHEADER
- _GETAGGREGATEDTENSORRESPONSE.fields_by_name['header'].message_type = _MESSAGEHEADER
- _GETAGGREGATEDTENSORRESPONSE.fields_by_name['tensor'].message_type = openfl_dot_protocols_dot_base__pb2._NAMEDTENSOR
- _TASKRESULTS.fields_by_name['header'].message_type = _MESSAGEHEADER
- _TASKRESULTS.fields_by_name['tensors'].message_type = openfl_dot_protocols_dot_base__pb2._NAMEDTENSOR
- _SENDLOCALTASKRESULTSRESPONSE.fields_by_name['header'].message_type = _MESSAGEHEADER
- _GETTRAINEDMODELREQUEST.fields_by_name['model_type'].enum_type = _GETTRAINEDMODELREQUEST_MODELTYPE
- _GETTRAINEDMODELREQUEST_MODELTYPE.containing_type = _GETTRAINEDMODELREQUEST
- _TRAINEDMODELRESPONSE.fields_by_name['model_proto'].message_type = openfl_dot_protocols_dot_base__pb2._MODELPROTO
- _GETEXPERIMENTDESCRIPTIONRESPONSE.fields_by_name['experiment'].message_type = openfl_dot_protocols_dot_base__pb2._EXPERIMENTDESCRIPTION
- DESCRIPTOR.message_types_by_name['MessageHeader'] = _MESSAGEHEADER
- DESCRIPTOR.message_types_by_name['GetTasksRequest'] = _GETTASKSREQUEST
- DESCRIPTOR.message_types_by_name['Task'] = _TASK
- DESCRIPTOR.message_types_by_name['GetTasksResponse'] = _GETTASKSRESPONSE
- DESCRIPTOR.message_types_by_name['GetAggregatedTensorRequest'] = _GETAGGREGATEDTENSORREQUEST
- DESCRIPTOR.message_types_by_name['GetAggregatedTensorResponse'] = _GETAGGREGATEDTENSORRESPONSE
- DESCRIPTOR.message_types_by_name['TaskResults'] = _TASKRESULTS
- DESCRIPTOR.message_types_by_name['SendLocalTaskResultsResponse'] = _SENDLOCALTASKRESULTSRESPONSE
- DESCRIPTOR.message_types_by_name['GetMetricStreamRequest'] = _GETMETRICSTREAMREQUEST
- DESCRIPTOR.message_types_by_name['GetMetricStreamResponse'] = _GETMETRICSTREAMRESPONSE
- DESCRIPTOR.message_types_by_name['GetTrainedModelRequest'] = _GETTRAINEDMODELREQUEST
- DESCRIPTOR.message_types_by_name['TrainedModelResponse'] = _TRAINEDMODELRESPONSE
- DESCRIPTOR.message_types_by_name['GetExperimentDescriptionRequest'] = _GETEXPERIMENTDESCRIPTIONREQUEST
- DESCRIPTOR.message_types_by_name['GetExperimentDescriptionResponse'] = _GETEXPERIMENTDESCRIPTIONRESPONSE
- _sym_db.RegisterFileDescriptor(DESCRIPTOR)
- 
- MessageHeader = _reflection.GeneratedProtocolMessageType('MessageHeader', (_message.Message,), {
-   'DESCRIPTOR' : _MESSAGEHEADER,
-   '__module__' : 'openfl.protocols.aggregator_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.aggregator.MessageHeader)
-   })
- _sym_db.RegisterMessage(MessageHeader)
- 
- GetTasksRequest = _reflection.GeneratedProtocolMessageType('GetTasksRequest', (_message.Message,), {
-   'DESCRIPTOR' : _GETTASKSREQUEST,
-   '__module__' : 'openfl.protocols.aggregator_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.aggregator.GetTasksRequest)
-   })
- _sym_db.RegisterMessage(GetTasksRequest)
- 
- Task = _reflection.GeneratedProtocolMessageType('Task', (_message.Message,), {
-   'DESCRIPTOR' : _TASK,
-   '__module__' : 'openfl.protocols.aggregator_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.aggregator.Task)
-   })
- _sym_db.RegisterMessage(Task)
- 
- GetTasksResponse = _reflection.GeneratedProtocolMessageType('GetTasksResponse', (_message.Message,), {
-   'DESCRIPTOR' : _GETTASKSRESPONSE,
-   '__module__' : 'openfl.protocols.aggregator_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.aggregator.GetTasksResponse)
-   })
- _sym_db.RegisterMessage(GetTasksResponse)
- 
- GetAggregatedTensorRequest = _reflection.GeneratedProtocolMessageType('GetAggregatedTensorRequest', (_message.Message,), {
-   'DESCRIPTOR' : _GETAGGREGATEDTENSORREQUEST,
-   '__module__' : 'openfl.protocols.aggregator_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.aggregator.GetAggregatedTensorRequest)
-   })
- _sym_db.RegisterMessage(GetAggregatedTensorRequest)
- 
- GetAggregatedTensorResponse = _reflection.GeneratedProtocolMessageType('GetAggregatedTensorResponse', (_message.Message,), {
-   'DESCRIPTOR' : _GETAGGREGATEDTENSORRESPONSE,
-   '__module__' : 'openfl.protocols.aggregator_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.aggregator.GetAggregatedTensorResponse)
-   })
- _sym_db.RegisterMessage(GetAggregatedTensorResponse)
- 
- TaskResults = _reflection.GeneratedProtocolMessageType('TaskResults', (_message.Message,), {
-   'DESCRIPTOR' : _TASKRESULTS,
-   '__module__' : 'openfl.protocols.aggregator_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.aggregator.TaskResults)
-   })
- _sym_db.RegisterMessage(TaskResults)
- 
- SendLocalTaskResultsResponse = _reflection.GeneratedProtocolMessageType('SendLocalTaskResultsResponse', (_message.Message,), {
-   'DESCRIPTOR' : _SENDLOCALTASKRESULTSRESPONSE,
-   '__module__' : 'openfl.protocols.aggregator_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.aggregator.SendLocalTaskResultsResponse)
-   })
- _sym_db.RegisterMessage(SendLocalTaskResultsResponse)
- 
- GetMetricStreamRequest = _reflection.GeneratedProtocolMessageType('GetMetricStreamRequest', (_message.Message,), {
-   'DESCRIPTOR' : _GETMETRICSTREAMREQUEST,
-   '__module__' : 'openfl.protocols.aggregator_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.aggregator.GetMetricStreamRequest)
-   })
- _sym_db.RegisterMessage(GetMetricStreamRequest)
- 
- GetMetricStreamResponse = _reflection.GeneratedProtocolMessageType('GetMetricStreamResponse', (_message.Message,), {
-   'DESCRIPTOR' : _GETMETRICSTREAMRESPONSE,
-   '__module__' : 'openfl.protocols.aggregator_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.aggregator.GetMetricStreamResponse)
-   })
- _sym_db.RegisterMessage(GetMetricStreamResponse)
- 
- GetTrainedModelRequest = _reflection.GeneratedProtocolMessageType('GetTrainedModelRequest', (_message.Message,), {
-   'DESCRIPTOR' : _GETTRAINEDMODELREQUEST,
-   '__module__' : 'openfl.protocols.aggregator_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.aggregator.GetTrainedModelRequest)
-   })
- _sym_db.RegisterMessage(GetTrainedModelRequest)
- 
- TrainedModelResponse = _reflection.GeneratedProtocolMessageType('TrainedModelResponse', (_message.Message,), {
-   'DESCRIPTOR' : _TRAINEDMODELRESPONSE,
-   '__module__' : 'openfl.protocols.aggregator_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.aggregator.TrainedModelResponse)
-   })
- _sym_db.RegisterMessage(TrainedModelResponse)
- 
- GetExperimentDescriptionRequest = _reflection.GeneratedProtocolMessageType('GetExperimentDescriptionRequest', (_message.Message,), {
-   'DESCRIPTOR' : _GETEXPERIMENTDESCRIPTIONREQUEST,
-   '__module__' : 'openfl.protocols.aggregator_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.aggregator.GetExperimentDescriptionRequest)
-   })
- _sym_db.RegisterMessage(GetExperimentDescriptionRequest)
- 
- GetExperimentDescriptionResponse = _reflection.GeneratedProtocolMessageType('GetExperimentDescriptionResponse', (_message.Message,), {
-   'DESCRIPTOR' : _GETEXPERIMENTDESCRIPTIONRESPONSE,
-   '__module__' : 'openfl.protocols.aggregator_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.aggregator.GetExperimentDescriptionResponse)
-   })
- _sym_db.RegisterMessage(GetExperimentDescriptionResponse)
- 
- 
- 
- _AGGREGATOR = _descriptor.ServiceDescriptor(
-   name='Aggregator',
-   full_name='openfl.aggregator.Aggregator',
-   file=DESCRIPTOR,
-   index=0,
-   serialized_options=None,
-   create_key=_descriptor._internal_create_key,
-   serialized_start=1608,
-   serialized_end=2268,
-   methods=[
-   _descriptor.MethodDescriptor(
-     name='GetTasks',
-     full_name='openfl.aggregator.Aggregator.GetTasks',
-     index=0,
-     containing_service=None,
-     input_type=_GETTASKSREQUEST,
-     output_type=_GETTASKSRESPONSE,
-     serialized_options=None,
-     create_key=_descriptor._internal_create_key,
-   ),
-   _descriptor.MethodDescriptor(
-     name='GetAggregatedTensor',
-     full_name='openfl.aggregator.Aggregator.GetAggregatedTensor',
-     index=1,
-     containing_service=None,
-     input_type=_GETAGGREGATEDTENSORREQUEST,
-     output_type=_GETAGGREGATEDTENSORRESPONSE,
-     serialized_options=None,
-     create_key=_descriptor._internal_create_key,
-   ),
-   _descriptor.MethodDescriptor(
-     name='SendLocalTaskResults',
-     full_name='openfl.aggregator.Aggregator.SendLocalTaskResults',
-     index=2,
-     containing_service=None,
-     input_type=openfl_dot_protocols_dot_base__pb2._DATASTREAM,
-     output_type=_SENDLOCALTASKRESULTSRESPONSE,
-     serialized_options=None,
-     create_key=_descriptor._internal_create_key,
-   ),
-   _descriptor.MethodDescriptor(
-     name='GetMetricStream',
-     full_name='openfl.aggregator.Aggregator.GetMetricStream',
-     index=3,
-     containing_service=None,
-     input_type=_GETMETRICSTREAMREQUEST,
-     output_type=_GETMETRICSTREAMRESPONSE,
-     serialized_options=None,
-     create_key=_descriptor._internal_create_key,
-   ),
-   _descriptor.MethodDescriptor(
-     name='GetTrainedModel',
-     full_name='openfl.aggregator.Aggregator.GetTrainedModel',
-     index=4,
-     containing_service=None,
-     input_type=_GETTRAINEDMODELREQUEST,
-     output_type=_TRAINEDMODELRESPONSE,
-     serialized_options=None,
-     create_key=_descriptor._internal_create_key,
-   ),
-   _descriptor.MethodDescriptor(
-     name='GetExperimentDescription',
-     full_name='openfl.aggregator.Aggregator.GetExperimentDescription',
-     index=5,
-     containing_service=None,
-     input_type=_GETEXPERIMENTDESCRIPTIONREQUEST,
-     output_type=_GETEXPERIMENTDESCRIPTIONRESPONSE,
-     serialized_options=None,
-     create_key=_descriptor._internal_create_key,
-   ),
- ])
- _sym_db.RegisterServiceDescriptor(_AGGREGATOR)
- 
- DESCRIPTOR.services_by_name['Aggregator'] = _AGGREGATOR
- 
- # @@protoc_insertion_point(module_scope)
--- 0 ----
diff -crB --new-file ./openfl/openfl/protocols/aggregator.proto ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols/aggregator.proto
*** ./openfl/openfl/protocols/aggregator.proto	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols/aggregator.proto	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,114 ****
- // Copyright (C) 2020-2021 Intel Corporation
- // Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- syntax = "proto3";
- 
- package openfl.aggregator;
- 
- import "openfl/protocols/base.proto";
- 
- 
- service Aggregator {
-   rpc GetTasks(GetTasksRequest) returns (GetTasksResponse) {}
-   rpc GetAggregatedTensor(GetAggregatedTensorRequest) returns (GetAggregatedTensorResponse) {}
-   rpc SendLocalTaskResults(stream DataStream) returns (SendLocalTaskResultsResponse) {}
-   rpc GetMetricStream(GetMetricStreamRequest) returns (stream GetMetricStreamResponse) {}
-   rpc GetTrainedModel(GetTrainedModelRequest) returns (TrainedModelResponse) {}
-   rpc GetExperimentDescription(GetExperimentDescriptionRequest)
-     returns (GetExperimentDescriptionResponse) {}
- }
- 
- message MessageHeader {
-   string sender = 1;
-   string receiver = 2;
-   string federation_uuid = 3;
-   string single_col_cert_common_name = 4;
- }
- 
- message GetTasksRequest {
-   MessageHeader header = 1;
- }
- 
- message Task {
-   string name = 1;
-   string function_name = 2;
-   string task_type = 3;
-   bool apply_local = 4;
- }
- 
- message GetTasksResponse {
-   MessageHeader header = 1;
-   int32 round_number = 2;
-   // these next three are exclusive. Oneof is probably a good idea
-   repeated Task tasks = 3;  // these three are exclusive
-   int32 sleep_time = 4;  // these three are exclusive
-   bool quit = 5;  // these three are exclusive
- }
- 
- message GetAggregatedTensorRequest {
-   MessageHeader header = 1;
-   string tensor_name = 2;
-   int32 round_number = 3;
-   bool report = 4;
-   repeated string	tags = 5;
-   bool require_lossless = 6;
- }
- 
- // we'll actually send this as a data stream
- message GetAggregatedTensorResponse {
-   MessageHeader header = 1;
-   int32 round_number = 2;
-   NamedTensor tensor = 3;
- }
- 
- // we'll actually send this as a data stream
- message TaskResults {
-   MessageHeader  header = 1;
-   int32 round_number = 2;
-   string task_name = 3;
-   int32	data_size = 4;
-   repeated NamedTensor tensors = 5;
- }
- 
- message SendLocalTaskResultsResponse {
-   MessageHeader header = 1;
- }
- 
- // The same with director.proto
- message GetMetricStreamRequest {
-   string experiment_name = 1;
- }
- 
- // The same with director.proto
- message GetMetricStreamResponse {
-   string metric_origin = 1;
-   string task_name = 2;
-   string metric_name = 3;
-   float metric_value = 4;
-   uint32 round = 5;
- }
- 
- // The same with director.proto
- message GetTrainedModelRequest {
-   enum ModelType {
-     BEST_MODEL = 0;
-     LAST_MODEL = 1;
-   }
-   string experiment_name = 2;
-   ModelType model_type = 3;
- }
- 
- // The same with director.proto
- message TrainedModelResponse {
-   ModelProto model_proto = 1;
- }
- 
- // The same with director.proto
- message GetExperimentDescriptionRequest {
-   string name = 1;
- }
- 
- // The same with director.proto
- message GetExperimentDescriptionResponse {
-   ExperimentDescription experiment = 1;
- }
--- 0 ----
diff -crB --new-file ./openfl/openfl/protocols/base_pb2.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols/base_pb2.py
*** ./openfl/openfl/protocols/base_pb2.py	2022-11-18 11:08:33.047181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols/base_pb2.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,614 ****
- # -*- coding: utf-8 -*-
- # Generated by the protocol buffer compiler.  DO NOT EDIT!
- # source: openfl/protocols/base.proto
- """Generated protocol buffer code."""
- from google.protobuf import descriptor as _descriptor
- from google.protobuf import message as _message
- from google.protobuf import reflection as _reflection
- from google.protobuf import symbol_database as _symbol_database
- # @@protoc_insertion_point(imports)
- 
- _sym_db = _symbol_database.Default()
- 
- 
- 
- 
- DESCRIPTOR = _descriptor.FileDescriptor(
-   name='openfl/protocols/base.proto',
-   package='',
-   syntax='proto3',
-   serialized_options=None,
-   create_key=_descriptor._internal_create_key,
-   serialized_pb=b'\n\x1bopenfl/protocols/base.proto\"+\n\nModelProto\x12\x1d\n\x07tensors\x18\x01 \x03(\x0b\x32\x0c.NamedTensor\"\xa3\x01\n\x0bNamedTensor\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x14\n\x0cround_number\x18\x02 \x01(\x05\x12\x10\n\x08lossless\x18\x03 \x01(\x08\x12\x0e\n\x06report\x18\x04 \x01(\x08\x12\x0c\n\x04tags\x18\x05 \x03(\t\x12,\n\x14transformer_metadata\x18\x06 \x03(\x0b\x32\x0e.MetadataProto\x12\x12\n\ndata_bytes\x18\x07 \x01(\x0c\"\x9d\x01\n\rMetadataProto\x12\x34\n\x0cint_to_float\x18\x01 \x03(\x0b\x32\x1e.MetadataProto.IntToFloatEntry\x12\x10\n\x08int_list\x18\x02 \x03(\x05\x12\x11\n\tbool_list\x18\x03 \x03(\x08\x1a\x31\n\x0fIntToFloatEntry\x12\x0b\n\x03key\x18\x01 \x01(\x05\x12\r\n\x05value\x18\x02 \x01(\x02:\x02\x38\x01\"+\n\nDataStream\x12\x0c\n\x04size\x18\x01 \x01(\r\x12\x0f\n\x07npbytes\x18\x02 \x01(\x0c\"\x81\x01\n\x17\x43ollaboratorDescription\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0e\n\x06status\x18\x02 \x01(\t\x12\x10\n\x08progress\x18\x03 \x01(\x02\x12\r\n\x05round\x18\x04 \x01(\r\x12\x14\n\x0c\x63urrent_task\x18\x05 \x01(\t\x12\x11\n\tnext_task\x18\x06 \x01(\t\"4\n\x0fTaskDescription\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x13\n\x0b\x64\x65scription\x18\x02 \x01(\t\".\n\x0e\x44ownloadStatus\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0e\n\x06status\x18\x02 \x01(\t\"R\n\x10\x44ownloadStatuses\x12\x1f\n\x06models\x18\x01 \x03(\x0b\x32\x0f.DownloadStatus\x12\x1d\n\x04logs\x18\x02 \x03(\x0b\x32\x0f.DownloadStatus\"\xf4\x01\n\x15\x45xperimentDescription\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0e\n\x06status\x18\x02 \x01(\t\x12\x10\n\x08progress\x18\x03 \x01(\x02\x12\x14\n\x0ctotal_rounds\x18\x04 \x01(\r\x12\x15\n\rcurrent_round\x18\x05 \x01(\r\x12,\n\x11\x64ownload_statuses\x18\x06 \x01(\x0b\x32\x11.DownloadStatuses\x12/\n\rcollaborators\x18\x07 \x03(\x0b\x32\x18.CollaboratorDescription\x12\x1f\n\x05tasks\x18\x08 \x03(\x0b\x32\x10.TaskDescriptionb\x06proto3'
- )
- 
- 
- 
- 
- _MODELPROTO = _descriptor.Descriptor(
-   name='ModelProto',
-   full_name='ModelProto',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='tensors', full_name='ModelProto.tensors', index=0,
-       number=1, type=11, cpp_type=10, label=3,
-       has_default_value=False, default_value=[],
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=31,
-   serialized_end=74,
- )
- 
- 
- _NAMEDTENSOR = _descriptor.Descriptor(
-   name='NamedTensor',
-   full_name='NamedTensor',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='name', full_name='NamedTensor.name', index=0,
-       number=1, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='round_number', full_name='NamedTensor.round_number', index=1,
-       number=2, type=5, cpp_type=1, label=1,
-       has_default_value=False, default_value=0,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='lossless', full_name='NamedTensor.lossless', index=2,
-       number=3, type=8, cpp_type=7, label=1,
-       has_default_value=False, default_value=False,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='report', full_name='NamedTensor.report', index=3,
-       number=4, type=8, cpp_type=7, label=1,
-       has_default_value=False, default_value=False,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='tags', full_name='NamedTensor.tags', index=4,
-       number=5, type=9, cpp_type=9, label=3,
-       has_default_value=False, default_value=[],
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='transformer_metadata', full_name='NamedTensor.transformer_metadata', index=5,
-       number=6, type=11, cpp_type=10, label=3,
-       has_default_value=False, default_value=[],
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='data_bytes', full_name='NamedTensor.data_bytes', index=6,
-       number=7, type=12, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"",
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=77,
-   serialized_end=240,
- )
- 
- 
- _METADATAPROTO_INTTOFLOATENTRY = _descriptor.Descriptor(
-   name='IntToFloatEntry',
-   full_name='MetadataProto.IntToFloatEntry',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='key', full_name='MetadataProto.IntToFloatEntry.key', index=0,
-       number=1, type=5, cpp_type=1, label=1,
-       has_default_value=False, default_value=0,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='value', full_name='MetadataProto.IntToFloatEntry.value', index=1,
-       number=2, type=2, cpp_type=6, label=1,
-       has_default_value=False, default_value=float(0),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=b'8\001',
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=351,
-   serialized_end=400,
- )
- 
- _METADATAPROTO = _descriptor.Descriptor(
-   name='MetadataProto',
-   full_name='MetadataProto',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='int_to_float', full_name='MetadataProto.int_to_float', index=0,
-       number=1, type=11, cpp_type=10, label=3,
-       has_default_value=False, default_value=[],
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='int_list', full_name='MetadataProto.int_list', index=1,
-       number=2, type=5, cpp_type=1, label=3,
-       has_default_value=False, default_value=[],
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='bool_list', full_name='MetadataProto.bool_list', index=2,
-       number=3, type=8, cpp_type=7, label=3,
-       has_default_value=False, default_value=[],
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[_METADATAPROTO_INTTOFLOATENTRY, ],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=243,
-   serialized_end=400,
- )
- 
- 
- _DATASTREAM = _descriptor.Descriptor(
-   name='DataStream',
-   full_name='DataStream',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='size', full_name='DataStream.size', index=0,
-       number=1, type=13, cpp_type=3, label=1,
-       has_default_value=False, default_value=0,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='npbytes', full_name='DataStream.npbytes', index=1,
-       number=2, type=12, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"",
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=402,
-   serialized_end=445,
- )
- 
- 
- _COLLABORATORDESCRIPTION = _descriptor.Descriptor(
-   name='CollaboratorDescription',
-   full_name='CollaboratorDescription',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='name', full_name='CollaboratorDescription.name', index=0,
-       number=1, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='status', full_name='CollaboratorDescription.status', index=1,
-       number=2, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='progress', full_name='CollaboratorDescription.progress', index=2,
-       number=3, type=2, cpp_type=6, label=1,
-       has_default_value=False, default_value=float(0),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='round', full_name='CollaboratorDescription.round', index=3,
-       number=4, type=13, cpp_type=3, label=1,
-       has_default_value=False, default_value=0,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='current_task', full_name='CollaboratorDescription.current_task', index=4,
-       number=5, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='next_task', full_name='CollaboratorDescription.next_task', index=5,
-       number=6, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=448,
-   serialized_end=577,
- )
- 
- 
- _TASKDESCRIPTION = _descriptor.Descriptor(
-   name='TaskDescription',
-   full_name='TaskDescription',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='name', full_name='TaskDescription.name', index=0,
-       number=1, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='description', full_name='TaskDescription.description', index=1,
-       number=2, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=579,
-   serialized_end=631,
- )
- 
- 
- _DOWNLOADSTATUS = _descriptor.Descriptor(
-   name='DownloadStatus',
-   full_name='DownloadStatus',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='name', full_name='DownloadStatus.name', index=0,
-       number=1, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='status', full_name='DownloadStatus.status', index=1,
-       number=2, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=633,
-   serialized_end=679,
- )
- 
- 
- _DOWNLOADSTATUSES = _descriptor.Descriptor(
-   name='DownloadStatuses',
-   full_name='DownloadStatuses',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='models', full_name='DownloadStatuses.models', index=0,
-       number=1, type=11, cpp_type=10, label=3,
-       has_default_value=False, default_value=[],
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='logs', full_name='DownloadStatuses.logs', index=1,
-       number=2, type=11, cpp_type=10, label=3,
-       has_default_value=False, default_value=[],
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=681,
-   serialized_end=763,
- )
- 
- 
- _EXPERIMENTDESCRIPTION = _descriptor.Descriptor(
-   name='ExperimentDescription',
-   full_name='ExperimentDescription',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='name', full_name='ExperimentDescription.name', index=0,
-       number=1, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='status', full_name='ExperimentDescription.status', index=1,
-       number=2, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='progress', full_name='ExperimentDescription.progress', index=2,
-       number=3, type=2, cpp_type=6, label=1,
-       has_default_value=False, default_value=float(0),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='total_rounds', full_name='ExperimentDescription.total_rounds', index=3,
-       number=4, type=13, cpp_type=3, label=1,
-       has_default_value=False, default_value=0,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='current_round', full_name='ExperimentDescription.current_round', index=4,
-       number=5, type=13, cpp_type=3, label=1,
-       has_default_value=False, default_value=0,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='download_statuses', full_name='ExperimentDescription.download_statuses', index=5,
-       number=6, type=11, cpp_type=10, label=1,
-       has_default_value=False, default_value=None,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='collaborators', full_name='ExperimentDescription.collaborators', index=6,
-       number=7, type=11, cpp_type=10, label=3,
-       has_default_value=False, default_value=[],
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='tasks', full_name='ExperimentDescription.tasks', index=7,
-       number=8, type=11, cpp_type=10, label=3,
-       has_default_value=False, default_value=[],
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=766,
-   serialized_end=1010,
- )
- 
- _MODELPROTO.fields_by_name['tensors'].message_type = _NAMEDTENSOR
- _NAMEDTENSOR.fields_by_name['transformer_metadata'].message_type = _METADATAPROTO
- _METADATAPROTO_INTTOFLOATENTRY.containing_type = _METADATAPROTO
- _METADATAPROTO.fields_by_name['int_to_float'].message_type = _METADATAPROTO_INTTOFLOATENTRY
- _DOWNLOADSTATUSES.fields_by_name['models'].message_type = _DOWNLOADSTATUS
- _DOWNLOADSTATUSES.fields_by_name['logs'].message_type = _DOWNLOADSTATUS
- _EXPERIMENTDESCRIPTION.fields_by_name['download_statuses'].message_type = _DOWNLOADSTATUSES
- _EXPERIMENTDESCRIPTION.fields_by_name['collaborators'].message_type = _COLLABORATORDESCRIPTION
- _EXPERIMENTDESCRIPTION.fields_by_name['tasks'].message_type = _TASKDESCRIPTION
- DESCRIPTOR.message_types_by_name['ModelProto'] = _MODELPROTO
- DESCRIPTOR.message_types_by_name['NamedTensor'] = _NAMEDTENSOR
- DESCRIPTOR.message_types_by_name['MetadataProto'] = _METADATAPROTO
- DESCRIPTOR.message_types_by_name['DataStream'] = _DATASTREAM
- DESCRIPTOR.message_types_by_name['CollaboratorDescription'] = _COLLABORATORDESCRIPTION
- DESCRIPTOR.message_types_by_name['TaskDescription'] = _TASKDESCRIPTION
- DESCRIPTOR.message_types_by_name['DownloadStatus'] = _DOWNLOADSTATUS
- DESCRIPTOR.message_types_by_name['DownloadStatuses'] = _DOWNLOADSTATUSES
- DESCRIPTOR.message_types_by_name['ExperimentDescription'] = _EXPERIMENTDESCRIPTION
- _sym_db.RegisterFileDescriptor(DESCRIPTOR)
- 
- ModelProto = _reflection.GeneratedProtocolMessageType('ModelProto', (_message.Message,), {
-   'DESCRIPTOR' : _MODELPROTO,
-   '__module__' : 'openfl.protocols.base_pb2'
-   # @@protoc_insertion_point(class_scope:ModelProto)
-   })
- _sym_db.RegisterMessage(ModelProto)
- 
- NamedTensor = _reflection.GeneratedProtocolMessageType('NamedTensor', (_message.Message,), {
-   'DESCRIPTOR' : _NAMEDTENSOR,
-   '__module__' : 'openfl.protocols.base_pb2'
-   # @@protoc_insertion_point(class_scope:NamedTensor)
-   })
- _sym_db.RegisterMessage(NamedTensor)
- 
- MetadataProto = _reflection.GeneratedProtocolMessageType('MetadataProto', (_message.Message,), {
- 
-   'IntToFloatEntry' : _reflection.GeneratedProtocolMessageType('IntToFloatEntry', (_message.Message,), {
-     'DESCRIPTOR' : _METADATAPROTO_INTTOFLOATENTRY,
-     '__module__' : 'openfl.protocols.base_pb2'
-     # @@protoc_insertion_point(class_scope:MetadataProto.IntToFloatEntry)
-     })
-   ,
-   'DESCRIPTOR' : _METADATAPROTO,
-   '__module__' : 'openfl.protocols.base_pb2'
-   # @@protoc_insertion_point(class_scope:MetadataProto)
-   })
- _sym_db.RegisterMessage(MetadataProto)
- _sym_db.RegisterMessage(MetadataProto.IntToFloatEntry)
- 
- DataStream = _reflection.GeneratedProtocolMessageType('DataStream', (_message.Message,), {
-   'DESCRIPTOR' : _DATASTREAM,
-   '__module__' : 'openfl.protocols.base_pb2'
-   # @@protoc_insertion_point(class_scope:DataStream)
-   })
- _sym_db.RegisterMessage(DataStream)
- 
- CollaboratorDescription = _reflection.GeneratedProtocolMessageType('CollaboratorDescription', (_message.Message,), {
-   'DESCRIPTOR' : _COLLABORATORDESCRIPTION,
-   '__module__' : 'openfl.protocols.base_pb2'
-   # @@protoc_insertion_point(class_scope:CollaboratorDescription)
-   })
- _sym_db.RegisterMessage(CollaboratorDescription)
- 
- TaskDescription = _reflection.GeneratedProtocolMessageType('TaskDescription', (_message.Message,), {
-   'DESCRIPTOR' : _TASKDESCRIPTION,
-   '__module__' : 'openfl.protocols.base_pb2'
-   # @@protoc_insertion_point(class_scope:TaskDescription)
-   })
- _sym_db.RegisterMessage(TaskDescription)
- 
- DownloadStatus = _reflection.GeneratedProtocolMessageType('DownloadStatus', (_message.Message,), {
-   'DESCRIPTOR' : _DOWNLOADSTATUS,
-   '__module__' : 'openfl.protocols.base_pb2'
-   # @@protoc_insertion_point(class_scope:DownloadStatus)
-   })
- _sym_db.RegisterMessage(DownloadStatus)
- 
- DownloadStatuses = _reflection.GeneratedProtocolMessageType('DownloadStatuses', (_message.Message,), {
-   'DESCRIPTOR' : _DOWNLOADSTATUSES,
-   '__module__' : 'openfl.protocols.base_pb2'
-   # @@protoc_insertion_point(class_scope:DownloadStatuses)
-   })
- _sym_db.RegisterMessage(DownloadStatuses)
- 
- ExperimentDescription = _reflection.GeneratedProtocolMessageType('ExperimentDescription', (_message.Message,), {
-   'DESCRIPTOR' : _EXPERIMENTDESCRIPTION,
-   '__module__' : 'openfl.protocols.base_pb2'
-   # @@protoc_insertion_point(class_scope:ExperimentDescription)
-   })
- _sym_db.RegisterMessage(ExperimentDescription)
- 
- 
- _METADATAPROTO_INTTOFLOATENTRY._options = None
- # @@protoc_insertion_point(module_scope)
--- 0 ----
diff -crB --new-file ./openfl/openfl/protocols/base.proto ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols/base.proto
*** ./openfl/openfl/protocols/base.proto	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols/base.proto	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,67 ****
- // Copyright (C) 2020-2021 Intel Corporation
- // Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- syntax = "proto3";
- 
- // This is only needed to initializing the model weights on the aggregator
- message ModelProto {
-   repeated NamedTensor tensors = 1;
- }
- 
- message NamedTensor {
-   string name = 1;
-   int32 round_number = 2;
-   bool lossless	= 3;
-   bool report = 4;
-   repeated string tags = 5;
-   repeated MetadataProto transformer_metadata = 6;
-   bytes data_bytes = 7;
- }
- 
- message MetadataProto {
-   map<int32, float> int_to_float = 1;
-   repeated int32 int_list = 2;
-   repeated bool bool_list = 3;
- }
- 
- // handles large size data
- message DataStream {
-   uint32 size = 1; // size, in bytes, of the data sent in npbytes
-   bytes npbytes = 2; // actual data
- }
- 
- message CollaboratorDescription {
-   string name = 1;
-   string status = 2;
-   float progress = 3;
-   uint32 round = 4;
-   string current_task = 5;
-   string next_task = 6;
- }
- 
- // The same with director.proto
- message TaskDescription {
-   string name = 1;
-   string description = 2;
- }
- 
- message DownloadStatus {
-   string name = 1;
-   string status = 2;
- }
- 
- message DownloadStatuses {
-   repeated DownloadStatus models = 1;
-   repeated DownloadStatus logs = 2;
- }
- 
- message ExperimentDescription {
-   string name = 1;
-   string status = 2;
-   float progress = 3;
-   uint32 total_rounds = 4;
-   uint32 current_round = 5;
-   DownloadStatuses download_statuses = 6;
-   repeated CollaboratorDescription collaborators = 7;
-   repeated TaskDescription tasks = 8;
- }
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl/protocols/compile_proto.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols/compile_proto.sh
*** ./openfl/openfl/protocols/compile_proto.sh	2022-11-18 11:08:33.047181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols/compile_proto.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,8 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- rm *_pb2.py *_pb2_grpc.py 2> /dev/null
- python -m pip install -qq grpcio-tools
- python -m grpc_tools.protoc -I ../.. --python_out=../.. --grpc_python_out=../.. \
-   openfl/protocols/aggregator.proto \
-   openfl/protocols/director.proto
- python -m grpc_tools.protoc -I ../.. --python_out=../.. openfl/protocols/base.proto
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl/protocols/director_pb2_grpc.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols/director_pb2_grpc.py
*** ./openfl/openfl/protocols/director_pb2_grpc.py	2022-11-18 11:08:33.047181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols/director_pb2_grpc.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,466 ****
- # Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
- """Client and server classes corresponding to protobuf-defined services."""
- import grpc
- 
- from openfl.protocols import director_pb2 as openfl_dot_protocols_dot_director__pb2
- 
- 
- class DirectorStub(object):
-     """Missing associated documentation comment in .proto file."""
- 
-     def __init__(self, channel):
-         """Constructor.
- 
-         Args:
-             channel: A grpc.Channel.
-         """
-         self.UpdateShardInfo = channel.unary_unary(
-                 '/openfl.director.Director/UpdateShardInfo',
-                 request_serializer=openfl_dot_protocols_dot_director__pb2.UpdateShardInfoRequest.SerializeToString,
-                 response_deserializer=openfl_dot_protocols_dot_director__pb2.UpdateShardInfoResponse.FromString,
-                 )
-         self.WaitExperiment = channel.stream_stream(
-                 '/openfl.director.Director/WaitExperiment',
-                 request_serializer=openfl_dot_protocols_dot_director__pb2.WaitExperimentRequest.SerializeToString,
-                 response_deserializer=openfl_dot_protocols_dot_director__pb2.WaitExperimentResponse.FromString,
-                 )
-         self.GetExperimentData = channel.unary_stream(
-                 '/openfl.director.Director/GetExperimentData',
-                 request_serializer=openfl_dot_protocols_dot_director__pb2.GetExperimentDataRequest.SerializeToString,
-                 response_deserializer=openfl_dot_protocols_dot_director__pb2.ExperimentData.FromString,
-                 )
-         self.UpdateEnvoyStatus = channel.unary_unary(
-                 '/openfl.director.Director/UpdateEnvoyStatus',
-                 request_serializer=openfl_dot_protocols_dot_director__pb2.UpdateEnvoyStatusRequest.SerializeToString,
-                 response_deserializer=openfl_dot_protocols_dot_director__pb2.UpdateEnvoyStatusResponse.FromString,
-                 )
-         self.SetExperimentFailed = channel.unary_unary(
-                 '/openfl.director.Director/SetExperimentFailed',
-                 request_serializer=openfl_dot_protocols_dot_director__pb2.SetExperimentFailedRequest.SerializeToString,
-                 response_deserializer=openfl_dot_protocols_dot_director__pb2.SetExperimentFailedResponse.FromString,
-                 )
-         self.GetExperimentDescription = channel.unary_unary(
-                 '/openfl.director.Director/GetExperimentDescription',
-                 request_serializer=openfl_dot_protocols_dot_director__pb2.GetExperimentDescriptionRequest.SerializeToString,
-                 response_deserializer=openfl_dot_protocols_dot_director__pb2.GetExperimentDescriptionResponse.FromString,
-                 )
-         self.GetExperimentsList = channel.unary_unary(
-                 '/openfl.director.Director/GetExperimentsList',
-                 request_serializer=openfl_dot_protocols_dot_director__pb2.GetExperimentsListRequest.SerializeToString,
-                 response_deserializer=openfl_dot_protocols_dot_director__pb2.GetExperimentsListResponse.FromString,
-                 )
-         self.SetNewExperiment = channel.stream_unary(
-                 '/openfl.director.Director/SetNewExperiment',
-                 request_serializer=openfl_dot_protocols_dot_director__pb2.ExperimentInfo.SerializeToString,
-                 response_deserializer=openfl_dot_protocols_dot_director__pb2.SetNewExperimentResponse.FromString,
-                 )
-         self.GetDatasetInfo = channel.unary_unary(
-                 '/openfl.director.Director/GetDatasetInfo',
-                 request_serializer=openfl_dot_protocols_dot_director__pb2.GetDatasetInfoRequest.SerializeToString,
-                 response_deserializer=openfl_dot_protocols_dot_director__pb2.GetDatasetInfoResponse.FromString,
-                 )
-         self.GetTrainedModel = channel.unary_unary(
-                 '/openfl.director.Director/GetTrainedModel',
-                 request_serializer=openfl_dot_protocols_dot_director__pb2.GetTrainedModelRequest.SerializeToString,
-                 response_deserializer=openfl_dot_protocols_dot_director__pb2.TrainedModelResponse.FromString,
-                 )
-         self.GetMetricStream = channel.unary_stream(
-                 '/openfl.director.Director/GetMetricStream',
-                 request_serializer=openfl_dot_protocols_dot_director__pb2.GetMetricStreamRequest.SerializeToString,
-                 response_deserializer=openfl_dot_protocols_dot_director__pb2.GetMetricStreamResponse.FromString,
-                 )
-         self.RemoveExperimentData = channel.unary_unary(
-                 '/openfl.director.Director/RemoveExperimentData',
-                 request_serializer=openfl_dot_protocols_dot_director__pb2.RemoveExperimentRequest.SerializeToString,
-                 response_deserializer=openfl_dot_protocols_dot_director__pb2.RemoveExperimentResponse.FromString,
-                 )
-         self.GetEnvoys = channel.unary_unary(
-                 '/openfl.director.Director/GetEnvoys',
-                 request_serializer=openfl_dot_protocols_dot_director__pb2.GetEnvoysRequest.SerializeToString,
-                 response_deserializer=openfl_dot_protocols_dot_director__pb2.GetEnvoysResponse.FromString,
-                 )
- 
- 
- class DirectorServicer(object):
-     """Missing associated documentation comment in .proto file."""
- 
-     def UpdateShardInfo(self, request, context):
-         """Envoy RPCs
-         """
-         context.set_code(grpc.StatusCode.UNIMPLEMENTED)
-         context.set_details('Method not implemented!')
-         raise NotImplementedError('Method not implemented!')
- 
-     def WaitExperiment(self, request_iterator, context):
-         """Shard owner could also provide some public data for tests
-         """
-         context.set_code(grpc.StatusCode.UNIMPLEMENTED)
-         context.set_details('Method not implemented!')
-         raise NotImplementedError('Method not implemented!')
- 
-     def GetExperimentData(self, request, context):
-         """Missing associated documentation comment in .proto file."""
-         context.set_code(grpc.StatusCode.UNIMPLEMENTED)
-         context.set_details('Method not implemented!')
-         raise NotImplementedError('Method not implemented!')
- 
-     def UpdateEnvoyStatus(self, request, context):
-         """Missing associated documentation comment in .proto file."""
-         context.set_code(grpc.StatusCode.UNIMPLEMENTED)
-         context.set_details('Method not implemented!')
-         raise NotImplementedError('Method not implemented!')
- 
-     def SetExperimentFailed(self, request, context):
-         """Missing associated documentation comment in .proto file."""
-         context.set_code(grpc.StatusCode.UNIMPLEMENTED)
-         context.set_details('Method not implemented!')
-         raise NotImplementedError('Method not implemented!')
- 
-     def GetExperimentDescription(self, request, context):
-         """Experiments RPCs
-         """
-         context.set_code(grpc.StatusCode.UNIMPLEMENTED)
-         context.set_details('Method not implemented!')
-         raise NotImplementedError('Method not implemented!')
- 
-     def GetExperimentsList(self, request, context):
-         """Missing associated documentation comment in .proto file."""
-         context.set_code(grpc.StatusCode.UNIMPLEMENTED)
-         context.set_details('Method not implemented!')
-         raise NotImplementedError('Method not implemented!')
- 
-     def SetNewExperiment(self, request_iterator, context):
-         """API RPCs
-         """
-         context.set_code(grpc.StatusCode.UNIMPLEMENTED)
-         context.set_details('Method not implemented!')
-         raise NotImplementedError('Method not implemented!')
- 
-     def GetDatasetInfo(self, request, context):
-         """Missing associated documentation comment in .proto file."""
-         context.set_code(grpc.StatusCode.UNIMPLEMENTED)
-         context.set_details('Method not implemented!')
-         raise NotImplementedError('Method not implemented!')
- 
-     def GetTrainedModel(self, request, context):
-         """Missing associated documentation comment in .proto file."""
-         context.set_code(grpc.StatusCode.UNIMPLEMENTED)
-         context.set_details('Method not implemented!')
-         raise NotImplementedError('Method not implemented!')
- 
-     def GetMetricStream(self, request, context):
-         """Missing associated documentation comment in .proto file."""
-         context.set_code(grpc.StatusCode.UNIMPLEMENTED)
-         context.set_details('Method not implemented!')
-         raise NotImplementedError('Method not implemented!')
- 
-     def RemoveExperimentData(self, request, context):
-         """Missing associated documentation comment in .proto file."""
-         context.set_code(grpc.StatusCode.UNIMPLEMENTED)
-         context.set_details('Method not implemented!')
-         raise NotImplementedError('Method not implemented!')
- 
-     def GetEnvoys(self, request, context):
-         """Missing associated documentation comment in .proto file."""
-         context.set_code(grpc.StatusCode.UNIMPLEMENTED)
-         context.set_details('Method not implemented!')
-         raise NotImplementedError('Method not implemented!')
- 
- 
- def add_DirectorServicer_to_server(servicer, server):
-     rpc_method_handlers = {
-             'UpdateShardInfo': grpc.unary_unary_rpc_method_handler(
-                     servicer.UpdateShardInfo,
-                     request_deserializer=openfl_dot_protocols_dot_director__pb2.UpdateShardInfoRequest.FromString,
-                     response_serializer=openfl_dot_protocols_dot_director__pb2.UpdateShardInfoResponse.SerializeToString,
-             ),
-             'WaitExperiment': grpc.stream_stream_rpc_method_handler(
-                     servicer.WaitExperiment,
-                     request_deserializer=openfl_dot_protocols_dot_director__pb2.WaitExperimentRequest.FromString,
-                     response_serializer=openfl_dot_protocols_dot_director__pb2.WaitExperimentResponse.SerializeToString,
-             ),
-             'GetExperimentData': grpc.unary_stream_rpc_method_handler(
-                     servicer.GetExperimentData,
-                     request_deserializer=openfl_dot_protocols_dot_director__pb2.GetExperimentDataRequest.FromString,
-                     response_serializer=openfl_dot_protocols_dot_director__pb2.ExperimentData.SerializeToString,
-             ),
-             'UpdateEnvoyStatus': grpc.unary_unary_rpc_method_handler(
-                     servicer.UpdateEnvoyStatus,
-                     request_deserializer=openfl_dot_protocols_dot_director__pb2.UpdateEnvoyStatusRequest.FromString,
-                     response_serializer=openfl_dot_protocols_dot_director__pb2.UpdateEnvoyStatusResponse.SerializeToString,
-             ),
-             'SetExperimentFailed': grpc.unary_unary_rpc_method_handler(
-                     servicer.SetExperimentFailed,
-                     request_deserializer=openfl_dot_protocols_dot_director__pb2.SetExperimentFailedRequest.FromString,
-                     response_serializer=openfl_dot_protocols_dot_director__pb2.SetExperimentFailedResponse.SerializeToString,
-             ),
-             'GetExperimentDescription': grpc.unary_unary_rpc_method_handler(
-                     servicer.GetExperimentDescription,
-                     request_deserializer=openfl_dot_protocols_dot_director__pb2.GetExperimentDescriptionRequest.FromString,
-                     response_serializer=openfl_dot_protocols_dot_director__pb2.GetExperimentDescriptionResponse.SerializeToString,
-             ),
-             'GetExperimentsList': grpc.unary_unary_rpc_method_handler(
-                     servicer.GetExperimentsList,
-                     request_deserializer=openfl_dot_protocols_dot_director__pb2.GetExperimentsListRequest.FromString,
-                     response_serializer=openfl_dot_protocols_dot_director__pb2.GetExperimentsListResponse.SerializeToString,
-             ),
-             'SetNewExperiment': grpc.stream_unary_rpc_method_handler(
-                     servicer.SetNewExperiment,
-                     request_deserializer=openfl_dot_protocols_dot_director__pb2.ExperimentInfo.FromString,
-                     response_serializer=openfl_dot_protocols_dot_director__pb2.SetNewExperimentResponse.SerializeToString,
-             ),
-             'GetDatasetInfo': grpc.unary_unary_rpc_method_handler(
-                     servicer.GetDatasetInfo,
-                     request_deserializer=openfl_dot_protocols_dot_director__pb2.GetDatasetInfoRequest.FromString,
-                     response_serializer=openfl_dot_protocols_dot_director__pb2.GetDatasetInfoResponse.SerializeToString,
-             ),
-             'GetTrainedModel': grpc.unary_unary_rpc_method_handler(
-                     servicer.GetTrainedModel,
-                     request_deserializer=openfl_dot_protocols_dot_director__pb2.GetTrainedModelRequest.FromString,
-                     response_serializer=openfl_dot_protocols_dot_director__pb2.TrainedModelResponse.SerializeToString,
-             ),
-             'GetMetricStream': grpc.unary_stream_rpc_method_handler(
-                     servicer.GetMetricStream,
-                     request_deserializer=openfl_dot_protocols_dot_director__pb2.GetMetricStreamRequest.FromString,
-                     response_serializer=openfl_dot_protocols_dot_director__pb2.GetMetricStreamResponse.SerializeToString,
-             ),
-             'RemoveExperimentData': grpc.unary_unary_rpc_method_handler(
-                     servicer.RemoveExperimentData,
-                     request_deserializer=openfl_dot_protocols_dot_director__pb2.RemoveExperimentRequest.FromString,
-                     response_serializer=openfl_dot_protocols_dot_director__pb2.RemoveExperimentResponse.SerializeToString,
-             ),
-             'GetEnvoys': grpc.unary_unary_rpc_method_handler(
-                     servicer.GetEnvoys,
-                     request_deserializer=openfl_dot_protocols_dot_director__pb2.GetEnvoysRequest.FromString,
-                     response_serializer=openfl_dot_protocols_dot_director__pb2.GetEnvoysResponse.SerializeToString,
-             ),
-     }
-     generic_handler = grpc.method_handlers_generic_handler(
-             'openfl.director.Director', rpc_method_handlers)
-     server.add_generic_rpc_handlers((generic_handler,))
- 
- 
-  # This class is part of an EXPERIMENTAL API.
- class Director(object):
-     """Missing associated documentation comment in .proto file."""
- 
-     @staticmethod
-     def UpdateShardInfo(request,
-             target,
-             options=(),
-             channel_credentials=None,
-             call_credentials=None,
-             insecure=False,
-             compression=None,
-             wait_for_ready=None,
-             timeout=None,
-             metadata=None):
-         return grpc.experimental.unary_unary(request, target, '/openfl.director.Director/UpdateShardInfo',
-             openfl_dot_protocols_dot_director__pb2.UpdateShardInfoRequest.SerializeToString,
-             openfl_dot_protocols_dot_director__pb2.UpdateShardInfoResponse.FromString,
-             options, channel_credentials,
-             insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
- 
-     @staticmethod
-     def WaitExperiment(request_iterator,
-             target,
-             options=(),
-             channel_credentials=None,
-             call_credentials=None,
-             insecure=False,
-             compression=None,
-             wait_for_ready=None,
-             timeout=None,
-             metadata=None):
-         return grpc.experimental.stream_stream(request_iterator, target, '/openfl.director.Director/WaitExperiment',
-             openfl_dot_protocols_dot_director__pb2.WaitExperimentRequest.SerializeToString,
-             openfl_dot_protocols_dot_director__pb2.WaitExperimentResponse.FromString,
-             options, channel_credentials,
-             insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
- 
-     @staticmethod
-     def GetExperimentData(request,
-             target,
-             options=(),
-             channel_credentials=None,
-             call_credentials=None,
-             insecure=False,
-             compression=None,
-             wait_for_ready=None,
-             timeout=None,
-             metadata=None):
-         return grpc.experimental.unary_stream(request, target, '/openfl.director.Director/GetExperimentData',
-             openfl_dot_protocols_dot_director__pb2.GetExperimentDataRequest.SerializeToString,
-             openfl_dot_protocols_dot_director__pb2.ExperimentData.FromString,
-             options, channel_credentials,
-             insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
- 
-     @staticmethod
-     def UpdateEnvoyStatus(request,
-             target,
-             options=(),
-             channel_credentials=None,
-             call_credentials=None,
-             insecure=False,
-             compression=None,
-             wait_for_ready=None,
-             timeout=None,
-             metadata=None):
-         return grpc.experimental.unary_unary(request, target, '/openfl.director.Director/UpdateEnvoyStatus',
-             openfl_dot_protocols_dot_director__pb2.UpdateEnvoyStatusRequest.SerializeToString,
-             openfl_dot_protocols_dot_director__pb2.UpdateEnvoyStatusResponse.FromString,
-             options, channel_credentials,
-             insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
- 
-     @staticmethod
-     def SetExperimentFailed(request,
-             target,
-             options=(),
-             channel_credentials=None,
-             call_credentials=None,
-             insecure=False,
-             compression=None,
-             wait_for_ready=None,
-             timeout=None,
-             metadata=None):
-         return grpc.experimental.unary_unary(request, target, '/openfl.director.Director/SetExperimentFailed',
-             openfl_dot_protocols_dot_director__pb2.SetExperimentFailedRequest.SerializeToString,
-             openfl_dot_protocols_dot_director__pb2.SetExperimentFailedResponse.FromString,
-             options, channel_credentials,
-             insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
- 
-     @staticmethod
-     def GetExperimentDescription(request,
-             target,
-             options=(),
-             channel_credentials=None,
-             call_credentials=None,
-             insecure=False,
-             compression=None,
-             wait_for_ready=None,
-             timeout=None,
-             metadata=None):
-         return grpc.experimental.unary_unary(request, target, '/openfl.director.Director/GetExperimentDescription',
-             openfl_dot_protocols_dot_director__pb2.GetExperimentDescriptionRequest.SerializeToString,
-             openfl_dot_protocols_dot_director__pb2.GetExperimentDescriptionResponse.FromString,
-             options, channel_credentials,
-             insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
- 
-     @staticmethod
-     def GetExperimentsList(request,
-             target,
-             options=(),
-             channel_credentials=None,
-             call_credentials=None,
-             insecure=False,
-             compression=None,
-             wait_for_ready=None,
-             timeout=None,
-             metadata=None):
-         return grpc.experimental.unary_unary(request, target, '/openfl.director.Director/GetExperimentsList',
-             openfl_dot_protocols_dot_director__pb2.GetExperimentsListRequest.SerializeToString,
-             openfl_dot_protocols_dot_director__pb2.GetExperimentsListResponse.FromString,
-             options, channel_credentials,
-             insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
- 
-     @staticmethod
-     def SetNewExperiment(request_iterator,
-             target,
-             options=(),
-             channel_credentials=None,
-             call_credentials=None,
-             insecure=False,
-             compression=None,
-             wait_for_ready=None,
-             timeout=None,
-             metadata=None):
-         return grpc.experimental.stream_unary(request_iterator, target, '/openfl.director.Director/SetNewExperiment',
-             openfl_dot_protocols_dot_director__pb2.ExperimentInfo.SerializeToString,
-             openfl_dot_protocols_dot_director__pb2.SetNewExperimentResponse.FromString,
-             options, channel_credentials,
-             insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
- 
-     @staticmethod
-     def GetDatasetInfo(request,
-             target,
-             options=(),
-             channel_credentials=None,
-             call_credentials=None,
-             insecure=False,
-             compression=None,
-             wait_for_ready=None,
-             timeout=None,
-             metadata=None):
-         return grpc.experimental.unary_unary(request, target, '/openfl.director.Director/GetDatasetInfo',
-             openfl_dot_protocols_dot_director__pb2.GetDatasetInfoRequest.SerializeToString,
-             openfl_dot_protocols_dot_director__pb2.GetDatasetInfoResponse.FromString,
-             options, channel_credentials,
-             insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
- 
-     @staticmethod
-     def GetTrainedModel(request,
-             target,
-             options=(),
-             channel_credentials=None,
-             call_credentials=None,
-             insecure=False,
-             compression=None,
-             wait_for_ready=None,
-             timeout=None,
-             metadata=None):
-         return grpc.experimental.unary_unary(request, target, '/openfl.director.Director/GetTrainedModel',
-             openfl_dot_protocols_dot_director__pb2.GetTrainedModelRequest.SerializeToString,
-             openfl_dot_protocols_dot_director__pb2.TrainedModelResponse.FromString,
-             options, channel_credentials,
-             insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
- 
-     @staticmethod
-     def GetMetricStream(request,
-             target,
-             options=(),
-             channel_credentials=None,
-             call_credentials=None,
-             insecure=False,
-             compression=None,
-             wait_for_ready=None,
-             timeout=None,
-             metadata=None):
-         return grpc.experimental.unary_stream(request, target, '/openfl.director.Director/GetMetricStream',
-             openfl_dot_protocols_dot_director__pb2.GetMetricStreamRequest.SerializeToString,
-             openfl_dot_protocols_dot_director__pb2.GetMetricStreamResponse.FromString,
-             options, channel_credentials,
-             insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
- 
-     @staticmethod
-     def RemoveExperimentData(request,
-             target,
-             options=(),
-             channel_credentials=None,
-             call_credentials=None,
-             insecure=False,
-             compression=None,
-             wait_for_ready=None,
-             timeout=None,
-             metadata=None):
-         return grpc.experimental.unary_unary(request, target, '/openfl.director.Director/RemoveExperimentData',
-             openfl_dot_protocols_dot_director__pb2.RemoveExperimentRequest.SerializeToString,
-             openfl_dot_protocols_dot_director__pb2.RemoveExperimentResponse.FromString,
-             options, channel_credentials,
-             insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
- 
-     @staticmethod
-     def GetEnvoys(request,
-             target,
-             options=(),
-             channel_credentials=None,
-             call_credentials=None,
-             insecure=False,
-             compression=None,
-             wait_for_ready=None,
-             timeout=None,
-             metadata=None):
-         return grpc.experimental.unary_unary(request, target, '/openfl.director.Director/GetEnvoys',
-             openfl_dot_protocols_dot_director__pb2.GetEnvoysRequest.SerializeToString,
-             openfl_dot_protocols_dot_director__pb2.GetEnvoysResponse.FromString,
-             options, channel_credentials,
-             insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
--- 0 ----
diff -crB --new-file ./openfl/openfl/protocols/director_pb2.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols/director_pb2.py
*** ./openfl/openfl/protocols/director_pb2.py	2022-11-18 11:08:33.047181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols/director_pb2.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,1680 ****
- # -*- coding: utf-8 -*-
- # Generated by the protocol buffer compiler.  DO NOT EDIT!
- # source: openfl/protocols/director.proto
- """Generated protocol buffer code."""
- from google.protobuf import descriptor as _descriptor
- from google.protobuf import message as _message
- from google.protobuf import reflection as _reflection
- from google.protobuf import symbol_database as _symbol_database
- # @@protoc_insertion_point(imports)
- 
- _sym_db = _symbol_database.Default()
- 
- 
- from google.protobuf import timestamp_pb2 as google_dot_protobuf_dot_timestamp__pb2
- from google.protobuf import duration_pb2 as google_dot_protobuf_dot_duration__pb2
- from openfl.protocols import base_pb2 as openfl_dot_protocols_dot_base__pb2
- 
- 
- DESCRIPTOR = _descriptor.FileDescriptor(
-   name='openfl/protocols/director.proto',
-   package='openfl.director',
-   syntax='proto3',
-   serialized_options=None,
-   create_key=_descriptor._internal_create_key,
-   serialized_pb=b'\n\x1fopenfl/protocols/director.proto\x12\x0fopenfl.director\x1a\x1fgoogle/protobuf/timestamp.proto\x1a\x1egoogle/protobuf/duration.proto\x1a\x1bopenfl/protocols/base.proto\"\xab\x01\n\x0e\x43udaDeviceInfo\x12\r\n\x05index\x18\x01 \x01(\x04\x12\x14\n\x0cmemory_total\x18\x02 \x01(\x04\x12\x17\n\x0fmemory_utilized\x18\x03 \x01(\x04\x12\x1a\n\x12\x64\x65vice_utilization\x18\x04 \x01(\t\x12\x1b\n\x13\x63uda_driver_version\x18\x05 \x01(\t\x12\x14\n\x0c\x63uda_version\x18\x06 \x01(\t\x12\x0c\n\x04name\x18\x07 \x01(\t\"O\n\x08NodeInfo\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x35\n\x0c\x63uda_devices\x18\x02 \x03(\x0b\x32\x1f.openfl.director.CudaDeviceInfo\"\x93\x01\n\tShardInfo\x12,\n\tnode_info\x18\x01 \x01(\x0b\x32\x19.openfl.director.NodeInfo\x12\x19\n\x11shard_description\x18\x02 \x01(\t\x12\x11\n\tn_samples\x18\x03 \x01(\x04\x12\x14\n\x0csample_shape\x18\x04 \x03(\t\x12\x14\n\x0ctarget_shape\x18\x05 \x03(\t\"H\n\x16UpdateShardInfoRequest\x12.\n\nshard_info\x18\x01 \x01(\x0b\x32\x1a.openfl.director.ShardInfo\"+\n\x17UpdateShardInfoResponse\x12\x10\n\x08\x61\x63\x63\x65pted\x18\x01 \x01(\x08\"2\n\x15WaitExperimentRequest\x12\x19\n\x11\x63ollaborator_name\x18\x01 \x01(\t\"1\n\x16WaitExperimentResponse\x12\x17\n\x0f\x65xperiment_name\x18\x01 \x01(\t\"N\n\x18GetExperimentDataRequest\x12\x17\n\x0f\x65xperiment_name\x18\x01 \x01(\t\x12\x19\n\x11\x63ollaborator_name\x18\x02 \x01(\t\"/\n\x0e\x45xperimentData\x12\x0c\n\x04size\x18\x01 \x01(\r\x12\x0f\n\x07npbytes\x18\x02 \x01(\x0c\"~\n\x18UpdateEnvoyStatusRequest\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x1d\n\x15is_experiment_running\x18\x02 \x01(\x08\x12\x35\n\x0c\x63uda_devices\x18\x03 \x03(\x0b\x32\x1f.openfl.director.CudaDeviceInfo\"S\n\x19UpdateEnvoyStatusResponse\x12\x36\n\x13health_check_period\x18\x01 \x01(\x0b\x32\x19.google.protobuf.Duration\"\x7f\n\x1aSetExperimentFailedRequest\x12\x17\n\x0f\x65xperiment_name\x18\x01 \x01(\t\x12\x19\n\x11\x63ollaborator_name\x18\x02 \x01(\t\x12\x12\n\nerror_code\x18\x03 \x01(\r\x12\x19\n\x11\x65rror_description\x18\x04 \x01(\t\"\x1d\n\x1bSetExperimentFailedResponse\"\x1b\n\x19GetExperimentsListRequest\"x\n\x12\x45xperimentListItem\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0e\n\x06status\x18\x02 \x01(\t\x12\x1c\n\x14\x63ollaborators_amount\x18\x03 \x01(\r\x12\x14\n\x0ctasks_amount\x18\x04 \x01(\r\x12\x10\n\x08progress\x18\x05 \x01(\x02\"V\n\x1aGetExperimentsListResponse\x12\x38\n\x0b\x65xperiments\x18\x01 \x03(\x0b\x32#.openfl.director.ExperimentListItem\"/\n\x1fGetExperimentDescriptionRequest\x12\x0c\n\x04name\x18\x01 \x01(\t\"N\n GetExperimentDescriptionResponse\x12*\n\nexperiment\x18\x01 \x01(\x0b\x32\x16.ExperimentDescription\"\x96\x01\n\x0e\x45xperimentInfo\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x1a\n\x12\x63ollaborator_names\x18\x02 \x03(\t\x12\x38\n\x0f\x65xperiment_data\x18\x03 \x01(\x0b\x32\x1f.openfl.director.ExperimentData\x12 \n\x0bmodel_proto\x18\x04 \x01(\x0b\x32\x0b.ModelProto\",\n\x18SetNewExperimentResponse\x12\x10\n\x08\x61\x63\x63\x65pted\x18\x01 \x01(\x08\"\xa5\x01\n\x16GetTrainedModelRequest\x12\x17\n\x0f\x65xperiment_name\x18\x02 \x01(\t\x12\x45\n\nmodel_type\x18\x03 \x01(\x0e\x32\x31.openfl.director.GetTrainedModelRequest.ModelType\"+\n\tModelType\x12\x0e\n\nBEST_MODEL\x10\x00\x12\x0e\n\nLAST_MODEL\x10\x01\"8\n\x14TrainedModelResponse\x12 \n\x0bmodel_proto\x18\x01 \x01(\x0b\x32\x0b.ModelProto\"\x17\n\x15GetDatasetInfoRequest\"H\n\x16GetDatasetInfoResponse\x12.\n\nshard_info\x18\x01 \x01(\x0b\x32\x1a.openfl.director.ShardInfo\"1\n\x16GetMetricStreamRequest\x12\x17\n\x0f\x65xperiment_name\x18\x01 \x01(\t\"}\n\x17GetMetricStreamResponse\x12\x15\n\rmetric_origin\x18\x01 \x01(\t\x12\x11\n\ttask_name\x18\x02 \x01(\t\x12\x13\n\x0bmetric_name\x18\x03 \x01(\t\x12\x14\n\x0cmetric_value\x18\x04 \x01(\x02\x12\r\n\x05round\x18\x05 \x01(\r\"2\n\x17RemoveExperimentRequest\x12\x17\n\x0f\x65xperiment_name\x18\x01 \x01(\t\"3\n\x18RemoveExperimentResponse\x12\x17\n\x0f\x61\x63knowledgement\x18\x01 \x01(\x08\"\xeb\x01\n\tEnvoyInfo\x12.\n\nshard_info\x18\x01 \x01(\x0b\x32\x1a.openfl.director.ShardInfo\x12\x11\n\tis_online\x18\x02 \x01(\x08\x12\x1d\n\x15is_experiment_running\x18\x03 \x01(\x08\x12\x30\n\x0clast_updated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x31\n\x0evalid_duration\x18\x05 \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x17\n\x0f\x65xperiment_name\x18\x06 \x01(\t\"\x12\n\x10GetEnvoysRequest\"D\n\x11GetEnvoysResponse\x12/\n\x0b\x65nvoy_infos\x18\x01 \x03(\x0b\x32\x1a.openfl.director.EnvoyInfo2\xf4\n\n\x08\x44irector\x12\x66\n\x0fUpdateShardInfo\x12\'.openfl.director.UpdateShardInfoRequest\x1a(.openfl.director.UpdateShardInfoResponse\"\x00\x12g\n\x0eWaitExperiment\x12&.openfl.director.WaitExperimentRequest\x1a\'.openfl.director.WaitExperimentResponse\"\x00(\x01\x30\x01\x12\x63\n\x11GetExperimentData\x12).openfl.director.GetExperimentDataRequest\x1a\x1f.openfl.director.ExperimentData\"\x00\x30\x01\x12l\n\x11UpdateEnvoyStatus\x12).openfl.director.UpdateEnvoyStatusRequest\x1a*.openfl.director.UpdateEnvoyStatusResponse\"\x00\x12r\n\x13SetExperimentFailed\x12+.openfl.director.SetExperimentFailedRequest\x1a,.openfl.director.SetExperimentFailedResponse\"\x00\x12\x81\x01\n\x18GetExperimentDescription\x12\x30.openfl.director.GetExperimentDescriptionRequest\x1a\x31.openfl.director.GetExperimentDescriptionResponse\"\x00\x12o\n\x12GetExperimentsList\x12*.openfl.director.GetExperimentsListRequest\x1a+.openfl.director.GetExperimentsListResponse\"\x00\x12\x62\n\x10SetNewExperiment\x12\x1f.openfl.director.ExperimentInfo\x1a).openfl.director.SetNewExperimentResponse\"\x00(\x01\x12\x63\n\x0eGetDatasetInfo\x12&.openfl.director.GetDatasetInfoRequest\x1a\'.openfl.director.GetDatasetInfoResponse\"\x00\x12\x63\n\x0fGetTrainedModel\x12\'.openfl.director.GetTrainedModelRequest\x1a%.openfl.director.TrainedModelResponse\"\x00\x12h\n\x0fGetMetricStream\x12\'.openfl.director.GetMetricStreamRequest\x1a(.openfl.director.GetMetricStreamResponse\"\x00\x30\x01\x12m\n\x14RemoveExperimentData\x12(.openfl.director.RemoveExperimentRequest\x1a).openfl.director.RemoveExperimentResponse\"\x00\x12T\n\tGetEnvoys\x12!.openfl.director.GetEnvoysRequest\x1a\".openfl.director.GetEnvoysResponse\"\x00\x62\x06proto3'
-   ,
-   dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR,google_dot_protobuf_dot_duration__pb2.DESCRIPTOR,openfl_dot_protocols_dot_base__pb2.DESCRIPTOR,])
- 
- 
- 
- _GETTRAINEDMODELREQUEST_MODELTYPE = _descriptor.EnumDescriptor(
-   name='ModelType',
-   full_name='openfl.director.GetTrainedModelRequest.ModelType',
-   filename=None,
-   file=DESCRIPTOR,
-   create_key=_descriptor._internal_create_key,
-   values=[
-     _descriptor.EnumValueDescriptor(
-       name='BEST_MODEL', index=0, number=0,
-       serialized_options=None,
-       type=None,
-       create_key=_descriptor._internal_create_key),
-     _descriptor.EnumValueDescriptor(
-       name='LAST_MODEL', index=1, number=1,
-       serialized_options=None,
-       type=None,
-       create_key=_descriptor._internal_create_key),
-   ],
-   containing_type=None,
-   serialized_options=None,
-   serialized_start=1965,
-   serialized_end=2008,
- )
- _sym_db.RegisterEnumDescriptor(_GETTRAINEDMODELREQUEST_MODELTYPE)
- 
- 
- _CUDADEVICEINFO = _descriptor.Descriptor(
-   name='CudaDeviceInfo',
-   full_name='openfl.director.CudaDeviceInfo',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='index', full_name='openfl.director.CudaDeviceInfo.index', index=0,
-       number=1, type=4, cpp_type=4, label=1,
-       has_default_value=False, default_value=0,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='memory_total', full_name='openfl.director.CudaDeviceInfo.memory_total', index=1,
-       number=2, type=4, cpp_type=4, label=1,
-       has_default_value=False, default_value=0,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='memory_utilized', full_name='openfl.director.CudaDeviceInfo.memory_utilized', index=2,
-       number=3, type=4, cpp_type=4, label=1,
-       has_default_value=False, default_value=0,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='device_utilization', full_name='openfl.director.CudaDeviceInfo.device_utilization', index=3,
-       number=4, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='cuda_driver_version', full_name='openfl.director.CudaDeviceInfo.cuda_driver_version', index=4,
-       number=5, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='cuda_version', full_name='openfl.director.CudaDeviceInfo.cuda_version', index=5,
-       number=6, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='name', full_name='openfl.director.CudaDeviceInfo.name', index=6,
-       number=7, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=147,
-   serialized_end=318,
- )
- 
- 
- _NODEINFO = _descriptor.Descriptor(
-   name='NodeInfo',
-   full_name='openfl.director.NodeInfo',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='name', full_name='openfl.director.NodeInfo.name', index=0,
-       number=1, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='cuda_devices', full_name='openfl.director.NodeInfo.cuda_devices', index=1,
-       number=2, type=11, cpp_type=10, label=3,
-       has_default_value=False, default_value=[],
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=320,
-   serialized_end=399,
- )
- 
- 
- _SHARDINFO = _descriptor.Descriptor(
-   name='ShardInfo',
-   full_name='openfl.director.ShardInfo',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='node_info', full_name='openfl.director.ShardInfo.node_info', index=0,
-       number=1, type=11, cpp_type=10, label=1,
-       has_default_value=False, default_value=None,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='shard_description', full_name='openfl.director.ShardInfo.shard_description', index=1,
-       number=2, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='n_samples', full_name='openfl.director.ShardInfo.n_samples', index=2,
-       number=3, type=4, cpp_type=4, label=1,
-       has_default_value=False, default_value=0,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='sample_shape', full_name='openfl.director.ShardInfo.sample_shape', index=3,
-       number=4, type=9, cpp_type=9, label=3,
-       has_default_value=False, default_value=[],
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='target_shape', full_name='openfl.director.ShardInfo.target_shape', index=4,
-       number=5, type=9, cpp_type=9, label=3,
-       has_default_value=False, default_value=[],
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=402,
-   serialized_end=549,
- )
- 
- 
- _UPDATESHARDINFOREQUEST = _descriptor.Descriptor(
-   name='UpdateShardInfoRequest',
-   full_name='openfl.director.UpdateShardInfoRequest',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='shard_info', full_name='openfl.director.UpdateShardInfoRequest.shard_info', index=0,
-       number=1, type=11, cpp_type=10, label=1,
-       has_default_value=False, default_value=None,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=551,
-   serialized_end=623,
- )
- 
- 
- _UPDATESHARDINFORESPONSE = _descriptor.Descriptor(
-   name='UpdateShardInfoResponse',
-   full_name='openfl.director.UpdateShardInfoResponse',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='accepted', full_name='openfl.director.UpdateShardInfoResponse.accepted', index=0,
-       number=1, type=8, cpp_type=7, label=1,
-       has_default_value=False, default_value=False,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=625,
-   serialized_end=668,
- )
- 
- 
- _WAITEXPERIMENTREQUEST = _descriptor.Descriptor(
-   name='WaitExperimentRequest',
-   full_name='openfl.director.WaitExperimentRequest',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='collaborator_name', full_name='openfl.director.WaitExperimentRequest.collaborator_name', index=0,
-       number=1, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=670,
-   serialized_end=720,
- )
- 
- 
- _WAITEXPERIMENTRESPONSE = _descriptor.Descriptor(
-   name='WaitExperimentResponse',
-   full_name='openfl.director.WaitExperimentResponse',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='experiment_name', full_name='openfl.director.WaitExperimentResponse.experiment_name', index=0,
-       number=1, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=722,
-   serialized_end=771,
- )
- 
- 
- _GETEXPERIMENTDATAREQUEST = _descriptor.Descriptor(
-   name='GetExperimentDataRequest',
-   full_name='openfl.director.GetExperimentDataRequest',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='experiment_name', full_name='openfl.director.GetExperimentDataRequest.experiment_name', index=0,
-       number=1, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='collaborator_name', full_name='openfl.director.GetExperimentDataRequest.collaborator_name', index=1,
-       number=2, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=773,
-   serialized_end=851,
- )
- 
- 
- _EXPERIMENTDATA = _descriptor.Descriptor(
-   name='ExperimentData',
-   full_name='openfl.director.ExperimentData',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='size', full_name='openfl.director.ExperimentData.size', index=0,
-       number=1, type=13, cpp_type=3, label=1,
-       has_default_value=False, default_value=0,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='npbytes', full_name='openfl.director.ExperimentData.npbytes', index=1,
-       number=2, type=12, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"",
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=853,
-   serialized_end=900,
- )
- 
- 
- _UPDATEENVOYSTATUSREQUEST = _descriptor.Descriptor(
-   name='UpdateEnvoyStatusRequest',
-   full_name='openfl.director.UpdateEnvoyStatusRequest',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='name', full_name='openfl.director.UpdateEnvoyStatusRequest.name', index=0,
-       number=1, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='is_experiment_running', full_name='openfl.director.UpdateEnvoyStatusRequest.is_experiment_running', index=1,
-       number=2, type=8, cpp_type=7, label=1,
-       has_default_value=False, default_value=False,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='cuda_devices', full_name='openfl.director.UpdateEnvoyStatusRequest.cuda_devices', index=2,
-       number=3, type=11, cpp_type=10, label=3,
-       has_default_value=False, default_value=[],
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=902,
-   serialized_end=1028,
- )
- 
- 
- _UPDATEENVOYSTATUSRESPONSE = _descriptor.Descriptor(
-   name='UpdateEnvoyStatusResponse',
-   full_name='openfl.director.UpdateEnvoyStatusResponse',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='health_check_period', full_name='openfl.director.UpdateEnvoyStatusResponse.health_check_period', index=0,
-       number=1, type=11, cpp_type=10, label=1,
-       has_default_value=False, default_value=None,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=1030,
-   serialized_end=1113,
- )
- 
- 
- _SETEXPERIMENTFAILEDREQUEST = _descriptor.Descriptor(
-   name='SetExperimentFailedRequest',
-   full_name='openfl.director.SetExperimentFailedRequest',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='experiment_name', full_name='openfl.director.SetExperimentFailedRequest.experiment_name', index=0,
-       number=1, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='collaborator_name', full_name='openfl.director.SetExperimentFailedRequest.collaborator_name', index=1,
-       number=2, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='error_code', full_name='openfl.director.SetExperimentFailedRequest.error_code', index=2,
-       number=3, type=13, cpp_type=3, label=1,
-       has_default_value=False, default_value=0,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='error_description', full_name='openfl.director.SetExperimentFailedRequest.error_description', index=3,
-       number=4, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=1115,
-   serialized_end=1242,
- )
- 
- 
- _SETEXPERIMENTFAILEDRESPONSE = _descriptor.Descriptor(
-   name='SetExperimentFailedResponse',
-   full_name='openfl.director.SetExperimentFailedResponse',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=1244,
-   serialized_end=1273,
- )
- 
- 
- _GETEXPERIMENTSLISTREQUEST = _descriptor.Descriptor(
-   name='GetExperimentsListRequest',
-   full_name='openfl.director.GetExperimentsListRequest',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=1275,
-   serialized_end=1302,
- )
- 
- 
- _EXPERIMENTLISTITEM = _descriptor.Descriptor(
-   name='ExperimentListItem',
-   full_name='openfl.director.ExperimentListItem',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='name', full_name='openfl.director.ExperimentListItem.name', index=0,
-       number=1, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='status', full_name='openfl.director.ExperimentListItem.status', index=1,
-       number=2, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='collaborators_amount', full_name='openfl.director.ExperimentListItem.collaborators_amount', index=2,
-       number=3, type=13, cpp_type=3, label=1,
-       has_default_value=False, default_value=0,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='tasks_amount', full_name='openfl.director.ExperimentListItem.tasks_amount', index=3,
-       number=4, type=13, cpp_type=3, label=1,
-       has_default_value=False, default_value=0,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='progress', full_name='openfl.director.ExperimentListItem.progress', index=4,
-       number=5, type=2, cpp_type=6, label=1,
-       has_default_value=False, default_value=float(0),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=1304,
-   serialized_end=1424,
- )
- 
- 
- _GETEXPERIMENTSLISTRESPONSE = _descriptor.Descriptor(
-   name='GetExperimentsListResponse',
-   full_name='openfl.director.GetExperimentsListResponse',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='experiments', full_name='openfl.director.GetExperimentsListResponse.experiments', index=0,
-       number=1, type=11, cpp_type=10, label=3,
-       has_default_value=False, default_value=[],
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=1426,
-   serialized_end=1512,
- )
- 
- 
- _GETEXPERIMENTDESCRIPTIONREQUEST = _descriptor.Descriptor(
-   name='GetExperimentDescriptionRequest',
-   full_name='openfl.director.GetExperimentDescriptionRequest',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='name', full_name='openfl.director.GetExperimentDescriptionRequest.name', index=0,
-       number=1, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=1514,
-   serialized_end=1561,
- )
- 
- 
- _GETEXPERIMENTDESCRIPTIONRESPONSE = _descriptor.Descriptor(
-   name='GetExperimentDescriptionResponse',
-   full_name='openfl.director.GetExperimentDescriptionResponse',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='experiment', full_name='openfl.director.GetExperimentDescriptionResponse.experiment', index=0,
-       number=1, type=11, cpp_type=10, label=1,
-       has_default_value=False, default_value=None,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=1563,
-   serialized_end=1641,
- )
- 
- 
- _EXPERIMENTINFO = _descriptor.Descriptor(
-   name='ExperimentInfo',
-   full_name='openfl.director.ExperimentInfo',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='name', full_name='openfl.director.ExperimentInfo.name', index=0,
-       number=1, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='collaborator_names', full_name='openfl.director.ExperimentInfo.collaborator_names', index=1,
-       number=2, type=9, cpp_type=9, label=3,
-       has_default_value=False, default_value=[],
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='experiment_data', full_name='openfl.director.ExperimentInfo.experiment_data', index=2,
-       number=3, type=11, cpp_type=10, label=1,
-       has_default_value=False, default_value=None,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='model_proto', full_name='openfl.director.ExperimentInfo.model_proto', index=3,
-       number=4, type=11, cpp_type=10, label=1,
-       has_default_value=False, default_value=None,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=1644,
-   serialized_end=1794,
- )
- 
- 
- _SETNEWEXPERIMENTRESPONSE = _descriptor.Descriptor(
-   name='SetNewExperimentResponse',
-   full_name='openfl.director.SetNewExperimentResponse',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='accepted', full_name='openfl.director.SetNewExperimentResponse.accepted', index=0,
-       number=1, type=8, cpp_type=7, label=1,
-       has_default_value=False, default_value=False,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=1796,
-   serialized_end=1840,
- )
- 
- 
- _GETTRAINEDMODELREQUEST = _descriptor.Descriptor(
-   name='GetTrainedModelRequest',
-   full_name='openfl.director.GetTrainedModelRequest',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='experiment_name', full_name='openfl.director.GetTrainedModelRequest.experiment_name', index=0,
-       number=2, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='model_type', full_name='openfl.director.GetTrainedModelRequest.model_type', index=1,
-       number=3, type=14, cpp_type=8, label=1,
-       has_default_value=False, default_value=0,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-     _GETTRAINEDMODELREQUEST_MODELTYPE,
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=1843,
-   serialized_end=2008,
- )
- 
- 
- _TRAINEDMODELRESPONSE = _descriptor.Descriptor(
-   name='TrainedModelResponse',
-   full_name='openfl.director.TrainedModelResponse',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='model_proto', full_name='openfl.director.TrainedModelResponse.model_proto', index=0,
-       number=1, type=11, cpp_type=10, label=1,
-       has_default_value=False, default_value=None,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=2010,
-   serialized_end=2066,
- )
- 
- 
- _GETDATASETINFOREQUEST = _descriptor.Descriptor(
-   name='GetDatasetInfoRequest',
-   full_name='openfl.director.GetDatasetInfoRequest',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=2068,
-   serialized_end=2091,
- )
- 
- 
- _GETDATASETINFORESPONSE = _descriptor.Descriptor(
-   name='GetDatasetInfoResponse',
-   full_name='openfl.director.GetDatasetInfoResponse',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='shard_info', full_name='openfl.director.GetDatasetInfoResponse.shard_info', index=0,
-       number=1, type=11, cpp_type=10, label=1,
-       has_default_value=False, default_value=None,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=2093,
-   serialized_end=2165,
- )
- 
- 
- _GETMETRICSTREAMREQUEST = _descriptor.Descriptor(
-   name='GetMetricStreamRequest',
-   full_name='openfl.director.GetMetricStreamRequest',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='experiment_name', full_name='openfl.director.GetMetricStreamRequest.experiment_name', index=0,
-       number=1, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=2167,
-   serialized_end=2216,
- )
- 
- 
- _GETMETRICSTREAMRESPONSE = _descriptor.Descriptor(
-   name='GetMetricStreamResponse',
-   full_name='openfl.director.GetMetricStreamResponse',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='metric_origin', full_name='openfl.director.GetMetricStreamResponse.metric_origin', index=0,
-       number=1, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='task_name', full_name='openfl.director.GetMetricStreamResponse.task_name', index=1,
-       number=2, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='metric_name', full_name='openfl.director.GetMetricStreamResponse.metric_name', index=2,
-       number=3, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='metric_value', full_name='openfl.director.GetMetricStreamResponse.metric_value', index=3,
-       number=4, type=2, cpp_type=6, label=1,
-       has_default_value=False, default_value=float(0),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='round', full_name='openfl.director.GetMetricStreamResponse.round', index=4,
-       number=5, type=13, cpp_type=3, label=1,
-       has_default_value=False, default_value=0,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=2218,
-   serialized_end=2343,
- )
- 
- 
- _REMOVEEXPERIMENTREQUEST = _descriptor.Descriptor(
-   name='RemoveExperimentRequest',
-   full_name='openfl.director.RemoveExperimentRequest',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='experiment_name', full_name='openfl.director.RemoveExperimentRequest.experiment_name', index=0,
-       number=1, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=2345,
-   serialized_end=2395,
- )
- 
- 
- _REMOVEEXPERIMENTRESPONSE = _descriptor.Descriptor(
-   name='RemoveExperimentResponse',
-   full_name='openfl.director.RemoveExperimentResponse',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='acknowledgement', full_name='openfl.director.RemoveExperimentResponse.acknowledgement', index=0,
-       number=1, type=8, cpp_type=7, label=1,
-       has_default_value=False, default_value=False,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=2397,
-   serialized_end=2448,
- )
- 
- 
- _ENVOYINFO = _descriptor.Descriptor(
-   name='EnvoyInfo',
-   full_name='openfl.director.EnvoyInfo',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='shard_info', full_name='openfl.director.EnvoyInfo.shard_info', index=0,
-       number=1, type=11, cpp_type=10, label=1,
-       has_default_value=False, default_value=None,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='is_online', full_name='openfl.director.EnvoyInfo.is_online', index=1,
-       number=2, type=8, cpp_type=7, label=1,
-       has_default_value=False, default_value=False,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='is_experiment_running', full_name='openfl.director.EnvoyInfo.is_experiment_running', index=2,
-       number=3, type=8, cpp_type=7, label=1,
-       has_default_value=False, default_value=False,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='last_updated', full_name='openfl.director.EnvoyInfo.last_updated', index=3,
-       number=4, type=11, cpp_type=10, label=1,
-       has_default_value=False, default_value=None,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='valid_duration', full_name='openfl.director.EnvoyInfo.valid_duration', index=4,
-       number=5, type=11, cpp_type=10, label=1,
-       has_default_value=False, default_value=None,
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-     _descriptor.FieldDescriptor(
-       name='experiment_name', full_name='openfl.director.EnvoyInfo.experiment_name', index=5,
-       number=6, type=9, cpp_type=9, label=1,
-       has_default_value=False, default_value=b"".decode('utf-8'),
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=2451,
-   serialized_end=2686,
- )
- 
- 
- _GETENVOYSREQUEST = _descriptor.Descriptor(
-   name='GetEnvoysRequest',
-   full_name='openfl.director.GetEnvoysRequest',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=2688,
-   serialized_end=2706,
- )
- 
- 
- _GETENVOYSRESPONSE = _descriptor.Descriptor(
-   name='GetEnvoysResponse',
-   full_name='openfl.director.GetEnvoysResponse',
-   filename=None,
-   file=DESCRIPTOR,
-   containing_type=None,
-   create_key=_descriptor._internal_create_key,
-   fields=[
-     _descriptor.FieldDescriptor(
-       name='envoy_infos', full_name='openfl.director.GetEnvoysResponse.envoy_infos', index=0,
-       number=1, type=11, cpp_type=10, label=3,
-       has_default_value=False, default_value=[],
-       message_type=None, enum_type=None, containing_type=None,
-       is_extension=False, extension_scope=None,
-       serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-   ],
-   extensions=[
-   ],
-   nested_types=[],
-   enum_types=[
-   ],
-   serialized_options=None,
-   is_extendable=False,
-   syntax='proto3',
-   extension_ranges=[],
-   oneofs=[
-   ],
-   serialized_start=2708,
-   serialized_end=2776,
- )
- 
- _NODEINFO.fields_by_name['cuda_devices'].message_type = _CUDADEVICEINFO
- _SHARDINFO.fields_by_name['node_info'].message_type = _NODEINFO
- _UPDATESHARDINFOREQUEST.fields_by_name['shard_info'].message_type = _SHARDINFO
- _UPDATEENVOYSTATUSREQUEST.fields_by_name['cuda_devices'].message_type = _CUDADEVICEINFO
- _UPDATEENVOYSTATUSRESPONSE.fields_by_name['health_check_period'].message_type = google_dot_protobuf_dot_duration__pb2._DURATION
- _GETEXPERIMENTSLISTRESPONSE.fields_by_name['experiments'].message_type = _EXPERIMENTLISTITEM
- _GETEXPERIMENTDESCRIPTIONRESPONSE.fields_by_name['experiment'].message_type = openfl_dot_protocols_dot_base__pb2._EXPERIMENTDESCRIPTION
- _EXPERIMENTINFO.fields_by_name['experiment_data'].message_type = _EXPERIMENTDATA
- _EXPERIMENTINFO.fields_by_name['model_proto'].message_type = openfl_dot_protocols_dot_base__pb2._MODELPROTO
- _GETTRAINEDMODELREQUEST.fields_by_name['model_type'].enum_type = _GETTRAINEDMODELREQUEST_MODELTYPE
- _GETTRAINEDMODELREQUEST_MODELTYPE.containing_type = _GETTRAINEDMODELREQUEST
- _TRAINEDMODELRESPONSE.fields_by_name['model_proto'].message_type = openfl_dot_protocols_dot_base__pb2._MODELPROTO
- _GETDATASETINFORESPONSE.fields_by_name['shard_info'].message_type = _SHARDINFO
- _ENVOYINFO.fields_by_name['shard_info'].message_type = _SHARDINFO
- _ENVOYINFO.fields_by_name['last_updated'].message_type = google_dot_protobuf_dot_timestamp__pb2._TIMESTAMP
- _ENVOYINFO.fields_by_name['valid_duration'].message_type = google_dot_protobuf_dot_duration__pb2._DURATION
- _GETENVOYSRESPONSE.fields_by_name['envoy_infos'].message_type = _ENVOYINFO
- DESCRIPTOR.message_types_by_name['CudaDeviceInfo'] = _CUDADEVICEINFO
- DESCRIPTOR.message_types_by_name['NodeInfo'] = _NODEINFO
- DESCRIPTOR.message_types_by_name['ShardInfo'] = _SHARDINFO
- DESCRIPTOR.message_types_by_name['UpdateShardInfoRequest'] = _UPDATESHARDINFOREQUEST
- DESCRIPTOR.message_types_by_name['UpdateShardInfoResponse'] = _UPDATESHARDINFORESPONSE
- DESCRIPTOR.message_types_by_name['WaitExperimentRequest'] = _WAITEXPERIMENTREQUEST
- DESCRIPTOR.message_types_by_name['WaitExperimentResponse'] = _WAITEXPERIMENTRESPONSE
- DESCRIPTOR.message_types_by_name['GetExperimentDataRequest'] = _GETEXPERIMENTDATAREQUEST
- DESCRIPTOR.message_types_by_name['ExperimentData'] = _EXPERIMENTDATA
- DESCRIPTOR.message_types_by_name['UpdateEnvoyStatusRequest'] = _UPDATEENVOYSTATUSREQUEST
- DESCRIPTOR.message_types_by_name['UpdateEnvoyStatusResponse'] = _UPDATEENVOYSTATUSRESPONSE
- DESCRIPTOR.message_types_by_name['SetExperimentFailedRequest'] = _SETEXPERIMENTFAILEDREQUEST
- DESCRIPTOR.message_types_by_name['SetExperimentFailedResponse'] = _SETEXPERIMENTFAILEDRESPONSE
- DESCRIPTOR.message_types_by_name['GetExperimentsListRequest'] = _GETEXPERIMENTSLISTREQUEST
- DESCRIPTOR.message_types_by_name['ExperimentListItem'] = _EXPERIMENTLISTITEM
- DESCRIPTOR.message_types_by_name['GetExperimentsListResponse'] = _GETEXPERIMENTSLISTRESPONSE
- DESCRIPTOR.message_types_by_name['GetExperimentDescriptionRequest'] = _GETEXPERIMENTDESCRIPTIONREQUEST
- DESCRIPTOR.message_types_by_name['GetExperimentDescriptionResponse'] = _GETEXPERIMENTDESCRIPTIONRESPONSE
- DESCRIPTOR.message_types_by_name['ExperimentInfo'] = _EXPERIMENTINFO
- DESCRIPTOR.message_types_by_name['SetNewExperimentResponse'] = _SETNEWEXPERIMENTRESPONSE
- DESCRIPTOR.message_types_by_name['GetTrainedModelRequest'] = _GETTRAINEDMODELREQUEST
- DESCRIPTOR.message_types_by_name['TrainedModelResponse'] = _TRAINEDMODELRESPONSE
- DESCRIPTOR.message_types_by_name['GetDatasetInfoRequest'] = _GETDATASETINFOREQUEST
- DESCRIPTOR.message_types_by_name['GetDatasetInfoResponse'] = _GETDATASETINFORESPONSE
- DESCRIPTOR.message_types_by_name['GetMetricStreamRequest'] = _GETMETRICSTREAMREQUEST
- DESCRIPTOR.message_types_by_name['GetMetricStreamResponse'] = _GETMETRICSTREAMRESPONSE
- DESCRIPTOR.message_types_by_name['RemoveExperimentRequest'] = _REMOVEEXPERIMENTREQUEST
- DESCRIPTOR.message_types_by_name['RemoveExperimentResponse'] = _REMOVEEXPERIMENTRESPONSE
- DESCRIPTOR.message_types_by_name['EnvoyInfo'] = _ENVOYINFO
- DESCRIPTOR.message_types_by_name['GetEnvoysRequest'] = _GETENVOYSREQUEST
- DESCRIPTOR.message_types_by_name['GetEnvoysResponse'] = _GETENVOYSRESPONSE
- _sym_db.RegisterFileDescriptor(DESCRIPTOR)
- 
- CudaDeviceInfo = _reflection.GeneratedProtocolMessageType('CudaDeviceInfo', (_message.Message,), {
-   'DESCRIPTOR' : _CUDADEVICEINFO,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.CudaDeviceInfo)
-   })
- _sym_db.RegisterMessage(CudaDeviceInfo)
- 
- NodeInfo = _reflection.GeneratedProtocolMessageType('NodeInfo', (_message.Message,), {
-   'DESCRIPTOR' : _NODEINFO,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.NodeInfo)
-   })
- _sym_db.RegisterMessage(NodeInfo)
- 
- ShardInfo = _reflection.GeneratedProtocolMessageType('ShardInfo', (_message.Message,), {
-   'DESCRIPTOR' : _SHARDINFO,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.ShardInfo)
-   })
- _sym_db.RegisterMessage(ShardInfo)
- 
- UpdateShardInfoRequest = _reflection.GeneratedProtocolMessageType('UpdateShardInfoRequest', (_message.Message,), {
-   'DESCRIPTOR' : _UPDATESHARDINFOREQUEST,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.UpdateShardInfoRequest)
-   })
- _sym_db.RegisterMessage(UpdateShardInfoRequest)
- 
- UpdateShardInfoResponse = _reflection.GeneratedProtocolMessageType('UpdateShardInfoResponse', (_message.Message,), {
-   'DESCRIPTOR' : _UPDATESHARDINFORESPONSE,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.UpdateShardInfoResponse)
-   })
- _sym_db.RegisterMessage(UpdateShardInfoResponse)
- 
- WaitExperimentRequest = _reflection.GeneratedProtocolMessageType('WaitExperimentRequest', (_message.Message,), {
-   'DESCRIPTOR' : _WAITEXPERIMENTREQUEST,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.WaitExperimentRequest)
-   })
- _sym_db.RegisterMessage(WaitExperimentRequest)
- 
- WaitExperimentResponse = _reflection.GeneratedProtocolMessageType('WaitExperimentResponse', (_message.Message,), {
-   'DESCRIPTOR' : _WAITEXPERIMENTRESPONSE,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.WaitExperimentResponse)
-   })
- _sym_db.RegisterMessage(WaitExperimentResponse)
- 
- GetExperimentDataRequest = _reflection.GeneratedProtocolMessageType('GetExperimentDataRequest', (_message.Message,), {
-   'DESCRIPTOR' : _GETEXPERIMENTDATAREQUEST,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.GetExperimentDataRequest)
-   })
- _sym_db.RegisterMessage(GetExperimentDataRequest)
- 
- ExperimentData = _reflection.GeneratedProtocolMessageType('ExperimentData', (_message.Message,), {
-   'DESCRIPTOR' : _EXPERIMENTDATA,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.ExperimentData)
-   })
- _sym_db.RegisterMessage(ExperimentData)
- 
- UpdateEnvoyStatusRequest = _reflection.GeneratedProtocolMessageType('UpdateEnvoyStatusRequest', (_message.Message,), {
-   'DESCRIPTOR' : _UPDATEENVOYSTATUSREQUEST,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.UpdateEnvoyStatusRequest)
-   })
- _sym_db.RegisterMessage(UpdateEnvoyStatusRequest)
- 
- UpdateEnvoyStatusResponse = _reflection.GeneratedProtocolMessageType('UpdateEnvoyStatusResponse', (_message.Message,), {
-   'DESCRIPTOR' : _UPDATEENVOYSTATUSRESPONSE,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.UpdateEnvoyStatusResponse)
-   })
- _sym_db.RegisterMessage(UpdateEnvoyStatusResponse)
- 
- SetExperimentFailedRequest = _reflection.GeneratedProtocolMessageType('SetExperimentFailedRequest', (_message.Message,), {
-   'DESCRIPTOR' : _SETEXPERIMENTFAILEDREQUEST,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.SetExperimentFailedRequest)
-   })
- _sym_db.RegisterMessage(SetExperimentFailedRequest)
- 
- SetExperimentFailedResponse = _reflection.GeneratedProtocolMessageType('SetExperimentFailedResponse', (_message.Message,), {
-   'DESCRIPTOR' : _SETEXPERIMENTFAILEDRESPONSE,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.SetExperimentFailedResponse)
-   })
- _sym_db.RegisterMessage(SetExperimentFailedResponse)
- 
- GetExperimentsListRequest = _reflection.GeneratedProtocolMessageType('GetExperimentsListRequest', (_message.Message,), {
-   'DESCRIPTOR' : _GETEXPERIMENTSLISTREQUEST,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.GetExperimentsListRequest)
-   })
- _sym_db.RegisterMessage(GetExperimentsListRequest)
- 
- ExperimentListItem = _reflection.GeneratedProtocolMessageType('ExperimentListItem', (_message.Message,), {
-   'DESCRIPTOR' : _EXPERIMENTLISTITEM,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.ExperimentListItem)
-   })
- _sym_db.RegisterMessage(ExperimentListItem)
- 
- GetExperimentsListResponse = _reflection.GeneratedProtocolMessageType('GetExperimentsListResponse', (_message.Message,), {
-   'DESCRIPTOR' : _GETEXPERIMENTSLISTRESPONSE,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.GetExperimentsListResponse)
-   })
- _sym_db.RegisterMessage(GetExperimentsListResponse)
- 
- GetExperimentDescriptionRequest = _reflection.GeneratedProtocolMessageType('GetExperimentDescriptionRequest', (_message.Message,), {
-   'DESCRIPTOR' : _GETEXPERIMENTDESCRIPTIONREQUEST,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.GetExperimentDescriptionRequest)
-   })
- _sym_db.RegisterMessage(GetExperimentDescriptionRequest)
- 
- GetExperimentDescriptionResponse = _reflection.GeneratedProtocolMessageType('GetExperimentDescriptionResponse', (_message.Message,), {
-   'DESCRIPTOR' : _GETEXPERIMENTDESCRIPTIONRESPONSE,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.GetExperimentDescriptionResponse)
-   })
- _sym_db.RegisterMessage(GetExperimentDescriptionResponse)
- 
- ExperimentInfo = _reflection.GeneratedProtocolMessageType('ExperimentInfo', (_message.Message,), {
-   'DESCRIPTOR' : _EXPERIMENTINFO,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.ExperimentInfo)
-   })
- _sym_db.RegisterMessage(ExperimentInfo)
- 
- SetNewExperimentResponse = _reflection.GeneratedProtocolMessageType('SetNewExperimentResponse', (_message.Message,), {
-   'DESCRIPTOR' : _SETNEWEXPERIMENTRESPONSE,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.SetNewExperimentResponse)
-   })
- _sym_db.RegisterMessage(SetNewExperimentResponse)
- 
- GetTrainedModelRequest = _reflection.GeneratedProtocolMessageType('GetTrainedModelRequest', (_message.Message,), {
-   'DESCRIPTOR' : _GETTRAINEDMODELREQUEST,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.GetTrainedModelRequest)
-   })
- _sym_db.RegisterMessage(GetTrainedModelRequest)
- 
- TrainedModelResponse = _reflection.GeneratedProtocolMessageType('TrainedModelResponse', (_message.Message,), {
-   'DESCRIPTOR' : _TRAINEDMODELRESPONSE,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.TrainedModelResponse)
-   })
- _sym_db.RegisterMessage(TrainedModelResponse)
- 
- GetDatasetInfoRequest = _reflection.GeneratedProtocolMessageType('GetDatasetInfoRequest', (_message.Message,), {
-   'DESCRIPTOR' : _GETDATASETINFOREQUEST,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.GetDatasetInfoRequest)
-   })
- _sym_db.RegisterMessage(GetDatasetInfoRequest)
- 
- GetDatasetInfoResponse = _reflection.GeneratedProtocolMessageType('GetDatasetInfoResponse', (_message.Message,), {
-   'DESCRIPTOR' : _GETDATASETINFORESPONSE,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.GetDatasetInfoResponse)
-   })
- _sym_db.RegisterMessage(GetDatasetInfoResponse)
- 
- GetMetricStreamRequest = _reflection.GeneratedProtocolMessageType('GetMetricStreamRequest', (_message.Message,), {
-   'DESCRIPTOR' : _GETMETRICSTREAMREQUEST,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.GetMetricStreamRequest)
-   })
- _sym_db.RegisterMessage(GetMetricStreamRequest)
- 
- GetMetricStreamResponse = _reflection.GeneratedProtocolMessageType('GetMetricStreamResponse', (_message.Message,), {
-   'DESCRIPTOR' : _GETMETRICSTREAMRESPONSE,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.GetMetricStreamResponse)
-   })
- _sym_db.RegisterMessage(GetMetricStreamResponse)
- 
- RemoveExperimentRequest = _reflection.GeneratedProtocolMessageType('RemoveExperimentRequest', (_message.Message,), {
-   'DESCRIPTOR' : _REMOVEEXPERIMENTREQUEST,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.RemoveExperimentRequest)
-   })
- _sym_db.RegisterMessage(RemoveExperimentRequest)
- 
- RemoveExperimentResponse = _reflection.GeneratedProtocolMessageType('RemoveExperimentResponse', (_message.Message,), {
-   'DESCRIPTOR' : _REMOVEEXPERIMENTRESPONSE,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.RemoveExperimentResponse)
-   })
- _sym_db.RegisterMessage(RemoveExperimentResponse)
- 
- EnvoyInfo = _reflection.GeneratedProtocolMessageType('EnvoyInfo', (_message.Message,), {
-   'DESCRIPTOR' : _ENVOYINFO,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.EnvoyInfo)
-   })
- _sym_db.RegisterMessage(EnvoyInfo)
- 
- GetEnvoysRequest = _reflection.GeneratedProtocolMessageType('GetEnvoysRequest', (_message.Message,), {
-   'DESCRIPTOR' : _GETENVOYSREQUEST,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.GetEnvoysRequest)
-   })
- _sym_db.RegisterMessage(GetEnvoysRequest)
- 
- GetEnvoysResponse = _reflection.GeneratedProtocolMessageType('GetEnvoysResponse', (_message.Message,), {
-   'DESCRIPTOR' : _GETENVOYSRESPONSE,
-   '__module__' : 'openfl.protocols.director_pb2'
-   # @@protoc_insertion_point(class_scope:openfl.director.GetEnvoysResponse)
-   })
- _sym_db.RegisterMessage(GetEnvoysResponse)
- 
- 
- 
- _DIRECTOR = _descriptor.ServiceDescriptor(
-   name='Director',
-   full_name='openfl.director.Director',
-   file=DESCRIPTOR,
-   index=0,
-   serialized_options=None,
-   create_key=_descriptor._internal_create_key,
-   serialized_start=2779,
-   serialized_end=4175,
-   methods=[
-   _descriptor.MethodDescriptor(
-     name='UpdateShardInfo',
-     full_name='openfl.director.Director.UpdateShardInfo',
-     index=0,
-     containing_service=None,
-     input_type=_UPDATESHARDINFOREQUEST,
-     output_type=_UPDATESHARDINFORESPONSE,
-     serialized_options=None,
-     create_key=_descriptor._internal_create_key,
-   ),
-   _descriptor.MethodDescriptor(
-     name='WaitExperiment',
-     full_name='openfl.director.Director.WaitExperiment',
-     index=1,
-     containing_service=None,
-     input_type=_WAITEXPERIMENTREQUEST,
-     output_type=_WAITEXPERIMENTRESPONSE,
-     serialized_options=None,
-     create_key=_descriptor._internal_create_key,
-   ),
-   _descriptor.MethodDescriptor(
-     name='GetExperimentData',
-     full_name='openfl.director.Director.GetExperimentData',
-     index=2,
-     containing_service=None,
-     input_type=_GETEXPERIMENTDATAREQUEST,
-     output_type=_EXPERIMENTDATA,
-     serialized_options=None,
-     create_key=_descriptor._internal_create_key,
-   ),
-   _descriptor.MethodDescriptor(
-     name='UpdateEnvoyStatus',
-     full_name='openfl.director.Director.UpdateEnvoyStatus',
-     index=3,
-     containing_service=None,
-     input_type=_UPDATEENVOYSTATUSREQUEST,
-     output_type=_UPDATEENVOYSTATUSRESPONSE,
-     serialized_options=None,
-     create_key=_descriptor._internal_create_key,
-   ),
-   _descriptor.MethodDescriptor(
-     name='SetExperimentFailed',
-     full_name='openfl.director.Director.SetExperimentFailed',
-     index=4,
-     containing_service=None,
-     input_type=_SETEXPERIMENTFAILEDREQUEST,
-     output_type=_SETEXPERIMENTFAILEDRESPONSE,
-     serialized_options=None,
-     create_key=_descriptor._internal_create_key,
-   ),
-   _descriptor.MethodDescriptor(
-     name='GetExperimentDescription',
-     full_name='openfl.director.Director.GetExperimentDescription',
-     index=5,
-     containing_service=None,
-     input_type=_GETEXPERIMENTDESCRIPTIONREQUEST,
-     output_type=_GETEXPERIMENTDESCRIPTIONRESPONSE,
-     serialized_options=None,
-     create_key=_descriptor._internal_create_key,
-   ),
-   _descriptor.MethodDescriptor(
-     name='GetExperimentsList',
-     full_name='openfl.director.Director.GetExperimentsList',
-     index=6,
-     containing_service=None,
-     input_type=_GETEXPERIMENTSLISTREQUEST,
-     output_type=_GETEXPERIMENTSLISTRESPONSE,
-     serialized_options=None,
-     create_key=_descriptor._internal_create_key,
-   ),
-   _descriptor.MethodDescriptor(
-     name='SetNewExperiment',
-     full_name='openfl.director.Director.SetNewExperiment',
-     index=7,
-     containing_service=None,
-     input_type=_EXPERIMENTINFO,
-     output_type=_SETNEWEXPERIMENTRESPONSE,
-     serialized_options=None,
-     create_key=_descriptor._internal_create_key,
-   ),
-   _descriptor.MethodDescriptor(
-     name='GetDatasetInfo',
-     full_name='openfl.director.Director.GetDatasetInfo',
-     index=8,
-     containing_service=None,
-     input_type=_GETDATASETINFOREQUEST,
-     output_type=_GETDATASETINFORESPONSE,
-     serialized_options=None,
-     create_key=_descriptor._internal_create_key,
-   ),
-   _descriptor.MethodDescriptor(
-     name='GetTrainedModel',
-     full_name='openfl.director.Director.GetTrainedModel',
-     index=9,
-     containing_service=None,
-     input_type=_GETTRAINEDMODELREQUEST,
-     output_type=_TRAINEDMODELRESPONSE,
-     serialized_options=None,
-     create_key=_descriptor._internal_create_key,
-   ),
-   _descriptor.MethodDescriptor(
-     name='GetMetricStream',
-     full_name='openfl.director.Director.GetMetricStream',
-     index=10,
-     containing_service=None,
-     input_type=_GETMETRICSTREAMREQUEST,
-     output_type=_GETMETRICSTREAMRESPONSE,
-     serialized_options=None,
-     create_key=_descriptor._internal_create_key,
-   ),
-   _descriptor.MethodDescriptor(
-     name='RemoveExperimentData',
-     full_name='openfl.director.Director.RemoveExperimentData',
-     index=11,
-     containing_service=None,
-     input_type=_REMOVEEXPERIMENTREQUEST,
-     output_type=_REMOVEEXPERIMENTRESPONSE,
-     serialized_options=None,
-     create_key=_descriptor._internal_create_key,
-   ),
-   _descriptor.MethodDescriptor(
-     name='GetEnvoys',
-     full_name='openfl.director.Director.GetEnvoys',
-     index=12,
-     containing_service=None,
-     input_type=_GETENVOYSREQUEST,
-     output_type=_GETENVOYSRESPONSE,
-     serialized_options=None,
-     create_key=_descriptor._internal_create_key,
-   ),
- ])
- _sym_db.RegisterServiceDescriptor(_DIRECTOR)
- 
- DESCRIPTOR.services_by_name['Director'] = _DIRECTOR
- 
- # @@protoc_insertion_point(module_scope)
--- 0 ----
diff -crB --new-file ./openfl/openfl/protocols/director.proto ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols/director.proto
*** ./openfl/openfl/protocols/director.proto	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols/director.proto	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,196 ****
- // Copyright (C) 2020-2021 Intel Corporation
- // Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- syntax = "proto3";
- 
- package openfl.director;
- 
- import "google/protobuf/timestamp.proto";
- import "google/protobuf/duration.proto";
- import "openfl/protocols/base.proto";
- 
- service Director {
-   // 1. Envoy RPCs
-   rpc UpdateShardInfo(UpdateShardInfoRequest) returns (UpdateShardInfoResponse) {}
-   // Shard owner could also provide some public data for tests
-   rpc WaitExperiment(stream WaitExperimentRequest) returns (stream WaitExperimentResponse) {}
-   rpc GetExperimentData(GetExperimentDataRequest) returns (stream ExperimentData) {}
-   rpc UpdateEnvoyStatus(UpdateEnvoyStatusRequest) returns (UpdateEnvoyStatusResponse) {}
-   rpc SetExperimentFailed (SetExperimentFailedRequest) returns (SetExperimentFailedResponse) {}
- 
-   // 2. Frontend RPCs
-   // 2.1 Extension RPCs
-   rpc GetExperimentDescription(GetExperimentDescriptionRequest)
-     returns (GetExperimentDescriptionResponse) {}
-   rpc GetExperimentsList(GetExperimentsListRequest) returns (GetExperimentsListResponse){}
- 
-   // 2.2 API RPCs
-   rpc SetNewExperiment(stream ExperimentInfo) returns (SetNewExperimentResponse) {}
-   rpc GetDatasetInfo(GetDatasetInfoRequest) returns (GetDatasetInfoResponse) {}
-   rpc GetTrainedModel(GetTrainedModelRequest) returns (TrainedModelResponse) {}
-   rpc GetMetricStream(GetMetricStreamRequest) returns (stream GetMetricStreamResponse) {}
-   rpc RemoveExperimentData(RemoveExperimentRequest) returns (RemoveExperimentResponse) {}
-   rpc GetEnvoys(GetEnvoysRequest) returns (GetEnvoysResponse) {}
- }
- 
- message CudaDeviceInfo {
-   uint64 index = 1;
-   uint64 memory_total = 2;
-   uint64 memory_utilized = 3;
-   string device_utilization = 4;
-   string cuda_driver_version = 5;
-   string cuda_version = 6;
-   string name = 7;
- }
- 
- // Envoy Messages
- 
- message NodeInfo {
-   string name = 1;
-   repeated CudaDeviceInfo cuda_devices = 2;
- }
- 
- message ShardInfo {
-   NodeInfo node_info = 1;
-   string shard_description = 2;
-   uint64 n_samples = 3;
-   // We just pass numpy shapes
-   repeated string sample_shape = 4;
-   repeated string target_shape = 5;
- }
- 
- message UpdateShardInfoRequest {
-   ShardInfo shard_info = 1;
- }
- 
- message UpdateShardInfoResponse {
-   bool accepted = 1;
- }
- 
- message WaitExperimentRequest {
-   string collaborator_name = 1;
- }
- 
- message WaitExperimentResponse {
-   string experiment_name = 1;
- }
- 
- message GetExperimentDataRequest {
-   string experiment_name = 1;
-   string collaborator_name = 2;
- }
- 
- message ExperimentData {
-   uint32 size = 1; // size, in bytes, of the data sent in npbytes
-   bytes npbytes = 2; //actual data
- }
- 
- message UpdateEnvoyStatusRequest {
-   string name = 1;
-   bool is_experiment_running = 2;
-   repeated CudaDeviceInfo cuda_devices = 3;
- }
- 
- message UpdateEnvoyStatusResponse {
-   google.protobuf.Duration health_check_period = 1;
- }
- 
- message SetExperimentFailedRequest {
-   string experiment_name = 1;
-   string collaborator_name = 2;
-   uint32 error_code = 3;
-   string error_description = 4;
- }
- 
- message SetExperimentFailedResponse {}
- 
- // Frontend. Extension Messages.
- 
- message GetExperimentsListRequest {}
- 
- message ExperimentListItem {
-   string name = 1;
-   string status = 2;
-   uint32 collaborators_amount = 3;
-   uint32 tasks_amount = 4;
-   float progress = 5;
- }
- 
- message GetExperimentsListResponse {
-   repeated ExperimentListItem experiments = 1;
- }
- 
- message GetExperimentDescriptionRequest {
-   string name = 1;
- }
- 
- message GetExperimentDescriptionResponse {
-   ExperimentDescription experiment = 1;
- }
- 
- // Frontend. API Messages
- 
- message ExperimentInfo {
-   string name = 1;
-   repeated string collaborator_names = 2;
-   ExperimentData experiment_data = 3;
-   ModelProto model_proto = 4;
- }
- 
- message SetNewExperimentResponse{
-   bool accepted = 1;
- }
- 
- message GetTrainedModelRequest {
-   enum ModelType {
-     BEST_MODEL = 0;
-     LAST_MODEL = 1;
-   }
-   string experiment_name = 2;
-   ModelType model_type = 3;
- }
- 
- message TrainedModelResponse {
-   ModelProto model_proto = 1;
- }
- 
- message GetDatasetInfoRequest {}
- 
- message GetDatasetInfoResponse {
-   ShardInfo shard_info = 1;
- }
- 
- message GetMetricStreamRequest {
-   string experiment_name = 1;
- }
- 
- message GetMetricStreamResponse {
-   string metric_origin = 1;
-   string task_name = 2;
-   string metric_name = 3;
-   float metric_value = 4;
-   uint32 round = 5;
- }
- 
- message RemoveExperimentRequest {
-   string experiment_name = 1;
- }
- 
- message RemoveExperimentResponse {
-   bool acknowledgement = 1;
- }
- 
- message EnvoyInfo {
-   ShardInfo shard_info = 1;
-   bool is_online = 2;
-   bool is_experiment_running = 3;
-   google.protobuf.Timestamp last_updated = 4;
-   google.protobuf.Duration valid_duration = 5;
-   string experiment_name = 6;
- }
- 
- message GetEnvoysRequest {}
- 
- message GetEnvoysResponse {
-   repeated EnvoyInfo envoy_infos = 1;
- }
--- 0 ----
diff -crB --new-file ./openfl/openfl/protocols/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols/__init__.py
*** ./openfl/openfl/protocols/__init__.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """openfl.protocols module."""
--- 0 ----
diff -crB --new-file ./openfl/openfl/protocols/interceptors.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols/interceptors.py
*** ./openfl/openfl/protocols/interceptors.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols/interceptors.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,78 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """gRPC interceptors module."""
- import collections
- 
- import grpc
- 
- 
- class _GenericClientInterceptor(grpc.UnaryUnaryClientInterceptor,
-                                 grpc.UnaryStreamClientInterceptor,
-                                 grpc.StreamUnaryClientInterceptor,
-                                 grpc.StreamStreamClientInterceptor):
- 
-     def __init__(self, interceptor_function):
-         self._fn = interceptor_function
- 
-     def intercept_unary_unary(self, continuation, client_call_details, request):
-         new_details, new_request_iterator, postprocess = self._fn(
-             client_call_details, iter((request,)), False, False)
-         response = continuation(new_details, next(new_request_iterator))
-         return postprocess(response) if postprocess else response
- 
-     def intercept_unary_stream(self, continuation, client_call_details,
-                                request):
-         new_details, new_request_iterator, postprocess = self._fn(
-             client_call_details, iter((request,)), False, True)
-         response_it = continuation(new_details, next(new_request_iterator))
-         return postprocess(response_it) if postprocess else response_it
- 
-     def intercept_stream_unary(self, continuation, client_call_details,
-                                request_iterator):
-         new_details, new_request_iterator, postprocess = self._fn(
-             client_call_details, request_iterator, True, False)
-         response = continuation(new_details, new_request_iterator)
-         return postprocess(response) if postprocess else response
- 
-     def intercept_stream_stream(self, continuation, client_call_details,
-                                 request_iterator):
-         new_details, new_request_iterator, postprocess = self._fn(
-             client_call_details, request_iterator, True, True)
-         response_it = continuation(new_details, new_request_iterator)
-         return postprocess(response_it) if postprocess else response_it
- 
- 
- def _create_generic_interceptor(intercept_call):
-     return _GenericClientInterceptor(intercept_call)
- 
- 
- class _ClientCallDetails(
-     collections.namedtuple(
-         '_ClientCallDetails',
-         ('method', 'timeout', 'metadata', 'credentials')
-     ),
-     grpc.ClientCallDetails
- ):
-     pass
- 
- 
- def headers_adder(headers):
-     """Create interceptor with added headers."""
- 
-     def intercept_call(client_call_details, request_iterator, request_streaming,
-                        response_streaming):
-         metadata = []
-         if client_call_details.metadata is not None:
-             metadata = list(client_call_details.metadata)
-         for header, value in headers.items():
-             metadata.append((
-                 header,
-                 value,
-             ))
-         client_call_details = _ClientCallDetails(
-             client_call_details.method, client_call_details.timeout, metadata,
-             client_call_details.credentials)
-         return client_call_details, request_iterator, None
- 
-     return _create_generic_interceptor(intercept_call)
--- 0 ----
diff -crB --new-file ./openfl/openfl/protocols/README.md ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols/README.md
*** ./openfl/openfl/protocols/README.md	2022-11-18 11:08:33.047181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols/README.md	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,9 ****
- # Compile Protocol Buffers description files
- 
- After changing proto files run 
- ```
- ./compile_proto.sh
- ```
- to recompile. It will delete old generated python 
- files (*_pb2.py and *_pb2_grpc.py) and generate new.
- Generated files should be committed with proto files.
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl/protocols/utils.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols/utils.py
*** ./openfl/openfl/protocols/utils.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols/utils.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,262 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Proto utils."""
- 
- from openfl.protocols import base_pb2
- from openfl.utilities import TensorKey
- 
- 
- def model_proto_to_bytes_and_metadata(model_proto):
-     """Convert the model protobuf to bytes and metadata.
- 
-     Args:
-         model_proto: Protobuf of the model
- 
-     Returns:
-         bytes_dict: Dictionary of the bytes contained in the model protobuf
-         metadata_dict: Dictionary of the meta data in the model protobuf
-     """
-     bytes_dict = {}
-     metadata_dict = {}
-     round_number = None
-     for tensor_proto in model_proto.tensors:
-         bytes_dict[tensor_proto.name] = tensor_proto.data_bytes
-         metadata_dict[tensor_proto.name] = [{
-             'int_to_float': proto.int_to_float,
-             'int_list': proto.int_list,
-             'bool_list': proto.bool_list
-         }
-             for proto in tensor_proto.transformer_metadata
-         ]
-         if round_number is None:
-             round_number = tensor_proto.round_number
-         else:
-             assert round_number == tensor_proto.round_number, (
-                 f'Round numbers in model are inconsistent: {round_number} '
-                 f'and {tensor_proto.round_number}'
-             )
-     return bytes_dict, metadata_dict, round_number
- 
- 
- def bytes_and_metadata_to_model_proto(bytes_dict, model_id, model_version,
-                                       is_delta, metadata_dict):
-     """Convert bytes and metadata to model protobuf."""
-     model_header = ModelHeader(id=model_id, version=model_version, is_delta=is_delta)  # NOQA:F821
- 
-     tensor_protos = []
-     for key, data_bytes in bytes_dict.items():
-         transformer_metadata = metadata_dict[key]
-         metadata_protos = []
-         for metadata in transformer_metadata:
-             if metadata.get('int_to_float') is not None:
-                 int_to_float = metadata.get('int_to_float')
-             else:
-                 int_to_float = {}
- 
-             if metadata.get('int_list') is not None:
-                 int_list = metadata.get('int_list')
-             else:
-                 int_list = []
- 
-             if metadata.get('bool_list') is not None:
-                 bool_list = metadata.get('bool_list')
-             else:
-                 bool_list = []
-             metadata_protos.append(base_pb2.MetadataProto(
-                 int_to_float=int_to_float,
-                 int_list=int_list,
-                 bool_list=bool_list,
-             ))
-         tensor_protos.append(TensorProto(name=key,  # NOQA:F821
-                                          data_bytes=data_bytes,
-                                          transformer_metadata=metadata_protos))
-     return base_pb2.ModelProto(header=model_header, tensors=tensor_protos)
- 
- 
- def construct_named_tensor(tensor_key, nparray, transformer_metadata, lossless):
-     """Construct named tensor."""
-     metadata_protos = []
-     for metadata in transformer_metadata:
-         if metadata.get('int_to_float') is not None:
-             int_to_float = metadata.get('int_to_float')
-         else:
-             int_to_float = {}
- 
-         if metadata.get('int_list') is not None:
-             int_list = metadata.get('int_list')
-         else:
-             int_list = []
- 
-         if metadata.get('bool_list') is not None:
-             bool_list = metadata.get('bool_list')
-         else:
-             bool_list = []
-         metadata_protos.append(base_pb2.MetadataProto(
-             int_to_float=int_to_float,
-             int_list=int_list,
-             bool_list=bool_list,
-         ))
- 
-     tensor_name, origin, round_number, report, tags = tensor_key
- 
-     return base_pb2.NamedTensor(
-         name=tensor_name,
-         round_number=round_number,
-         lossless=lossless,
-         report=report,
-         tags=tags,
-         transformer_metadata=metadata_protos,
-         data_bytes=nparray,
-     )
- 
- 
- def construct_proto(tensor_dict, model_id, model_version, is_delta, compression_pipeline):
-     """Construct proto."""
-     # compress the arrays in the tensor_dict, and form the model proto
-     # TODO: Hold-out tensors from the compression pipeline.
-     bytes_dict = {}
-     metadata_dict = {}
-     for key, array in tensor_dict.items():
-         bytes_dict[key], metadata_dict[key] = compression_pipeline.forward(data=array)
- 
-     # convert the compressed_tensor_dict and metadata to protobuf, and make the new model proto
-     model_proto = bytes_and_metadata_to_model_proto(bytes_dict=bytes_dict,
-                                                     model_id=model_id,
-                                                     model_version=model_version,
-                                                     is_delta=is_delta,
-                                                     metadata_dict=metadata_dict)
-     return model_proto
- 
- 
- def construct_model_proto(tensor_dict, round_number, tensor_pipe):
-     """Construct model proto from tensor dict."""
-     # compress the arrays in the tensor_dict, and form the model proto
-     # TODO: Hold-out tensors from the tensor compression pipeline.
-     named_tensors = []
-     for key, nparray in tensor_dict.items():
-         bytes_data, transformer_metadata = tensor_pipe.forward(data=nparray)
-         tensor_key = TensorKey(key, 'agg', round_number, False, ('model',))
-         named_tensors.append(construct_named_tensor(
-             tensor_key,
-             bytes_data,
-             transformer_metadata,
-             lossless=True,
-         ))
- 
-     return base_pb2.ModelProto(tensors=named_tensors)
- 
- 
- def deconstruct_model_proto(model_proto, compression_pipeline):
-     """Deconstruct model proto."""
-     # extract the tensor_dict and metadata
-     bytes_dict, metadata_dict, round_number = model_proto_to_bytes_and_metadata(model_proto)
- 
-     # decompress the tensors
-     # TODO: Handle tensors meant to be held-out from the compression pipeline
-     #  (currently none are held out).
-     tensor_dict = {}
-     for key in bytes_dict:
-         tensor_dict[key] = compression_pipeline.backward(data=bytes_dict[key],
-                                                          transformer_metadata=metadata_dict[key])
-     return tensor_dict, round_number
- 
- 
- def deconstruct_proto(model_proto, compression_pipeline):
-     """Deconstruct the protobuf.
- 
-     Args:
-         model_proto: The protobuf of the model
-         compression_pipeline: The compression pipeline object
- 
-     Returns:
-         protobuf: A protobuf of the model
-     """
-     # extract the tensor_dict and metadata
-     bytes_dict, metadata_dict = model_proto_to_bytes_and_metadata(model_proto)
- 
-     # decompress the tensors
-     # TODO: Handle tensors meant to be held-out from the compression pipeline
-     #  (currently none are held out).
-     tensor_dict = {}
-     for key in bytes_dict:
-         tensor_dict[key] = compression_pipeline.backward(data=bytes_dict[key],
-                                                          transformer_metadata=metadata_dict[key])
-     return tensor_dict
- 
- 
- def load_proto(fpath):
-     """Load the protobuf.
- 
-     Args:
-         fpath: The filepath for the protobuf
- 
-     Returns:
-         protobuf: A protobuf of the model
-     """
-     with open(fpath, 'rb') as f:
-         loaded = f.read()
-         model = base_pb2.ModelProto().FromString(loaded)
-         return model
- 
- 
- def dump_proto(model_proto, fpath):
-     """Dump the protobuf to a file.
- 
-     Args:
-         model_proto: The protobuf of the model
-         fpath: The filename to save the model protobuf
- 
-     """
-     s = model_proto.SerializeToString()
-     with open(fpath, 'wb') as f:
-         f.write(s)
- 
- 
- def datastream_to_proto(proto, stream, logger=None):
-     """Convert the datastream to the protobuf.
- 
-     Args:
-         model_proto: The protobuf of the model
-         stream: The data stream from the remote connection
-         logger: (Optional) The log object
- 
-     Returns:
-         protobuf: A protobuf of the model
-     """
-     npbytes = b''
-     for chunk in stream:
-         npbytes += chunk.npbytes
- 
-     if len(npbytes) > 0:
-         proto.ParseFromString(npbytes)
-         if logger is not None:
-             logger.debug(f'datastream_to_proto parsed a {type(proto)}.')
-         return proto
-     else:
-         raise RuntimeError(f'Received empty stream message of type {type(proto)}')
- 
- 
- def proto_to_datastream(proto, logger, max_buffer_size=(2 * 1024 * 1024)):
-     """Convert the protobuf to the datastream for the remote connection.
- 
-     Args:
-         model_proto: The protobuf of the model
-         logger: The log object
-         max_buffer_size: The buffer size (Default= 2*1024*1024)
-     Returns:
-         reply: The message for the remote connection.
-     """
-     npbytes = proto.SerializeToString()
-     data_size = len(npbytes)
-     buffer_size = data_size if max_buffer_size > data_size else max_buffer_size
-     logger.debug(f'Setting stream chunks with size {buffer_size} for proto of type {type(proto)}')
- 
-     for i in range(0, data_size, buffer_size):
-         chunk = npbytes[i: i + buffer_size]
-         reply = base_pb2.DataStream(npbytes=chunk, size=len(chunk))
-         yield reply
- 
- 
- def get_headers(context) -> dict:
-     """Get headers from context."""
-     return {header[0]: header[1] for header in context.invocation_metadata()}
--- 0 ----
diff -crB --new-file ./openfl/openfl/transport/grpc/aggregator_client.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/transport/grpc/aggregator_client.py
*** ./openfl/openfl/transport/grpc/aggregator_client.py	2022-11-18 11:08:33.047181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/transport/grpc/aggregator_client.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,321 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """AggregatorGRPCClient module."""
- 
- import time
- from logging import getLogger
- from typing import Optional
- from typing import Tuple
- 
- import grpc
- 
- from openfl.pipelines import NoCompressionPipeline
- from openfl.protocols import aggregator_pb2
- from openfl.protocols import aggregator_pb2_grpc
- from openfl.protocols import utils
- from openfl.utilities import check_equal
- 
- 
- class ConstantBackoff:
-     """Constant Backoff policy."""
- 
-     def __init__(self, reconnect_interval, logger, uri):
-         """Initialize Constant Backoff."""
-         self.reconnect_interval = reconnect_interval
-         self.logger = logger
-         self.uri = uri
- 
-     def sleep(self):
-         """Sleep for specified interval."""
-         self.logger.info(f'Attempting to connect to aggregator at {self.uri}')
-         time.sleep(self.reconnect_interval)
- 
- 
- class RetryOnRpcErrorClientInterceptor(
-     grpc.UnaryUnaryClientInterceptor, grpc.StreamUnaryClientInterceptor
- ):
-     """Retry gRPC connection on failure."""
- 
-     def __init__(
-             self,
-             sleeping_policy,
-             status_for_retry: Optional[Tuple[grpc.StatusCode]] = None,
-     ):
-         """Initialize function for gRPC retry."""
-         self.sleeping_policy = sleeping_policy
-         self.status_for_retry = status_for_retry
- 
-     def _intercept_call(self, continuation, client_call_details, request_or_iterator):
-         """Intercept the call to the gRPC server."""
-         while True:
-             response = continuation(client_call_details, request_or_iterator)
- 
-             if isinstance(response, grpc.RpcError):
- 
-                 # If status code is not in retryable status codes
-                 self.sleeping_policy.logger.info(f'Response code: {response.code()}')
-                 if (
-                         self.status_for_retry
-                         and response.code() not in self.status_for_retry
-                 ):
-                     return response
- 
-                 self.sleeping_policy.sleep()
-             else:
-                 return response
- 
-     def intercept_unary_unary(self, continuation, client_call_details, request):
-         """Wrap intercept call for unary->unary RPC."""
-         return self._intercept_call(continuation, client_call_details, request)
- 
-     def intercept_stream_unary(
-             self, continuation, client_call_details, request_iterator
-     ):
-         """Wrap intercept call for stream->unary RPC."""
-         return self._intercept_call(continuation, client_call_details, request_iterator)
- 
- 
- def _atomic_connection(func):
-     def wrapper(self, *args, **kwargs):
-         self.reconnect()
-         response = func(self, *args, **kwargs)
-         self.disconnect()
-         return response
- 
-     return wrapper
- 
- 
- class AggregatorGRPCClient:
-     """Client to the aggregator over gRPC-TLS."""
- 
-     def __init__(self,
-                  agg_addr,
-                  agg_port,
-                  tls,
-                  disable_client_auth,
-                  root_certificate,
-                  certificate,
-                  private_key,
-                  aggregator_uuid=None,
-                  federation_uuid=None,
-                  single_col_cert_common_name=None,
-                  **kwargs):
-         """Initialize."""
-         self.uri = f'{agg_addr}:{agg_port}'
-         self.tls = tls
-         self.disable_client_auth = disable_client_auth
-         self.root_certificate = root_certificate
-         self.certificate = certificate
-         self.private_key = private_key
- 
-         self.channel_options = [
-             ('grpc.max_metadata_size', 32 * 1024 * 1024),
-             ('grpc.max_send_message_length', 128 * 1024 * 1024),
-             ('grpc.max_receive_message_length', 128 * 1024 * 1024)
-         ]
- 
-         self.logger = getLogger(__name__)
- 
-         if not self.tls:
-             self.logger.warn(
-                 'gRPC is running on insecure channel with TLS disabled.')
-             self.channel = self.create_insecure_channel(self.uri)
-         else:
-             self.channel = self.create_tls_channel(
-                 self.uri,
-                 self.root_certificate,
-                 self.disable_client_auth,
-                 self.certificate,
-                 self.private_key
-             )
- 
-         self.header = None
-         self.aggregator_uuid = aggregator_uuid
-         self.federation_uuid = federation_uuid
-         self.single_col_cert_common_name = single_col_cert_common_name
- 
-         # Adding an interceptor for RPC Errors
-         self.interceptors = (
-             RetryOnRpcErrorClientInterceptor(
-                 sleeping_policy=ConstantBackoff(
-                     logger=self.logger,
-                     reconnect_interval=int(kwargs.get('client_reconnect_interval', 1)),
-                     uri=self.uri),
-                 status_for_retry=(grpc.StatusCode.UNAVAILABLE,),
-             ),
-         )
-         self.stub = aggregator_pb2_grpc.AggregatorStub(
-             grpc.intercept_channel(self.channel, *self.interceptors)
-         )
- 
-     def create_insecure_channel(self, uri):
-         """
-         Set an insecure gRPC channel (i.e. no TLS) if desired.
- 
-         Warns user that this is not recommended.
- 
-         Args:
-             uri: The uniform resource identifier fo the insecure channel
- 
-         Returns:
-             An insecure gRPC channel object
- 
-         """
-         return grpc.insecure_channel(uri, options=self.channel_options)
- 
-     def create_tls_channel(self, uri, root_certificate, disable_client_auth,
-                            certificate, private_key):
-         """
-         Set an secure gRPC channel (i.e. TLS).
- 
-         Args:
-             uri: The uniform resource identifier fo the insecure channel
-             root_certificate: The Certificate Authority filename
-             disable_client_auth (boolean): True disabled client-side
-              authentication (not recommended, throws warning to user)
-             certificate: The client certficate filename from the collaborator
-              (signed by the certificate authority)
- 
-         Returns:
-             An insecure gRPC channel object
-         """
-         with open(root_certificate, 'rb') as f:
-             root_certificate_b = f.read()
- 
-         if disable_client_auth:
-             self.logger.warn('Client-side authentication is disabled.')
-             private_key_b = None
-             certificate_b = None
-         else:
-             with open(private_key, 'rb') as f:
-                 private_key_b = f.read()
-             with open(certificate, 'rb') as f:
-                 certificate_b = f.read()
- 
-         credentials = grpc.ssl_channel_credentials(
-             root_certificates=root_certificate_b,
-             private_key=private_key_b,
-             certificate_chain=certificate_b,
-         )
- 
-         return grpc.secure_channel(
-             uri, credentials, options=self.channel_options)
- 
-     def _set_header(self, collaborator_name):
-         self.header = aggregator_pb2.MessageHeader(
-             sender=collaborator_name,
-             receiver=self.aggregator_uuid,
-             federation_uuid=self.federation_uuid,
-             single_col_cert_common_name=self.single_col_cert_common_name or ''
-         )
- 
-     def validate_response(self, reply, collaborator_name):
-         """Validate the aggregator response."""
-         # check that the message was intended to go to this collaborator
-         check_equal(reply.header.receiver, collaborator_name, self.logger)
-         check_equal(reply.header.sender, self.aggregator_uuid, self.logger)
- 
-         # check that federation id matches
-         check_equal(
-             reply.header.federation_uuid,
-             self.federation_uuid,
-             self.logger
-         )
- 
-         # check that there is aggrement on the single_col_cert_common_name
-         check_equal(
-             reply.header.single_col_cert_common_name,
-             self.single_col_cert_common_name or '',
-             self.logger
-         )
- 
-     def disconnect(self):
-         """Close the gRPC channel."""
-         self.logger.debug(f'Disconnecting from gRPC server at {self.uri}')
-         self.channel.close()
- 
-     def reconnect(self):
-         """Create a new channel with the gRPC server."""
-         # channel.close() is idempotent. Call again here in case it wasn't issued previously
-         self.disconnect()
- 
-         if not self.tls:
-             self.channel = self.create_insecure_channel(self.uri)
-         else:
-             self.channel = self.create_tls_channel(
-                 self.uri,
-                 self.root_certificate,
-                 self.disable_client_auth,
-                 self.certificate,
-                 self.private_key
-             )
- 
-         self.logger.debug(f'Connecting to gRPC at {self.uri}')
- 
-         self.stub = aggregator_pb2_grpc.AggregatorStub(
-             grpc.intercept_channel(self.channel, *self.interceptors)
-         )
- 
-     @_atomic_connection
-     def get_tasks(self, collaborator_name):
-         """Get tasks from the aggregator."""
-         self._set_header(collaborator_name)
-         request = aggregator_pb2.GetTasksRequest(header=self.header)
-         response = self.stub.GetTasks(request)
-         self.validate_response(response, collaborator_name)
- 
-         return response.tasks, response.round_number, response.sleep_time, response.quit
- 
-     @_atomic_connection
-     def get_aggregated_tensor(self, collaborator_name, tensor_name, round_number,
-                               report, tags, require_lossless):
-         """Get aggregated tensor from the aggregator."""
-         self._set_header(collaborator_name)
-         request = aggregator_pb2.GetAggregatedTensorRequest(
-             header=self.header,
-             tensor_name=tensor_name,
-             round_number=round_number,
-             report=report,
-             tags=tags,
-             require_lossless=require_lossless
-         )
-         response = self.stub.GetAggregatedTensor(request)
-         # also do other validation, like on the round_number
-         self.validate_response(response, collaborator_name)
- 
-         return response.tensor
- 
-     @_atomic_connection
-     def send_local_task_results(self, collaborator_name, round_number,
-                                 task_name, data_size, named_tensors):
-         """Send task results to the aggregator."""
-         self._set_header(collaborator_name)
-         request = aggregator_pb2.TaskResults(
-             header=self.header,
-             round_number=round_number,
-             task_name=task_name,
-             data_size=data_size,
-             tensors=named_tensors
-         )
- 
-         # convert (potentially) long list of tensors into stream
-         stream = []
-         stream += utils.proto_to_datastream(request, self.logger)
-         response = self.stub.SendLocalTaskResults(iter(stream))
- 
-         # also do other validation, like on the round_number
-         self.validate_response(response, collaborator_name)
- 
-     def _get_trained_model(self, experiment_name, model_type):
-         """Get trained model RPC."""
-         get_model_request = self.stub.GetTrainedModelRequest(
-             experiment_name=experiment_name,
-             model_type=model_type,
-         )
-         model_proto_response = self.stub.GetTrainedModel(get_model_request)
-         tensor_dict, _ = utils.deconstruct_model_proto(
-             model_proto_response.model_proto,
-             NoCompressionPipeline(),
-         )
-         return tensor_dict
--- 0 ----
diff -crB --new-file ./openfl/openfl/transport/grpc/aggregator_server.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/transport/grpc/aggregator_server.py
*** ./openfl/openfl/transport/grpc/aggregator_server.py	2022-11-18 11:08:33.047181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/transport/grpc/aggregator_server.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,276 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """AggregatorGRPCServer module."""
- 
- import logging
- from concurrent.futures import ThreadPoolExecutor
- from multiprocessing import cpu_count
- from time import sleep
- 
- from grpc import server
- from grpc import ssl_server_credentials
- 
- from openfl.protocols import aggregator_pb2
- from openfl.protocols import aggregator_pb2_grpc
- from openfl.protocols import utils
- from openfl.utilities import check_equal
- from openfl.utilities import check_is_in
- 
- logger = logging.getLogger(__name__)
- 
- 
- class AggregatorGRPCServer(aggregator_pb2_grpc.AggregatorServicer):
-     """gRPC server class for the Aggregator."""
- 
-     def __init__(self,
-                  aggregator,
-                  agg_port,
-                  tls=True,
-                  disable_client_auth=False,
-                  root_certificate=None,
-                  certificate=None,
-                  private_key=None,
-                  **kwargs):
-         """
-         Class initializer.
- 
-         Args:
-             aggregator: The aggregator
-         Args:
-             fltask (FLtask): The gRPC service task.
-             tls (bool): To disable the TLS. (Default: True)
-             disable_client_auth (bool): To disable the client side
-             authentication. (Default: False)
-             root_certificate (str): File path to the CA certificate.
-             certificate (str): File path to the server certificate.
-             private_key (str): File path to the private key.
-             kwargs (dict): Additional arguments to pass into function
-         """
-         self.aggregator = aggregator
-         self.uri = f'[::]:{agg_port}'
-         self.tls = tls
-         self.disable_client_auth = disable_client_auth
-         self.root_certificate = root_certificate
-         self.certificate = certificate
-         self.private_key = private_key
-         self.channel_options = [
-             ('grpc.max_metadata_size', 32 * 1024 * 1024),
-             ('grpc.max_send_message_length', 128 * 1024 * 1024),
-             ('grpc.max_receive_message_length', 128 * 1024 * 1024)
-         ]
-         self.server = None
-         self.server_credentials = None
- 
-         self.logger = logging.getLogger(__name__)
- 
-     def validate_collaborator(self, request, context):
-         """
-         Validate the collaborator.
- 
-         Args:
-             request: The gRPC message request
-             context: The gRPC context
- 
-         Raises:
-             ValueError: If the collaborator or collaborator certificate is not
-              valid then raises error.
- 
-         """
-         if self.tls:
-             common_name = context.auth_context()[
-                 'x509_common_name'][0].decode('utf-8')
-             collaborator_common_name = request.header.sender
-             if not self.aggregator.valid_collaborator_cn_and_id(
-                     common_name, collaborator_common_name):
-                 raise ValueError(
-                     f'Invalid collaborator. CN: |{common_name}| '
-                     f'collaborator_common_name: |{collaborator_common_name}|')
- 
-     def get_header(self, collaborator_name):
-         """
-         Compose and return MessageHeader.
- 
-         Args:
-             collaborator_name : str
-                 The collaborator the message is intended for
-         """
-         return aggregator_pb2.MessageHeader(
-             sender=self.aggregator.uuid,
-             receiver=collaborator_name,
-             federation_uuid=self.aggregator.federation_uuid,
-             single_col_cert_common_name=self.aggregator.single_col_cert_common_name
-         )
- 
-     def check_request(self, request):
-         """
-         Validate request header matches expected values.
- 
-         Args:
-             request : protobuf
-                 Request sent from a collaborator that requires validation
-         """
-         # TODO improve this check. the sender name could be spoofed
-         check_is_in(request.header.sender, self.aggregator.authorized_cols, self.logger)
- 
-         # check that the message is for me
-         check_equal(request.header.receiver, self.aggregator.uuid, self.logger)
- 
-         # check that the message is for my federation
-         check_equal(
-             request.header.federation_uuid, self.aggregator.federation_uuid, self.logger)
- 
-         # check that we agree on the single cert common name
-         check_equal(
-             request.header.single_col_cert_common_name,
-             self.aggregator.single_col_cert_common_name,
-             self.logger
-         )
- 
-     def GetTasks(self, request, context):  # NOQA:N802
-         """
-         Request a job from aggregator.
- 
-         Args:
-             request: The gRPC message request
-             context: The gRPC context
- 
-         """
-         self.validate_collaborator(request, context)
-         self.check_request(request)
-         collaborator_name = request.header.sender
-         tasks, round_number, sleep_time, time_to_quit = self.aggregator.get_tasks(
-             request.header.sender)
-         if tasks:
-             if isinstance(tasks[0], str):
-                 # backward compatibility
-                 tasks_proto = [
-                     aggregator_pb2.Task(
-                         name=task,
-                     ) for task in tasks
-                 ]
-             else:
-                 tasks_proto = [
-                     aggregator_pb2.Task(
-                         name=task.name,
-                         function_name=task.function_name,
-                         task_type=task.task_type,
-                         apply_local=task.apply_local
-                     ) for task in tasks
-                 ]
-         else:
-             tasks_proto = []
- 
-         return aggregator_pb2.GetTasksResponse(
-             header=self.get_header(collaborator_name),
-             round_number=round_number,
-             tasks=tasks_proto,
-             sleep_time=sleep_time,
-             quit=time_to_quit
-         )
- 
-     def GetAggregatedTensor(self, request, context):  # NOQA:N802
-         """
-         Request a job from aggregator.
- 
-         Args:
-             request: The gRPC message request
-             context: The gRPC context
- 
-         """
-         self.validate_collaborator(request, context)
-         self.check_request(request)
-         collaborator_name = request.header.sender
-         tensor_name = request.tensor_name
-         require_lossless = request.require_lossless
-         round_number = request.round_number
-         report = request.report
-         tags = request.tags
- 
-         named_tensor = self.aggregator.get_aggregated_tensor(
-             collaborator_name, tensor_name, round_number, report, tags, require_lossless)
- 
-         return aggregator_pb2.GetAggregatedTensorResponse(
-             header=self.get_header(collaborator_name),
-             round_number=round_number,
-             tensor=named_tensor
-         )
- 
-     def SendLocalTaskResults(self, request, context):  # NOQA:N802
-         """
-         Request a model download from aggregator.
- 
-         Args:
-             request: The gRPC message request
-             context: The gRPC context
- 
-         """
-         proto = aggregator_pb2.TaskResults()
-         proto = utils.datastream_to_proto(proto, request)
- 
-         self.validate_collaborator(proto, context)
-         # all messages get sanity checked
-         self.check_request(proto)
- 
-         collaborator_name = proto.header.sender
-         task_name = proto.task_name
-         round_number = proto.round_number
-         data_size = proto.data_size
-         named_tensors = proto.tensors
-         self.aggregator.send_local_task_results(
-             collaborator_name, round_number, task_name, data_size, named_tensors)
-         # turn data stream into local model update
-         return aggregator_pb2.SendLocalTaskResultsResponse(
-             header=self.get_header(collaborator_name)
-         )
- 
-     def get_server(self):
-         """Return gRPC server."""
-         self.server = server(ThreadPoolExecutor(max_workers=cpu_count()),
-                              options=self.channel_options)
- 
-         aggregator_pb2_grpc.add_AggregatorServicer_to_server(self, self.server)
- 
-         if not self.tls:
- 
-             self.logger.warn(
-                 'gRPC is running on insecure channel with TLS disabled.')
-             port = self.server.add_insecure_port(self.uri)
-             self.logger.info(f'Insecure port: {port}')
- 
-         else:
- 
-             with open(self.private_key, 'rb') as f:
-                 private_key_b = f.read()
-             with open(self.certificate, 'rb') as f:
-                 certificate_b = f.read()
-             with open(self.root_certificate, 'rb') as f:
-                 root_certificate_b = f.read()
- 
-             if self.disable_client_auth:
-                 self.logger.warn('Client-side authentication is disabled.')
- 
-             self.server_credentials = ssl_server_credentials(
-                 ((private_key_b, certificate_b),),
-                 root_certificates=root_certificate_b,
-                 require_client_auth=not self.disable_client_auth
-             )
- 
-             self.server.add_secure_port(self.uri, self.server_credentials)
- 
-         return self.server
- 
-     def serve(self):
-         """Start an aggregator gRPC service."""
-         self.get_server()
- 
-         self.logger.info('Starting Aggregator gRPC Server')
-         self.server.start()
- 
-         try:
-             while not self.aggregator.all_quit_jobs_sent():
-                 sleep(5)
-         except KeyboardInterrupt:
-             pass
- 
-         self.server.stop(0)
--- 0 ----
diff -crB --new-file ./openfl/openfl/transport/grpc/director_client.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/transport/grpc/director_client.py
*** ./openfl/openfl/transport/grpc/director_client.py	2022-11-18 11:08:33.047181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/transport/grpc/director_client.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,311 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Director clients module."""
- 
- import logging
- from datetime import datetime
- from typing import List
- from typing import Type
- 
- import grpc
- 
- from openfl.interface.interactive_api.shard_descriptor import ShardDescriptor
- from openfl.pipelines import NoCompressionPipeline
- from openfl.protocols import director_pb2
- from openfl.protocols import director_pb2_grpc
- from openfl.protocols import interceptors
- from openfl.protocols.utils import construct_model_proto
- from openfl.protocols.utils import deconstruct_model_proto
- from openfl.transport.grpc.director_server import CLIENT_ID_DEFAULT
- 
- logger = logging.getLogger(__name__)
- 
- 
- class ShardDirectorClient:
-     """The internal director client class."""
- 
-     def __init__(self, *, director_host, director_port, shard_name, tls=True,
-                  root_certificate=None, private_key=None, certificate=None) -> None:
-         """Initialize a shard director client object."""
-         self.shard_name = shard_name
-         director_addr = f'{director_host}:{director_port}'
-         options = [('grpc.max_message_length', 100 * 1024 * 1024)]
-         if not tls:
-             channel = grpc.insecure_channel(director_addr, options=options)
-         else:
-             if not (root_certificate and private_key and certificate):
-                 raise Exception('No certificates provided')
-             try:
-                 with open(root_certificate, 'rb') as f:
-                     root_certificate_b = f.read()
-                 with open(private_key, 'rb') as f:
-                     private_key_b = f.read()
-                 with open(certificate, 'rb') as f:
-                     certificate_b = f.read()
-             except FileNotFoundError as exc:
-                 raise Exception(f'Provided certificate file is not exist: {exc.filename}')
- 
-             credentials = grpc.ssl_channel_credentials(
-                 root_certificates=root_certificate_b,
-                 private_key=private_key_b,
-                 certificate_chain=certificate_b
-             )
-             channel = grpc.secure_channel(director_addr, credentials, options=options)
-         self.stub = director_pb2_grpc.DirectorStub(channel)
- 
-     def report_shard_info(self, shard_descriptor: Type[ShardDescriptor],
-                           cuda_devices: tuple) -> bool:
-         """Report shard info to the director."""
-         logger.info('Send report UpdateShardInfo')
-         # True considered as successful registration
-         shard_info = director_pb2.ShardInfo(
-             shard_description=shard_descriptor.dataset_description,
-             sample_shape=shard_descriptor.sample_shape,
-             target_shape=shard_descriptor.target_shape
-         )
- 
-         shard_info.node_info.name = self.shard_name
-         shard_info.node_info.cuda_devices.extend(
-             director_pb2.CudaDeviceInfo(index=cuda_device)
-             for cuda_device in cuda_devices
-         )
- 
-         request = director_pb2.UpdateShardInfoRequest(shard_info=shard_info)
-         acknowledgement = self.stub.UpdateShardInfo(request)
-         return acknowledgement.accepted
- 
-     def wait_experiment(self):
-         """Wait an experiment data from the director."""
-         logger.info('Send WaitExperiment request')
-         response_iter = self.stub.WaitExperiment(self._get_experiment_data())
-         logger.info('WaitExperiment response has received')
-         response = next(response_iter)
-         experiment_name = response.experiment_name
-         if not experiment_name:
-             raise Exception('No experiment')
- 
-         return experiment_name
- 
-     def get_experiment_data(self, experiment_name):
-         """Get an experiment data from the director."""
-         logger.info(f'Request experiment {experiment_name}')
-         request = director_pb2.GetExperimentDataRequest(
-             experiment_name=experiment_name,
-             collaborator_name=self.shard_name
-         )
-         data_stream = self.stub.GetExperimentData(request)
- 
-         return data_stream
- 
-     def set_experiment_failed(
-             self,
-             experiment_name: str,
-             error_code: int = 1,
-             error_description: str = ''
-     ):
-         """Set the experiment failed."""
-         request = director_pb2.SetExperimentFailedRequest(
-             experiment_name=experiment_name,
-             collaborator_name=self.shard_name,
-             error_code=error_code,
-             error_description=error_description
-         )
-         self.stub.SetExperimentFailed(request)
- 
-     def _get_experiment_data(self):
-         """Generate the experiment data request."""
-         yield director_pb2.WaitExperimentRequest(collaborator_name=self.shard_name)
- 
-     def send_health_check(
-             self, *,
-             envoy_name: str,
-             is_experiment_running: bool,
-             cuda_devices_info: List[dict] = None,
-     ) -> int:
-         """Send envoy health check."""
-         status = director_pb2.UpdateEnvoyStatusRequest(
-             name=envoy_name,
-             is_experiment_running=is_experiment_running,
-         )
- 
-         cuda_messages = []
-         if cuda_devices_info is not None:
-             try:
-                 cuda_messages = [
-                     director_pb2.CudaDeviceInfo(**item)
-                     for item in cuda_devices_info
-                 ]
-             except Exception as e:
-                 logger.info(f'{e}')
- 
-         status.cuda_devices.extend(cuda_messages)
- 
-         logger.debug(f'Sending health check status: {status}')
- 
-         response = self.stub.UpdateEnvoyStatus(status)
-         health_check_period = response.health_check_period.seconds
- 
-         return health_check_period
- 
- 
- class DirectorClient:
-     """Director client class for users."""
- 
-     def __init__(
-             self, *,
-             client_id: str,
-             director_host: str,
-             director_port: int,
-             tls: bool,
-             root_certificate: str,
-             private_key: str,
-             certificate: str,
-     ) -> None:
-         """Initialize director client object."""
-         director_addr = f'{director_host}:{director_port}'
-         channel_opt = [('grpc.max_send_message_length', 512 * 1024 * 1024),
-                        ('grpc.max_receive_message_length', 512 * 1024 * 1024)]
-         if not tls:
-             if not client_id:
-                 client_id = CLIENT_ID_DEFAULT
-             channel = grpc.insecure_channel(director_addr, options=channel_opt)
-             headers = {
-                 'client_id': client_id,
-             }
-             header_interceptor = interceptors.headers_adder(headers)
-             channel = grpc.intercept_channel(channel, header_interceptor)
-         else:
-             if not (root_certificate and private_key and certificate):
-                 raise Exception('No certificates provided')
-             try:
-                 with open(root_certificate, 'rb') as f:
-                     root_certificate_b = f.read()
-                 with open(private_key, 'rb') as f:
-                     private_key_b = f.read()
-                 with open(certificate, 'rb') as f:
-                     certificate_b = f.read()
-             except FileNotFoundError as exc:
-                 raise Exception(f'Provided certificate file is not exist: {exc.filename}')
- 
-             credentials = grpc.ssl_channel_credentials(
-                 root_certificates=root_certificate_b,
-                 private_key=private_key_b,
-                 certificate_chain=certificate_b
-             )
- 
-             channel = grpc.secure_channel(director_addr, credentials, options=channel_opt)
-         self.stub = director_pb2_grpc.DirectorStub(channel)
- 
-     def set_new_experiment(self, name, col_names, arch_path,
-                            initial_tensor_dict=None):
-         """Send the new experiment to director to launch."""
-         logger.info('SetNewExperiment')
-         if initial_tensor_dict:
-             model_proto = construct_model_proto(initial_tensor_dict, 0, NoCompressionPipeline())
-             experiment_info_gen = self._get_experiment_info(
-                 arch_path=arch_path,
-                 name=name,
-                 col_names=col_names,
-                 model_proto=model_proto,
-             )
-             resp = self.stub.SetNewExperiment(experiment_info_gen)
-             return resp
- 
-     def _get_experiment_info(self, arch_path, name, col_names, model_proto):
-         with open(arch_path, 'rb') as arch:
-             max_buffer_size = 2 * 1024 * 1024
-             chunk = arch.read(max_buffer_size)
-             while chunk != b'':
-                 if not chunk:
-                     raise StopIteration
-                 # TODO: add hash or/and size to check
-                 experiment_info = director_pb2.ExperimentInfo(
-                     name=name,
-                     collaborator_names=col_names,
-                     model_proto=model_proto
-                 )
-                 experiment_info.experiment_data.size = len(chunk)
-                 experiment_info.experiment_data.npbytes = chunk
-                 yield experiment_info
-                 chunk = arch.read(max_buffer_size)
- 
-     def get_dataset_info(self):
-         """Request the dataset info from the director."""
-         resp = self.stub.GetDatasetInfo(director_pb2.GetDatasetInfoRequest())
-         return resp.shard_info.sample_shape, resp.shard_info.target_shape
- 
-     def _get_trained_model(self, experiment_name, model_type):
-         """Get trained model RPC."""
-         get_model_request = director_pb2.GetTrainedModelRequest(
-             experiment_name=experiment_name,
-             model_type=model_type,
-         )
-         model_proto_response = self.stub.GetTrainedModel(get_model_request)
-         tensor_dict, _ = deconstruct_model_proto(
-             model_proto_response.model_proto,
-             NoCompressionPipeline(),
-         )
-         return tensor_dict
- 
-     def get_best_model(self, experiment_name):
-         """Get best model method."""
-         model_type = director_pb2.GetTrainedModelRequest.BEST_MODEL
-         return self._get_trained_model(experiment_name, model_type)
- 
-     def get_last_model(self, experiment_name):
-         """Get last model method."""
-         model_type = director_pb2.GetTrainedModelRequest.LAST_MODEL
-         return self._get_trained_model(experiment_name, model_type)
- 
-     def stream_metrics(self, experiment_name):
-         """Stream metrics RPC."""
-         request = director_pb2.GetMetricStreamRequest(experiment_name=experiment_name)
-         for metric_message in self.stub.GetMetricStream(request):
-             yield {
-                 'metric_origin': metric_message.metric_origin,
-                 'task_name': metric_message.task_name,
-                 'metric_name': metric_message.metric_name,
-                 'metric_value': metric_message.metric_value,
-                 'round': metric_message.round,
-             }
- 
-     def remove_experiment_data(self, name):
-         """Remove experiment data RPC."""
-         request = director_pb2.RemoveExperimentRequest(experiment_name=name)
-         response = self.stub.RemoveExperimentData(request)
-         return response.acknowledgement
- 
-     def get_envoys(self, raw_result=False):
-         """Get envoys info."""
-         envoys = self.stub.GetEnvoys(director_pb2.GetEnvoysRequest())
-         if raw_result:
-             return envoys
-         now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
-         result = {}
-         for envoy in envoys.envoy_infos:
-             result[envoy.shard_info.node_info.name] = {
-                 'shard_info': envoy.shard_info,
-                 'is_online': envoy.is_online or False,
-                 'is_experiment_running': envoy.is_experiment_running or False,
-                 'last_updated': datetime.fromtimestamp(
-                     envoy.last_updated.seconds).strftime('%Y-%m-%d %H:%M:%S'),
-                 'current_time': now,
-                 'valid_duration': envoy.valid_duration,
-                 'experiment_name': 'ExperimentName Mock',
-             }
-         return result
- 
-     def get_experiments_list(self):
-         """Get experiments list."""
-         response = self.stub.GetExperimentsList(
-             director_pb2.GetExperimentsListRequest()
-         )
-         return response.experiments
- 
-     def get_experiment_description(self, name):
-         """Get experiment info."""
-         response = self.stub.GetExperimentDescription(
-             director_pb2.GetExperimentDescriptionRequest(name=name)
-         )
-         return response.experiment
--- 0 ----
diff -crB --new-file ./openfl/openfl/transport/grpc/director_server.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/transport/grpc/director_server.py
*** ./openfl/openfl/transport/grpc/director_server.py	2022-11-18 11:08:33.047181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/transport/grpc/director_server.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,361 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Director server."""
- 
- import asyncio
- import logging
- import uuid
- from pathlib import Path
- from typing import Optional
- from typing import Union
- 
- from google.protobuf.json_format import MessageToDict
- from google.protobuf.json_format import ParseDict
- from grpc import aio
- from grpc import ssl_server_credentials
- 
- from openfl.pipelines import NoCompressionPipeline
- from openfl.protocols import base_pb2
- from openfl.protocols import director_pb2
- from openfl.protocols import director_pb2_grpc
- from openfl.protocols.utils import construct_model_proto
- from openfl.protocols.utils import deconstruct_model_proto
- from openfl.protocols.utils import get_headers
- 
- logger = logging.getLogger(__name__)
- 
- CLIENT_ID_DEFAULT = '__default__'
- 
- 
- class DirectorGRPCServer(director_pb2_grpc.DirectorServicer):
-     """Director transport class."""
- 
-     def __init__(
-             self, *,
-             director_cls,
-             tls: bool = True,
-             root_certificate: Optional[Union[Path, str]] = None,
-             private_key: Optional[Union[Path, str]] = None,
-             certificate: Optional[Union[Path, str]] = None,
-             listen_host: str = '[::]',
-             listen_port: int = 50051,
-             **kwargs,
-     ) -> None:
-         """Initialize a director object."""
-         # TODO: add working directory
-         super().__init__()
- 
-         self.listen_uri = f'{listen_host}:{listen_port}'
-         self.tls = tls
-         self.root_certificate = None
-         self.private_key = None
-         self.certificate = None
-         self._fill_certs(root_certificate, private_key, certificate)
-         self.server = None
-         self.root_dir = Path.cwd()
-         self.director = director_cls(
-             tls=self.tls,
-             root_certificate=self.root_certificate,
-             private_key=self.private_key,
-             certificate=self.certificate,
-             **kwargs
-         )
- 
-     def _fill_certs(self, root_certificate, private_key, certificate):
-         """Fill certificates."""
-         if self.tls:
-             if not (root_certificate and private_key and certificate):
-                 raise Exception('No certificates provided')
-             self.root_certificate = Path(root_certificate).absolute()
-             self.private_key = Path(private_key).absolute()
-             self.certificate = Path(certificate).absolute()
- 
-     def get_caller(self, context):
-         """
-         Get caller name from context.
- 
-             if tls == True: get caller name from auth_context
-             if tls == False: get caller name from context header 'client_id'
-         """
-         if self.tls:
-             return context.auth_context()['x509_common_name'][0].decode('utf-8')
-         headers = get_headers(context)
-         client_id = headers.get('client_id', CLIENT_ID_DEFAULT)
-         return client_id
- 
-     def start(self):
-         """Launch the director GRPC server."""
-         loop = asyncio.get_event_loop()  # TODO: refactor after end of support for python3.6
-         loop.create_task(self.director.start_experiment_execution_loop())
-         loop.run_until_complete(self._run_server())
- 
-     async def _run_server(self):
-         channel_opt = [('grpc.max_send_message_length', 512 * 1024 * 1024),
-                        ('grpc.max_receive_message_length', 512 * 1024 * 1024)]
-         self.server = aio.server(options=channel_opt)
-         director_pb2_grpc.add_DirectorServicer_to_server(self, self.server)
- 
-         if not self.tls:
-             self.server.add_insecure_port(self.listen_uri)
-         else:
-             with open(self.private_key, 'rb') as f:
-                 private_key_b = f.read()
-             with open(self.certificate, 'rb') as f:
-                 certificate_b = f.read()
-             with open(self.root_certificate, 'rb') as f:
-                 root_certificate_b = f.read()
-             server_credentials = ssl_server_credentials(
-                 ((private_key_b, certificate_b),),
-                 root_certificates=root_certificate_b,
-                 require_client_auth=True
-             )
-             self.server.add_secure_port(self.listen_uri, server_credentials)
-         logger.info(f'Starting server on {self.listen_uri}')
-         await self.server.start()
-         await self.server.wait_for_termination()
- 
-     async def UpdateShardInfo(self, request, context):  # NOQA:N802
-         """Receive acknowledge shard info."""
-         logger.info(f'UpdateShardInfo request has got: {request.shard_info}')
-         dict_shard_info = MessageToDict(
-             request.shard_info,
-             preserving_proto_field_name=True
-         )
-         is_accepted = self.director.acknowledge_shard(dict_shard_info)
-         reply = director_pb2.UpdateShardInfoResponse(accepted=is_accepted)
- 
-         return reply
- 
-     async def SetNewExperiment(self, stream, context):  # NOQA:N802
-         """Request to set new experiment."""
-         logger.info(f'SetNewExperiment request has got {stream}')
-         # TODO: add streaming reader
-         data_file_path = self.root_dir / str(uuid.uuid4())
-         with open(data_file_path, 'wb') as data_file:
-             async for request in stream:
-                 if request.experiment_data.size == len(request.experiment_data.npbytes):
-                     data_file.write(request.experiment_data.npbytes)
-                 else:
-                     raise Exception('Bad request')
- 
-         tensor_dict = None
-         if request.model_proto:
-             tensor_dict, _ = deconstruct_model_proto(request.model_proto, NoCompressionPipeline())
- 
-         caller = self.get_caller(context)
- 
-         is_accepted = await self.director.set_new_experiment(
-             experiment_name=request.name,
-             sender_name=caller,
-             tensor_dict=tensor_dict,
-             collaborator_names=request.collaborator_names,
-             experiment_archive_path=data_file_path
-         )
- 
-         logger.info('Send response')
-         return director_pb2.SetNewExperimentResponse(accepted=is_accepted)
- 
-     async def GetTrainedModel(self, request, context):  # NOQA:N802
-         """RPC for retrieving trained models."""
-         logger.info('Request GetTrainedModel has got!')
- 
-         if request.model_type == director_pb2.GetTrainedModelRequest.BEST_MODEL:
-             model_type = 'best'
-         elif request.model_type == director_pb2.GetTrainedModelRequest.LAST_MODEL:
-             model_type = 'last'
-         else:
-             logger.error('Incorrect model type')
-             return director_pb2.TrainedModelResponse()
- 
-         caller = self.get_caller(context)
- 
-         trained_model_dict = self.director.get_trained_model(
-             experiment_name=request.experiment_name,
-             caller=caller,
-             model_type=model_type
-         )
- 
-         if trained_model_dict is None:
-             return director_pb2.TrainedModelResponse()
- 
-         model_proto = construct_model_proto(trained_model_dict, 0, NoCompressionPipeline())
- 
-         return director_pb2.TrainedModelResponse(model_proto=model_proto)
- 
-     async def GetExperimentData(self, request, context):  # NOQA:N802
-         """Receive experiment data."""
-         # TODO: add size filling
-         # TODO: add experiment name field
-         # TODO: rename npbytes to data
-         data_file_path = self.director.get_experiment_data(request.experiment_name)
-         max_buffer_size = (2 * 1024 * 1024)
-         with open(data_file_path, 'rb') as df:
-             while True:
-                 data = df.read(max_buffer_size)
-                 if len(data) == 0:
-                     break
-                 yield director_pb2.ExperimentData(size=len(data), npbytes=data)
- 
-     async def WaitExperiment(self, request_iterator, context):  # NOQA:N802
-         """Request for wait an experiment."""
-         logger.info('Request WaitExperiment has got!')
-         async for msg in request_iterator:
-             logger.info(msg)
-             experiment_name = await self.director.wait_experiment(msg.collaborator_name)
-             logger.info(f'Experiment {experiment_name} was prepared')
- 
-             yield director_pb2.WaitExperimentResponse(experiment_name=experiment_name)
- 
-     async def GetDatasetInfo(self, request, context):  # NOQA:N802
-         """Request the info about target and sample shapes in the dataset."""
-         logger.info('Request GetDatasetInfo has got!')
- 
-         sample_shape, target_shape = self.director.get_dataset_info()
-         shard_info = director_pb2.ShardInfo(
-             sample_shape=sample_shape,
-             target_shape=target_shape
-         )
-         resp = director_pb2.GetDatasetInfoResponse(shard_info=shard_info)
-         return resp
- 
-     async def GetMetricStream(self, request, context):  # NOQA:N802
-         """Request to stream metrics from the aggregator to frontend."""
-         logger.info(f'Request GetMetricStream for {request.experiment_name} experiment has got!')
- 
-         caller = self.get_caller(context)
-         async for metric_dict in self.director.stream_metrics(
-                 experiment_name=request.experiment_name, caller=caller
-         ):
-             if metric_dict is None:
-                 await asyncio.sleep(1)
-                 continue
-             yield director_pb2.GetMetricStreamResponse(**metric_dict)
- 
-     async def RemoveExperimentData(self, request, context):  # NOQA:N802
-         """Remove experiment data RPC."""
-         response = director_pb2.RemoveExperimentResponse(acknowledgement=False)
-         caller = self.get_caller(context)
-         self.director.remove_experiment_data(
-             experiment_name=request.experiment_name,
-             caller=caller,
-         )
- 
-         response.acknowledgement = True
-         return response
- 
-     async def SetExperimentFailed(self, request, context):  # NOQA:N802
-         """Set the experiment failed."""
-         response = director_pb2.SetExperimentFailedResponse()
-         if self.get_caller(context) != CLIENT_ID_DEFAULT:
-             return response
-         logger.error(f'Collaborator {request.collaborator_name} was failed with error code:'
-                      f' {request.error_code}, error_description: {request.error_description}'
-                      f'Stopping experiment.')
-         self.director.set_experiment_failed(
-             experiment_name=request.experiment_name,
-             collaborator_name=request.collaborator_name
-         )
- 
-         return response
- 
-     async def UpdateEnvoyStatus(self, request, context):  # NOQA:N802
-         """Accept health check from envoy."""
-         logger.debug(f'Request UpdateEnvoyStatus has got: {request}')
-         cuda_devices_info = [
-             MessageToDict(message, preserving_proto_field_name=True)
-             for message in request.cuda_devices
-         ]
-         health_check_period = self.director.update_envoy_status(
-             envoy_name=request.name,
-             is_experiment_running=request.is_experiment_running,
-             cuda_devices_status=cuda_devices_info
-         )
-         resp = director_pb2.UpdateEnvoyStatusResponse()
-         resp.health_check_period.seconds = health_check_period
- 
-         return resp
- 
-     async def GetEnvoys(self, request, context):  # NOQA:N802
-         """Get a status information about envoys."""
-         envoy_infos = self.director.get_envoys()
-         envoy_statuses = []
-         for envoy_info in envoy_infos:
-             envoy_info_message = director_pb2.EnvoyInfo(
-                 shard_info=ParseDict(
-                     envoy_info['shard_info'], director_pb2.ShardInfo(),
-                     ignore_unknown_fields=True),
-                 is_online=envoy_info['is_online'],
-                 is_experiment_running=envoy_info['is_experiment_running'])
-             envoy_info_message.valid_duration.seconds = envoy_info['valid_duration']
-             envoy_info_message.last_updated.seconds = int(envoy_info['last_updated'])
- 
-             envoy_statuses.append(envoy_info_message)
- 
-         return director_pb2.GetEnvoysResponse(envoy_infos=envoy_statuses)
- 
-     async def GetExperimentsList(self, request, context):  # NOQA:N802
-         """Get list of experiments description."""
-         caller = self.get_caller(context)
-         experiments = self.director.get_experiments_list(caller)
-         experiment_list = [
-             director_pb2.ExperimentListItem(**exp)
-             for exp in experiments
-         ]
-         return director_pb2.GetExperimentsListResponse(
-             experiments=experiment_list
-         )
- 
-     async def GetExperimentDescription(self, request, context):  # NOQA:N802
-         """Get an experiment description."""
-         caller = self.get_caller(context)
-         experiment = self.director.get_experiment_description(caller, request.name)
-         models_statuses = [
-             base_pb2.DownloadStatus(
-                 name=ms['name'],
-                 status=ms['status']
-             )
-             for ms in experiment['download_statuses']['models']
-         ]
-         logs_statuses = [
-             base_pb2.DownloadStatus(
-                 name=ls['name'],
-                 status=ls['status']
-             )
-             for ls in experiment['download_statuses']['logs']
-         ]
-         download_statuses = base_pb2.DownloadStatuses(
-             models=models_statuses,
-             logs=logs_statuses,
-         )
-         collaborators = [
-             base_pb2.CollaboratorDescription(
-                 name=col['name'],
-                 status=col['status'],
-                 progress=col['progress'],
-                 round=col['round'],
-                 current_task=col['current_task'],
-                 next_task=col['next_task']
-             )
-             for col in experiment['collaborators']
-         ]
-         tasks = [
-             base_pb2.TaskDescription(
-                 name=task['name'],
-                 description=task['description']
-             )
-             for task in experiment['tasks']
-         ]
- 
-         return director_pb2.GetExperimentDescriptionResponse(
-             experiment=base_pb2.ExperimentDescription(
-                 name=experiment['name'],
-                 status=experiment['status'],
-                 progress=experiment['progress'],
-                 current_round=experiment['current_round'],
-                 total_rounds=experiment['total_rounds'],
-                 download_statuses=download_statuses,
-                 collaborators=collaborators,
-                 tasks=tasks,
-             ),
-         )
--- 0 ----
diff -crB --new-file ./openfl/openfl/transport/grpc/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/transport/grpc/__init__.py
*** ./openfl/openfl/transport/grpc/__init__.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/transport/grpc/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,14 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """openfl.transport.grpc package."""
- 
- from .aggregator_client import AggregatorGRPCClient
- from .aggregator_server import AggregatorGRPCServer
- from .director_server import DirectorGRPCServer
- 
- __all__ = [
-     'AggregatorGRPCServer',
-     'AggregatorGRPCClient',
-     'DirectorGRPCServer',
- ]
--- 0 ----
diff -crB --new-file ./openfl/openfl/transport/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/transport/__init__.py
*** ./openfl/openfl/transport/__init__.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/transport/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,14 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """openfl.transport package."""
- 
- from .grpc import AggregatorGRPCClient
- from .grpc import AggregatorGRPCServer
- from .grpc import DirectorGRPCServer
- 
- __all__ = [
-     'AggregatorGRPCServer',
-     'AggregatorGRPCClient',
-     'DirectorGRPCServer',
- ]
--- 0 ----
diff -crB --new-file ./openfl/openfl/utilities/ca.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/ca.py
*** ./openfl/openfl/utilities/ca.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/ca.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,18 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Generic check functions."""
- import os
- 
- 
- def get_credentials(folder_path):
-     """Get credentials from folder by template."""
-     root_ca, key, cert = None, None, None
-     if os.path.exists(folder_path):
-         for f in os.listdir(folder_path):
-             if '.key' in f:
-                 key = folder_path + '/' + f
-             if '.crt' in f and 'root_ca' not in f:
-                 cert = folder_path + '/' + f
-             if 'root_ca' in f:
-                 root_ca = folder_path + '/' + f
-     return root_ca, key, cert
--- 0 ----
diff -crB --new-file ./openfl/openfl/utilities/checks.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/checks.py
*** ./openfl/openfl/utilities/checks.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/checks.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,43 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Generic check functions."""
- 
- 
- def check_type(obj, expected_type, logger):
-     """Assert `obj` is of `expected_type` type."""
-     if not isinstance(obj, expected_type):
-         exception = TypeError(f'Expected type {type(obj)}, got type {str(expected_type)}')
-         logger.exception(repr(exception))
-         raise exception
- 
- 
- def check_equal(x, y, logger):
-     """Assert `x` and `y` are equal."""
-     if x != y:
-         exception = ValueError(f'{x} != {y}')
-         logger.exception(repr(exception))
-         raise exception
- 
- 
- def check_not_equal(x, y, logger, name='None provided'):
-     """Assert `x` and `y` are not equal."""
-     if x == y:
-         exception = ValueError(f'Name {name}. Expected inequality, but {x} == {y}')
-         logger.exception(repr(exception))
-         raise exception
- 
- 
- def check_is_in(element, _list, logger):
-     """Assert `element` is in `_list` collection."""
-     if element not in _list:
-         exception = ValueError(f'Expected sequence membership, but {element} is not in {_list}')
-         logger.exception(repr(exception))
-         raise exception
- 
- 
- def check_not_in(element, _list, logger):
-     """Assert `element` is not in `_list` collection."""
-     if element in _list:
-         exception = ValueError(f'Expected not in sequence, but {element} is in {_list}')
-         logger.exception(repr(exception))
-         raise exception
--- 0 ----
diff -crB --new-file ./openfl/openfl/utilities/click_types.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/click_types.py
*** ./openfl/openfl/utilities/click_types.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/click_types.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,35 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Click types module."""
- 
- import click
- 
- from openfl.utilities import utils
- 
- 
- class FqdnParamType(click.ParamType):
-     """Domain Type for click arguments."""
- 
-     name = 'fqdn'
- 
-     def convert(self, value, param, ctx):
-         """Validate value, if value is valid, return it."""
-         if not utils.is_fqdn(value):
-             self.fail(f'{value} is not a valid domain name', param, ctx)
-         return value
- 
- 
- class IpAddressParamType(click.ParamType):
-     """IpAddress Type for click arguments."""
- 
-     name = 'IpAddress type'
- 
-     def convert(self, value, param, ctx):
-         """Validate value, if value is valid, return it."""
-         if not utils.is_api_adress(value):
-             self.fail(f'{value} is not a valid ip adress name', param, ctx)
-         return value
- 
- 
- FQDN = FqdnParamType()
- IP_ADDRESS = IpAddressParamType()
--- 0 ----
diff -crB --new-file ./openfl/openfl/utilities/data_splitters/data_splitter.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/data_splitters/data_splitter.py
*** ./openfl/openfl/utilities/data_splitters/data_splitter.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/data_splitters/data_splitter.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,20 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """openfl.utilities.data_splitters.data_splitter module."""
- from abc import ABC
- from abc import abstractmethod
- from typing import Iterable
- from typing import List
- from typing import TypeVar
- 
- T = TypeVar('T')
- 
- 
- class DataSplitter(ABC):
-     """Base class for data splitting."""
- 
-     @abstractmethod
-     def split(self, data: Iterable[T], num_collaborators: int) -> List[Iterable[T]]:
-         """Split the data."""
-         raise NotImplementedError
--- 0 ----
diff -crB --new-file ./openfl/openfl/utilities/data_splitters/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/data_splitters/__init__.py
*** ./openfl/openfl/utilities/data_splitters/__init__.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/data_splitters/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,19 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0-
- 
- """openfl.utilities.data package."""
- from openfl.utilities.data_splitters.data_splitter import DataSplitter
- from openfl.utilities.data_splitters.numpy import DirichletNumPyDataSplitter
- from openfl.utilities.data_splitters.numpy import EqualNumPyDataSplitter
- from openfl.utilities.data_splitters.numpy import LogNormalNumPyDataSplitter
- from openfl.utilities.data_splitters.numpy import NumPyDataSplitter
- from openfl.utilities.data_splitters.numpy import RandomNumPyDataSplitter
- 
- __all__ = [
-     'DataSplitter',
-     'DirichletNumPyDataSplitter',
-     'EqualNumPyDataSplitter',
-     'LogNormalNumPyDataSplitter',
-     'NumPyDataSplitter',
-     'RandomNumPyDataSplitter',
- ]
--- 0 ----
diff -crB --new-file ./openfl/openfl/utilities/data_splitters/numpy.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/data_splitters/numpy.py
*** ./openfl/openfl/utilities/data_splitters/numpy.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/data_splitters/numpy.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,224 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """UnbalancedFederatedDataset module."""
- 
- from abc import abstractmethod
- from typing import List
- 
- import numpy as np
- from tqdm import trange
- 
- from openfl.utilities.data_splitters.data_splitter import DataSplitter
- 
- 
- def get_label_count(labels, label):
-     """Count samples with label `label` in `labels` array."""
-     return len(np.nonzero(labels == label)[0])
- 
- 
- def one_hot(labels, classes):
-     """Apply One-Hot encoding to labels."""
-     return np.eye(classes)[labels]
- 
- 
- class NumPyDataSplitter(DataSplitter):
-     """Base class for splitting numpy arrays of data."""
- 
-     @abstractmethod
-     def split(self, data: np.ndarray, num_collaborators: int) -> List[List[int]]:
-         """Split the data."""
-         raise NotImplementedError
- 
- 
- class EqualNumPyDataSplitter(NumPyDataSplitter):
-     """Splits the data evenly."""
- 
-     def __init__(self, shuffle=True, seed=0):
-         """Initialize.
- 
-         Args:
-             shuffle(bool): Flag determining whether to shuffle the dataset before splitting.
-             seed(int): Random numbers generator seed.
-                 For different splits on envoys, try setting different values for this parameter
-                 on each shard descriptor.
-         """
-         self.shuffle = shuffle
-         self.seed = seed
- 
-     def split(self, data, num_collaborators):
-         """Split the data."""
-         np.random.seed(self.seed)
-         idx = range(len(data))
-         if self.shuffle:
-             idx = np.random.permutation(idx)
-         slices = np.array_split(idx, num_collaborators)
-         return slices
- 
- 
- class RandomNumPyDataSplitter(NumPyDataSplitter):
-     """Splits the data randomly."""
- 
-     def __init__(self, shuffle=True, seed=0):
-         """Initialize.
- 
-         Args:
-             shuffle(bool): Flag determining whether to shuffle the dataset before splitting.
-             seed(int): Random numbers generator seed.
-                 For different splits on envoys, try setting different values for this parameter
-                 on each shard descriptor.
-         """
-         self.shuffle = shuffle
-         self.seed = seed
- 
-     def split(self, data, num_collaborators):
-         """Split the data."""
-         np.random.seed(self.seed)
-         idx = range(len(data))
-         if self.shuffle:
-             idx = np.random.permutation(idx)
-         random_idx = np.sort(np.random.choice(len(data), num_collaborators - 1, replace=False))
- 
-         return np.split(idx, random_idx)
- 
- 
- class LogNormalNumPyDataSplitter(NumPyDataSplitter):
-     """Unbalanced (LogNormal) dataset split.
- 
-     This split assumes only several classes are assigned to each collaborator.
-     Firstly, it assigns classes_per_col * min_samples_per_class items of dataset
-     to each collaborator so all of collaborators will have some data after the split.
-     Then, it generates positive integer numbers by log-normal (power) law.
-     These numbers correspond to numbers of dataset items picked each time from dataset
-     and assigned to a collaborator.
-     Generation is repeated for each class assigned to a collaborator.
-     This is a parametrized version of non-i.i.d. data split in FedProx algorithm.
-     Origin source: https://github.com/litian96/FedProx/blob/master/data/mnist/generate_niid.py#L30
- 
-     NOTE: This split always drops out some part of the dataset!
-     Non-deterministic behavior selects only random subpart of class items.
-     """
- 
-     def __init__(self, mu,
-                  sigma,
-                  num_classes,
-                  classes_per_col,
-                  min_samples_per_class,
-                  seed=0):
-         """Initialize the generator.
- 
-         Args:
-             mu(float): Distribution hyperparameter.
-             sigma(float): Distribution hyperparameter.
-             classes_per_col(int): Number of classes assigned to each collaborator.
-             min_samples_per_class(int): Minimum number of collaborator samples of each class.
-             seed(int): Random numbers generator seed.
-                 For different splits on envoys, try setting different values for this parameter
-                 on each shard descriptor.
-         """
-         self.mu = mu
-         self.sigma = sigma
-         self.num_classes = num_classes
-         self.classes_per_col = classes_per_col
-         self.min_samples_per_class = min_samples_per_class
-         self.seed = seed
- 
-     def split(self, data, num_collaborators):
-         """Split the data.
- 
-         Args:
-             data(np.ndarray): numpy-like label array.
-             num_collaborators(int): number of collaborators to split data across.
-                 Should be divisible by number of classes in ``data``.
-         """
-         np.random.seed(self.seed)
-         idx = [[] for _ in range(num_collaborators)]
-         samples_per_col = self.classes_per_col * self.min_samples_per_class
-         for col in range(num_collaborators):
-             for c in range(self.classes_per_col):
-                 label = (col + c) % self.num_classes
-                 label_idx = np.nonzero(data == label)[0]
-                 slice_start = col // self.num_classes * samples_per_col
-                 slice_start += self.min_samples_per_class * c
-                 slice_end = slice_start + self.min_samples_per_class
-                 print(f'Assigning {slice_start}:{slice_end} of class {label} to {col} col...')
-                 idx[col] += list(label_idx[slice_start:slice_end])
-         if any([len(i) != samples_per_col for i in idx]):
-             raise SystemError(f'''All collaborators should have {samples_per_col} elements
- but distribution is {[len(i) for i in idx]}''')
- 
-         props_shape = (
-             self.num_classes,
-             num_collaborators // self.num_classes,
-             self.classes_per_col
-         )
-         props = np.random.lognormal(self.mu, self.sigma, props_shape)
-         num_samples_per_class = [[[get_label_count(data, label) - self.min_samples_per_class]]
-                                  for label in range(self.num_classes)]
-         num_samples_per_class = np.array(num_samples_per_class)
-         props = num_samples_per_class * props / np.sum(props, (1, 2), keepdims=True)
-         for col in trange(num_collaborators):
-             for j in range(self.classes_per_col):
-                 label = (col + j) % self.num_classes
-                 num_samples = int(props[label, col // self.num_classes, j])
- 
-                 print(f'Trying to append {num_samples} samples of {label} class to {col} col...')
-                 slice_start = np.count_nonzero(data[np.hstack(idx)] == label)
-                 slice_end = slice_start + num_samples
-                 label_count = get_label_count(data, label)
-                 if slice_end < label_count:
-                     label_subset = np.nonzero(data == (col + j) % self.num_classes)[0]
-                     idx_to_append = label_subset[slice_start:slice_end]
-                     idx[col] = np.append(idx[col], idx_to_append)
-                 else:
-                     print(f'Index {slice_end} is out of bounds '
-                           f'of array of length {label_count}. Skipping...')
-         print(f'Split result: {[len(i) for i in idx]}.')
-         return idx
- 
- 
- class DirichletNumPyDataSplitter(NumPyDataSplitter):
-     """Numpy splitter according to dirichlet distribution.
- 
-     Generates the random sample of integer numbers from dirichlet distribution
-     until minimum subset length exceeds the specified threshold.
-     This behavior is a parametrized version of non-i.i.d. split in FedMA algorithm.
-     Origin source: https://github.com/IBM/FedMA/blob/master/utils.py#L96
-     """
- 
-     def __init__(self, alpha=0.5, min_samples_per_col=10, seed=0):
-         """Initialize.
- 
-         Args:
-             alpha(float): Dirichlet distribution parameter.
-             min_samples_per_col(int): Minimal amount of samples per collaborator.
-             seed(int): Random numbers generator seed.
-                 For different splits on envoys, try setting different values for this parameter
-                 on each shard descriptor.
-         """
-         self.alpha = alpha
-         self.min_samples_per_col = min_samples_per_col
-         self.seed = seed
- 
-     def split(self, data, num_collaborators):
-         """Split the data."""
-         np.random.seed(self.seed)
-         classes = len(np.unique(data))
-         min_size = 0
- 
-         n = len(data)
-         while min_size < self.min_samples_per_col:
-             idx_batch = [[] for _ in range(num_collaborators)]
-             for k in range(classes):
-                 idx_k = np.where(data == k)[0]
-                 np.random.shuffle(idx_k)
-                 proportions = np.random.dirichlet(np.repeat(self.alpha, num_collaborators))
-                 proportions = [p * (len(idx_j) < n / num_collaborators)
-                                for p, idx_j in zip(proportions, idx_batch)]
-                 proportions = np.array(proportions)
-                 proportions = proportions / proportions.sum()
-                 proportions = (np.cumsum(proportions) * len(idx_k)).astype(int)[:-1]
-                 idx_splitted = np.split(idx_k, proportions)
-                 idx_batch = [idx_j + idx.tolist() for idx_j, idx in zip(idx_batch, idx_splitted)]
-                 min_size = min([len(idx_j) for idx_j in idx_batch])
-         return idx_batch
--- 0 ----
diff -crB --new-file ./openfl/openfl/utilities/fedcurv/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/fedcurv/__init__.py
*** ./openfl/openfl/utilities/fedcurv/__init__.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/fedcurv/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """openfl.utilities.fedcurv package."""
--- 0 ----
diff -crB --new-file ./openfl/openfl/utilities/fedcurv/torch/fedcurv.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/fedcurv/torch/fedcurv.py
*** ./openfl/openfl/utilities/fedcurv/torch/fedcurv.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/fedcurv/torch/fedcurv.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,164 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Implementation of FedCurv algorithm."""
- 
- from copy import deepcopy
- 
- import torch
- import torch.nn.functional as F
- 
- 
- def register_buffer(module: torch.nn.Module, name: str, value: torch.Tensor):
-     """Add a buffer to module.
- 
-     Args:
-         module: Module
-         name: Buffer name. Supports complex module names like 'model.conv1.bias'.
-         value: Buffer value
-     """
-     module_path, _, name = name.rpartition('.')
-     mod = module.get_submodule(module_path)
-     mod.register_buffer(name, value)
- 
- 
- def get_buffer(module, target):
-     """Get module buffer.
- 
-     Remove after pinning to a version
-     where https://github.com/pytorch/pytorch/pull/61429 is included.
-     Use module.get_buffer() instead.
-     """
-     module_path, _, buffer_name = target.rpartition('.')
- 
-     mod: torch.nn.Module = module.get_submodule(module_path)
- 
-     if not hasattr(mod, buffer_name):
-         raise AttributeError(f'{mod._get_name()} has no attribute `{buffer_name}`')
- 
-     buffer: torch.Tensor = getattr(mod, buffer_name)
- 
-     if buffer_name not in mod._buffers:
-         raise AttributeError('`' + buffer_name + '` is not a buffer')
- 
-     return buffer
- 
- 
- class FedCurv:
-     """Federated Curvature class.
- 
-     Requires torch>=1.9.0.
-     """
- 
-     def __init__(self, model: torch.nn.Module, importance: float):
-         """Initialize.
- 
-         Args:
-             model: Base model. Parameters of it are used in loss penalty calculation.
-             importance: Lambda coefficient of FedCurv algorithm.
-         """
-         self.importance = importance
-         self._params = {}
-         self._register_fisher_parameters(model)
- 
-     def _register_fisher_parameters(self, model):
-         params = list(model.named_parameters())
-         for n, p in params:
-             u = torch.zeros_like(p, requires_grad=False)
-             v = torch.zeros_like(p, requires_grad=False)
-             w = torch.zeros_like(p, requires_grad=False)
- 
-             # Add buffers to model for aggregation
-             register_buffer(model, f'{n}_u', u)
-             register_buffer(model, f'{n}_v', v)
-             register_buffer(model, f'{n}_w', w)
- 
-             # Store buffers locally for subtraction in loss function
-             setattr(self, f'{n}_u', u)
-             setattr(self, f'{n}_v', v)
-             setattr(self, f'{n}_w', w)
- 
-     def _update_params(self, model):
-         self._params = deepcopy({n: p for n, p in model.named_parameters() if p.requires_grad})
- 
-     def _diag_fisher(self, model, data_loader, device):
-         precision_matrices = {}
-         for n, p in self._params.items():
-             p.data.zero_()
-             precision_matrices[n] = p.data.to(device)
- 
-         model.eval()
-         model.to(device)
-         for sample, target in data_loader:
-             model.zero_grad()
-             sample = sample.to(device)
-             target = target.to(device)
-             output = model(sample)
-             loss = F.nll_loss(F.log_softmax(output, dim=1), target)
-             loss.backward()
- 
-             for n, p in model.named_parameters():
-                 if p.requires_grad:
-                     precision_matrices[n].data = p.grad.data ** 2 / len(data_loader)
- 
-         return precision_matrices
- 
-     def get_penalty(self, model):
-         """Calculate the penalty term for the loss function.
- 
-         Args:
-             model(torch.nn.Module): Model that stores global u_t and v_t values as buffers.
- 
-         Returns:
-             float: Penalty term.
-         """
-         penalty = 0
-         if not self._params:
-             return penalty
-         for name, param in model.named_parameters():
-             if param.requires_grad:
-                 u_global, v_global, w_global = (
-                     get_buffer(model, target).detach()
-                     for target in (f'{name}_u', f'{name}_v', f'{name}_w')
-                 )
-                 u_local, v_local, w_local = (
-                     getattr(self, name).detach()
-                     for name in (f'{name}_u', f'{name}_v', f'{name}_w')
-                 )
-                 u = u_global - u_local
-                 v = v_global - v_local
-                 w = w_global - w_local
-                 _penalty = param ** 2 * u - 2 * param * v + w
-                 penalty += _penalty.sum()
-         penalty = self.importance * penalty
-         return penalty.float()
- 
-     def on_train_begin(self, model):
-         """Pre-train steps.
- 
-         Args:
-             model(torch.nn.Module): model for training.
-         """
-         self._update_params(model)
- 
-     def on_train_end(self, model: torch.nn.Module, data_loader, device):
-         """Post-train steps.
- 
-         Args:
-             model(torch.nn.Module): Trained model.
-             data_loader(Iterable): Train dataset iterator.
-             device(str): Model device.
-             loss_fn(Callable): Train loss function.
-         """
-         precision_matrices = self._diag_fisher(model, data_loader, device)
-         for n, m in precision_matrices.items():
-             u = m.data.to(device)
-             v = m.data * model.get_parameter(n)
-             v = v.to(device)
-             w = m.data * model.get_parameter(n) ** 2
-             w = w.to(device)
-             register_buffer(model, f'{n}_u', u.clone().detach())
-             register_buffer(model, f'{n}_v', v.clone().detach())
-             register_buffer(model, f'{n}_w', w.clone().detach())
-             setattr(self, f'{n}_u', u.clone().detach())
-             setattr(self, f'{n}_v', v.clone().detach())
-             setattr(self, f'{n}_w', w.clone().detach())
--- 0 ----
diff -crB --new-file ./openfl/openfl/utilities/fedcurv/torch/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/fedcurv/torch/__init__.py
*** ./openfl/openfl/utilities/fedcurv/torch/__init__.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/fedcurv/torch/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """openfl.utilities.fedcurv.torch package."""
- from .fedcurv import FedCurv  # NOQA
--- 0 ----
diff -crB --new-file ./openfl/openfl/utilities/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/__init__.py
*** ./openfl/openfl/utilities/__init__.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,8 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """openfl.utilities package."""
- 
- from .types import *  # NOQA
- from .checks import *  # NOQA
- from .utils import *  # NOQA
--- 0 ----
diff -crB --new-file ./openfl/openfl/utilities/logs.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/logs.py
*** ./openfl/openfl/utilities/logs.py	2022-11-18 11:08:33.047181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/logs.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,38 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Logs utilities."""
- 
- import logging
- 
- from rich.console import Console
- from rich.logging import RichHandler
- from tensorboardX import SummaryWriter
- 
- writer = None
- 
- 
- def get_writer():
-     """Create global writer object."""
-     global writer
-     if not writer:
-         writer = SummaryWriter('./logs/cnn_mnist', flush_secs=5)
- 
- 
- def write_metric(node_name, task_name, metric_name, metric, round_number):
-     """Write metric callback."""
-     get_writer()
-     writer.add_scalar(f'{node_name}/{task_name}/{metric_name}', metric, round_number)
- 
- 
- def setup_loggers(log_level=logging.INFO):
-     """Configure loggers."""
-     root = logging.getLogger()
-     root.setLevel(log_level)
-     console = Console(width=160)
-     handler = RichHandler(console=console)
-     formatter = logging.Formatter(
-         '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'
-     )
-     handler.setFormatter(formatter)
-     root.addHandler(handler)
--- 0 ----
diff -crB --new-file ./openfl/openfl/utilities/optimizers/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/optimizers/__init__.py
*** ./openfl/openfl/utilities/optimizers/__init__.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/optimizers/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Optimizers package."""
--- 0 ----
diff -crB --new-file ./openfl/openfl/utilities/optimizers/keras/fedprox.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/optimizers/keras/fedprox.py
*** ./openfl/openfl/utilities/optimizers/keras/fedprox.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/optimizers/keras/fedprox.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,77 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """FedProx Keras optimizer module."""
- import tensorflow as tf
- import tensorflow.keras as keras
- from tensorflow.python.ops import standard_ops
- 
- 
- @keras.utils.register_keras_serializable()
- class FedProxOptimizer(keras.optimizers.Optimizer):
-     """FedProx optimizer.
- 
-     Paper: https://arxiv.org/pdf/1812.06127.pdf
-     """
- 
-     def __init__(self, learning_rate=0.01, mu=0.01, name='FedProxOptimizer', **kwargs):
-         """Initialize."""
-         super().__init__(name=name, **kwargs)
- 
-         self._set_hyper('learning_rate', learning_rate)
-         self._set_hyper('mu', mu)
- 
-         self._lr_t = None
-         self._mu_t = None
- 
-     def _prepare(self, var_list):
-         self._lr_t = tf.convert_to_tensor(self._get_hyper('learning_rate'), name='lr')
-         self._mu_t = tf.convert_to_tensor(self._get_hyper('mu'), name='mu')
- 
-     def _create_slots(self, var_list):
-         for v in var_list:
-             self.add_slot(v, 'vstar')
- 
-     def _resource_apply_dense(self, grad, var):
-         lr_t = tf.cast(self._lr_t, var.dtype.base_dtype)
-         mu_t = tf.cast(self._mu_t, var.dtype.base_dtype)
-         vstar = self.get_slot(var, 'vstar')
- 
-         var_update = var.assign_sub(lr_t * (grad + mu_t * (var - vstar)))
- 
-         return tf.group(*[var_update, ])
- 
-     def _apply_sparse_shared(self, grad, var, indices, scatter_add):
-         lr_t = tf.cast(self._lr_t, var.dtype.base_dtype)
-         mu_t = tf.cast(self._mu_t, var.dtype.base_dtype)
-         vstar = self.get_slot(var, 'vstar')
-         v_diff = vstar.assign(mu_t * (var - vstar), use_locking=self._use_locking)
- 
-         with tf.control_dependencies([v_diff]):
-             scaled_grad = scatter_add(vstar, indices, grad)
-         var_update = var.assign_sub(lr_t * scaled_grad)
- 
-         return tf.group(*[var_update, ])
- 
-     def _resource_apply_sparse(self, grad, var):
-         return self._apply_sparse_shared(
-             grad.values, var, grad.indices,
-             lambda x, i, v: standard_ops.scatter_add(x, i, v))
- 
-     def get_config(self):
-         """Return the config of the optimizer.
- 
-         An optimizer config is a Python dictionary (serializable)
-         containing the configuration of an optimizer.
-         The same optimizer can be reinstantiated later
-         (without any saved state) from this configuration.
- 
-         Returns:
-             Python dictionary.
-         """
-         base_config = super(FedProxOptimizer, self).get_config()
-         return {
-             **base_config,
-             'lr': self._serialize_hyperparameter('learning_rate'),
-             'mu': self._serialize_hyperparameter('mu')
-         }
--- 0 ----
diff -crB --new-file ./openfl/openfl/utilities/optimizers/keras/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/optimizers/keras/__init__.py
*** ./openfl/openfl/utilities/optimizers/keras/__init__.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/optimizers/keras/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,8 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Keras optimizers package."""
- import pkgutil
- 
- if pkgutil.find_loader('tensorflow'):
-     from .fedprox import FedProxOptimizer # NOQA
--- 0 ----
diff -crB --new-file ./openfl/openfl/utilities/optimizers/numpy/adagrad_optimizer.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/optimizers/numpy/adagrad_optimizer.py
*** ./openfl/openfl/utilities/optimizers/numpy/adagrad_optimizer.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/optimizers/numpy/adagrad_optimizer.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,89 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Adagrad optimizer module."""
- 
- from typing import Dict
- from typing import Optional
- 
- import numpy as np
- 
- from .base_optimizer import Optimizer
- 
- 
- class NumPyAdagrad(Optimizer):
-     """Adagrad optimizer implementation.
- 
-     Original paper: http://jmlr.org/papers/v12/duchi11a.html
-     """
- 
-     def __init__(
-         self,
-         *,
-         params: Optional[Dict[str, np.ndarray]] = None,
-         model_interface=None,
-         learning_rate: float = 0.01,
-         initial_accumulator_value: float = 0.1,
-         epsilon: float = 1e-10,
-     ) -> None:
-         """Initialize.
- 
-         Args:
-             params: Parameters to be stored for optimization.
-             model_interface: Model interface instance to provide parameters.
-             learning_rate: Tuning parameter that determines
-                 the step size at each iteration.
-             initial_accumulator_value: Initial value for squared gradients.
-             epsilon: Value for computational stability.
-         """
-         super().__init__()
- 
-         if model_interface is None and params is None:
-             raise ValueError('Should provide one of the params or model_interface')
- 
-         if learning_rate < 0:
-             raise ValueError(
-                 f'Invalid learning rate: {learning_rate}. Learning rate must be >= 0.')
-         if initial_accumulator_value < 0:
-             raise ValueError(
-                 f'Invalid initial_accumulator_value value: {initial_accumulator_value}.'
-                 'Initial accumulator value must be >= 0.')
-         if epsilon <= 0:
-             raise ValueError(
-                 f'Invalid epsilon value: {epsilon}. Epsilon avalue must be > 0.')
- 
-         self.params = params
- 
-         if params is None and model_interface is not None:
-             self._set_params_from_model(model_interface)
- 
-         self.learning_rate = learning_rate
-         self.initial_accumulator_value = initial_accumulator_value
-         self.epsilon = epsilon
- 
-         self.grads_squared = {}
-         for param_name in self.params:
-             self.grads_squared[param_name] = np.full_like(self.params[param_name],
-                                                           self.initial_accumulator_value)
- 
-     def _update_param(self, grad_name: str, grad: np.ndarray) -> None:
-         """Update papams by given gradients."""
-         self.params[grad_name] -= (self.learning_rate * grad
-                                    / (np.sqrt(self.grads_squared[grad_name]) + self.epsilon))
- 
-     def step(self, gradients: Dict[str, np.ndarray]) -> None:
-         """
-         Perform a single step for parameter update.
- 
-         Implement Adagrad optimizer weights update rule.
- 
-         Args:
-             gradients: Partial derivatives with respect to optimized parameters.
-         """
-         for grad_name in gradients:
-             if grad_name not in self.grads_squared:
-                 raise KeyError(f"Key {grad_name} doesn't exist in optimized parameters")
- 
-             grad = gradients[grad_name]
-             self.grads_squared[grad_name] = self.grads_squared[grad_name] + grad**2
-             self._update_param(grad_name, grad)
--- 0 ----
diff -crB --new-file ./openfl/openfl/utilities/optimizers/numpy/adam_optimizer.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/optimizers/numpy/adam_optimizer.py
*** ./openfl/openfl/utilities/optimizers/numpy/adam_optimizer.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/optimizers/numpy/adam_optimizer.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,126 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Adam optimizer module."""
- 
- from typing import Dict
- from typing import Optional
- from typing import Tuple
- 
- import numpy as np
- 
- from .base_optimizer import Optimizer
- 
- 
- class NumPyAdam(Optimizer):
-     """Adam optimizer implementation.
- 
-     Original paper: https://openreview.net/forum?id=ryQu7f-RZ
-     """
- 
-     def __init__(
-         self,
-         *,
-         params: Optional[Dict[str, np.ndarray]] = None,
-         model_interface=None,
-         learning_rate: float = 0.01,
-         betas: Tuple[float, float] = (0.9, 0.999),
-         initial_accumulator_value: float = 0.0,
-         epsilon: float = 1e-8,
-     ) -> None:
-         """Initialize.
- 
-         Args:
-             params: Parameters to be stored for optimization.
-             model_interface: Model interface instance to provide parameters.
-             learning_rate: Tuning parameter that determines
-                 the step size at each iteration.
-             betas: Coefficients used for computing running
-                 averages of gradient and its square.
-             initial_accumulator_value: Initial value for gradients
-                 and squared gradients.
-             epsilon: Value for computational stability.
-         """
-         super().__init__()
- 
-         if model_interface is None and params is None:
-             raise ValueError('Should provide one of the params or model_interface')
- 
-         if learning_rate < 0:
-             raise ValueError(
-                 f'Invalid learning rate: {learning_rate}. Learning rate must be >= 0.')
-         if not 0.0 <= betas[0] < 1:
-             raise ValueError(
-                 f'Invalid betas[0] value: {betas[0]}. betas[0] must be in [0, 1).')
-         if not 0.0 <= betas[1] < 1:
-             raise ValueError(
-                 f'Invalid betas[1] value: {betas[1]}. betas[1] must be in [0, 1).')
-         if initial_accumulator_value < 0:
-             raise ValueError(
-                 f'Invalid initial_accumulator_value value: {initial_accumulator_value}. \
-                 Initial accumulator value must be >= 0.')
-         if epsilon <= 0:
-             raise ValueError(
-                 f'Invalid epsilon value: {epsilon}. Epsilon avalue must be > 0.')
- 
-         self.params = params
- 
-         if params is None and model_interface is not None:
-             self._set_params_from_model(model_interface)
- 
-         self.learning_rate = learning_rate
-         self.beta_1, self.beta_2 = betas
-         self.initial_accumulator_value = initial_accumulator_value
-         self.epsilon = epsilon
-         self.current_step: Dict[str, int] = {param_name: 0 for param_name in self.params}
- 
-         self.grads_first_moment, self.grads_second_moment = {}, {}
- 
-         for param_name in self.params:
-             self.grads_first_moment[param_name] = np.full_like(self.params[param_name],
-                                                                self.initial_accumulator_value)
-             self.grads_second_moment[param_name] = np.full_like(self.params[param_name],
-                                                                 self.initial_accumulator_value)
- 
-     def _update_first_moment(self, grad_name: str, grad: np.ndarray) -> None:
-         """Update gradients first moment."""
-         self.grads_first_moment[grad_name] = (self.beta_1
-                                               * self.grads_first_moment[grad_name]
-                                               + ((1.0 - self.beta_1) * grad))
- 
-     def _update_second_moment(self, grad_name: str, grad: np.ndarray) -> None:
-         """Update gradients second moment."""
-         self.grads_second_moment[grad_name] = (self.beta_2
-                                                * self.grads_second_moment[grad_name]
-                                                + ((1.0 - self.beta_2) * grad**2))
- 
-     def step(self, gradients: Dict[str, np.ndarray]) -> None:
-         """
-         Perform a single step for parameter update.
- 
-         Implement Adam optimizer weights update rule.
- 
-         Args:
-             gradients: Partial derivatives with respect to optimized parameters.
-         """
-         for grad_name in gradients:
-             if grad_name not in self.grads_first_moment:
-                 raise KeyError(f"Key {grad_name} doesn't exist in optimized parameters")
- 
-             grad = gradients[grad_name]
- 
-             self._update_first_moment(grad_name, grad)
-             self._update_second_moment(grad_name, grad)
- 
-             t = self.current_step[grad_name] + 1
-             mean = self.grads_first_moment[grad_name]
-             var = self.grads_second_moment[grad_name]
- 
-             grads_first_moment_normalized = mean / (1. - self.beta_1 ** t)
-             grads_second_moment_normalized = var / (1. - self.beta_2 ** t)
- 
-             # Make an update for a group of parameters
-             self.params[grad_name] -= (self.learning_rate * grads_first_moment_normalized
-                                        / (np.sqrt(grads_second_moment_normalized) + self.epsilon))
- 
-             self.current_step[grad_name] += 1
--- 0 ----
diff -crB --new-file ./openfl/openfl/utilities/optimizers/numpy/base_optimizer.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/optimizers/numpy/base_optimizer.py
*** ./openfl/openfl/utilities/optimizers/numpy/base_optimizer.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/optimizers/numpy/base_optimizer.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,37 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Base abstract optimizer class module."""
- import abc
- from importlib import import_module
- from os.path import splitext
- from typing import Dict
- 
- from numpy import ndarray
- 
- from openfl.plugins.frameworks_adapters.framework_adapter_interface import (
-     FrameworkAdapterPluginInterface
- )
- 
- 
- class Optimizer(abc.ABC):
-     """Base abstract optimizer class."""
- 
-     @abc.abstractmethod
-     def step(self, gradients: Dict[str, ndarray]) -> None:
-         """Perform a single step for parameter update.
- 
-         Args:
-             gradients: Partial derivatives with respect to optimized parameters.
-         """
-         pass
- 
-     def _set_params_from_model(self, model_interface):
-         """Eject and store model parameters."""
-         class_name = splitext(model_interface.framework_plugin)[1].strip('.')
-         module_path = splitext(model_interface.framework_plugin)[0]
-         framework_adapter = import_module(module_path)
-         framework_adapter_plugin: FrameworkAdapterPluginInterface = getattr(
-             framework_adapter, class_name, None)
-         self.params: Dict[str, ndarray] = framework_adapter_plugin.get_tensor_dict(
-             model_interface.provide_model())
--- 0 ----
diff -crB --new-file ./openfl/openfl/utilities/optimizers/numpy/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/optimizers/numpy/__init__.py
*** ./openfl/openfl/utilities/optimizers/numpy/__init__.py	2022-11-18 11:06:29.755187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/optimizers/numpy/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,13 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Numpy optimizers package."""
- from .adagrad_optimizer import NumPyAdagrad
- from .adam_optimizer import NumPyAdam
- from .yogi_optimizer import NumPyYogi
- 
- __all__ = [
-     'NumPyAdagrad',
-     'NumPyAdam',
-     'NumPyYogi',
- ]
--- 0 ----
diff -crB --new-file ./openfl/openfl/utilities/optimizers/numpy/yogi_optimizer.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/optimizers/numpy/yogi_optimizer.py
*** ./openfl/openfl/utilities/optimizers/numpy/yogi_optimizer.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/optimizers/numpy/yogi_optimizer.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,68 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Adam optimizer module."""
- 
- from typing import Dict
- from typing import Optional
- from typing import Tuple
- 
- import numpy as np
- 
- from .adam_optimizer import NumPyAdam
- 
- 
- class NumPyYogi(NumPyAdam):
-     """Yogi optimizer implementation.
- 
-     Original paper:
-     https://papers.nips.cc/paper/8186-adaptive-methods-for-nonconvex-optimization
-     """
- 
-     def __init__(
-         self,
-         *,
-         params: Optional[Dict[str, np.ndarray]] = None,
-         model_interface=None,
-         learning_rate: float = 0.01,
-         betas: Tuple[float, float] = (0.9, 0.999),
-         initial_accumulator_value: float = 0.0,
-         epsilon: float = 1e-8,
-     ) -> None:
-         """Initialize.
- 
-         Args:
-             params: Parameters to be stored for optimization.
-             model_interface: Model interface instance to provide parameters.
-             learning_rate: Tuning parameter that determines
-                 the step size at each iteration.
-             betas: Coefficients used for computing running
-                 averages of gradient and its square.
-             initial_accumulator_value: Initial value for gradients
-                 and squared gradients.
-             epsilon: Value for computational stability.
-         """
-         super().__init__(params=params,
-                          model_interface=model_interface,
-                          learning_rate=learning_rate,
-                          betas=betas,
-                          initial_accumulator_value=initial_accumulator_value,
-                          epsilon=epsilon)
- 
-     def _update_second_moment(self, grad_name: str, grad: np.ndarray) -> None:
-         """Override second moment update rule for Yogi optimization updates."""
-         sign = np.sign(grad**2 - self.grads_second_moment[grad_name])
-         self.grads_second_moment[grad_name] = (self.beta_2
-                                                * self.grads_second_moment[grad_name]
-                                                + (1.0 - self.beta_2) * sign * grad**2)
- 
-     def step(self, gradients: Dict[str, np.ndarray]) -> None:
-         """
-         Perform a single step for parameter update.
- 
-         Implement Yogi optimizer weights update rule.
- 
-         Args:
-             gradients: Partial derivatives with respect to optimized parameters.
-         """
-         super().step(gradients)
--- 0 ----
diff -crB --new-file ./openfl/openfl/utilities/optimizers/torch/fedprox.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/optimizers/torch/fedprox.py
*** ./openfl/openfl/utilities/optimizers/torch/fedprox.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/optimizers/torch/fedprox.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,252 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """PyTorch FedProx optimizer module."""
- 
- import math
- 
- import torch
- from torch.optim import Optimizer
- from torch.optim.optimizer import required
- 
- 
- class FedProxOptimizer(Optimizer):
-     """FedProx optimizer.
- 
-     Paper: https://arxiv.org/pdf/1812.06127.pdf
-     """
- 
-     def __init__(self,
-                  params,
-                  lr=required,
-                  mu=0.0,
-                  momentum=0,
-                  dampening=0,
-                  weight_decay=0,
-                  nesterov=False):
-         """Initialize."""
-         if momentum < 0.0:
-             raise ValueError(f'Invalid momentum value: {momentum}')
-         if lr is not required and lr < 0.0:
-             raise ValueError(f'Invalid learning rate: {lr}')
-         if weight_decay < 0.0:
-             raise ValueError(f'Invalid weight_decay value: {weight_decay}')
-         if mu < 0.0:
-             raise ValueError(f'Invalid mu value: {mu}')
-         defaults = {
-             'dampening': dampening,
-             'lr': lr,
-             'momentum': momentum,
-             'mu': mu,
-             'nesterov': nesterov,
-             'weight_decay': weight_decay,
-         }
- 
-         if nesterov and (momentum <= 0 or dampening != 0):
-             raise ValueError('Nesterov momentum requires a momentum and zero dampening')
- 
-         super(FedProxOptimizer, self).__init__(params, defaults)
- 
-     def __setstate__(self, state):
-         """Set optimizer state."""
-         super(FedProxOptimizer, self).__setstate__(state)
-         for group in self.param_groups:
-             group.setdefault('nesterov', False)
- 
-     @torch.no_grad()
-     def step(self, closure=None):
-         """Perform a single optimization step.
- 
-         Arguments:
-             closure (callable, optional): A closure that reevaluates the model
-                 and returns the loss.
-         """
-         loss = None
-         if closure is not None:
-             loss = closure()
- 
-         for group in self.param_groups:
-             weight_decay = group['weight_decay']
-             momentum = group['momentum']
-             dampening = group['dampening']
-             nesterov = group['nesterov']
-             mu = group['mu']
-             w_old = group['w_old']
-             for p, w_old_p in zip(group['params'], w_old):
-                 if p.grad is None:
-                     continue
-                 d_p = p.grad
-                 if weight_decay != 0:
-                     d_p = d_p.add(p, alpha=weight_decay)
-                 if momentum != 0:
-                     param_state = self.state[p]
-                     if 'momentum_buffer' not in param_state:
-                         buf = param_state['momentum_buffer'] = torch.clone(d_p).detach()
-                     else:
-                         buf = param_state['momentum_buffer']
-                         buf.mul_(momentum).add_(d_p, alpha=1 - dampening)
-                     if nesterov:
-                         d_p = d_p.add(buf, alpha=momentum)
-                     else:
-                         d_p = buf
-                 if w_old is not None:
-                     d_p.add_(p - w_old_p, alpha=mu)
-                 p.add_(d_p, alpha=-group['lr'])
- 
-         return loss
- 
-     def set_old_weights(self, old_weights):
-         """Set the global weights parameter to `old_weights` value."""
-         for param_group in self.param_groups:
-             param_group['w_old'] = old_weights
- 
- 
- class FedProxAdam(Optimizer):
-     """FedProxAdam optimizer."""
- 
-     def __init__(self, params, mu=0, lr=1e-3, betas=(0.9, 0.999), eps=1e-8,
-                  weight_decay=0, amsgrad=False):
-         """Initialize."""
-         if not 0.0 <= lr:
-             raise ValueError(f'Invalid learning rate: {lr}')
-         if not 0.0 <= eps:
-             raise ValueError(f'Invalid epsilon value: {eps}')
-         if not 0.0 <= betas[0] < 1.0:
-             raise ValueError(f'Invalid beta parameter at index 0: {betas[0]}')
-         if not 0.0 <= betas[1] < 1.0:
-             raise ValueError(f'Invalid beta parameter at index 1: {betas[1]}')
-         if not 0.0 <= weight_decay:
-             raise ValueError(f'Invalid weight_decay value: {weight_decay}')
-         if mu < 0.0:
-             raise ValueError(f'Invalid mu value: {mu}')
-         defaults = {'lr': lr, 'betas': betas, 'eps': eps,
-                     'weight_decay': weight_decay, 'amsgrad': amsgrad, 'mu': mu}
-         super(FedProxAdam, self).__init__(params, defaults)
- 
-     def __setstate__(self, state):
-         """Set optimizer state."""
-         super(FedProxAdam, self).__setstate__(state)
-         for group in self.param_groups:
-             group.setdefault('amsgrad', False)
- 
-     def set_old_weights(self, old_weights):
-         """Set the global weights parameter to `old_weights` value."""
-         for param_group in self.param_groups:
-             param_group['w_old'] = old_weights
- 
-     @torch.no_grad()
-     def step(self, closure=None):
-         """Perform a single optimization step.
- 
-         Args:
-             closure (callable, optional): A closure that reevaluates the model
-                 and returns the loss.
-         """
-         loss = None
-         if closure is not None:
-             with torch.enable_grad():
-                 loss = closure()
- 
-         for group in self.param_groups:
-             params_with_grad = []
-             grads = []
-             exp_avgs = []
-             exp_avg_sqs = []
-             max_exp_avg_sqs = []
-             state_steps = []
- 
-             for p in group['params']:
-                 if p.grad is not None:
-                     params_with_grad.append(p)
-                     if p.grad.is_sparse:
-                         raise RuntimeError(
-                             'Adam does not support sparse gradients, '
-                             'please consider SparseAdam instead')
-                     grads.append(p.grad)
- 
-                     state = self.state[p]
-                     # Lazy state initialization
-                     if len(state) == 0:
-                         state['step'] = 0
-                         # Exponential moving average of gradient values
-                         state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
-                         # Exponential moving average of squared gradient values
-                         state['exp_avg_sq'] = torch.zeros_like(
-                             p, memory_format=torch.preserve_format)
-                         if group['amsgrad']:
-                             # Maintains max of all exp. moving avg. of sq. grad. values
-                             state['max_exp_avg_sq'] = torch.zeros_like(
-                                 p, memory_format=torch.preserve_format)
- 
-                     exp_avgs.append(state['exp_avg'])
-                     exp_avg_sqs.append(state['exp_avg_sq'])
- 
-                     if group['amsgrad']:
-                         max_exp_avg_sqs.append(state['max_exp_avg_sq'])
- 
-                     # update the steps for each param group update
-                     state['step'] += 1
-                     # record the step after step update
-                     state_steps.append(state['step'])
- 
-             beta1, beta2 = group['betas']
-             self.adam(params_with_grad,
-                       grads,
-                       exp_avgs,
-                       exp_avg_sqs,
-                       max_exp_avg_sqs,
-                       state_steps,
-                       group['amsgrad'],
-                       beta1,
-                       beta2,
-                       group['lr'],
-                       group['weight_decay'],
-                       group['eps'],
-                       group['mu'],
-                       group['w_old']
-                       )
-         return loss
- 
-     def adam(self, params,
-              grads,
-              exp_avgs,
-              exp_avg_sqs,
-              max_exp_avg_sqs,
-              state_steps,
-              amsgrad,
-              beta1: float,
-              beta2: float,
-              lr: float,
-              weight_decay: float,
-              eps: float,
-              mu: float,
-              w_old):
-         """Updtae optimizer parameters."""
-         for i, param in enumerate(params):
-             w_old_p = w_old[i]
-             grad = grads[i]
-             grad.add_(param - w_old_p, alpha=mu)
-             exp_avg = exp_avgs[i]
-             exp_avg_sq = exp_avg_sqs[i]
-             step = state_steps[i]
- 
-             bias_correction1 = 1 - beta1 ** step
-             bias_correction2 = 1 - beta2 ** step
- 
-             if weight_decay != 0:
-                 grad = grad.add(param, alpha=weight_decay)
- 
-             # Decay the first and second moment running average coefficient
-             exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)
-             exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)
-             if amsgrad:
-                 # Maintains the maximum of all 2nd moment running avg. till now
-                 torch.maximum(max_exp_avg_sqs[i], exp_avg_sq, out=max_exp_avg_sqs[i])
-                 # Use the max. for normalizing running avg. of gradient
-                 denom = (max_exp_avg_sqs[i].sqrt() / math.sqrt(bias_correction2)).add_(eps)
-             else:
-                 denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)
- 
-             step_size = lr / bias_correction1
- 
-             param.addcdiv_(exp_avg, denom, value=-step_size)
--- 0 ----
diff -crB --new-file ./openfl/openfl/utilities/optimizers/torch/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/optimizers/torch/__init__.py
*** ./openfl/openfl/utilities/optimizers/torch/__init__.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/optimizers/torch/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,9 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """PyTorch optimizers package."""
- import pkgutil
- 
- if pkgutil.find_loader('torch'):
-     from .fedprox import FedProxOptimizer # NOQA
-     from .fedprox import FedProxAdam # NOQA
--- 0 ----
diff -crB --new-file ./openfl/openfl/utilities/path_check.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/path_check.py
*** ./openfl/openfl/utilities/path_check.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/path_check.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,17 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """openfl path checks."""
- 
- import os
- from pathlib import Path
- from typing import Union
- 
- 
- def is_directory_traversal(directory: Union[str, Path]) -> bool:
-     """Check for directory traversal."""
-     cwd = os.path.abspath(os.getcwd())
-     requested_path = os.path.relpath(directory, start=cwd)
-     requested_path = os.path.abspath(requested_path)
-     common_prefix = os.path.commonprefix([requested_path, cwd])
-     return common_prefix != cwd
--- 0 ----
diff -crB --new-file ./openfl/openfl/utilities/types.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/types.py
*** ./openfl/openfl/utilities/types.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/types.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,25 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """openfl common object types."""
- 
- from abc import ABCMeta
- from collections import namedtuple
- 
- TensorKey = namedtuple('TensorKey', ['tensor_name', 'origin', 'round_number', 'report', 'tags'])
- TaskResultKey = namedtuple('TaskResultKey', ['task_name', 'owner', 'round_number'])
- 
- Metric = namedtuple('Metric', ['name', 'value'])
- LocalTensor = namedtuple('LocalTensor', ['col_name', 'tensor', 'weight'])
- 
- 
- class SingletonABCMeta(ABCMeta):
-     """Metaclass for singleton instances."""
- 
-     _instances = {}
- 
-     def __call__(cls, *args, **kwargs):
-         """Use the singleton instance if it has already been created."""
-         if cls not in cls._instances:
-             cls._instances[cls] = super(SingletonABCMeta, cls).__call__(*args, **kwargs)
-         return cls._instances[cls]
--- 0 ----
diff -crB --new-file ./openfl/openfl/utilities/utils.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/utils.py
*** ./openfl/openfl/utilities/utils.py	2022-11-18 11:08:33.047181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/utils.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,238 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Utilities module."""
- 
- import hashlib
- import ipaddress
- import logging
- import os
- import re
- from collections.abc import Callable
- from functools import partial
- from socket import getfqdn
- from typing import List
- from typing import Optional
- from typing import Tuple
- 
- import numpy as np
- from dynaconf import Dynaconf
- from tqdm import tqdm
- 
- 
- def getfqdn_env(name: str = '') -> str:
-     """
-     Get the system FQDN, with priority given to environment variables.
- 
-     Args:
-         name: The name from which to extract the FQDN.
- 
-     Returns:
-         The FQDN of the system.
-     """
-     fqdn = os.environ.get('FQDN', None)
-     if fqdn is not None:
-         return fqdn
-     return getfqdn(name)
- 
- 
- def is_fqdn(hostname: str) -> bool:
-     """https://en.m.wikipedia.org/wiki/Fully_qualified_domain_name."""
-     if not 1 < len(hostname) < 253:
-         return False
- 
-     # Remove trailing dot
-     hostname.rstrip('.')
- 
-     #  Split hostname into list of DNS labels
-     labels = hostname.split('.')
- 
-     #  Define pattern of DNS label
-     #  Can begin and end with a number or letter only
-     #  Can contain hyphens, a-z, A-Z, 0-9
-     #  1 - 63 chars allowed
-     fqdn = re.compile(r'^[a-z0-9]([a-z-0-9-]{0,61}[a-z0-9])?$', re.IGNORECASE)  # noqa FS003
- 
-     # Check that all labels match that pattern.
-     return all(fqdn.match(label) for label in labels)
- 
- 
- def is_api_adress(address: str) -> bool:
-     """Validate ip address value."""
-     try:
-         ipaddress.ip_address(address)
-         return True
-     except ValueError:
-         return False
- 
- 
- def add_log_level(level_name, level_num, method_name=None):
-     """
-     Add a new logging level to the logging module.
- 
-     Args:
-         level_name: name of log level.
-         level_num: log level value.
-         method_name: log method wich will use new log level (default = level_name.lower())
- 
-     """
-     if not method_name:
-         method_name = level_name.lower()
- 
-     def log_for_level(self, message, *args, **kwargs):
-         if self.isEnabledFor(level_num):
-             self._log(level_num, message, args, **kwargs)
- 
-     def log_to_root(message, *args, **kwargs):
-         logging.log(level_num, message, *args, **kwargs)
- 
-     logging.addLevelName(level_num, level_name)
-     setattr(logging, level_name, level_num)
-     setattr(logging.getLoggerClass(), method_name, log_for_level)
-     setattr(logging, method_name, log_to_root)
- 
- 
- def split_tensor_dict_into_floats_and_non_floats(tensor_dict):
-     """
-     Split the tensor dictionary into float and non-floating point values.
- 
-     Splits a tensor dictionary into float and non-float values.
- 
-     Args:
-         tensor_dict: A dictionary of tensors
- 
-     Returns:
-         Two dictionaries: the first contains all of the floating point tensors
-         and the second contains all of the non-floating point tensors
- 
-     """
-     float_dict = {}
-     non_float_dict = {}
-     for k, v in tensor_dict.items():
-         if np.issubdtype(v.dtype, np.floating):
-             float_dict[k] = v
-         else:
-             non_float_dict[k] = v
-     return float_dict, non_float_dict
- 
- 
- def split_tensor_dict_by_types(tensor_dict, keep_types):
-     """
-     Split the tensor dictionary into supported and not supported types.
- 
-     Args:
-         tensor_dict: A dictionary of tensors
-         keep_types: An iterable of supported types
-     Returns:
-         Two dictionaries: the first contains all of the supported tensors
-         and the second contains all of the not supported tensors
- 
-     """
-     keep_dict = {}
-     holdout_dict = {}
-     for k, v in tensor_dict.items():
-         if any([np.issubdtype(v.dtype, type_) for type_ in keep_types]):
-             keep_dict[k] = v
-         else:
-             holdout_dict[k] = v
-     return keep_dict, holdout_dict
- 
- 
- def split_tensor_dict_for_holdouts(logger, tensor_dict,
-                                    keep_types=(np.floating, np.integer),
-                                    holdout_tensor_names=()):
-     """
-     Split a tensor according to tensor types.
- 
-     Args:
-         logger: The log object
-         tensor_dict: A dictionary of tensors
-         keep_types: A list of types to keep in dictionary of tensors
-         holdout_tensor_names: A list of tensor names to extract from the
-          dictionary of tensors
- 
-     Returns:
-         Two dictionaries: the first is the original tensor dictionary minus
-         the holdout tenors and the second is a tensor dictionary with only the
-         holdout tensors
- 
-     """
-     # initialization
-     tensors_to_send = tensor_dict.copy()
-     holdout_tensors = {}
- 
-     # filter by-name tensors from tensors_to_send and add to holdout_tensors
-     # (for ones not already held out becuase of their type)
-     for tensor_name in holdout_tensor_names:
-         if tensor_name not in holdout_tensors.keys():
-             try:
-                 holdout_tensors[tensor_name] = tensors_to_send.pop(tensor_name)
-             except KeyError:
-                 logger.warn(f'tried to remove tensor: {tensor_name} not present '
-                             f'in the tensor dict')
-                 continue
- 
-     # filter holdout_types from tensors_to_send and add to holdout_tensors
-     tensors_to_send, not_supported_tensors_dict = split_tensor_dict_by_types(
-         tensors_to_send,
-         keep_types
-     )
-     holdout_tensors = {**holdout_tensors, **not_supported_tensors_dict}
- 
-     return tensors_to_send, holdout_tensors
- 
- 
- def validate_file_hash(file_path, expected_hash, chunk_size=8192):
-     """Validate SHA384 hash for file specified.
- 
-     Args:
-         file_path(path-like): path-like object giving the pathname
-             (absolute or relative to the current working directory)
-             of the file to be opened or an integer file descriptor of the file to be wrapped.
-         expected_hash(str): hash string to compare with.
-         hasher(_Hash): hash algorithm. Default value: `hashlib.sha384()`
-         chunk_size(int): Buffer size for file reading.
-     """
-     h = hashlib.sha384()
-     with open(file_path, 'rb') as file:
-         # Reading is buffered, so we can read smaller chunks.
-         while True:
-             chunk = file.read(chunk_size)
-             if not chunk:
-                 break
-             h.update(chunk)
- 
-     if h.hexdigest() != expected_hash:
-         raise SystemError('ZIP File hash doesn\'t match expected file hash.')
- 
- 
- def tqdm_report_hook():
-     """Visualize downloading."""
- 
-     def report_hook(pbar, count, block_size, total_size):
-         """Update progressbar."""
-         if pbar.total is None and total_size:
-             pbar.total = total_size
-         progress_bytes = count * block_size
-         pbar.update(progress_bytes - pbar.n)
- 
-     pbar = tqdm(total=None)
-     return partial(report_hook, pbar)
- 
- 
- def merge_configs(
-         overwrite_dict: Optional[dict] = None,
-         value_transform: Optional[List[Tuple[str, Callable]]] = None,
-         **kwargs,
- ) -> Dynaconf:
-     """Create Dynaconf settings, merge its with `overwrite_dict` and validate result."""
-     settings = Dynaconf(**kwargs, YAML_LOADER='safe_load')
-     if overwrite_dict:
-         for key, value in overwrite_dict.items():
-             if value is not None or settings.get(key) is None:
-                 settings.set(key, value, merge=True)
-     if value_transform:
-         for key, operation in value_transform:
-             value = settings.get(key)
-             settings.set(key, operation(value))
-     settings.validators.validate()
-     return settings
--- 0 ----
diff -crB --new-file ./openfl/openfl/utilities/workspace.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/workspace.py
*** ./openfl/openfl/utilities/workspace.py	2022-11-18 11:08:33.047181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/workspace.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,128 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Workspace utils module."""
- 
- import logging
- import os
- import shutil
- import sys
- import time
- from pathlib import Path
- from subprocess import check_call
- from sys import executable
- from typing import Optional
- from typing import Tuple
- from typing import Union
- 
- logger = logging.getLogger(__name__)
- 
- 
- class ExperimentWorkspace:
-     """Experiment workspace context manager."""
- 
-     def __init__(
-             self,
-             experiment_name: str,
-             data_file_path: Path,
-             is_install_requirements: bool = False
-     ) -> None:
-         """Initialize workspace context manager."""
-         self.experiment_name = experiment_name
-         self.data_file_path = data_file_path
-         self.cwd = os.getcwd()
-         self.experiment_work_dir = f'{self.cwd}/{self.experiment_name}'
-         self.is_install_requirements = is_install_requirements
- 
-     def _install_requirements(self):
-         """Install experiment requirements."""
-         requirements_filename = f'{self.experiment_work_dir}/requirements.txt'
- 
-         if os.path.isfile(requirements_filename):
-             attempts = 10
-             for _ in range(attempts):
-                 try:
-                     check_call([
-                         executable, '-m', 'pip', 'install', '-r', requirements_filename],
-                         shell=False)
-                 except Exception as exc:
-                     logger.error(f'Failed to install requirements: {exc}')
-                     # It's a workaround for cases when collaborators run
-                     # in common virtual environment
-                     time.sleep(5)
-                 else:
-                     break
-         else:
-             logger.error('No ' + requirements_filename + ' file found.')
- 
-     def __enter__(self):
-         """Create a collaborator workspace for the experiment."""
-         if os.path.exists(self.experiment_work_dir):
-             shutil.rmtree(self.experiment_work_dir)
-         os.makedirs(self.experiment_work_dir)
- 
-         shutil.unpack_archive(self.data_file_path, self.experiment_work_dir, format='zip')
- 
-         if self.is_install_requirements:
-             self._install_requirements()
- 
-         os.chdir(self.experiment_work_dir)
- 
-         # This is needed for python module finder
-         sys.path.append(self.experiment_work_dir)
- 
-     def __exit__(self, exc_type, exc_value, traceback):
-         """Remove the workspace."""
-         os.chdir(self.cwd)
-         shutil.rmtree(self.experiment_name, ignore_errors=True)
-         if self.experiment_work_dir in sys.path:
-             sys.path.remove(self.experiment_work_dir)
-         os.remove(self.data_file_path)
- 
- 
- def dump_requirements_file(
-         path: Union[str, Path] = './requirements.txt',
-         keep_original_prefixes: bool = True,
-         prefixes: Optional[Union[Tuple[str], str]] = None,
- ) -> None:
-     """Prepare and save requirements.txt."""
-     from pip._internal.operations import freeze
-     path = Path(path).absolute()
- 
-     # Prepare user provided prefixes for merge with original ones
-     if prefixes is None:
-         prefixes = set()
-     elif type(prefixes) is str:
-         prefixes = set(prefixes,)
-     else:
-         prefixes = set(prefixes)
- 
-     # Merge prefixes:
-     # We expect that all the prefixes in a requirement file
-     # are placed at the top
-     if keep_original_prefixes and path.is_file():
-         with open(path) as f:
-             for line in f:
-                 if line == '\n':
-                     continue
-                 if line[0] == '-':
-                     prefixes |= {line.replace('\n', '')}
-                 else:
-                     break
- 
-     requirements_generator = freeze.freeze()
-     with open(path, 'w') as f:
-         for prefix in prefixes:
-             f.write(prefix + '\n')
- 
-         for package in requirements_generator:
-             if _is_package_versioned(package):
-                 f.write(package + '\n')
- 
- 
- def _is_package_versioned(package: str) -> bool:
-     """Check if the package has a version."""
-     return ('==' in package
-             and package not in ['pkg-resources==0.0.0', 'pkg_resources==0.0.0']
-             and '-e ' not in package
-             )
--- 0 ----
diff -crB --new-file ./openfl/openfl/__version__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/__version__.py
*** ./openfl/openfl/__version__.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/__version__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """openfl version information."""
- __version__ = '1.3'
--- 0 ----
diff -crB --new-file ./openfl/openfl-docker/Dockerfile.base ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-docker/Dockerfile.base
*** ./openfl/openfl-docker/Dockerfile.base	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-docker/Dockerfile.base	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,60 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- # If your machine is behind a proxy, make sure you set it up in ~/.docker/config.json
- 
- FROM ubuntu:18.04
- 
- SHELL ["/bin/bash", "-o", "pipefail", "-c"]
- ARG INSTALL_SOURCES="no"
- WORKDIR /thirdparty
- 
- RUN dpkg --get-selections | grep -v deinstall | awk '{print $1}' > base_packages.txt  && \
-     rm -rf /var/lib/apt/lists/*
- 
- RUN apt-get update && \
-     apt-get install -y --no-install-recommends \
-         openssh-server=\* \
-         python3.8=\* \
-         python3-distutils=\* \
-         curl=\* \
-         ca-certificates=\* && \
-     if [ "$INSTALL_SOURCES" = "yes" ]; then \
-         dpkg --get-selections | grep -v deinstall | awk '{print $1}' > all_packages.txt && \
-         sed -Ei 's/# deb-src /deb-src /' /etc/apt/sources.list && \
-         apt-get update && \
-         grep -v -f base_packages.txt all_packages.txt | while read -r line; do \
-             package=$line; \
-             name=("${package//:/ }"); \
-             echo "${name[0]}" >> all_dependencies.txt; \
-             echo "${name[0]}" >> licenses.txt;\
-             cat /usr/share/doc/"${name[0]}"/copyright >> licenses.txt; \
-             grep -lE 'GPL|MPL|EPL' /usr/share/doc/"${name[0]}"/copyright; \
-             exit_status=$?; \
-             if [ $exit_status -eq 0 ]; then \
-                 apt-get source -q --download-only "$package";  \
-             fi \
-         done && rm -rf ./*packages.txt && \
-         echo "Download source for $(find . | wc -l) third-party packages: $(du -sh)"; fi && \
-     rm -rf /var/lib/apt/lists/*
- 
- WORKDIR /openfl
- COPY . .
- 
- # Install pip
- RUN update-alternatives --install /usr/bin/python python /usr/bin/python3.8 1
- RUN curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python get-pip.py && rm -rf get-pip.py
- RUN pip install --no-cache-dir . 
- WORKDIR /thirdparty
- RUN if [ "$INSTALL_SOURCES" = "yes" ]; then \
-     pip install --no-cache-dir pip-licenses; \
-     pip-licenses -l >> licenses.txt; \
-     pip-licenses | awk '{for(i=1;i<=NF;i++) if(i!=2) printf $i" "; print ""}' | tee -a all_dependencies.txt; \
-     pip-licenses | grep -E 'GPL|MPL|EPL' | awk '{OFS="=="} {print $1,$2}' | xargs pip download --no-binary :all:; \
- fi
- WORKDIR /openfl
- 
- HEALTHCHECK  --interval=30m --timeout=3s \
-   CMD echo "Container works" || exit 1
- 
- CMD [ "/bin/bash" ]
--- 0 ----
diff -crB --new-file ./openfl/openfl-docker/Dockerfile.workspace ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-docker/Dockerfile.workspace
*** ./openfl/openfl-docker/Dockerfile.workspace	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-docker/Dockerfile.workspace	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,25 ****
- ARG BASE_IMAGE=openfl:latest
- FROM ${BASE_IMAGE}
- 
- # Create unprivileged user to limit changes to mounted volumes
- ENV username=user
- ARG USER_ID=10001
- ARG GROUP_ID=1001
- RUN addgroup --gid $GROUP_ID $username
- RUN adduser --disabled-password --gecos '' --uid $USER_ID --gid $GROUP_ID $username
- 
- WORKDIR /home/user
- # Allow user to work in home dir
- RUN chmod -R a+rw .
- # Allow pip to work with existing packages (?)
- RUN chmod -R a+rwx /usr/local
- USER user
- 
- ARG WORKSPACE_NAME
- COPY ${WORKSPACE_NAME}.zip .
- 
- RUN fx workspace import --archive ${WORKSPACE_NAME}.zip
- # Unifying the workspace folder name
- RUN mv ${WORKSPACE_NAME} workspace
- WORKDIR /home/user/workspace
- RUN pip install -r requirements.txt
--- 0 ----
diff -crB --new-file ./openfl/openfl-docker/Makefile ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-docker/Makefile
*** ./openfl/openfl-docker/Makefile	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-docker/Makefile	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,6 ****
- build:
- 	@docker build -t openfl -f Dockerfile.base ..
- run:
- 	@docker run -it --network host openfl
- save:
- 	@docker save openfl > openfl.tar
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-docker/start_actor_in_container.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-docker/start_actor_in_container.sh
*** ./openfl/openfl-docker/start_actor_in_container.sh	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-docker/start_actor_in_container.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,14 ****
- #!/bin/bash
- set -m
- 
- if [ $CONTAINER_TYPE = 'collaborator' ]
- then
-     tar -xf /certs.tar
-     fx collaborator certify --import agg_to_col_${COL}_signed_cert.zip
-     fx --log-level debug collaborator start -n ${COL}
- 
- elif [ $CONTAINER_TYPE = 'aggregator' ]
- then
-     tar -xf /certs.tar
-     fx --log-level debug aggregator start
- fi
--- 0 ----
diff -crB --new-file ./openfl/openfl-gramine/Dockerfile.gramine ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-gramine/Dockerfile.gramine
*** ./openfl/openfl-gramine/Dockerfile.gramine	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-gramine/Dockerfile.gramine	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,36 ****
- ARG BASE_IMAGE=python:3.8
- FROM ${BASE_IMAGE}
- 
- SHELL ["/bin/bash", "-o", "pipefail", "-c"]
- 
- # until these changes are not in pip, install from repo
- RUN git clone https://github.com/intel/openfl.git
- WORKDIR /openfl
- RUN --mount=type=cache,target=/root/.cache/ \
-     pip install --upgrade pip && \
-     pip install .
- WORKDIR /
- 
- # install gramine
- RUN curl -fsSLo /usr/share/keyrings/gramine-keyring.gpg https://packages.gramineproject.io/gramine-keyring.gpg && \
-     echo 'deb [arch=amd64 signed-by=/usr/share/keyrings/gramine-keyring.gpg] https://packages.gramineproject.io/ stable main' | \
-     tee /etc/apt/sources.list.d/gramine.list
- RUN --mount=type=cache,id=apt-dev,target=/var/cache/apt \
-     apt-get update && \
-     apt-get install -y --no-install-recommends \
-     gramine libprotobuf-c-dev \
-     && rm -rf /var/lib/apt/lists/*
-     # there is an issue for libprotobuf-c in gramine repo, install from apt for now
- 
- # graminelibos is under this dir
- ENV PYTHONPATH=/usr/local/lib/python3.8/site-packages/:/usr/lib/python3/dist-packages/:
- 
- # install linux headers
- # WORKDIR /tmp/
- # RUN wget -c https://kernel.ubuntu.com/~kernel-ppa/mainline/v5.11/amd64/linux-headers-5.11.0-051100_5.11.0-051100.202102142330_all.deb
- # RUN dpkg -i *.deb
- # RUN mv /usr/src/linux-headers-5.11.0-051100/ /usr/src/linux-headers-5.11.0-051100rc5-generic/
- # WORKDIR /
- 
- # ENV LC_ALL=C.UTF-8
- # ENV LANG=C.UTF-8
--- 0 ----
diff -crB --new-file ./openfl/openfl-gramine/Dockerfile.graminized.workspace ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-gramine/Dockerfile.graminized.workspace
*** ./openfl/openfl-gramine/Dockerfile.graminized.workspace	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-gramine/Dockerfile.graminized.workspace	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,22 ****
- ARG BASE_IMAGE=gramine_openfl
- FROM ${BASE_IMAGE} as builder
- 
- ARG WORKSPACE_ARCHIVE
- COPY ${WORKSPACE_ARCHIVE} /workspace.zip
- RUN --mount=type=cache,target=/root/.cache/ \
-     fx workspace import --archive /workspace.zip
- 
- WORKDIR /workspace
- 
- # TODO: Find a way to remove the hardcoded paths
- RUN cp /usr/local/lib/python3.8/site-packages/openfl-gramine/openfl.manifest.template . && \
-     cp /usr/local/lib/python3.8/site-packages/openfl-gramine/Makefile . && \
-     cp /usr/local/lib/python3.8/site-packages/openfl-gramine/start_process.sh .
- 
- ARG SGX_BUILD=1
- RUN --mount=type=secret,id=signer-key,dst=/key.pem \
-     make clean && make SGX=${SGX_BUILD} SGX_SIGNER_KEY=/key.pem
- 
- ENV GRAMINE_EXECUTABLE=gramine-sgx
- ENTRYPOINT ["/bin/bash", "start_process.sh"]
- CMD [ "aggregator", "start"]
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-gramine/Makefile ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-gramine/Makefile
*** ./openfl/openfl-gramine/Makefile	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-gramine/Makefile	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,50 ****
- ARCH_LIBDIR ?= /lib/$(shell $(CC) -dumpmachine)
- 
- # This is a signer key on the BUILDING machine
- SGX_SIGNER_KEY ?= /key.pem
- 
- ifeq ($(DEBUG),1)
- GRAMINE_LOG_LEVEL = debug
- else
- GRAMINE_LOG_LEVEL = error
- endif
- 
- .PHONY: all
- all: openfl.manifest
- ifeq ($(SGX),1)
- all: openfl.manifest.sgx openfl.sig openfl.token
- endif
- 
- openfl.manifest: openfl.manifest.template
- 	@echo "Making openfl.manifest file"
- 	gramine-manifest \
- 		-Dlog_level=$(GRAMINE_LOG_LEVEL) \
- 		-Darch_libdir=$(ARCH_LIBDIR) \
- 		-Dno_proxy=$(no_proxy) \
- 		-Dhttp_proxy=$(http_proxy) \
- 		-Dhttps_proxy=$(https_proxy) \
- 		$< >$@
- 
- openfl.manifest.sgx: openfl.manifest
- 	@echo "Making openfl.manifest.sgx file"
- 	@test -s $(SGX_SIGNER_KEY) || \
- 	    { echo "SGX signer private key was not found, please specify SGX_SIGNER_KEY!"; exit 1; }
- 	gramine-sgx-sign \
- 		--key $(SGX_SIGNER_KEY) \
- 		--manifest $< \
- 		--output $@
- 
- openfl.sig: openfl.manifest.sgx
- 
- openfl.token: openfl.sig
- 	@echo "Making openfl.sig file"
- 	gramine-sgx-get-token --output $@ --sig $<
- 
- 
- .PHONY: clean
- clean:
- 	$(RM) *.manifest *.manifest.sgx *.token *.sig OUTPUT* *.PID TEST_STDOUT TEST_STDERR
- 	$(RM) -r scripts/__pycache__
- 
- .PHONY: distclean
- distclean: clean
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-gramine/MANUAL.md ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-gramine/MANUAL.md
*** ./openfl/openfl-gramine/MANUAL.md	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-gramine/MANUAL.md	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,220 ****
- # OpenFL + Gramine
- This manual will help you run OpenFL with Aggregator-based workflow inside SGX enclave with Gramine.
- 
- ## Prerequisites
- Building machine:
- - OpenFL
- - Docker should be installed, user included in Docker group
- 
- Machines that will run an Aggregator and Collaborator containers should have the following:
- - FSGSBASE feature and SGX enabled from BIOS
- - Intel SGX driver or Linux 5.11+ driver
- - Intel SGX SDK/PSW
- </br>
- This is a short list, see more in [Gramine docs](https://gramine.readthedocs.io/en/latest/devel/building.html).
- 
- ## Workflow
- The user will mainly interact with OpenFL CLI, docker CLI, and other command-line tools. But the user is also expected to modify plan.yaml file and Python code under workspace/src folder to set up an FL Experiment.
- ### On the building machine (Data Scientist's node):
- 1. As usual, **create a workspace**: 
- ```
- export WORKSPACE_NAME=my_sgx_federation_workspace
- export TEMPLATE_NAME=torch_cnn_histology
- 
- fx workspace create --prefix $WORKSPACE_NAME --template $TEMPLATE_NAME
- cd $WORKSPACE_NAME
- ```
- Modify the code and the plan.yaml, set up your training procedure. </br>
- Pay attention to the following: 
- - make sure the data loading code reads data from ./data folder inside the workspace
- - if you download data (development scenario) make sure your code first checks if data exists, as connecting to the internet from an enclave may be problematic.
- - make sure you do not use any CUDA driver-dependent packages
- 
- Default workspaces (templates) in OpenFL differ in their data downloading procedures. Workspaces with data loading flow that do not require changes to run with Gramine include:
- - torch_unet_kvasir
- - torch_cnn_histology
- - keras_nlp
- 
- 2. **Initialize the experiment plan** </br> 
- Find out the FQDN of the aggregator machine and use it for plan initialization.
- For example, on Unix-like OS try the following command:
- ```
- hostname --all-fqdns | awk '{print $1}'
- ```
- (In case this FQDN does not work for your federation, try putting the machine IP instead)
- Then pass the result as `AGG_FQDN` parameter to:
- ```
- fx plan initialize -a $AGG_FQDN
- ```
- 
- 3. (Optional) **Generate a signing key** on the building machine if you do not have one.</br>
- It will be used to calculate hashes of trusted files. If you plan to test the application without SGX (gramine-direct) you also do not need a signer key.
- ```
- export KEY_LOCATION=.
- 
- openssl genrsa -3 -out $KEY_LOCATION/key.pem 3072
- ```
- This key will not be packed into the final Docker image.
- 
- 4. **Build the Experiment Docker image**
- 
- ```
- fx workspace graminize -s $KEY_LOCATION/key.pem
- ```
- This command will build and save a Docker image with your Experiment. The saved image will contain all the required files to start a process in an enclave.</br>
- If a signing key is not provided, the application will be built without SGX support, but it still can be started with gramine-direct executable.
- 
- 
- ### Image distribution:
- Data scientist (builder) now must transfer the Docker image to the aggregator and collaborator machines. The Aggregator will also need initial model weights.
- 
- 5. **Transfer files** to the aggregator and collaborator machines.
- If there is a connection between machines, you may use `scp`. In other cases use the transfer channel that suits your situation.</br>
- Send files to the aggregator machine:
- ```
- scp BUILDING_MACHINE:WORKSPACE_PATH/WORKSPACE_NAME.tar.gz AGGREGATOR_MACHINE:SOME_PATH
- scp BUILDING_MACHINE:WORKSPACE_PATH/save/WORKSPACE_NAME_init.pbuf AGGREGATOR_MACHINE:SOME_PATH
- ```
- 
- Send the image archive to collaborator machines:
- ```
- scp BUILDING_MACHINE:WORKSPACE_PATH/WORKSPACE_NAME.tar.gz COLLABORATOR_MACHINE:SOME_PATH
- ```
- 
- Please, keep in mind, if you run a test Federation, with data downloaded from the internet, you should also transfer/download data to collaborator machines.
- 
- ### On the running machines (Aggregator and Collaborator nodes):
- 6. **Load the image.**
- Execute the following command on all running machines:
- ```
- docker load < WORKSPACE_NAME.tar.gz
- ```
- 
- 7. **Prepare certificates**
- Certificates exchange is a big separate topic. To run an experiment following OpenFL Aggregator-based workflow, a user must follow the established procedure, please refer to [the docs](https://openfl.readthedocs.io/en/latest/running_the_federation.html#bare-metal-approach).
- Following the above-mentioned procedure, running machines will acquire certificates. Moreover, as the result of this procedure, the aggregator machine will also obtain a `cols.yaml` file (required to start an experiment) with registered collaborators' names, and the collaborator machines will obtain `data.yaml` files.
- 
- We recommend replicating the OpenFL workspace folder structure on all the machines and following the usual certifying procedure. Finally, on the aggregator node you should have the following folder structure:
- ```
- workspace/
- --save/WORKSPACE_NAME_init.pbuf
- --logs/
- --plan/cols.yaml
- --cert/
-   --client/*col.crt
-   --server/
-     --agg_FQDN.crt
-     --agg_FQDN.key
- ```
- 
- On collaborator nodes:
- ```
- workspace/
- --data/*dataset*
- --plan/data.yaml
- --cert/
-   --client/
-     --col_name.crt
-     --col_name.key
- ```
- 
- To speed up the certification process for one-node test runs, it makes sense to utilize the OpenFL [integration test script](https://github.com/intel/openfl/blob/develop/tests/github/test_graminize.sh), that will create required folders and certify an aggregator and two collaborators.
- 
- ### **Run the Federation in enclaves**
- #### On the Aggregator machine run:
- ```
- export WORKSPACE_NAME=your_workspace_name
- export WORKSPACE_PATH=path_to_workspace
- docker run -it --rm --device=/dev/sgx_enclave --volume=/var/run/aesmd/aesm.socket:/var/run/aesmd/aesm.socket \
- --network=host \
- --volume=${WORKSPACE_PATH}/cert:/workspace/cert \
- --volume=${WORKSPACE_PATH}/logs:/workspace/logs \
- --volume=${WORKSPACE_PATH}/plan/cols.yaml:/workspace/plan/cols.yaml \
- --mount type=bind,src=${WORKSPACE_PATH}/save,dst=/workspace/save,readonly=0 \
- ${WORKSPACE_NAME} aggregator start
- ```
- 
- #### On the Collaborator machines run:
- ```
- export WORKSPACE_NAME=your_workspace_name
- export WORKSPACE_PATH=path_to_workspace
- export COL_NAME=col_name
- docker run -it --rm --device=/dev/sgx_enclave --volume=/var/run/aesmd/aesm.socket:/var/run/aesmd/aesm.socket \
- --network=host \
- --volume=${WORKSPACE_PATH}/cert:/workspace/cert \
- --volume=${WORKSPACE_PATH}/plan/data.yaml:/workspace/plan/data.yaml \
- --volume=${WORKSPACE_PATH}/data:/workspace/data \
- ${WORKSPACE_NAME} collaborator start -n ${COL_NAME}
- ```
- 
- ### **No SGX run (`gramine-direct`)**:
- The user may run an experiment under gramine without SGX. Note how we do not mount `sgx_enclave` device and pass a `--security-opt` instead that allows syscalls required by `gramine-direct`
- 
- #### On the Aggregator machine run:
- ```
- export WORKSPACE_NAME=your_workspace_name
- export WORKSPACE_PATH=path_to_workspace
- docker run -it --rm --security-opt seccomp=unconfined -e GRAMINE_EXECUTABLE=gramine-direct \
- --network=host \
- --volume=${WORKSPACE_PATH}/cert:/workspace/cert \
- --volume=${WORKSPACE_PATH}/logs:/workspace/logs \
- --volume=${WORKSPACE_PATH}/plan/cols.yaml:/workspace/plan/cols.yaml \
- --mount type=bind,src=${WORKSPACE_PATH}/save,dst=/workspace/save,readonly=0 \
- ${WORKSPACE_NAME} aggregator start
- ```
- 
- #### On the Collaborator machines run:
- 
- ```
- export WORKSPACE_NAME=your_workspace_name
- export WORKSPACE_PATH=path_to_workspace
- export COL_NAME=col_name
- docker run -it --rm --security-opt seccomp=unconfined -e GRAMINE_EXECUTABLE=gramine-direct \
- --network=host \
- --volume=${WORKSPACE_PATH}/cert:/workspace/cert \
- --volume=${WORKSPACE_PATH}/plan/data.yaml:/workspace/plan/data.yaml \
- --volume=${WORKSPACE_PATH}/data:/workspace/data \
- ${WORKSPACE_NAME} collaborator start -n ${COL_NAME}
- ```
- 
- ## The Routine
- Gramine+OpenFL PR brings in `openfl-gramine` folder, that contains the following files:
-  - MANUAL.md - this manual
-  - Dockerfile.gamine - the base image Dockerfile for all experiments, it starts from Python3.8 image and installs OpenFL and Gramine packages.
-  - Dockerfile.graminized.workspace - this one is for building the final experiment image. It starts from the previous image and imports the experiment archive (executes 'fx workspace import') inside an image. At this stage, we have an experiment workspace and all the requirements installed inside the image. Then it runs a unified Makefile that uses the openfl.manifest.template to prepare required files to run OpenFL under gramine inside an SGX enclave.
-  - Makefile - follows regular gramine app building workflow, please refer to [gramine examples](https://github.com/gramineproject/examples) for details
-  - openfl.manifest.template - universal FL experiment [gramine manifest template](https://gramine.readthedocs.io/en/latest/manifest-syntax.html)
-  - start_process.sh - bash script used to start an OpenFL actor in a container.
- 
- There is a files access peculiarity that should be kept in mind during debugging and development.
- Both Dockerfiles are read from the bare-metal OpenFL installation, i.e. from an OpenFL package on a building machine.
- While the gramine manifest template and the Makefile are read in image build time from the local (in-image) OpenFL package. </br>
- Thus, if one wants to make changes to the gramine manifest template or the Makefile, they should change the OpenFL installation procedure in Dockerfile.gramine, so their changes may be pulled to the base image. One option is to push the changes to a GitHub fork and install OpenFL from this fork. 
- ```
- *Dockerfile.gramine:*
- 
- RUN git clone https://github.com/your-username/openfl.git --branch some_branch
- WORKDIR /openfl
- RUN --mount=type=cache,target=/root/.cache/ \
-     pip install --upgrade pip && \
-     pip install .
- WORKDIR /
- ```
- In this case, to rebuild the image, use `fx workspace dockerize --rebuild` with `--rebuild` flag that will pass '--no-cache' to docker build command.
- 
- Another option is to copy OpenFL source files from an on-disk cloned repo, but it would mean that the user must build the graminized image from the repo directory using Docker CLI.
- 
- 
- ## Known issues:
- - Kvasir experiment: aggregation takes really long, debug log-level does not show the reason
- - We need workspace zip to import it and create certs. We need to know the number of collaborators prior to zipping the workspace. SOLUTION: mount cols.yaml and data.yaml
- - During plan initialization we need data to initialize the model. so at least one collaborator should be in data.yaml and its data should be available. cols.yaml may be empty at first
- During cert sign request generation cols.yaml on collaborators remain empty, data.yaml is extended if needed. On aggregator, cols.yaml are updated during signing procedure, data.yaml remains unmodified
- - `error: Disallowing access to file '/usr/local/lib/python3.8/__pycache__/signal.cpython-38.pyc.3423950304'; file is not protected, trusted or allowed.`
- 
-  ## TO-DO:
- - [X] import manifest and makefile from OpenFL dist-package 
- - [X] pass wheel repository to pip (for CPU versions of PyTorch for example)
- - [ ] get rid of command line args (insecure)
- - [ ] introduce `fx workspace create --prefix WORKSPACE_NAME` command without --template option to the OpenFL CLI, which will create just an empty workspace with the right folder structure.
- - [ ] introduce `fx *actor* start --from image`
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-gramine/openfl.manifest.template ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-gramine/openfl.manifest.template
*** ./openfl/openfl-gramine/openfl.manifest.template	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-gramine/openfl.manifest.template	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,76 ****
- loader.preload = "file:{{ gramine.libos }}"
- libos.entrypoint = "/usr/local/bin/python3.8"
- loader.log_level = "{{ log_level }}"
- 
- loader.env.LD_LIBRARY_PATH = "{{ python.stdlib }}/lib:/lib:{{ arch_libdir }}:/usr/lib:/usr/{{ arch_libdir }}"
- loader.env.no_proxy = "{{ no_proxy }}"
- loader.env.https_proxy = "{{ https_proxy }}"
- loader.env.http_proxy = "{{ http_proxy }}"
- loader.env.SSL_CERT_DIR = "/etc/ssl/certs"
- 
- loader.insecure__use_cmdline_argv = true
- 
- sys.enable_sigterm_injection = true
- 
- fs.start_dir="/workspace"
- 
- 
- # .URI - path on host
- # .PATH - pointer inside gramine
- 
- fs.mount.lib.type = "chroot"
- fs.mount.lib.path = "/lib"
- fs.mount.lib.uri = "file:{{ gramine.runtimedir() }}"
- 
- fs.mount.lib2.type = "chroot"
- fs.mount.lib2.path = "{{ arch_libdir }}"
- fs.mount.lib2.uri = "file:{{ arch_libdir }}"
- 
- fs.mount.usr.type = "chroot"
- fs.mount.usr.path = "/usr"
- fs.mount.usr.uri = "file:/usr"
- 
- fs.mount.etc.type = "chroot"
- fs.mount.etc.path = "/etc"
- fs.mount.etc.uri = "file:/etc"
- 
- fs.mount.workspace.type = "chroot"
- fs.mount.workspace.path = "/workspace"
- fs.mount.workspace.uri = "file:/workspace"
- 
- sgx.preheat_enclave = false
- 
- # Detected a huge manifest, preallocating 64MB of internal memory.
- # error: Too small `loader.pal_internal_mem_size`, need at least 64MB because the manifest is large
- loader.pal_internal_mem_size = "256M"
- 
- sgx.debug = false
- sgx.nonpie_binary = true
- sgx.enclave_size = "16G"
- sys.stack.size = "4M"
- sgx.thread_num = 512
- #sys.brk.max_size = "1M"
- 
- sgx.trusted_files = [
-   "file:/usr/local/bin/python3.8",
-   "file:{{ gramine.runtimedir() }}/",
-   "file:{{ arch_libdir }}/",
-   "file:/usr/{{ arch_libdir }}/",
-   "file:/usr/local/lib/python3.8/",
-   "file:/usr/local/lib/libpython3.8.so.1.0",
-   "file:/usr/lib/python3/dist-packages/",
-   "file:/workspace/src/",
-   "file:/workspace/plan/plan.yaml",
-   "file:/usr/local/bin/fx",
- ]
- 
- sgx.allowed_files = [
-   "file:/tmp",
-   "file:/etc",
-   "file:/workspace/save",
-   "file:/workspace/logs",
-   "file:/workspace/cert",
-   "file:/workspace/data",
-   "file:/workspace/plan/cols.yaml",
-   "file:/workspace/plan/data.yaml",
- ]
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-gramine/start_process.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-gramine/start_process.sh
*** ./openfl/openfl-gramine/start_process.sh	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-gramine/start_process.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- fx_command=$@;
- 
- $GRAMINE_EXECUTABLE ./openfl /usr/local/bin/fx $fx_command
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openFL.patch ../mlwins-simulation-framework/ml-frameworks/federated-learning/openFL.patch
*** ./openfl/openFL.patch	1969-12-31 16:00:00.000000000 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openFL.patch	2022-11-18 12:04:11.935017653 -0800
***************
*** 0 ****
--- 1,4224 ----
+ Only in ./openfl: .dockerignore
+ diff -crB ./openfl/docs/overriding_agg_fn.rst ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/overriding_agg_fn.rst
+ *** ./openfl/docs/overriding_agg_fn.rst	2022-11-18 11:08:33.039181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/overriding_agg_fn.rst	2022-08-15 11:42:19.106825370 -0700
+ ***************
+ *** 155,161 ****
+   Custom Aggregation Functions
+   ----------------------------
+   
+ ! You can also create your own implementation of :class:`openfl.component.aggregation_functions.core.AggregationFunction`. See `example <https://github.com/intel/openfl/blob/develop/openfl-tutorials/Federated_Pytorch_MNIST_custom_aggregation_Tutorial.ipynb>`_ for details.
+   
+   1. Define the behavior of the aggregation.
+   
+ --- 155,161 ----
+   Custom Aggregation Functions
+   ----------------------------
+   
+ ! OpenFL provides interfaces to support your own custom aggregation functions. You can also create your own implementation of :class:`openfl.component.aggregation_functions.core.AggregationFunction`. See `example <https://github.com/intel/openfl/blob/develop/openfl-tutorials/Federated_Pytorch_MNIST_custom_aggregation_Tutorial.ipynb>`_ for details.
+   
+   1. Define the behavior of the aggregation.
+   
+ ***************
+ *** 289,291 ****
+ --- 289,381 ----
+               return np.average(clipped_tensors, weights=weights, axis=0)
+   
+   A full implementation can be found at `Federated_Pytorch_MNIST_custom_aggregation_Tutorial.ipynb <https://github.com/intel/openfl/blob/develop/openfl-tutorials/Federated_Pytorch_MNIST_custom_aggregation_Tutorial.ipynb>`_
+ + 
+ + Example of a Privileged Aggregation Function
+ + ========================================
+ + 
+ + Most of the time the AggregationFunction interface is sufficient to implement custom methods, but in certain scenarios users may want to store additional information inside the TensorDB Dataframe beyond the aggregated tensor. The :class:`openfl.component.aggregation_functions.experimental.PrivilegedAggregationFunction` interface is provided for this use, and gives the user direct access to aggregator's TensorDB dataframe (notice the `tensor_db` param in the call function replaces the `db_iterator` from the standard AggregationFunction interface). As the name suggests, this interface is called privileged because with great power comes great responsibility, and modifying the TensorDB dataframe directly can lead to unexpected behavior and experiment failures if entries are arbitrarily deleted.
+ + 
+ + .. code-block:: python
+ + 
+ +     from openfl.component.aggregation_functions.experimental import PrivilegedAggregationFunction 
+ +     import numpy as np
+ +     import pandas as pd
+ + 
+ +     class PrioritizeLeastImproved(PrivilegedAggregationFunction):
+ +         """
+ +             Give collaborator with the least improvement in validation accuracy more influence over future weights
+ +             
+ +         """
+ +             
+ +         def call(self,
+ +                  local_tensors,
+ +                  tensor_db,
+ +                  tensor_name,
+ +                  fl_round,
+ +                  tags):
+ +             """Aggregate tensors.
+ +     
+ +             Args:
+ +                 local_tensors(list[openfl.utilities.LocalTensor]): List of local tensors to aggregate.
+ +                 tensor_db: Aggregator's TensorDB [writable]. Columns:
+ +                     - 'tensor_name': name of the tensor.
+ +                         Examples for `torch.nn.Module`s: 'conv1.weight', 'fc2.bias'.
+ +                     - 'round': 0-based number of round corresponding to this tensor.
+ +                     - 'tags': tuple of tensor tags. Tags that can appear:
+ +                         - 'model' indicates that the tensor is a model parameter.
+ +                         - 'trained' indicates that tensor is a part of a training result.
+ +                             These tensors are passed to the aggregator node after local learning.
+ +                         - 'aggregated' indicates that tensor is a result of aggregation.
+ +                             These tensors are sent to collaborators for the next round.
+ +                         - 'delta' indicates that value is a difference between rounds
+ +                             for a specific tensor.
+ +                         also one of the tags is a collaborator name
+ +                         if it corresponds to a result of a local task.
+ +     
+ +                     - 'nparray': value of the tensor.
+ +                 tensor_name: name of the tensor
+ +                 fl_round: round number
+ +                 tags: tuple of tags for this tensor
+ +             Returns:
+ +                 np.ndarray: aggregated tensor
+ +             """
+ +             from openfl.utilities import change_tags
+ +     
+ +             tensors, weights, collaborators = zip(*[(x.tensor, x.weight, x.col_name) for idx,x in enumerate(local_tensors)])
+ +             tensors, weights, collaborators = np.array(tensors), np.array(weights), collaborators
+ +     
+ +             if fl_round > 0:
+ +                 metric_tags = ('metric','validate_agg')
+ +                 collaborator_accuracy = {}
+ +                 previous_col_accuracy = {}
+ +                 change_in_accuracy = {}
+ +                 for col in collaborators:
+ +                     col_metric_tag = change_tags(metric_tags,add_field=col)
+ +                     collaborator_accuracy[col] = float(tensor_db[(tensor_db['tensor_name'] == 'acc') &
+ +                                                            (tensor_db['round'] == fl_round) &
+ +                                                            (tensor_db['tags'] == col_metric_tag)]['nparray'])
+ +                     previous_col_accuracy[col] = float(tensor_db[(tensor_db['tensor_name'] == 'acc') &
+ +                                                            (tensor_db['round'] == fl_round - 1) &
+ +                                                            (tensor_db['tags'] == col_metric_tag)]['nparray'])
+ +                     change_in_accuracy[col] = collaborator_accuracy[col] - previous_col_accuracy[col]
+ +                     
+ +             
+ +                 least_improved_collaborator = min(change_in_accuracy,key=change_in_accuracy.get)
+ +                 
+ +                 # Dont add least improved collaborator more than once
+ +                 if len(tensor_db[(tensor_db['tags'] == ('least_improved',)) &
+ +                              (tensor_db['round'] == fl_round)]) == 0:
+ +                     tensor_db.loc[tensor_db.shape[0]] = \
+ +                             ['_','_',fl_round,True,('least_improved',),np.array(least_improved_collaborator)]
+ +                     fx.logger.info(f'Least improved collaborator = {least_improved_collaborator}')
+ +                     fx.logger.info(f"Least improved = {tensor_db[(tensor_db['tags'] == ('least_improved',)) & (tensor_db['nparray'] == np.array(least_improved_collaborator))]}")
+ +                     fx.logger.info(f'Collaborator accuracy = {collaborator_accuracy}')
+ +                     fx.logger.info(f'Change in accuracy {change_in_accuracy}')
+ +                 least_improved_weight_factor = 0.1 * len(tensor_db[(tensor_db['tags'] == ('least_improved',)) &
+ +                                                                    (tensor_db['nparray'] == np.array(least_improved_collaborator))])
+ +                 weights[collaborators.index(least_improved_collaborator)] += least_improved_weight_factor
+ +                 weights = weights / np.sum(weights)
+ +                 
+ +             return np.average(tensors, weights=weights, axis=0)
+ + 
+ + A full implementation can be found at `Federated_Pytorch_MNIST_custom_aggregation_Tutorial.ipynb <https://github.com/intel/openfl/blob/develop/openfl-tutorials/Federated_Pytorch_MNIST_custom_aggregation_Tutorial.ipynb>`_
+ diff -crB ./openfl/docs/running_the_federation.rst ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/running_the_federation.rst
+ *** ./openfl/docs/running_the_federation.rst	2022-11-18 11:08:33.039181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/docs/running_the_federation.rst	2022-08-15 11:42:19.106825370 -0700
+ ***************
+ *** 7,19 ****
+   Run the Federation
+   ******************
+   
+ ! OpenFL currently supports two types of workflow for how to set up and run a federation: Director-based workflow (preferrable) and Aggregator-based workflow (old workflow, will not be supported soon). Director-based workflow introduces a new and more convenient way to set up a federation and brings "long-lived" components in a federation ("Director" and "Envoy").
+   
+   `Director-Based Workflow`_
+ !     A federation created with this workflow continues to be available to distribute more experiments in series.
+   
+   `Aggregator-Based Workflow`_
+ !     With this workflow, the federation is terminated when the experiment is finished.
+   
+   
+   .. _director_workflow:
+ --- 7,20 ----
+   Run the Federation
+   ******************
+   
+ ! OpenFL currently offers two ways to set up and run experiments with a federation: the Director-based workflow and Aggregator-based workflow. The Director-based workflow introduces a new and more convenient way to set up a federation and brings "long-lived" components in a federation ("Director" and "Envoy"), while the Aggregator-based workflow is advised for scenarios where the workload needs to be verified prior to execution.
+   
+   `Director-Based Workflow`_
+ !     Setup long-lived components to run many experiments in series. Recommended for FL research when many changes to model, dataloader, or hyperparameters are expected
+ ! 
+   
+   `Aggregator-Based Workflow`_
+ !     Define an experiment and distribute it manually. All participants can verify model code and [FL plan](https://openfl.readthedocs.io/en/latest/running_the_federation.html#federated-learning-plan-fl-plan-settings) prior to execution. The federation is terminated when the experiment is finished
+   
+   
+   .. _director_workflow:
+ ***************
+ *** 38,44 ****
+   
+   - *Experiment manager* (or Data scientist) is a person or group of people using OpenFL.
+   - *Director Manager* is ML model creator's representative controlling Director.
+ ! - *Collaborator manager* is Data onwer's representative controlling Envoy.
+   
+   .. note::
+       The Open Federated Learning (|productName|) interactive Python API enables the Experiment manager (data scientists) to define and start a federated learning experiment from a single entry point: a Jupyter\*\  notebook or a Python\*\  script.
+ --- 39,45 ----
+   
+   - *Experiment manager* (or Data scientist) is a person or group of people using OpenFL.
+   - *Director Manager* is ML model creator's representative controlling Director.
+ ! - *Collaborator manager* is Data owner's representative controlling Envoy.
+   
+   .. note::
+       The Open Federated Learning (|productName|) interactive Python API enables the Experiment manager (data scientists) to define and start a federated learning experiment from a single entry point: a Jupyter\*\  notebook or a Python\*\  script.
+ ***************
+ *** 52,58 ****
+   .. centered:: Overview of the Director-Based Workflow
+   
+   
+ ! .. # Copyright (C) 2020-2021 Intel Corporation
+   .. # SPDX-License-Identifier: Apache-2.0
+   
+   
+ --- 53,59 ----
+   .. centered:: Overview of the Director-Based Workflow
+   
+   
+ ! .. # Copyright (C) 2020-2022 Intel Corporation
+   .. # SPDX-License-Identifier: Apache-2.0
+   
+   
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning: .eggs
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning: eggs
+ Only in ./openfl: .git
+ Only in ./openfl: .github
+ Only in ./openfl: .gitignore
+ diff -crB ./openfl/openfl/component/aggregation_functions/adam_adaptive_aggregation.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/adam_adaptive_aggregation.py
+ *** ./openfl/openfl/component/aggregation_functions/adam_adaptive_aggregation.py	2022-11-18 11:08:33.043181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/adam_adaptive_aggregation.py	2022-08-15 11:42:21.394825319 -0700
+ ***************
+ *** 52,56 ****
+                           learning_rate=learning_rate,
+                           betas=betas,
+                           initial_accumulator_value=initial_accumulator_value,
+ !                         epsilo=epsilon)
+           super().__init__(opt, agg_func)
+ --- 52,56 ----
+                           learning_rate=learning_rate,
+                           betas=betas,
+                           initial_accumulator_value=initial_accumulator_value,
+ !                         epsilon=epsilon)
+           super().__init__(opt, agg_func)
+ diff -crB ./openfl/openfl/component/aggregation_functions/core/adaptive_aggregation.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/core/adaptive_aggregation.py
+ *** ./openfl/openfl/component/aggregation_functions/core/adaptive_aggregation.py	2022-11-18 11:08:33.043181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/core/adaptive_aggregation.py	2022-08-15 11:42:21.394825319 -0700
+ ***************
+ *** 30,35 ****
+ --- 30,36 ----
+               agg_func: Aggregate function for aggregating
+                   parameters that are not inside the optimizer.
+           """
+ +         super().__init__()
+           self.optimizer = optimizer
+           self.default_agg_func = agg_func
+   
+ ***************
+ *** 54,60 ****
+   
+           Args:
+               local_tensors(list[openfl.utilities.LocalTensor]): List of local tensors to aggregate.
+ !             db_iterator: iterator over history of all tensors. Columns:
+                   - 'tensor_name': name of the tensor.
+                       Examples for `torch.nn.Module`s: 'conv1.weight', 'fc2.bias'.
+                   - 'fl_round': 0-based number of round corresponding to this tensor.
+ --- 55,61 ----
+   
+           Args:
+               local_tensors(list[openfl.utilities.LocalTensor]): List of local tensors to aggregate.
+ !             db_iterator: An iterator over history of all tensors. Columns:
+                   - 'tensor_name': name of the tensor.
+                       Examples for `torch.nn.Module`s: 'conv1.weight', 'fc2.bias'.
+                   - 'fl_round': 0-based number of round corresponding to this tensor.
+ diff -crB ./openfl/openfl/component/aggregation_functions/core/interface.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/core/interface.py
+ *** ./openfl/openfl/component/aggregation_functions/core/interface.py	2022-11-18 11:08:33.043181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/core/interface.py	2022-08-15 11:42:21.394825319 -0700
+ ***************
+ *** 5,10 ****
+ --- 5,11 ----
+   from typing import Iterator
+   from typing import List
+   from typing import Tuple
+ + from typing import Union
+   
+   import numpy as np
+   import pandas as pd
+ ***************
+ *** 16,21 ****
+ --- 17,29 ----
+   class AggregationFunction(metaclass=SingletonABCMeta):
+       """Interface for specifying aggregation function."""
+   
+ +     def __init__(self):
+ +         """Initialize common AggregationFunction params
+ +         
+ +            Default: Read only access to TensorDB
+ +         """
+ +         self._privileged = False
+ + 
+       @abstractmethod
+       def call(self,
+                local_tensors: List[LocalTensor],
+ ***************
+ *** 27,33 ****
+   
+           Args:
+               local_tensors(list[openfl.utilities.LocalTensor]): List of local tensors to aggregate.
+ !             db_iterator: iterator over history of all tensors. Columns:
+                   - 'tensor_name': name of the tensor.
+                       Examples for `torch.nn.Module`s: 'conv1.weight', 'fc2.bias'.
+                   - 'round': 0-based number of round corresponding to this tensor.
+ --- 35,41 ----
+   
+           Args:
+               local_tensors(list[openfl.utilities.LocalTensor]): List of local tensors to aggregate.
+ !             db_iterator: An iterator over history of all tensors. Columns:
+                   - 'tensor_name': name of the tensor.
+                       Examples for `torch.nn.Module`s: 'conv1.weight', 'fc2.bias'.
+                   - 'round': 0-based number of round corresponding to this tensor.
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions: experimental
+ diff -crB ./openfl/openfl/component/aggregation_functions/fedcurv_weighted_average.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/fedcurv_weighted_average.py
+ *** ./openfl/openfl/component/aggregation_functions/fedcurv_weighted_average.py	2022-11-18 11:08:33.043181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/fedcurv_weighted_average.py	2022-08-15 11:42:21.394825319 -0700
+ ***************
+ *** 16,22 ****
+       FedCurv paper: https://arxiv.org/pdf/1910.07796.pdf
+       """
+   
+ !     def call(self, local_tensors, db_iterator, tensor_name, fl_round, tags):
+           """Apply aggregation."""
+           if (
+               tensor_name.endswith('_u')
+ --- 16,22 ----
+       FedCurv paper: https://arxiv.org/pdf/1910.07796.pdf
+       """
+   
+ !     def call(self, local_tensors, tensor_db, tensor_name, fl_round, tags):
+           """Apply aggregation."""
+           if (
+               tensor_name.endswith('_u')
+ diff -crB ./openfl/openfl/component/aggregation_functions/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/__init__.py
+ *** ./openfl/openfl/component/aggregation_functions/__init__.py	2022-11-18 11:08:33.043181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregation_functions/__init__.py	2022-08-15 11:42:21.394825319 -0700
+ ***************
+ *** 6,11 ****
+ --- 6,12 ----
+   from .adagrad_adaptive_aggregation import AdagradAdaptiveAggregation
+   from .adam_adaptive_aggregation import AdamAdaptiveAggregation
+   from .core import AggregationFunction
+ + from .experimental import PrivilegedAggregationFunction
+   from .fedcurv_weighted_average import FedCurvWeightedAverage
+   from .geometric_median import GeometricMedian
+   from .median import Median
+ ***************
+ *** 19,22 ****
+ --- 20,24 ----
+              'AdamAdaptiveAggregation',
+              'YogiAdaptiveAggregation',
+              'AggregationFunction',
+ +            'PrivilegedAggregationFunction',
+              'FedCurvWeightedAverage']
+ diff -crB ./openfl/openfl/component/aggregator/aggregator.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregator/aggregator.py
+ *** ./openfl/openfl/component/aggregator/aggregator.py	2022-11-18 11:08:33.043181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/aggregator/aggregator.py	2022-11-18 12:02:35.135022401 -0800
+ ***************
+ *** 1,7 ****
+   # Copyright (C) 2020-2021 Intel Corporation
+   # SPDX-License-Identifier: Apache-2.0
+   
+ ! """Aggregator module."""
+   import queue
+   from logging import getLogger
+   
+ --- 1,8 ----
+   # Copyright (C) 2020-2021 Intel Corporation
+   # SPDX-License-Identifier: Apache-2.0
+   
+ ! """Aggregator module.""" 
+ ! import time
+   import queue
+   from logging import getLogger
+   
+ ***************
+ *** 11,16 ****
+ --- 12,18 ----
+   from openfl.pipelines import TensorCodec
+   from openfl.protocols import base_pb2
+   from openfl.protocols import utils
+ + from openfl.utilities import change_tags
+   from openfl.utilities import TaskResultKey
+   from openfl.utilities import TensorKey
+   from openfl.utilities.logs import write_metric
+ ***************
+ *** 314,320 ****
+           return tasks, self.round_number, sleep_time, time_to_quit
+   
+       def get_aggregated_tensor(self, collaborator_name, tensor_name,
+ !                               round_number, report, tags, require_lossless):
+           """
+           RPC called by collaborator.
+   
+ --- 317,323 ----
+           return tasks, self.round_number, sleep_time, time_to_quit
+   
+       def get_aggregated_tensor(self, collaborator_name, tensor_name,
+ !                               round_number, report, tags, require_lossless, meta=None):
+           """
+           RPC called by collaborator.
+   
+ ***************
+ *** 328,334 ****
+               require_lossless: bool
+               round_number: int
+               report: bool
+ !             tags: list[str]
+           Returns:
+               named_tensor : protobuf NamedTensor
+                   the tensor requested by the collaborator
+ --- 331,337 ----
+               require_lossless: bool
+               round_number: int
+               report: bool
+ !             tags: tuple[str, ...]
+           Returns:
+               named_tensor : protobuf NamedTensor
+                   the tensor requested by the collaborator
+ ***************
+ *** 341,358 ****
+           else:
+               compress_lossless = False
+   
+ -         tags = list(tags)
+ - 
+           # TODO the TensorDB doesn't support compressed data yet.
+           #  The returned tensor will
+           # be recompressed anyway.
+           if 'compressed' in tags:
+ !             tags.remove('compressed')
+           if 'lossy_compressed' in tags:
+ !             tags.remove('lossy_compressed')
+   
+           tensor_key = TensorKey(
+ !             tensor_name, self.uuid, round_number, report, tuple(tags)
+           )
+           tensor_name, origin, round_number, report, tags = tensor_key
+   
+ --- 344,359 ----
+           else:
+               compress_lossless = False
+   
+           # TODO the TensorDB doesn't support compressed data yet.
+           #  The returned tensor will
+           # be recompressed anyway.
+           if 'compressed' in tags:
+ !             tags = change_tags(tags, remove_field='compressed')
+           if 'lossy_compressed' in tags:
+ !             tags = change_tags(tags, remove_field='lossy_compressed')
+   
+           tensor_key = TensorKey(
+ !             tensor_name, self.uuid, round_number, report, tags
+           )
+           tensor_name, origin, round_number, report, tags = tensor_key
+   
+ ***************
+ *** 365,370 ****
+ --- 366,379 ----
+   
+           nparray = self.tensor_db.get_tensor_from_cache(agg_tensor_key)
+   
+ +         start_retrieving_time = time.time()
+ +         while(nparray is None):
+ +             self.logger.debug(f'Waiting for tensor_key {agg_tensor_key}')
+ +             time.sleep(5)
+ +             nparray = self.tensor_db.get_tensor_from_cache(agg_tensor_key)
+ +             if (time.time() - start_retrieving_time) > 60:
+ +                 break
+ + 
+           if nparray is None:
+               raise ValueError(f'Aggregator does not have an aggregated tensor for {tensor_key}')
+   
+ ***************
+ *** 388,397 ****
+ --- 397,408 ----
+           Also includes logic to create delta, compress tensors with the TensorCodec, etc.
+           """
+           tensor_name, origin, round_number, report, tags = tensor_key
+ +         #print('_nparray_to_named_tensor', tensor_key)
+           # if we have an aggregated tensor, we can make a delta
+           if 'aggregated' in tags and send_model_deltas:
+               # Should get the pretrained model to create the delta. If training
+               # has happened, Model should already be stored in the TensorDB
+ +             #print ('YYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYY')
+               model_tk = TensorKey(tensor_name,
+                                    origin,
+                                    round_number - 1,
+ ***************
+ *** 459,465 ****
+           return task_key in self.collaborator_tasks_results
+   
+       def send_local_task_results(self, collaborator_name, round_number, task_name,
+ !                                 data_size, named_tensors):
+           """
+           RPC called by collaborator.
+   
+ --- 470,476 ----
+           return task_key in self.collaborator_tasks_results
+   
+       def send_local_task_results(self, collaborator_name, round_number, task_name,
+ !                                 data_size, named_tensors, metaInfo=None):
+           """
+           RPC called by collaborator.
+   
+ ***************
+ *** 478,484 ****
+               f'Collaborator {collaborator_name} is sending task results '
+               f'for {task_name}, round {round_number}'
+           )
+ ! 
+           task_key = TaskResultKey(task_name, collaborator_name, round_number)
+   
+           # we mustn't have results already
+ --- 489,495 ----
+               f'Collaborator {collaborator_name} is sending task results '
+               f'for {task_name}, round {round_number}'
+           )
+ !         
+           task_key = TaskResultKey(task_name, collaborator_name, round_number)
+   
+           # we mustn't have results already
+ ***************
+ *** 527,540 ****
+                   self.metric_queue.put(metric_dict)
+   
+               task_results.append(tensor_key)
+ !             # By giving task_key it's own weight, we can support different
+ !             # training/validation weights
+ !             # As well as eventually supporting weights that change by round
+ !             # (if more data is added)
+ !             self.collaborator_task_weight[task_key] = data_size
+   
+           self.collaborator_tasks_results[task_key] = task_results
+ ! 
+           self._end_of_task_check(task_name)
+   
+       def _process_named_tensor(self, named_tensor, collaborator_name):
+ --- 538,556 ----
+                   self.metric_queue.put(metric_dict)
+   
+               task_results.append(tensor_key)
+ !             self.collaborator_task_weight[task_key] = data_size        
+   
+           self.collaborator_tasks_results[task_key] = task_results
+ !         
+ !         
+ !         
+ !         if task_name == 'train':
+ !             if 'status' in metaInfo and metaInfo['status'] == '0':
+ !                 print('openFL (Round:', self.round_number, '): Aggregator', 'Send task results (training) RPC failed over wireless for collaborator', collaborator_name)
+ !                 self.assigner.collaborators_for_task[round_number][task_name].remove(collaborator_name)
+ !             else: 
+ !                 print('openFL (Round:', self.round_number, '): Aggregator', 'Send task results (training) RPC succeeded over wireless for collaborator', collaborator_name)
+ !             
+           self._end_of_task_check(task_name)
+   
+       def _process_named_tensor(self, named_tensor, collaborator_name):
+ ***************
+ *** 583,592 ****
+               )
+               dec_name, dec_origin, dec_round_num, dec_report, dec_tags = dec_tk
+               # Need to add the collaborator tag to the resulting tensor
+ !             if type(dec_tags) == str:
+ !                 new_tags = tuple([dec_tags] + [collaborator_name])
+ !             else:
+ !                 new_tags = tuple(list(dec_tags) + [collaborator_name])
+               # layer.agg.n.trained.delta.col_i
+               decompressed_tensor_key = TensorKey(
+                   dec_name, dec_origin, dec_round_num, dec_report, new_tags
+ --- 599,606 ----
+               )
+               dec_name, dec_origin, dec_round_num, dec_report, dec_tags = dec_tk
+               # Need to add the collaborator tag to the resulting tensor
+ !             new_tags = change_tags(dec_tags, add_field=collaborator_name)
+ ! 
+               # layer.agg.n.trained.delta.col_i
+               decompressed_tensor_key = TensorKey(
+                   dec_name, dec_origin, dec_round_num, dec_report, new_tags
+ ***************
+ *** 599,608 ****
+                   require_lossless=False
+               )
+               dec_name, dec_origin, dec_round_num, dec_report, dec_tags = dec_tk
+ !             if type(dec_tags) == str:
+ !                 new_tags = tuple([dec_tags] + [collaborator_name])
+ !             else:
+ !                 new_tags = tuple(list(dec_tags) + [collaborator_name])
+               # layer.agg.n.trained.delta.lossy_decompressed.col_i
+               decompressed_tensor_key = TensorKey(
+                   dec_name, dec_origin, dec_round_num, dec_report, new_tags
+ --- 613,619 ----
+                   require_lossless=False
+               )
+               dec_name, dec_origin, dec_round_num, dec_report, dec_tags = dec_tk
+ !             new_tags = change_tags(dec_tags, add_field=collaborator_name)
+               # layer.agg.n.trained.delta.lossy_decompressed.col_i
+               decompressed_tensor_key = TensorKey(
+                   dec_name, dec_origin, dec_round_num, dec_report, new_tags
+ ***************
+ *** 758,763 ****
+ --- 769,788 ----
+           collaborators_for_task = self.assigner.get_collaborators_for_task(
+               task_name, self.round_number
+           )
+ +         #print('************************ Performing validation task for', task_name)
+ +         if not collaborators_for_task:
+ +             if task_name == 'train':
+ +                 tempTensorKeyList = []
+ +                 for element in self.tensor_db._iterate():
+ +                     if element['round'] == self.round_number:
+ +                         tempTensorKeyList.append(TensorKey(element['tensor_name'], self.uuid, element['round'], False, element['tags']))
+ +                 for tempTensorKey in tempTensorKeyList:
+ +                     tensor_name, origin, round_number, report, tags = tempTensorKey
+ +                     tempTensorArray = self.tensor_db.get_tensor_from_cache(tempTensorKey)
+ +                     newTempTensorKey = TensorKey(tensor_name, origin, round_number + 1, report, tags)
+ +                     self.tensor_db.cache_tensor({newTempTensorKey:tempTensorArray})
+ +                 #print('XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX cached old model')
+ +             return
+           # The collaborator data sizes for that task
+           collaborator_weights_unnormalized = {
+               c: self.collaborator_task_weight[TaskResultKey(task_name, c, self.round_number)]
+ ***************
+ *** 778,788 ****
+           task_key = TaskResultKey(task_name, collaborators_for_task[0], self.round_number)
+           for tensor_key in self.collaborator_tasks_results[task_key]:
+               tensor_name, origin, round_number, report, tags = tensor_key
+ !             assert (tags[-1] == collaborators_for_task[0]), (
+                   f'Tensor {tensor_key} in task {task_name} has not been processed correctly'
+               )
+               # Strip the collaborator label, and lookup aggregated tensor
+ !             new_tags = tuple(tags[:-1])
+               agg_tensor_key = TensorKey(tensor_name, origin, round_number, report, new_tags)
+               agg_tensor_name, agg_origin, agg_round_number, agg_report, agg_tags = agg_tensor_key
+               agg_function = WeightedAverage() if 'metric' in tags else task_agg_function
+ --- 803,813 ----
+           task_key = TaskResultKey(task_name, collaborators_for_task[0], self.round_number)
+           for tensor_key in self.collaborator_tasks_results[task_key]:
+               tensor_name, origin, round_number, report, tags = tensor_key
+ !             assert (collaborators_for_task[0] in tags), (
+                   f'Tensor {tensor_key} in task {task_name} has not been processed correctly'
+               )
+               # Strip the collaborator label, and lookup aggregated tensor
+ !             new_tags = change_tags(tags, remove_field=collaborators_for_task[0])
+               agg_tensor_key = TensorKey(tensor_name, origin, round_number, report, new_tags)
+               agg_tensor_name, agg_origin, agg_round_number, agg_report, agg_tags = agg_tensor_key
+               agg_function = WeightedAverage() if 'metric' in tags else task_agg_function
+ ***************
+ *** 849,855 ****
+   
+           # Once all of the task results have been processed
+           self.round_number += 1
+ ! 
+           # Save the latest model
+           self.logger.info(f'Saving round {self.round_number} model...')
+           self._save_model(self.round_number, self.last_state_path)
+ --- 874,880 ----
+   
+           # Once all of the task results have been processed
+           self.round_number += 1
+ !         
+           # Save the latest model
+           self.logger.info(f'Saving round {self.round_number} model...')
+           self._save_model(self.round_number, self.last_state_path)
+ ***************
+ *** 862,867 ****
+ --- 887,893 ----
+   
+           # Cleaning tensor db
+           self.tensor_db.clean_up(self.db_store_rounds)
+ +         
+   
+       def _is_task_done(self, task_name):
+           """Check that task is done."""
+ diff -crB ./openfl/openfl/component/collaborator/collaborator.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/collaborator/collaborator.py
+ *** ./openfl/openfl/component/collaborator/collaborator.py	2022-11-18 11:06:29.751187475 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/collaborator/collaborator.py	2022-11-18 12:02:35.135022401 -0800
+ ***************
+ *** 3,8 ****
+ --- 3,9 ----
+   
+   """Collaborator module."""
+   
+ + from cgitb import text
+   from enum import Enum
+   from logging import getLogger
+   from time import sleep
+ ***************
+ *** 14,19 ****
+ --- 15,22 ----
+   from openfl.protocols import utils
+   from openfl.utilities import TensorKey
+   
+ + from . import mlsimInterfaceMsgs_pb2
+ + import os
+   
+   class DevicePolicy(Enum):
+       """Device assignment policy."""
+ ***************
+ *** 79,86 ****
+ --- 82,91 ----
+                    delta_updates=False,
+                    compression_pipeline=None,
+                    db_store_rounds=1,
+ +                  mlsim_controller_interface=None,
+                    **kwargs):
+           """Initialize."""
+ + 
+           self.single_col_cert_common_name = None
+   
+           if self.single_col_cert_common_name is None:
+ ***************
+ *** 123,128 ****
+ --- 128,144 ----
+   
+           self.task_runner.set_optimizer_treatment(self.opt_treatment.name)
+   
+ +         if mlsim_controller_interface != None:
+ +             self.mlSimControllerInterface = mlsim_controller_interface
+ +         
+ +         pipeName = '/tmp/shard_descriptor_' + self.collaborator_name
+ +          
+ +         self.vehicleId = 0
+ +         rf = os.open(pipeName, os.O_RDONLY)
+ +         #print('Opened pipe', pipeName, rf)
+ +         self.vehicleId = (os.read(rf, 100)).decode('utf-8')
+ +         #print('Got vehicle id from carla ==========================================', self.vehicleId)
+ + 
+       def set_available_devices(self, cuda: Tuple[str] = ()):
+           """
+           Set available CUDA devices.
+ ***************
+ *** 133,140 ****
+ --- 149,183 ----
+   
+       def run(self):
+           """Run the collaborator."""
+ +         msgFromController = self.mlSimControllerInterface.receiveMessage()
+ +         mlsimInterfaceMsg = mlsimInterfaceMsgs_pb2.MlSimInterfaceMessage()
+ +         mlsimInterfaceMsg.ParseFromString(msgFromController)
+ + 
+ +         if mlsimInterfaceMsg.messageType == mlsimInterfaceMsgs_pb2.CMD_INIT_REQ:
+ +             assert mlsimInterfaceMsg.HasField('initRequest')
+ +             print('openFL: Collaborator', self.collaborator_name, ': Received initialization request from controller')
+ +             
+ +             mlsimInterfaceMsg = mlsimInterfaceMsgs_pb2.MlSimInterfaceMessage()
+ +             mlsimInterfaceMsg.messageType = mlsimInterfaceMsgs_pb2.CMD_INIT_RSP
+ +             mlsimInterfaceMsg.initResponse.description = "Initialization Successful"
+ +             mlsimInterfaceMsg.initResponse.clientName = self.collaborator_name
+ +             mlsimInterfaceMsg.initResponse.mobileNodeId = self.vehicleId
+ +             self.mlSimControllerInterface.sendMessage(mlsimInterfaceMsg.SerializeToString())
+ +         else: print ('Received unexpected message', mlsimInterfaceMsg.messageType)
+ + 
+           while True:
+ +             msgFromController = self.mlSimControllerInterface.receiveMessage()
+ +             mlsimInterfaceMsg = mlsimInterfaceMsgs_pb2.MlSimInterfaceMessage()
+ +             mlsimInterfaceMsg.ParseFromString(msgFromController)
+ +             
+ +             if mlsimInterfaceMsg.messageType == mlsimInterfaceMsgs_pb2.CMD_SIM_STEP_REQ:
+ +                 print('openFL: Collaborator:', self.collaborator_name, 'Received request from controller to start a new round')
+ +             else: 
+ +                 print('Unexpected message type!')
+ +                 continue
+ + 
+               tasks, round_number, sleep_time, time_to_quit = self.get_tasks()
+ +             print('openFL: Collaborator:', self.collaborator_name, 'Starting a new round of tasks ...')
+               if time_to_quit:
+                   break
+               elif sleep_time > 0:
+ ***************
+ *** 142,152 ****
+ --- 185,203 ----
+               else:
+                   self.logger.info(f'Received the following tasks: {tasks}')
+                   for task in tasks:
+ +                     print('openFL (Round:', round_number, '): Collaborator', self.collaborator_name, 'Performing task', task.name)
+                       self.do_task(task, round_number)
+   
+                   # Cleaning tensor db
+                   self.tensor_db.clean_up(self.db_store_rounds)
+   
+ +             mlsimInterfaceMsg = mlsimInterfaceMsgs_pb2.MlSimInterfaceMessage()
+ +             mlsimInterfaceMsg.messageType = mlsimInterfaceMsgs_pb2.CMD_SIM_STEP_RSP
+ +             mlsimInterfaceMsg.simStepResponse.description = "Sim step successful"
+ +             mlsimInterfaceMsg.simStepResponse.clientName = self.collaborator_name
+ +             mlsimInterfaceMsg.simStepResponse.status = 1
+ +             self.mlSimControllerInterface.sendMessage(mlsimInterfaceMsg.SerializeToString())
+ + 
+           self.logger.info('End of Federation reached. Exiting...')
+   
+       def run_simulation(self):
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/collaborator: mlsimInterfaceMsgs_pb2.py
+ diff -crB ./openfl/openfl/component/envoy/envoy.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/envoy/envoy.py
+ *** ./openfl/openfl/component/envoy/envoy.py	2022-11-18 11:06:29.751187475 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/envoy/envoy.py	2022-08-15 11:42:21.394825319 -0700
+ ***************
+ *** 21,26 ****
+ --- 21,28 ----
+   from openfl.transport.grpc.director_client import ShardDirectorClient
+   from openfl.utilities.workspace import ExperimentWorkspace
+   
+ + from .mlsim_controller_interface import MlSimControllerInterface
+ + 
+   logger = logging.getLogger(__name__)
+   
+   DEFAULT_RETRY_TIMEOUT_IN_SECONDS = 5
+ ***************
+ *** 41,46 ****
+ --- 43,50 ----
+               tls: bool = True,
+               cuda_devices: Union[tuple, list] = (),
+               cuda_device_monitor: Optional[Type[CUDADeviceMonitor]] = None,
+ +             mlsim_controller_interface_ip_address: Optional[str],
+ +             mlsim_controller_interface_port_number: Optional[str],
+       ) -> None:
+           """Initialize a envoy object."""
+           self.name = shard_name
+ ***************
+ *** 64,69 ****
+ --- 68,80 ----
+           # Optional plugins
+           self.cuda_device_monitor = cuda_device_monitor
+   
+ +         # Controller connection
+ +         self.mlSimControllerInterface = None
+ +         if mlsim_controller_interface_ip_address is not None and mlsim_controller_interface_port_number is not None:
+ +             self.mlSimControllerInterface = MlSimControllerInterface(mlsim_controller_interface_ip_address, mlsim_controller_interface_port_number)
+ +             self.mlSimControllerInterface.bind()
+ +             
+ + 
+           self.executor = ThreadPoolExecutor()
+           self.running_experiments = {}
+           self.is_experiment_running = False
+ ***************
+ *** 159,165 ****
+           logger.info('🧿 Starting a Collaborator Service.')
+   
+           col = plan.get_collaborator(self.name, self.root_certificate, self.private_key,
+ !                                     self.certificate, shard_descriptor=self.shard_descriptor)
+           col.set_available_devices(cuda=self.cuda_devices)
+           col.run()
+   
+ --- 170,176 ----
+           logger.info('🧿 Starting a Collaborator Service.')
+   
+           col = plan.get_collaborator(self.name, self.root_certificate, self.private_key,
+ !                                     self.certificate, shard_descriptor=self.shard_descriptor, mlsim_controller_interace=self.mlSimControllerInterface)
+           col.set_available_devices(cuda=self.cuda_devices)
+           col.run()
+   
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/component/envoy: mlsim_controller_interface.py
+ diff -crB ./openfl/openfl/cryptography/ca.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/cryptography/ca.py
+ *** ./openfl/openfl/cryptography/ca.py	2022-11-18 11:08:33.043181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/cryptography/ca.py	2022-08-15 11:42:21.394825319 -0700
+ ***************
+ *** 5,21 ****
+   
+   import datetime
+   import uuid
+   
+   from cryptography import x509
+   from cryptography.hazmat.backends import default_backend
+   from cryptography.hazmat.primitives import hashes
+   from cryptography.hazmat.primitives.asymmetric import rsa
+   from cryptography.x509.extensions import ExtensionNotFound
+   from cryptography.x509.oid import ExtensionOID
+   from cryptography.x509.oid import NameOID
+   
+   
+ ! def generate_root_cert(days_to_expiration=365):
+       """Generate_root_certificate."""
+       now = datetime.datetime.utcnow()
+       expiration_delta = days_to_expiration * datetime.timedelta(1, 0, 0)
+ --- 5,26 ----
+   
+   import datetime
+   import uuid
+ + from typing import Tuple
+   
+   from cryptography import x509
+   from cryptography.hazmat.backends import default_backend
+   from cryptography.hazmat.primitives import hashes
+   from cryptography.hazmat.primitives.asymmetric import rsa
+ + from cryptography.hazmat.primitives.asymmetric.rsa import RSAPrivateKey
+ + from cryptography.x509.base import Certificate
+ + from cryptography.x509.base import CertificateSigningRequest
+   from cryptography.x509.extensions import ExtensionNotFound
+ + from cryptography.x509.name import Name
+   from cryptography.x509.oid import ExtensionOID
+   from cryptography.x509.oid import NameOID
+   
+   
+ ! def generate_root_cert(days_to_expiration: int = 365) -> Tuple[RSAPrivateKey, Certificate]:
+       """Generate_root_certificate."""
+       now = datetime.datetime.utcnow()
+       expiration_delta = days_to_expiration * datetime.timedelta(1, 0, 0)
+ ***************
+ *** 58,64 ****
+       return root_private_key, certificate
+   
+   
+ ! def generate_signing_csr():
+       """Generate signing CSR."""
+       # Generate private key
+       signing_private_key = rsa.generate_private_key(
+ --- 63,69 ----
+       return root_private_key, certificate
+   
+   
+ ! def generate_signing_csr() -> Tuple[RSAPrivateKey, CertificateSigningRequest]:
+       """Generate signing CSR."""
+       # Generate private key
+       signing_private_key = rsa.generate_private_key(
+ ***************
+ *** 89,95 ****
+       return signing_private_key, csr
+   
+   
+ ! def sign_certificate(csr, issuer_private_key, issuer_name, days_to_expiration=365, ca=False):
+       """
+       Sign the incoming CSR request.
+   
+ --- 94,102 ----
+       return signing_private_key, csr
+   
+   
+ ! def sign_certificate(csr: CertificateSigningRequest, issuer_private_key: RSAPrivateKey,
+ !                      issuer_name: Name, days_to_expiration: int = 365,
+ !                      ca: bool = False) -> Certificate:
+       """
+       Sign the incoming CSR request.
+   
+ diff -crB ./openfl/openfl/cryptography/io.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/cryptography/io.py
+ *** ./openfl/openfl/cryptography/io.py	2022-11-18 11:08:33.043181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/cryptography/io.py	2022-08-15 11:42:21.394825319 -0700
+ ***************
+ *** 4,17 ****
+   """Cryptography IO utilities."""
+   
+   from hashlib import sha384
+   
+   from cryptography import x509
+   from cryptography.hazmat.primitives import serialization
+   from cryptography.hazmat.primitives.asymmetric import rsa
+   from cryptography.hazmat.primitives.serialization import load_pem_private_key
+   
+   
+ ! def read_key(path):
+       """
+       Read private key.
+   
+ --- 4,22 ----
+   """Cryptography IO utilities."""
+   
+   from hashlib import sha384
+ + from pathlib import Path
+ + from typing import Tuple
+   
+   from cryptography import x509
+   from cryptography.hazmat.primitives import serialization
+   from cryptography.hazmat.primitives.asymmetric import rsa
+ + from cryptography.hazmat.primitives.asymmetric.rsa import RSAPrivateKey
+   from cryptography.hazmat.primitives.serialization import load_pem_private_key
+ + from cryptography.x509.base import Certificate
+ + from cryptography.x509.base import CertificateSigningRequest
+   
+   
+ ! def read_key(path: Path) -> RSAPrivateKey:
+       """
+       Read private key.
+   
+ ***************
+ *** 29,35 ****
+       return signing_key
+   
+   
+ ! def write_key(key, path):
+       """
+       Write private key.
+   
+ --- 34,40 ----
+       return signing_key
+   
+   
+ ! def write_key(key: RSAPrivateKey, path: Path) -> None:
+       """
+       Write private key.
+   
+ ***************
+ *** 46,52 ****
+           ))
+   
+   
+ ! def read_crt(path):
+       """
+       Read signed TLS certificate.
+   
+ --- 51,57 ----
+           ))
+   
+   
+ ! def read_crt(path: Path) -> Certificate:
+       """
+       Read signed TLS certificate.
+   
+ ***************
+ *** 64,70 ****
+       return certificate
+   
+   
+ ! def write_crt(certificate, path):
+       """
+       Write cryptography certificate / csr.
+   
+ --- 69,75 ----
+       return certificate
+   
+   
+ ! def write_crt(certificate: Certificate, path: Path) -> None:
+       """
+       Write cryptography certificate / csr.
+   
+ ***************
+ *** 81,87 ****
+           ))
+   
+   
+ ! def read_csr(path):
+       """
+       Read certificate signing request.
+   
+ --- 86,92 ----
+           ))
+   
+   
+ ! def read_csr(path: Path) -> Tuple[CertificateSigningRequest, str]:
+       """
+       Read certificate signing request.
+   
+ diff -crB ./openfl/openfl/cryptography/participant.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/cryptography/participant.py
+ *** ./openfl/openfl/cryptography/participant.py	2022-11-18 11:08:33.043181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/cryptography/participant.py	2022-08-15 11:42:21.394825319 -0700
+ ***************
+ *** 2,16 ****
+   # SPDX-License-Identifier: Apache-2.0
+   
+   """Cryptography participant utilities."""
+   
+   from cryptography import x509
+   from cryptography.hazmat.backends import default_backend
+   from cryptography.hazmat.primitives import hashes
+   from cryptography.hazmat.primitives.asymmetric import rsa
+   from cryptography.x509.oid import NameOID
+   
+   
+ ! def generate_csr(common_name, server=False):
+       """Issue certificate signing request for server and client."""
+       # Generate private key
+       private_key = rsa.generate_private_key(
+ --- 2,20 ----
+   # SPDX-License-Identifier: Apache-2.0
+   
+   """Cryptography participant utilities."""
+ + from typing import Tuple
+   
+   from cryptography import x509
+   from cryptography.hazmat.backends import default_backend
+   from cryptography.hazmat.primitives import hashes
+   from cryptography.hazmat.primitives.asymmetric import rsa
+ + from cryptography.hazmat.primitives.asymmetric.rsa import RSAPrivateKey
+ + from cryptography.x509.base import CertificateSigningRequest
+   from cryptography.x509.oid import NameOID
+   
+   
+ ! def generate_csr(common_name: str,
+ !                  server: bool = False) -> Tuple[RSAPrivateKey, CertificateSigningRequest]:
+       """Issue certificate signing request for server and client."""
+       # Generate private key
+       private_key = rsa.generate_private_key(
+ diff -crB ./openfl/openfl/databases/tensor_db.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/databases/tensor_db.py
+ *** ./openfl/openfl/databases/tensor_db.py	2022-11-18 11:08:33.043181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/databases/tensor_db.py	2022-08-15 11:42:21.394825319 -0700
+ ***************
+ *** 4,15 ****
+ --- 4,22 ----
+   """TensorDB Module."""
+   
+   from threading import Lock
+ + from typing import Dict
+ + from typing import Iterator
+ + from typing import Optional
+ + from types import MethodType
+   
+   import numpy as np
+   import pandas as pd
+   
+ + from openfl.component.aggregation_functions import AggregationFunction
+ + from openfl.utilities import change_tags
+   from openfl.utilities import LocalTensor
+   from openfl.utilities import TensorKey
+ + from openfl.databases.utilities import _search,_store,_retrieve, ROUND_PLACEHOLDER
+   
+   
+   class TensorDB:
+ ***************
+ *** 21,54 ****
+       collaborator and aggregator has its own TensorDB.
+       """
+   
+ !     def __init__(self):
+           """Initialize."""
+           self.tensor_db = pd.DataFrame([], columns=[
+               'tensor_name', 'origin', 'round', 'report', 'tags', 'nparray'
+           ])
+           self.mutex = Lock()
+   
+ !     def __repr__(self):
+           """Representation of the object."""
+           with pd.option_context('display.max_rows', None):
+               content = self.tensor_db[['tensor_name', 'origin', 'round', 'report', 'tags']]
+               return f'TensorDB contents:\n{content}'
+   
+ !     def __str__(self):
+           """Printable string representation."""
+           return self.__repr__()
+   
+ !     def clean_up(self, remove_older_than=1):
+           """Remove old entries from database preventing the db from becoming too large and slow."""
+           if remove_older_than < 0:
+               # Getting a negative argument calls off cleaning
+               return
+ !         current_round = int(self.tensor_db['round'].max())
+           self.tensor_db = self.tensor_db[
+ !             self.tensor_db['round'] > current_round - remove_older_than
+           ].reset_index(drop=True)
+   
+ !     def cache_tensor(self, tensor_key_dict):
+           """Insert tensor into TensorDB (dataframe).
+   
+           Args:
+ --- 28,76 ----
+       collaborator and aggregator has its own TensorDB.
+       """
+   
+ !     def __init__(self) -> None:
+           """Initialize."""
+           self.tensor_db = pd.DataFrame([], columns=[
+               'tensor_name', 'origin', 'round', 'report', 'tags', 'nparray'
+           ])
+ +         self._bind_convenience_methods()
+ +         
+           self.mutex = Lock()
+   
+ !     def _bind_convenience_methods(self):
+ !         # Bind convenience methods for TensorDB dataframe to make storage, retrieval, and search easier
+ !         if not hasattr(self.tensor_db, 'store'):
+ !             self.tensor_db.store = MethodType(_store, self.tensor_db)
+ !         if not hasattr(self.tensor_db, 'retrieve'):
+ !             self.tensor_db.retrieve = MethodType(_retrieve, self.tensor_db)
+ !         if not hasattr(self.tensor_db, 'search'):
+ !             self.tensor_db.search = MethodType(_search, self.tensor_db)
+ ! 
+ !     def __repr__(self) -> str:
+           """Representation of the object."""
+           with pd.option_context('display.max_rows', None):
+               content = self.tensor_db[['tensor_name', 'origin', 'round', 'report', 'tags']]
+               return f'TensorDB contents:\n{content}'
+   
+ !     def __str__(self) -> str:
+           """Printable string representation."""
+           return self.__repr__()
+ +         
+   
+ !     def clean_up(self, remove_older_than: int = 1) -> None:
+           """Remove old entries from database preventing the db from becoming too large and slow."""
+           if remove_older_than < 0:
+               # Getting a negative argument calls off cleaning
+               return
+ !         current_round = self.tensor_db['round'].astype(int).max()
+ !         if current_round == ROUND_PLACEHOLDER:
+ !             current_round = np.sort(self.tensor_db['round'].astype(int).unique())[-2]
+           self.tensor_db = self.tensor_db[
+ !             (self.tensor_db['round'].astype(int) > current_round - remove_older_than) |
+ !             (self.tensor_db['report'] == True)
+           ].reset_index(drop=True)
+   
+ !     def cache_tensor(self, tensor_key_dict: Dict[TensorKey, np.ndarray]) -> None:
+           """Insert tensor into TensorDB (dataframe).
+   
+           Args:
+ ***************
+ *** 79,85 ****
+                   [self.tensor_db, *entries_to_add], ignore_index=True
+               )
+   
+ !     def get_tensor_from_cache(self, tensor_key):
+           """
+           Perform a lookup of the tensor_key in the TensorDB.
+   
+ --- 101,107 ----
+                   [self.tensor_db, *entries_to_add], ignore_index=True
+               )
+   
+ !     def get_tensor_from_cache(self, tensor_key: TensorKey) -> Optional[np.ndarray]:
+           """
+           Perform a lookup of the tensor_key in the TensorDB.
+   
+ ***************
+ *** 99,106 ****
+               return None
+           return np.array(df['nparray'].iloc[0])
+   
+ !     def get_aggregated_tensor(self, tensor_key, collaborator_weight_dict,
+ !                               aggregation_function):
+           """
+           Determine whether all of the collaborator tensors are present for a given tensor key.
+   
+ --- 121,129 ----
+               return None
+           return np.array(df['nparray'].iloc[0])
+   
+ !     def get_aggregated_tensor(self, tensor_key: TensorKey, collaborator_weight_dict: dict,
+ !                               aggregation_function: AggregationFunction
+ !                               ) -> Optional[np.ndarray]:
+           """
+           Determine whether all of the collaborator tensors are present for a given tensor key.
+   
+ ***************
+ *** 140,149 ****
+               return np.array(raw_df.iloc[0]), {}
+   
+           for col in collaborator_names:
+ !             if type(tags) == str:
+ !                 new_tags = tuple([tags] + [col])
+ !             else:
+ !                 new_tags = tuple(list(tags) + [col])
+               raw_df = self.tensor_db[
+                   (self.tensor_db['tensor_name'] == tensor_name)
+                   & (self.tensor_db['origin'] == origin)
+ --- 163,169 ----
+               return np.array(raw_df.iloc[0]), {}
+   
+           for col in collaborator_names:
+ !             new_tags = change_tags(tags, add_field=col)
+               raw_df = self.tensor_db[
+                   (self.tensor_db['tensor_name'] == tensor_name)
+                   & (self.tensor_db['origin'] == origin)
+ ***************
+ *** 162,167 ****
+ --- 182,203 ----
+                                        weight=collaborator_weight_dict[col_name])
+                            for col_name in collaborator_names]
+   
+ +         if hasattr(aggregation_function, '_privileged'):
+ +             if(aggregation_function._privileged):
+ +                 with self.mutex:
+ +                     #self.tensor_db.store = MethodType(_store, self.tensor_db)
+ +                     #self.tensor_db.retrieve = MethodType(_retrieve, self.tensor_db)
+ +                     #self.tensor_db.search = MethodType(_search, self.tensor_db)
+ +                     self._bind_convenience_methods()
+ +                     agg_nparray = aggregation_function(local_tensors,
+ +                                                        self.tensor_db,
+ +                                                        tensor_name,
+ +                                                        fl_round,
+ +                                                        tags)
+ +                 self.cache_tensor({tensor_key: agg_nparray})
+ + 
+ +                 return np.array(agg_nparray)
+ + 
+           db_iterator = self._iterate()
+           agg_nparray = aggregation_function(local_tensors,
+                                              db_iterator,
+ ***************
+ *** 172,178 ****
+   
+           return np.array(agg_nparray)
+   
+ !     def _iterate(self, order_by='round', ascending=False):
+           columns = ['round', 'nparray', 'tensor_name', 'tags']
+           rows = self.tensor_db[columns].sort_values(by=order_by, ascending=ascending).iterrows()
+           for _, row in rows:
+ --- 208,214 ----
+   
+           return np.array(agg_nparray)
+   
+ !     def _iterate(self, order_by: str = 'round', ascending: bool = False) -> Iterator[pd.Series]:
+           columns = ['round', 'nparray', 'tensor_name', 'tags']
+           rows = self.tensor_db[columns].sort_values(by=order_by, ascending=ascending).iterrows()
+           for _, row in rows:
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/databases: utilities
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/data: loader_fets_challenge.py
+ diff -crB ./openfl/openfl/federated/plan/plan.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/plan/plan.py
+ *** ./openfl/openfl/federated/plan/plan.py	2022-11-18 11:08:33.043181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/plan/plan.py	2022-08-15 11:42:21.394825319 -0700
+ ***************
+ *** 226,231 ****
+ --- 226,233 ----
+           self.name_ = None
+           self.serializer_ = None
+   
+ +         self.mlSimControllerInterface_ = None
+ + 
+       @property
+       def hash(self):  # NOQA
+           """Generate hash for this instance."""
+ ***************
+ *** 421,427 ****
+           return self.runner_
+   
+       def get_collaborator(self, collaborator_name, root_certificate=None, private_key=None,
+ !                          certificate=None, task_runner=None, client=None, shard_descriptor=None):
+           """Get collaborator."""
+           defaults = self.config.get(
+               'collaborator',
+ --- 423,429 ----
+           return self.runner_
+   
+       def get_collaborator(self, collaborator_name, root_certificate=None, private_key=None,
+ !                          certificate=None, task_runner=None, client=None, shard_descriptor=None, mlsim_controller_interace=None):
+           """Get collaborator."""
+           defaults = self.config.get(
+               'collaborator',
+ ***************
+ *** 458,463 ****
+ --- 460,470 ----
+   
+           defaults[SETTINGS]['compression_pipeline'] = self.get_tensor_pipe()
+           defaults[SETTINGS]['task_config'] = self.config.get('tasks', {})
+ +         
+ +         if mlsim_controller_interace != None:
+ +             self.mlSimControllerInterface_ = mlsim_controller_interace
+ +             defaults[SETTINGS]['mlsim_controller_interface'] = self.mlSimControllerInterface_
+ + 
+           if client is not None:
+               defaults[SETTINGS]['client'] = client
+           else:
+ ***************
+ *** 467,473 ****
+                   self.federation_uuid,
+                   root_certificate,
+                   private_key,
+ !                 certificate
+               )
+   
+           if self.collaborator_ is None:
+ --- 474,481 ----
+                   self.federation_uuid,
+                   root_certificate,
+                   private_key,
+ !                 certificate,
+ !                 mlsim_controller_interace
+               )
+   
+           if self.collaborator_ is None:
+ ***************
+ *** 476,482 ****
+           return self.collaborator_
+   
+       def get_client(self, collaborator_name, aggregator_uuid, federation_uuid,
+ !                    root_certificate=None, private_key=None, certificate=None):
+           """Get gRPC client for the specified collaborator."""
+           common_name = collaborator_name
+           if not root_certificate or not private_key or not certificate:
+ --- 484,490 ----
+           return self.collaborator_
+   
+       def get_client(self, collaborator_name, aggregator_uuid, federation_uuid,
+ !                    root_certificate=None, private_key=None, certificate=None, mlSimControllerInterface=None):
+           """Get gRPC client for the specified collaborator."""
+           common_name = collaborator_name
+           if not root_certificate or not private_key or not certificate:
+ ***************
+ *** 495,500 ****
+ --- 503,511 ----
+           client_args['aggregator_uuid'] = aggregator_uuid
+           client_args['federation_uuid'] = federation_uuid
+   
+ +         client_args['mlsim_controller_interface'] = mlSimControllerInterface
+ +         client_args['collaborator_name'] = collaborator_name
+ + 
+           if self.client_ is None:
+               self.client_ = AggregatorGRPCClient(**client_args)
+   
+ diff -crB ./openfl/openfl/federated/task/runner_fe.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/task/runner_fe.py
+ *** ./openfl/openfl/federated/task/runner_fe.py	2022-11-18 11:08:33.043181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/task/runner_fe.py	2022-08-15 11:42:21.394825319 -0700
+ ***************
+ *** 4,9 ****
+ --- 4,10 ----
+   
+   import numpy as np
+   
+ + from openfl.utilities import change_tags
+   from openfl.utilities import split_tensor_dict_for_holdouts
+   from openfl.utilities import TensorKey
+   from .runner import TaskRunner
+ ***************
+ *** 181,187 ****
+               suffix += '_local'
+           else:
+               suffix += '_agg'
+ !         tags = ('metric', suffix)
+           output_tensor_dict = {
+               TensorKey(
+                   metric, origin, round_num, True, tags
+ --- 182,189 ----
+               suffix += '_local'
+           else:
+               suffix += '_agg'
+ !         tags = ('metric',)
+ !         tags = change_tags(tags, add_field=suffix)
+           output_tensor_dict = {
+               TensorKey(
+                   metric, origin, round_num, True, tags
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/task: runner_fets_challenge.py
+ diff -crB ./openfl/openfl/federated/task/runner_keras.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/task/runner_keras.py
+ *** ./openfl/openfl/federated/task/runner_keras.py	2022-11-18 11:08:33.043181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/task/runner_keras.py	2022-08-15 11:42:21.394825319 -0700
+ ***************
+ *** 11,16 ****
+ --- 11,17 ----
+   
+   import numpy as np
+   
+ + from openfl.utilities import change_tags
+   from openfl.utilities import Metric
+   from openfl.utilities import split_tensor_dict_for_holdouts
+   from openfl.utilities import TensorKey
+ ***************
+ *** 230,236 ****
+               suffix += '_local'
+           else:
+               suffix += '_agg'
+ !         tags = ('metric', suffix)
+           output_tensor_dict = {
+               TensorKey(metric, origin, round_num, True, tags):
+                   np.array(ret_dict[metric])
+ --- 231,238 ----
+               suffix += '_local'
+           else:
+               suffix += '_agg'
+ !         tags = ('metric',)
+ !         tags = change_tags(tags, add_field=suffix)
+           output_tensor_dict = {
+               TensorKey(metric, origin, round_num, True, tags):
+                   np.array(ret_dict[metric])
+ diff -crB ./openfl/openfl/federated/task/runner_pt.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/task/runner_pt.py
+ *** ./openfl/openfl/federated/task/runner_pt.py	2022-11-18 11:08:33.043181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/task/runner_pt.py	2022-08-15 11:42:21.394825319 -0700
+ ***************
+ *** 12,17 ****
+ --- 12,18 ----
+   import torch.nn as nn
+   import tqdm
+   
+ + from openfl.utilities import change_tags
+   from openfl.utilities import Metric
+   from openfl.utilities import split_tensor_dict_for_holdouts
+   from openfl.utilities import TensorKey
+ ***************
+ *** 117,123 ****
+               suffix += '_local'
+           else:
+               suffix += '_agg'
+ !         tags = ('metric', suffix)
+           # TODO figure out a better way to pass in metric for this pytorch
+           #  validate function
+           output_tensor_dict = {
+ --- 118,125 ----
+               suffix += '_local'
+           else:
+               suffix += '_agg'
+ !         tags = ('metric',)
+ !         tags = change_tags(tags, add_field=suffix)
+           # TODO figure out a better way to pass in metric for this pytorch
+           #  validate function
+           output_tensor_dict = {
+ diff -crB ./openfl/openfl/federated/task/task_runner.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/task/task_runner.py
+ *** ./openfl/openfl/federated/task/task_runner.py	2022-11-18 11:08:33.043181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/federated/task/task_runner.py	2022-08-15 11:42:21.394825319 -0700
+ ***************
+ *** 6,11 ****
+ --- 6,12 ----
+   
+   import numpy as np
+   
+ + from openfl.utilities import change_tags
+   from openfl.utilities import split_tensor_dict_for_holdouts
+   from openfl.utilities import TensorKey
+   
+ ***************
+ *** 73,79 ****
+           else:
+               suffix = 'validate' + validation_flag
+               tags = (suffix,)
+ !         tags = ('metric', *tags)
+           metric_dict = {
+               TensorKey(metric, origin, round_num, True, tags):
+                   np.array(value) for metric, value in metric_dict.items()
+ --- 74,80 ----
+           else:
+               suffix = 'validate' + validation_flag
+               tags = (suffix,)
+ !         tags = change_tags(tags, add_field='metric')
+           metric_dict = {
+               TensorKey(metric, origin, round_num, True, tags):
+                   np.array(value) for metric, value in metric_dict.items()
+ diff -crB ./openfl/openfl/interface/envoy.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/envoy.py
+ *** ./openfl/openfl/interface/envoy.py	2022-11-18 11:06:29.755187475 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/interface/envoy.py	2022-11-18 12:02:35.135022401 -0800
+ ***************
+ *** 93,99 ****
+               module = import_module(module_path)
+               instance = getattr(module, class_name)(**plugin_params)
+               envoy_params[plugin_name] = instance
+ ! 
+       # Instantiate Shard Descriptor
+       shard_descriptor = shard_descriptor_from_config(config.get('shard_descriptor', {}))
+       envoy = Envoy(
+ --- 93,104 ----
+               module = import_module(module_path)
+               instance = getattr(module, class_name)(**plugin_params)
+               envoy_params[plugin_name] = instance
+ !     mlsim_controller_interface = config.get('mlsim_controller_interface')
+ !     if mlsim_controller_interface is not None:
+ !         for key, value in mlsim_controller_interface.items():
+ !             envoy_params['mlsim_controller_interface_'+key] = value
+ !             #print('mlsim_controller_interface_'+key, value)
+ !             
+       # Instantiate Shard Descriptor
+       shard_descriptor = shard_descriptor_from_config(config.get('shard_descriptor', {}))
+       envoy = Envoy(
+ diff -crB ./openfl/openfl/pipelines/tensor_codec.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/pipelines/tensor_codec.py
+ *** ./openfl/openfl/pipelines/tensor_codec.py	2022-11-18 11:08:33.047181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/pipelines/tensor_codec.py	2022-08-15 11:42:21.398825319 -0700
+ ***************
+ *** 6,11 ****
+ --- 6,12 ----
+   import numpy as np
+   
+   from openfl.pipelines import NoCompressionPipeline
+ + from openfl.utilities import change_tags
+   from openfl.utilities import TensorKey
+   
+   
+ ***************
+ *** 67,75 ****
+           # returned ('trained.delta'->'trained.delta.lossy_compressed')
+           tensor_name, origin, round_number, report, tags = tensor_key
+           if not self.compression_pipeline.is_lossy() or require_lossless:
+ !             new_tags = tuple(list(tags) + ['compressed'])
+           else:
+ !             new_tags = tuple(list(tags) + ['lossy_compressed'])
+           compressed_tensor_key = TensorKey(
+               tensor_name, origin, round_number, report, new_tags)
+           return compressed_tensor_key, compressed_nparray, metadata
+ --- 68,76 ----
+           # returned ('trained.delta'->'trained.delta.lossy_compressed')
+           tensor_name, origin, round_number, report, tags = tensor_key
+           if not self.compression_pipeline.is_lossy() or require_lossless:
+ !             new_tags = change_tags(tags, add_field='compressed')
+           else:
+ !             new_tags = change_tags(tags, add_field='lossy_compressed')
+           compressed_tensor_key = TensorKey(
+               tensor_name, origin, round_number, report, new_tags)
+           return compressed_tensor_key, compressed_nparray, metadata
+ ***************
+ *** 121,138 ****
+                   data, transformer_metadata, **kwargs)
+           # Define the decompressed tensorkey that should be returned
+           if 'lossy_compressed' in tags:
+ !             lc_idx = tags.index('lossy_compressed')
+ !             new_tags = list(tags)
+ !             new_tags[lc_idx] = 'lossy_decompressed'
+               decompressed_tensor_key = TensorKey(
+ !                 tensor_name, origin, round_number, report, tuple(new_tags))
+           elif 'compressed' in tags:
+               # 'compressed' == lossless compression; no need for
+               # compression related tag after decompression
+ !             new_tags = list(tags)
+ !             new_tags.remove('compressed')
+               decompressed_tensor_key = TensorKey(
+ !                 tensor_name, origin, round_number, report, tuple(new_tags))
+           else:
+               raise NotImplementedError(
+                   'Decompression is only supported on compressed data')
+ --- 122,137 ----
+                   data, transformer_metadata, **kwargs)
+           # Define the decompressed tensorkey that should be returned
+           if 'lossy_compressed' in tags:
+ !             new_tags = change_tags(
+ !                 tags, add_field='lossy_decompressed', remove_field='lossy_compressed')
+               decompressed_tensor_key = TensorKey(
+ !                 tensor_name, origin, round_number, report, new_tags)
+           elif 'compressed' in tags:
+               # 'compressed' == lossless compression; no need for
+               # compression related tag after decompression
+ !             new_tags = change_tags(tags, remove_field='compressed')
+               decompressed_tensor_key = TensorKey(
+ !                 tensor_name, origin, round_number, report, new_tags)
+           else:
+               raise NotImplementedError(
+                   'Decompression is only supported on compressed data')
+ ***************
+ *** 170,179 ****
+           assert 'model' not in tags, (
+               'The tensorkey should be provided '
+               'from the layer with new weights, not the base model')
+ !         if type(tags) == str:
+ !             new_tags = tuple([tensor_key[3]] + ['delta'])
+ !         else:
+ !             new_tags = tuple(list(tags) + ['delta'])
+           delta_tensor_key = TensorKey(
+               tensor_name, origin, round_number, report, new_tags)
+           return delta_tensor_key, nparray - base_model_nparray
+ --- 169,175 ----
+           assert 'model' not in tags, (
+               'The tensorkey should be provided '
+               'from the layer with new weights, not the base model')
+ !         new_tags = change_tags(tags, add_field='delta')
+           delta_tensor_key = TensorKey(
+               tensor_name, origin, round_number, report, new_tags)
+           return delta_tensor_key, nparray - base_model_nparray
+ ***************
+ *** 209,217 ****
+           # from the base model'
+           # Aggregator UUID has the prefix 'aggregator'
+           if 'aggregator' in origin and not creates_model:
+ !             tags = list(tags)
+ !             tags.remove('delta')
+ !             new_tags = tuple(tags)
+               new_model_tensor_key = TensorKey(
+                   tensor_name, origin, round_number, report, new_tags)
+           else:
+ --- 205,211 ----
+           # from the base model'
+           # Aggregator UUID has the prefix 'aggregator'
+           if 'aggregator' in origin and not creates_model:
+ !             new_tags = change_tags(tags, remove_field='delta')
+               new_model_tensor_key = TensorKey(
+                   tensor_name, origin, round_number, report, new_tags)
+           else:
+ diff -crB ./openfl/openfl/plugins/frameworks_adapters/keras_adapter.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/plugins/frameworks_adapters/keras_adapter.py
+ *** ./openfl/openfl/plugins/frameworks_adapters/keras_adapter.py	2022-11-18 11:08:33.047181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/plugins/frameworks_adapters/keras_adapter.py	2022-08-15 11:42:21.398825319 -0700
+ ***************
+ *** 14,51 ****
+       @staticmethod
+       def serialization_setup():
+           """Prepare model for serialization (optional)."""
+ !         # Source: https://github.com/tensorflow/tensorflow/issues/34697
+ !         from tensorflow.keras.models import Model
+ !         from tensorflow.python.keras.layers import deserialize
+ !         from tensorflow.python.keras.layers import serialize
+ !         from tensorflow.python.keras.saving import saving_utils
+ ! 
+ !         def unpack(model, training_config, weights):
+ !             restored_model = deserialize(model)
+ !             if training_config is not None:
+ !                 restored_model.compile(
+ !                     **saving_utils.compile_args_from_training_config(
+ !                         training_config
+ !                     )
+ !                 )
+ !             restored_model.set_weights(weights)
+ !             return restored_model
+ ! 
+ !         # Hotfix function
+ !         def make_keras_picklable():
+ ! 
+ !             def __reduce__(self):  # NOQA:N807
+ !                 model_metadata = saving_utils.model_metadata(self)
+ !                 training_config = model_metadata.get('training_config', None)
+ !                 model = serialize(self)
+ !                 weights = self.get_weights()
+ !                 return (unpack, (model, training_config, weights))
+ ! 
+ !             cls = Model
+ !             cls.__reduce__ = __reduce__
+ ! 
+ !         # Run the function
+ !         make_keras_picklable()
+   
+       @staticmethod
+       def get_tensor_dict(model, optimizer=None, suffix=''):
+ --- 14,22 ----
+       @staticmethod
+       def serialization_setup():
+           """Prepare model for serialization (optional)."""
+ !         # Keras supports serialization natively.
+ !         # https://github.com/keras-team/keras/pull/14748.
+ !         pass
+   
+       @staticmethod
+       def get_tensor_dict(model, optimizer=None, suffix=''):
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols: base_pb2_grpc.py
+ Only in ./openfl/openfl/protocols: compile_proto.sh
+ diff -crB ./openfl/openfl/protocols/director_pb2_grpc.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols/director_pb2_grpc.py
+ *** ./openfl/openfl/protocols/director_pb2_grpc.py	2022-11-18 11:08:33.047181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols/director_pb2_grpc.py	2022-10-28 12:05:37.340709854 -0700
+ ***************
+ *** 85,91 ****
+       """Missing associated documentation comment in .proto file."""
+   
+       def UpdateShardInfo(self, request, context):
+ !         """Envoy RPCs
+           """
+           context.set_code(grpc.StatusCode.UNIMPLEMENTED)
+           context.set_details('Method not implemented!')
+ --- 85,91 ----
+       """Missing associated documentation comment in .proto file."""
+   
+       def UpdateShardInfo(self, request, context):
+ !         """1. Envoy RPCs
+           """
+           context.set_code(grpc.StatusCode.UNIMPLEMENTED)
+           context.set_details('Method not implemented!')
+ ***************
+ *** 117,123 ****
+           raise NotImplementedError('Method not implemented!')
+   
+       def GetExperimentDescription(self, request, context):
+ !         """Experiments RPCs
+           """
+           context.set_code(grpc.StatusCode.UNIMPLEMENTED)
+           context.set_details('Method not implemented!')
+ --- 117,124 ----
+           raise NotImplementedError('Method not implemented!')
+   
+       def GetExperimentDescription(self, request, context):
+ !         """2. Frontend RPCs
+ !         2.1 Extension RPCs
+           """
+           context.set_code(grpc.StatusCode.UNIMPLEMENTED)
+           context.set_details('Method not implemented!')
+ ***************
+ *** 130,136 ****
+           raise NotImplementedError('Method not implemented!')
+   
+       def SetNewExperiment(self, request_iterator, context):
+ !         """API RPCs
+           """
+           context.set_code(grpc.StatusCode.UNIMPLEMENTED)
+           context.set_details('Method not implemented!')
+ --- 131,137 ----
+           raise NotImplementedError('Method not implemented!')
+   
+       def SetNewExperiment(self, request_iterator, context):
+ !         """2.2 API RPCs
+           """
+           context.set_code(grpc.StatusCode.UNIMPLEMENTED)
+           context.set_details('Method not implemented!')
+ diff -crB ./openfl/openfl/protocols/README.md ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols/README.md
+ *** ./openfl/openfl/protocols/README.md	2022-11-18 11:08:33.047181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/protocols/README.md	2022-08-15 11:42:21.398825319 -0700
+ ***************
+ *** 1,9 ****
+ ! # Compile Protocol Buffers description files
+   
+ ! After changing proto files run 
+ ! ```
+ ! ./compile_proto.sh
+ ! ```
+ ! to recompile. It will delete old generated python 
+ ! files (*_pb2.py and *_pb2_grpc.py) and generate new.
+ ! Generated files should be committed with proto files.
+ \ No newline at end of file
+ --- 1,4 ----
+ ! # OpenFL gRPC protocols
+   
+ ! All `*_pb2*` files are generated automatically during the installation via `pip`.
+ ! You can always build these files manually by running `python setup.py build_grpc` command from the root repository directory.
+ \ No newline at end of file
+ diff -crB ./openfl/openfl/transport/grpc/aggregator_client.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/transport/grpc/aggregator_client.py
+ *** ./openfl/openfl/transport/grpc/aggregator_client.py	2022-11-18 11:08:33.047181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/transport/grpc/aggregator_client.py	2022-08-22 20:17:16.850766880 -0700
+ ***************
+ *** 15,21 ****
+   from openfl.protocols import aggregator_pb2_grpc
+   from openfl.protocols import utils
+   from openfl.utilities import check_equal
+ ! 
+   
+   class ConstantBackoff:
+       """Constant Backoff policy."""
+ --- 15,21 ----
+   from openfl.protocols import aggregator_pb2_grpc
+   from openfl.protocols import utils
+   from openfl.utilities import check_equal
+ ! from .mlsim_client_interceptor import MlSimClientInterceptor
+   
+   class ConstantBackoff:
+       """Constant Backoff policy."""
+ ***************
+ *** 100,105 ****
+ --- 100,108 ----
+                    aggregator_uuid=None,
+                    federation_uuid=None,
+                    single_col_cert_common_name=None,
+ +                  client_interceptor=None,
+ +                  mlsim_controller_interface=None,
+ +                  collaborator_name=None,
+                    **kwargs):
+           """Initialize."""
+           self.uri = f'{agg_addr}:{agg_port}'
+ ***************
+ *** 112,118 ****
+           self.channel_options = [
+               ('grpc.max_metadata_size', 32 * 1024 * 1024),
+               ('grpc.max_send_message_length', 128 * 1024 * 1024),
+ !             ('grpc.max_receive_message_length', 128 * 1024 * 1024)
+           ]
+   
+           self.logger = getLogger(__name__)
+ --- 115,122 ----
+           self.channel_options = [
+               ('grpc.max_metadata_size', 32 * 1024 * 1024),
+               ('grpc.max_send_message_length', 128 * 1024 * 1024),
+ !             ('grpc.max_receive_message_length', 128 * 1024 * 1024),
+ !             ('grpc.keepalive_time_ms', 1000)
+           ]
+   
+           self.logger = getLogger(__name__)
+ ***************
+ *** 140,149 ****
+               RetryOnRpcErrorClientInterceptor(
+                   sleeping_policy=ConstantBackoff(
+                       logger=self.logger,
+ !                     reconnect_interval=int(kwargs.get('client_reconnect_interval', 1)),
+                       uri=self.uri),
+                   status_for_retry=(grpc.StatusCode.UNAVAILABLE,),
+               ),
+           )
+           self.stub = aggregator_pb2_grpc.AggregatorStub(
+               grpc.intercept_channel(self.channel, *self.interceptors)
+ --- 144,154 ----
+               RetryOnRpcErrorClientInterceptor(
+                   sleeping_policy=ConstantBackoff(
+                       logger=self.logger,
+ !                     reconnect_interval=int(kwargs.get('client_reconnect_interval', 100)),
+                       uri=self.uri),
+                   status_for_retry=(grpc.StatusCode.UNAVAILABLE,),
+               ),
+ +             MlSimClientInterceptor(collaborator_name, mlsim_controller_interface),
+           )
+           self.stub = aggregator_pb2_grpc.AggregatorStub(
+               grpc.intercept_channel(self.channel, *self.interceptors)
+ diff -crB ./openfl/openfl/transport/grpc/aggregator_server.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/transport/grpc/aggregator_server.py
+ *** ./openfl/openfl/transport/grpc/aggregator_server.py	2022-11-18 11:08:33.047181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/transport/grpc/aggregator_server.py	2022-08-15 11:42:21.398825319 -0700
+ ***************
+ *** 57,63 ****
+           self.channel_options = [
+               ('grpc.max_metadata_size', 32 * 1024 * 1024),
+               ('grpc.max_send_message_length', 128 * 1024 * 1024),
+ !             ('grpc.max_receive_message_length', 128 * 1024 * 1024)
+           ]
+           self.server = None
+           self.server_credentials = None
+ --- 57,64 ----
+           self.channel_options = [
+               ('grpc.max_metadata_size', 32 * 1024 * 1024),
+               ('grpc.max_send_message_length', 128 * 1024 * 1024),
+ !             ('grpc.max_receive_message_length', 128 * 1024 * 1024),
+ !             ('grpc.keepalive_time_ms', 1000)
+           ]
+           self.server = None
+           self.server_credentials = None
+ ***************
+ *** 185,194 ****
+           require_lossless = request.require_lossless
+           round_number = request.round_number
+           report = request.report
+ !         tags = request.tags
+   
+           named_tensor = self.aggregator.get_aggregated_tensor(
+ !             collaborator_name, tensor_name, round_number, report, tags, require_lossless)
+   
+           return aggregator_pb2.GetAggregatedTensorResponse(
+               header=self.get_header(collaborator_name),
+ --- 186,195 ----
+           require_lossless = request.require_lossless
+           round_number = request.round_number
+           report = request.report
+ !         tags = tuple(request.tags)
+   
+           named_tensor = self.aggregator.get_aggregated_tensor(
+ !             collaborator_name, tensor_name, round_number, report, tags, require_lossless, dict(context.invocation_metadata()))
+   
+           return aggregator_pb2.GetAggregatedTensorResponse(
+               header=self.get_header(collaborator_name),
+ ***************
+ *** 218,224 ****
+           data_size = proto.data_size
+           named_tensors = proto.tensors
+           self.aggregator.send_local_task_results(
+ !             collaborator_name, round_number, task_name, data_size, named_tensors)
+           # turn data stream into local model update
+           return aggregator_pb2.SendLocalTaskResultsResponse(
+               header=self.get_header(collaborator_name)
+ --- 219,225 ----
+           data_size = proto.data_size
+           named_tensors = proto.tensors
+           self.aggregator.send_local_task_results(
+ !             collaborator_name, round_number, task_name, data_size, named_tensors, dict(context.invocation_metadata()))
+           # turn data stream into local model update
+           return aggregator_pb2.SendLocalTaskResultsResponse(
+               header=self.get_header(collaborator_name)
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/transport/grpc: mlsim_client_interceptor.py
+ diff -crB ./openfl/openfl/utilities/logs.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/logs.py
+ *** ./openfl/openfl/utilities/logs.py	2022-11-18 11:08:33.047181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/logs.py	2022-08-15 11:42:21.398825319 -0700
+ ***************
+ *** 16,22 ****
+       """Create global writer object."""
+       global writer
+       if not writer:
+ !         writer = SummaryWriter('./logs/cnn_mnist', flush_secs=5)
+   
+   
+   def write_metric(node_name, task_name, metric_name, metric, round_number):
+ --- 16,22 ----
+       """Create global writer object."""
+       global writer
+       if not writer:
+ !         writer = SummaryWriter('./logs/tensorboard', flush_secs=5)
+   
+   
+   def write_metric(node_name, task_name, metric_name, metric, round_number):
+ diff -crB ./openfl/openfl/utilities/utils.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/utils.py
+ *** ./openfl/openfl/utilities/utils.py	2022-11-18 11:08:33.047181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl/utilities/utils.py	2022-08-15 11:42:21.398825319 -0700
+ ***************
+ *** 236,238 ****
+ --- 236,260 ----
+               settings.set(key, operation(value))
+       settings.validators.validate()
+       return settings
+ + 
+ + 
+ + def change_tags(tags, *, add_field=None, remove_field=None) -> Tuple[str, ...]:
+ +     """Change tensor tags to add or remove fields.
+ + 
+ +     Args:
+ +         tags(tuple): tensor tags.
+ +         add_field(str): add a new tensor tag field.
+ +         remove_field(str): remove a tensor tag field.
+ +     """
+ +     tags = list(set(tags))
+ + 
+ +     if add_field is not None and add_field not in tags:
+ +         tags.append(add_field)
+ +     if remove_field is not None:
+ +         if remove_field in tags:
+ +             tags.remove(remove_field)
+ +         else:
+ +             raise Exception(f'{remove_field} not in tags {tuple(tags)}')
+ + 
+ +     tags = tuple(sorted(tags))
+ +     return tags
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning: openfl.egg-info
+ diff -crB ./openfl/openfl-tutorials/Federated_Pytorch_MNIST_custom_aggregation_Tutorial.ipynb ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/Federated_Pytorch_MNIST_custom_aggregation_Tutorial.ipynb
+ *** ./openfl/openfl-tutorials/Federated_Pytorch_MNIST_custom_aggregation_Tutorial.ipynb	2022-11-18 11:08:33.039181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/Federated_Pytorch_MNIST_custom_aggregation_Tutorial.ipynb	2022-08-15 11:42:19.110825370 -0700
+ ***************
+ *** 197,209 ****
+      ]
+     },
+     {
+ -    "cell_type": "markdown",
+ -    "metadata": {},
+ -    "source": [
+ -     "Now we are ready to run our experiment. If we want to pass in custom plan settings, we can easily do that with the `override_config` parameter"
+ -    ]
+ -   },
+ -   {
+      "cell_type": "code",
+      "execution_count": null,
+      "metadata": {},
+ --- 197,202 ----
+ ***************
+ *** 426,431 ****
+ --- 419,657 ----
+      ]
+     },
+     {
+ +    "cell_type": "markdown",
+ +    "metadata": {},
+ +    "source": [
+ +     "# Privileged Aggregation Functions\n",
+ +     "Most of the time the `AggregationFunction` interface is sufficient to implement custom methods, but in certain scenarios users may want to store additional information inside the TensorDB Dataframe beyond the aggregated tensor. The `openfl.component.aggregation_functions.experimental.PrivilegedAggregationFunction` interface is provided for this use, and gives the user direct access to aggregator's TensorDB dataframe (notice the `tensor_db` param in the call function replaces the `db_iterator` from the standard AggregationFunction interface). As the name suggests, this interface is called privileged because with great power comes great responsibility, and modifying the TensorDB dataframe directly can lead to unexpected behavior and experiment failures if entries are arbitrarily deleted.\n",
+ +     "\n",
+ +     "Note that in-place methods (`.loc`) on the tensor_db dataframe are required for write operations. "
+ +    ]
+ +   },
+ +   {
+ +    "cell_type": "code",
+ +    "execution_count": null,
+ +    "metadata": {},
+ +    "outputs": [],
+ +    "source": [
+ +     "from openfl.component.aggregation_functions.experimental import PrivilegedAggregationFunction\n",
+ +     "import numpy as np\n",
+ +     "import pandas as pd\n",
+ +     "\n",
+ +     "class PrioritizeLeastImproved(PrivilegedAggregationFunction):\n",
+ +     "    \"\"\"\n",
+ +     "        Give collaborator with the least improvement in validation accuracy more influence over future weights\n",
+ +     "        \n",
+ +     "    \"\"\"\n",
+ +     "        \n",
+ +     "    def call(self,\n",
+ +     "             local_tensors,\n",
+ +     "             tensor_db,\n",
+ +     "             tensor_name,\n",
+ +     "             fl_round,\n",
+ +     "             tags):\n",
+ +     "        \"\"\"Aggregate tensors.\n",
+ +     "\n",
+ +     "        Args:\n",
+ +     "            local_tensors(list[openfl.utilities.LocalTensor]): List of local tensors to aggregate.\n",
+ +     "            tensor_db: Aggregator's TensorDB [writable]. Columns:\n",
+ +     "                - 'tensor_name': name of the tensor.\n",
+ +     "                    Examples for `torch.nn.Module`s: 'conv1.weight', 'fc2.bias'.\n",
+ +     "                - 'round': 0-based number of round corresponding to this tensor.\n",
+ +     "                - 'tags': tuple of tensor tags. Tags that can appear:\n",
+ +     "                    - 'model' indicates that the tensor is a model parameter.\n",
+ +     "                    - 'trained' indicates that tensor is a part of a training result.\n",
+ +     "                        These tensors are passed to the aggregator node after local learning.\n",
+ +     "                    - 'aggregated' indicates that tensor is a result of aggregation.\n",
+ +     "                        These tensors are sent to collaborators for the next round.\n",
+ +     "                    - 'delta' indicates that value is a difference between rounds\n",
+ +     "                        for a specific tensor.\n",
+ +     "                    also one of the tags is a collaborator name\n",
+ +     "                    if it corresponds to a result of a local task.\n",
+ +     "\n",
+ +     "                - 'nparray': value of the tensor.\n",
+ +     "            tensor_name: name of the tensor\n",
+ +     "            fl_round: round number\n",
+ +     "            tags: tuple of tags for this tensor\n",
+ +     "        Returns:\n",
+ +     "            np.ndarray: aggregated tensor\n",
+ +     "        \"\"\"\n",
+ +     "        from openfl.utilities import change_tags\n",
+ +     "\n",
+ +     "        tensors, weights, collaborators = zip(*[(x.tensor, x.weight, x.col_name) for idx,x in enumerate(local_tensors)])\n",
+ +     "        tensors, weights, collaborators = np.array(tensors), np.array(weights), collaborators\n",
+ +     "\n",
+ +     "        if fl_round > 0:\n",
+ +     "            metric_tags = ('metric','validate_agg')\n",
+ +     "            collaborator_accuracy = {}\n",
+ +     "            previous_col_accuracy = {}\n",
+ +     "            change_in_accuracy = {}\n",
+ +     "            for col in collaborators:\n",
+ +     "                col_metric_tag = change_tags(metric_tags,add_field=col)\n",
+ +     "                collaborator_accuracy[col] = float(tensor_db[(tensor_db['tensor_name'] == 'acc') &\n",
+ +     "                                                       (tensor_db['round'] == fl_round) &\n",
+ +     "                                                       (tensor_db['tags'] == col_metric_tag)]['nparray'])\n",
+ +     "                previous_col_accuracy[col] = float(tensor_db[(tensor_db['tensor_name'] == 'acc') &\n",
+ +     "                                                       (tensor_db['round'] == fl_round - 1) &\n",
+ +     "                                                       (tensor_db['tags'] == col_metric_tag)]['nparray'])\n",
+ +     "                change_in_accuracy[col] = collaborator_accuracy[col] - previous_col_accuracy[col]\n",
+ +     "                \n",
+ +     "        \n",
+ +     "            least_improved_collaborator = min(change_in_accuracy,key=change_in_accuracy.get)\n",
+ +     "            \n",
+ +     "            # Dont add least improved collaborator more than once\n",
+ +     "            if len(tensor_db[(tensor_db['tags'] == ('least_improved',)) &\n",
+ +     "                         (tensor_db['round'] == fl_round)]) == 0:\n",
+ +     "                tensor_db.loc[tensor_db.shape[0]] = \\\n",
+ +     "                        ['_','_',fl_round,True,('least_improved',),np.array(least_improved_collaborator)]\n",
+ +     "            least_improved_weight_factor = 0.1 * len(tensor_db[(tensor_db['tags'] == ('least_improved',)) &\n",
+ +     "                                                               (tensor_db['nparray'] == np.array(least_improved_collaborator))])\n",
+ +     "            weights[collaborators.index(least_improved_collaborator)] += least_improved_weight_factor\n",
+ +     "            weights = weights / np.sum(weights)\n",
+ +     "            \n",
+ +     "        return np.average(tensors, weights=weights, axis=0)"
+ +    ]
+ +   },
+ +   {
+ +    "cell_type": "markdown",
+ +    "metadata": {},
+ +    "source": [
+ +     "To make the process of writing, reading from, and searching through dataframes easier, we add three methods to the tensor_db dataframe. `store`, `retrieve`, and `search`. Power users can still use all of the built-in pandas dataframe methods, but because some prior knowledge is needed to effectively deal with dataframe column types, iterating through them, and how to store them in a consistent way that won't break other OpenFL functionality, these three methods provide a conventient way to let researchers focus on algorithms instead internal framework machinery.  "
+ +    ]
+ +   },
+ +   {
+ +    "cell_type": "code",
+ +    "execution_count": null,
+ +    "metadata": {},
+ +    "outputs": [],
+ +    "source": [
+ +     "class FedAvgM_Selection(PrivilegedAggregationFunction):\n",
+ +     "    \"\"\"\n",
+ +     "        Adapted from FeTS Challenge 2021\n",
+ +     "        Federated Brain Tumor Segmentation:Multi-Institutional Privacy-Preserving Collaborative Learning\n",
+ +     "        Ece Isik-Polat, Gorkem Polat,Altan Kocyigit1, and Alptekin Temizel1\n",
+ +     "        \n",
+ +     "    \"\"\"\n",
+ +     "        \n",
+ +     "    def call(\n",
+ +     "             self,\n",
+ +     "             local_tensors,\n",
+ +     "             tensor_db,\n",
+ +     "             tensor_name,\n",
+ +     "             fl_round,\n",
+ +     "             tags):\n",
+ +     "    \n",
+ +     "        \"\"\"Aggregate tensors.\n",
+ +     "\n",
+ +     "        Args:\n",
+ +     "            local_tensors(list[openfl.utilities.LocalTensor]): List of local tensors to aggregate.\n",
+ +     "            tensor_db: Aggregator's TensorDB [writable]. Columns:\n",
+ +     "                - 'tensor_name': name of the tensor.\n",
+ +     "                    Examples for `torch.nn.Module`s: 'conv1.weight', 'fc2.bias'.\n",
+ +     "                - 'round': 0-based number of round corresponding to this tensor.\n",
+ +     "                - 'tags': tuple of tensor tags. Tags that can appear:\n",
+ +     "                    - 'model' indicates that the tensor is a model parameter.\n",
+ +     "                    - 'trained' indicates that tensor is a part of a training result.\n",
+ +     "                        These tensors are passed to the aggregator node after local learning.\n",
+ +     "                    - 'aggregated' indicates that tensor is a result of aggregation.\n",
+ +     "                        These tensors are sent to collaborators for the next round.\n",
+ +     "                    - 'delta' indicates that value is a difference between rounds\n",
+ +     "                        for a specific tensor.\n",
+ +     "                    also one of the tags is a collaborator name\n",
+ +     "                    if it corresponds to a result of a local task.\n",
+ +     "\n",
+ +     "                - 'nparray': value of the tensor.\n",
+ +     "            tensor_name: name of the tensor\n",
+ +     "            fl_round: round number\n",
+ +     "            tags: tuple of tags for this tensor\n",
+ +     "        Returns:\n",
+ +     "            np.ndarray: aggregated tensor\n",
+ +     "        \"\"\"\n",
+ +     "        #momentum\n",
+ +     "        tensor_db.store(tensor_name='momentum',nparray=0.9,overwrite=False)\n",
+ +     "        #aggregator_lr\n",
+ +     "        tensor_db.store(tensor_name='aggregator_lr',nparray=1.0,overwrite=False)\n",
+ +     "\n",
+ +     "        if fl_round == 0:\n",
+ +     "            # Just apply FedAvg\n",
+ +     "\n",
+ +     "            tensor_values = [t.tensor for t in local_tensors]\n",
+ +     "            weight_values = [t.weight for t in local_tensors]               \n",
+ +     "            new_tensor_weight =  np.average(tensor_values, weights=weight_values, axis=0)        \n",
+ +     "\n",
+ +     "            #if not (tensor_name in weight_speeds):\n",
+ +     "            if tensor_name not in tensor_db.search(tags=('weight_speeds',))['tensor_name']:    \n",
+ +     "                #weight_speeds[tensor_name] = np.zeros_like(local_tensors[0].tensor) # weight_speeds[tensor_name] = np.zeros(local_tensors[0].tensor.shape)\n",
+ +     "                tensor_db.store(\n",
+ +     "                    tensor_name=tensor_name, \n",
+ +     "                    tags=('weight_speeds',), \n",
+ +     "                    nparray=np.zeros_like(local_tensors[0].tensor),\n",
+ +     "                )\n",
+ +     "            return new_tensor_weight        \n",
+ +     "        else:\n",
+ +     "            if tensor_name.endswith(\"weight\") or tensor_name.endswith(\"bias\"):\n",
+ +     "                # Calculate aggregator's last value\n",
+ +     "                previous_tensor_value = None\n",
+ +     "                for _, record in tensor_db.iterrows():\n",
+ +     "                    if (record['round'] == fl_round \n",
+ +     "                        and record[\"tensor_name\"] == tensor_name\n",
+ +     "                        and record[\"tags\"] == (\"aggregated\",)): \n",
+ +     "                        previous_tensor_value = record['nparray']\n",
+ +     "                        break\n",
+ +     "\n",
+ +     "                if previous_tensor_value is None:\n",
+ +     "                    logger.warning(\"Error in fedAvgM: previous_tensor_value is None\")\n",
+ +     "                    logger.warning(\"Tensor: \" + tensor_name)\n",
+ +     "\n",
+ +     "                    # Just apply FedAvg       \n",
+ +     "                    tensor_values = [t.tensor for t in local_tensors]\n",
+ +     "                    weight_values = [t.weight for t in local_tensors]               \n",
+ +     "                    new_tensor_weight =  np.average(tensor_values, weights=weight_values, axis=0)        \n",
+ +     "                    \n",
+ +     "                    if tensor_name not in tensor_db.search(tags=('weight_speeds',))['tensor_name']:    \n",
+ +     "                        tensor_db.store(\n",
+ +     "                            tensor_name=tensor_name, \n",
+ +     "                            tags=('weight_speeds',), \n",
+ +     "                            nparray=np.zeros_like(local_tensors[0].tensor),\n",
+ +     "                        )\n",
+ +     "\n",
+ +     "                    return new_tensor_weight\n",
+ +     "                else:\n",
+ +     "                    # compute the average delta for that layer\n",
+ +     "                    deltas = [previous_tensor_value - t.tensor for t in local_tensors]\n",
+ +     "                    weight_values = [t.weight for t in local_tensors]\n",
+ +     "                    average_deltas = np.average(deltas, weights=weight_values, axis=0) \n",
+ +     "\n",
+ +     "                    # V_(t+1) = momentum*V_t + Average_Delta_t\n",
+ +     "                    tensor_weight_speed = tensor_db.retrieve(\n",
+ +     "                        tensor_name=tensor_name,\n",
+ +     "                        tags=('weight_speeds',)\n",
+ +     "                    )\n",
+ +     "                    \n",
+ +     "                    momentum = float(tensor_db.retrieve(tensor_name='momentum'))\n",
+ +     "                    aggregator_lr = float(tensor_db.retrieve(tensor_name='aggregator_lr'))\n",
+ +     "                    \n",
+ +     "                    new_tensor_weight_speed = momentum * tensor_weight_speed + average_deltas # fix delete (1-momentum)\n",
+ +     "                    \n",
+ +     "                    tensor_db.store(\n",
+ +     "                        tensor_name=tensor_name, \n",
+ +     "                        tags=('weight_speeds',), \n",
+ +     "                        nparray=new_tensor_weight_speed\n",
+ +     "                    )\n",
+ +     "                    # W_(t+1) = W_t-lr*V_(t+1)\n",
+ +     "                    new_tensor_weight = previous_tensor_value - aggregator_lr*new_tensor_weight_speed\n",
+ +     "\n",
+ +     "                    return new_tensor_weight\n",
+ +     "            else:\n",
+ +     "                # Just apply FedAvg       \n",
+ +     "                tensor_values = [t.tensor for t in local_tensors]\n",
+ +     "                weight_values = [t.weight for t in local_tensors]               \n",
+ +     "                new_tensor_weight =  np.average(tensor_values, weights=weight_values, axis=0)\n",
+ +     "\n",
+ +     "                return new_tensor_weight"
+ +    ]
+ +   },
+ +   {
+      "cell_type": "code",
+      "execution_count": null,
+      "metadata": {},
+ ***************
+ *** 436,442 ****
+       "                                   {\n",
+       "                                       'aggregator.settings.rounds_to_train':5,\n",
+       "                                       'aggregator.settings.db_store_rounds':5,\n",
+ !     "                                       'tasks.train.aggregation_type': ConditionalThresholdAveraging(lambda round_num: 0.85 + 0.03 * round_num)\n",
+       "                                   })"
+      ]
+     },
+ --- 662,668 ----
+       "                                   {\n",
+       "                                       'aggregator.settings.rounds_to_train':5,\n",
+       "                                       'aggregator.settings.db_store_rounds':5,\n",
+ !     "                                       'tasks.train.aggregation_type': ClippedAveraging(ratio=0.9)\n",
+       "                                   })"
+      ]
+     },
+ ***************
+ *** 449,461 ****
+       "#Save final model\n",
+       "final_fl_model.save_native('final_pytorch_model')"
+      ]
+     }
+    ],
+    "metadata": {
+     "kernelspec": {
+ !    "display_name": "Python 3",
+      "language": "python",
+ !    "name": "python3"
+     },
+     "language_info": {
+      "codemirror_mode": {
+ --- 675,694 ----
+       "#Save final model\n",
+       "final_fl_model.save_native('final_pytorch_model')"
+      ]
+ +   },
+ +   {
+ +    "cell_type": "code",
+ +    "execution_count": null,
+ +    "metadata": {},
+ +    "outputs": [],
+ +    "source": []
+     }
+    ],
+    "metadata": {
+     "kernelspec": {
+ !    "display_name": "py3.7",
+      "language": "python",
+ !    "name": "py3.7"
+     },
+     "language_info": {
+      "codemirror_mode": {
+ ***************
+ *** 467,473 ****
+      "name": "python",
+      "nbconvert_exporter": "python",
+      "pygments_lexer": "ipython3",
+ !    "version": "3.8.12"
+     }
+    },
+    "nbformat": 4,
+ --- 700,706 ----
+      "name": "python",
+      "nbconvert_exporter": "python",
+      "pygments_lexer": "ipython3",
+ !    "version": "3.7.9"
+     }
+    },
+    "nbformat": 4,
+ diff -crB ./openfl/openfl-tutorials/Federated_PyTorch_TinyImageNet.ipynb ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/Federated_PyTorch_TinyImageNet.ipynb
+ *** ./openfl/openfl-tutorials/Federated_PyTorch_TinyImageNet.ipynb	2022-11-18 11:08:33.039181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/Federated_PyTorch_TinyImageNet.ipynb	2022-08-15 11:42:19.110825370 -0700
+ ***************
+ *** 234,240 ****
+       "    def get_feature_shape(self):\n",
+       "        return self.train_set[0][0].shape\n",
+       "    \n",
+ !     "    def get_train_loader(self, num_batches):\n",
+       "        return DataLoader(self.train_set, batch_size=self.batch_size)\n",
+       "    \n",
+       "    def get_valid_loader(self):\n",
+ --- 234,240 ----
+       "    def get_feature_shape(self):\n",
+       "        return self.train_set[0][0].shape\n",
+       "    \n",
+ !     "    def get_train_loader(self, num_batches=None):\n",
+       "        return DataLoader(self.train_set, batch_size=self.batch_size)\n",
+       "    \n",
+       "    def get_valid_loader(self):\n",
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api: Tensorflow_CARLA
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/director: 324ee5e3-cb5b-4b61-a02b-b205e570d045
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/director: 3a0bb4b6-1f56-4905-a085-d9e032a7df6e
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/director: 4eff2b37-62ca-4e9d-8762-9f50f198f0d1
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/director: 63740e24-5c74-4333-afdf-8639c0d7e283
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/director: 7dfddc1d-fd99-47b4-8eb1-529b10acde1a
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/director: a9cec0f7-15fe-4812-8983-772caa8c3488
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/director: c38ac301-4290-4425-b25c-b33cf41b666d
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/director: ca4bfc8d-58ee-47d7-a47d-24efe08f5977
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/director: dc40a2cd-69f6-4907-9995-2b57d2e30112
+ diff -crB ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/director/director_config.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/director/director_config.yaml
+ *** ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/director/director_config.yaml	2022-11-18 11:08:33.039181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/director/director_config.yaml	2022-08-15 11:42:21.390825319 -0700
+ ***************
+ *** 1,5 ****
+   settings:
+     listen_host: localhost
+     listen_port: 50051
+ !   sample_shape: ['784']
+     target_shape: ['1']
+ --- 1,5 ----
+   settings:
+     listen_host: localhost
+     listen_port: 50051
+ !   sample_shape: ['28', '28', '1']
+     target_shape: ['1']
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/director: e609eeec-bd25-44dd-85c6-ba6fe46c2847
+ diff -crB ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/director/start_director.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/director/start_director.sh
+ *** ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/director/start_director.sh	2022-11-18 11:06:29.743187476 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/director/start_director.sh	2022-11-18 12:02:35.131022401 -0800
+ ***************
+ *** 1,4 ****
+   #!/bin/bash
+   set -e
+   
+ ! fx director start --disable-tls -c director_config.yaml
+ \ No newline at end of file
+ --- 1,4 ----
+   #!/bin/bash
+   set -e
+   
+ ! fx --log-level critical director start --disable-tls -c director_config.yaml
+ \ No newline at end of file
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy: carlaInterface.py
+ diff -crB ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/envoy_config_one.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/envoy_config_one.yaml
+ *** ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/envoy_config_one.yaml	2022-11-18 11:06:29.743187476 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/envoy_config_one.yaml	2022-08-22 20:11:18.358780702 -0700
+ ***************
+ *** 2,9 ****
+     cuda_devices: []
+   
+   optional_plugin_components: {}
+   
+   shard_descriptor:
+     template: mnist_shard_descriptor.MnistShardDescriptor
+     params:
+ !     rank_worldsize: 1, 2
+ --- 2,17 ----
+     cuda_devices: []
+   
+   optional_plugin_components: {}
+ + mlsim_controller_interface: 
+ +   ip_address: 127.0.0.1
+ +   port_number: 5556
+   
+   shard_descriptor:
+     template: mnist_shard_descriptor.MnistShardDescriptor
+     params:
+ !     rank_worldsize: 1, 3
+ !     envoy_name: env_one
+ !     ip_address: 10.54.84.176
+ !     port: 5000
+ !     tm_port: 5050
+ !     town_map: Town05
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy: envoy_config_three.yaml
+ diff -crB ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/envoy_config_two.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/envoy_config_two.yaml
+ *** ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/envoy_config_two.yaml	2022-11-18 11:06:29.743187476 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/envoy_config_two.yaml	2022-08-22 20:11:23.810780492 -0700
+ ***************
+ *** 2,9 ****
+     cuda_devices: []
+   
+   optional_plugin_components: {}
+   
+   shard_descriptor:
+     template: mnist_shard_descriptor.MnistShardDescriptor
+     params:
+ !     rank_worldsize: 2, 2
+ --- 2,17 ----
+     cuda_devices: []
+   
+   optional_plugin_components: {}
+ + mlsim_controller_interface: 
+ +   ip_address: 127.0.0.1
+ +   port_number: 5557
+   
+   shard_descriptor:
+     template: mnist_shard_descriptor.MnistShardDescriptor
+     params:
+ !     rank_worldsize: 2, 3
+ !     envoy_name: env_two
+ !     ip_address: 10.54.84.176
+ !     port: 5000
+ !     tm_port: 5050
+ !     town_map: Town05
+ \ No newline at end of file
+ diff -crB ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/mnist_shard_descriptor.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/mnist_shard_descriptor.py
+ *** ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/mnist_shard_descriptor.py	2022-11-18 11:08:33.039181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/mnist_shard_descriptor.py	2022-11-18 12:02:35.131022401 -0800
+ ***************
+ *** 13,18 ****
+ --- 13,20 ----
+   from openfl.interface.interactive_api.shard_descriptor import ShardDataset
+   from openfl.interface.interactive_api.shard_descriptor import ShardDescriptor
+   
+ + from carlaInterface import CarlaInterface
+ + 
+   logger = logging.getLogger(__name__)
+   
+   
+ ***************
+ *** 41,50 ****
+   
+       def __init__(
+               self,
+ !             rank_worldsize: str = '1, 1',
+               **kwargs
+       ):
+           """Initialize MnistShardDescriptor."""
+           self.rank, self.worldsize = tuple(int(num) for num in rank_worldsize.split(','))
+           (x_train, y_train), (x_test, y_test) = self.download_data()
+           self.data_by_type = {
+ --- 43,54 ----
+   
+       def __init__(
+               self,
+ !             rank_worldsize: str = '1, 1', 
+ !             envoy_name: str = '', ip_address: str = '127.0.0.1', port: int = 2000, tm_port: int = 8000, town_map: str = '',
+               **kwargs
+       ):
+           """Initialize MnistShardDescriptor."""
+ +         self.carlaInterface = CarlaInterface(envoy_name, ip_address, port, tm_port, town_map)
+           self.rank, self.worldsize = tuple(int(num) for num in rank_worldsize.split(','))
+           (x_train, y_train), (x_test, y_test) = self.download_data()
+           self.data_by_type = {
+ ***************
+ *** 60,65 ****
+ --- 64,71 ----
+           """Return a shard dataset by type."""
+           if dataset_type not in self.data_by_type:
+               raise Exception(f'Wrong dataset type: {dataset_type}')
+ +         print('shaya',type(self.data_by_type[dataset_type][0]))
+ +         
+           return MnistShardDataset(
+               *self.data_by_type[dataset_type],
+               data_type=dataset_type,
+ ***************
+ *** 70,76 ****
+       @property
+       def sample_shape(self):
+           """Return the sample shape info."""
+ !         return ['784']
+   
+       @property
+       def target_shape(self):
+ --- 76,82 ----
+       @property
+       def sample_shape(self):
+           """Return the sample shape info."""
+ !         return ['28', '28', '1']
+   
+       @property
+       def target_shape(self):
+ ***************
+ *** 94,101 ****
+           with np.load(local_file_path) as f:
+               x_train, y_train = f['x_train'], f['y_train']
+               x_test, y_test = f['x_test'], f['y_test']
+ !             x_train = np.reshape(x_train, (-1, 784))
+ !             x_test = np.reshape(x_test, (-1, 784))
+   
+           os.remove(local_file_path)  # remove mnist.npz
+           print('Mnist data was loaded!')
+ --- 100,107 ----
+           with np.load(local_file_path) as f:
+               x_train, y_train = f['x_train'], f['y_train']
+               x_test, y_test = f['x_test'], f['y_test']
+ !             x_train = np.reshape(x_train, (-1, 28, 28, 1))
+ !             x_test = np.reshape(x_test, (-1, 28, 28, 1))
+   
+           os.remove(local_file_path)  # remove mnist.npz
+           print('Mnist data was loaded!')
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy: __pycache__
+ diff -crB ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/start_envoy.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/start_envoy.sh
+ *** ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/start_envoy.sh	2022-11-18 11:06:29.743187476 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/start_envoy.sh	2022-11-18 12:02:35.131022401 -0800
+ ***************
+ *** 3,6 ****
+   ENVOY_NAME=$1
+   ENVOY_CONF=$2
+   
+ ! fx envoy start -n "$ENVOY_NAME" --disable-tls --envoy-config-path "$ENVOY_CONF" -dh localhost -dp 50051
+ --- 3,6 ----
+   ENVOY_NAME=$1
+   ENVOY_CONF=$2
+   
+ ! fx --log-level critical envoy start -n "$ENVOY_NAME" --disable-tls --envoy-config-path "$ENVOY_CONF" -dh localhost -dp 50051
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy: start_multi_envoys.sh
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST: _out
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/workspace: aggregation_function_obj.pkl
+ Only in ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/workspace: layers.py
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/workspace: loader_obj.pkl
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/workspace: logs
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/workspace: model_obj.pkl
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/workspace: plan
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/workspace: requirements.txt
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/workspace: save
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/workspace: task_assigner_obj.pkl
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/workspace: tasks_obj.pkl
+ diff -crB ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/workspace/Tensorflow_MNIST.ipynb ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/workspace/Tensorflow_MNIST.ipynb
+ *** ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/workspace/Tensorflow_MNIST.ipynb	2022-11-18 11:08:33.039181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/workspace/Tensorflow_MNIST.ipynb	2022-08-15 11:42:21.390825319 -0700
+ ***************
+ *** 5,22 ****
+      "id": "26fdd9ed",
+      "metadata": {},
+      "source": [
+ !     "# Federated Tensorflow Mnist Tutorial"
+      ]
+     },
+     {
+      "cell_type": "code",
+ !    "execution_count": null,
+ !    "id": "d0570122",
+      "metadata": {},
+      "outputs": [],
+      "source": [
+ !     "# Install dependencies if not already installed\n",
+ !     "!pip install tensorflow==2.3.1"
+      ]
+     },
+     {
+ --- 5,57 ----
+      "id": "26fdd9ed",
+      "metadata": {},
+      "source": [
+ !     "# Federated Tensorflow MNIST Tutorial"
+      ]
+     },
+     {
+      "cell_type": "code",
+ !    "execution_count": 1,
+ !    "id": "1329f2e6",
+      "metadata": {},
+      "outputs": [],
+      "source": [
+ !     "# Install TF if not already. We recommend TF2.7 or greater.\n",
+ !     "# !pip install tensorflow==2.8"
+ !    ]
+ !   },
+ !   {
+ !    "cell_type": "markdown",
+ !    "id": "e0d30942",
+ !    "metadata": {},
+ !    "source": [
+ !     "## Imports"
+ !    ]
+ !   },
+ !   {
+ !    "cell_type": "code",
+ !    "execution_count": 2,
+ !    "id": "0833dfc9",
+ !    "metadata": {},
+ !    "outputs": [
+ !     {
+ !      "name": "stderr",
+ !      "output_type": "stream",
+ !      "text": [
+ !       "2022-06-14 09:59:00.352749: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
+ !       "2022-06-14 09:59:00.352769: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
+ !      ]
+ !     },
+ !     {
+ !      "name": "stdout",
+ !      "output_type": "stream",
+ !      "text": [
+ !       "TensorFlow 2.9.1\n"
+ !      ]
+ !     }
+ !    ],
+ !    "source": [
+ !     "import tensorflow as tf\n",
+ !     "print('TensorFlow', tf.__version__)"
+      ]
+     },
+     {
+ ***************
+ *** 24,47 ****
+      "id": "246f9c98",
+      "metadata": {},
+      "source": [
+ !     "## Connect to the Federation"
+      ]
+     },
+     {
+      "cell_type": "code",
+ !    "execution_count": null,
+      "id": "d657e463",
+      "metadata": {},
+      "outputs": [],
+      "source": [
+ -     "# Create a federation\n",
+       "from openfl.interface.interactive_api.federation import Federation\n",
+       "\n",
+       "# please use the same identificator that was used in signed certificate\n",
+       "client_id = 'api'\n",
+       "cert_dir = 'cert'\n",
+       "director_node_fqdn = 'localhost'\n",
+ !     "director_port=50051\n",
+       "# 1) Run with API layer - Director mTLS \n",
+       "# If the user wants to enable mTLS their must provide CA root chain, and signed key pair to the federation interface\n",
+       "# cert_chain = f'{cert_dir}/root_ca.crt'\n",
+ --- 59,85 ----
+      "id": "246f9c98",
+      "metadata": {},
+      "source": [
+ !     "## Connect to the Federation\n",
+ !     "\n",
+ !     "Start `Director` and `Envoy` before proceeding with this cell. \n",
+ !     "\n",
+ !     "This cell connects this notebook to the Federation."
+      ]
+     },
+     {
+      "cell_type": "code",
+ !    "execution_count": 3,
+      "id": "d657e463",
+      "metadata": {},
+      "outputs": [],
+      "source": [
+       "from openfl.interface.interactive_api.federation import Federation\n",
+       "\n",
+       "# please use the same identificator that was used in signed certificate\n",
+       "client_id = 'api'\n",
+       "cert_dir = 'cert'\n",
+       "director_node_fqdn = 'localhost'\n",
+ !     "director_port = 50051\n",
+       "# 1) Run with API layer - Director mTLS \n",
+       "# If the user wants to enable mTLS their must provide CA root chain, and signed key pair to the federation interface\n",
+       "# cert_chain = f'{cert_dir}/root_ca.crt'\n",
+ ***************
+ *** 60,80 ****
+       "# --------------------------------------------------------------------------------------------------------------------\n",
+       "\n",
+       "# 2) Run with TLS disabled (trusted environment)\n",
+ !     "# Federation can also determine local fqdn automatically\n",
+       "federation = Federation(\n",
+       "    client_id=client_id,\n",
+       "    director_node_fqdn=director_node_fqdn,\n",
+       "    director_port=director_port, \n",
+       "    tls=False\n",
+ !     ")\n"
+      ]
+     },
+     {
+      "cell_type": "code",
+ !    "execution_count": null,
+      "id": "47dcfab3",
+      "metadata": {},
+ !    "outputs": [],
+      "source": [
+       "shard_registry = federation.get_shard_registry()\n",
+       "shard_registry"
+ --- 98,165 ----
+       "# --------------------------------------------------------------------------------------------------------------------\n",
+       "\n",
+       "# 2) Run with TLS disabled (trusted environment)\n",
+ !     "\n",
+ !     "# Create a Federation\n",
+       "federation = Federation(\n",
+       "    client_id=client_id,\n",
+       "    director_node_fqdn=director_node_fqdn,\n",
+       "    director_port=director_port, \n",
+       "    tls=False\n",
+ !     ")"
+ !    ]
+ !   },
+ !   {
+ !    "cell_type": "markdown",
+ !    "id": "6efe22a8",
+ !    "metadata": {},
+ !    "source": [
+ !     "## Query Datasets from Shard Registry"
+      ]
+     },
+     {
+      "cell_type": "code",
+ !    "execution_count": 4,
+      "id": "47dcfab3",
+      "metadata": {},
+ !    "outputs": [
+ !     {
+ !      "data": {
+ !       "text/plain": [
+ !        "{'env_one': {'shard_info': node_info {\n",
+ !        "    name: \"env_one\"\n",
+ !        "  }\n",
+ !        "  shard_description: \"Mnist dataset, shard number 1 out of 2\"\n",
+ !        "  sample_shape: \"28\"\n",
+ !        "  sample_shape: \"28\"\n",
+ !        "  sample_shape: \"1\"\n",
+ !        "  target_shape: \"1\",\n",
+ !        "  'is_online': True,\n",
+ !        "  'is_experiment_running': False,\n",
+ !        "  'last_updated': '2022-06-14 09:58:22',\n",
+ !        "  'current_time': '2022-06-14 09:59:02',\n",
+ !        "  'valid_duration': seconds: 120,\n",
+ !        "  'experiment_name': 'ExperimentName Mock'},\n",
+ !        " 'env_two': {'shard_info': node_info {\n",
+ !        "    name: \"env_two\"\n",
+ !        "  }\n",
+ !        "  shard_description: \"Mnist dataset, shard number 2 out of 2\"\n",
+ !        "  sample_shape: \"28\"\n",
+ !        "  sample_shape: \"28\"\n",
+ !        "  sample_shape: \"1\"\n",
+ !        "  target_shape: \"1\",\n",
+ !        "  'is_online': True,\n",
+ !        "  'is_experiment_running': False,\n",
+ !        "  'last_updated': '2022-06-14 09:58:37',\n",
+ !        "  'current_time': '2022-06-14 09:59:02',\n",
+ !        "  'valid_duration': seconds: 120,\n",
+ !        "  'experiment_name': 'ExperimentName Mock'}}"
+ !       ]
+ !      },
+ !      "execution_count": 4,
+ !      "metadata": {},
+ !      "output_type": "execute_result"
+ !     }
+ !    ],
+      "source": [
+       "shard_registry = federation.get_shard_registry()\n",
+       "shard_registry"
+ ***************
+ *** 82,91 ****
+     },
+     {
+      "cell_type": "code",
+ !    "execution_count": null,
+      "id": "a2a6c237",
+      "metadata": {},
+ !    "outputs": [],
+      "source": [
+       "# First, request a dummy_shard_desc that holds information about the federated dataset \n",
+       "dummy_shard_desc = federation.get_dummy_shard_descriptor(size=10)\n",
+ --- 167,187 ----
+     },
+     {
+      "cell_type": "code",
+ !    "execution_count": 5,
+      "id": "a2a6c237",
+      "metadata": {},
+ !    "outputs": [
+ !     {
+ !      "data": {
+ !       "text/plain": [
+ !        "'Sample shape: (28, 28, 1), target shape: (1,)'"
+ !       ]
+ !      },
+ !      "execution_count": 5,
+ !      "metadata": {},
+ !      "output_type": "execute_result"
+ !     }
+ !    ],
+      "source": [
+       "# First, request a dummy_shard_desc that holds information about the federated dataset \n",
+       "dummy_shard_desc = federation.get_dummy_shard_descriptor(size=10)\n",
+ ***************
+ *** 99,115 ****
+      "id": "cc0dbdbd",
+      "metadata": {},
+      "source": [
+ !     "## Describing FL experimen"
+      ]
+     },
+     {
+      "cell_type": "code",
+ !    "execution_count": null,
+      "id": "fc88700a",
+      "metadata": {},
+      "outputs": [],
+      "source": [
+ !     "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment"
+      ]
+     },
+     {
+ --- 195,213 ----
+      "id": "cc0dbdbd",
+      "metadata": {},
+      "source": [
+ !     "## Describing FL experiment"
+      ]
+     },
+     {
+      "cell_type": "code",
+ !    "execution_count": 6,
+      "id": "fc88700a",
+      "metadata": {},
+      "outputs": [],
+      "source": [
+ !     "from openfl.interface.interactive_api.experiment import TaskInterface\n",
+ !     "from openfl.interface.interactive_api.experiment import ModelInterface\n",
+ !     "from openfl.interface.interactive_api.experiment import FLExperiment"
+      ]
+     },
+     {
+ ***************
+ *** 122,135 ****
+     },
+     {
+      "cell_type": "code",
+ !    "execution_count": null,
+      "id": "06545bbb",
+      "metadata": {},
+ !    "outputs": [],
+ !    "source": [
+ !     "from layers import create_model, optimizer\n",
+       "framework_adapter = 'openfl.plugins.frameworks_adapters.keras_adapter.FrameworkAdapterPlugin'\n",
+ -     "model = create_model()\n",
+       "MI = ModelInterface(model=model, optimizer=optimizer, framework_plugin=framework_adapter)"
+      ]
+     },
+ --- 220,307 ----
+     },
+     {
+      "cell_type": "code",
+ !    "execution_count": 7,
+      "id": "06545bbb",
+      "metadata": {},
+ !    "outputs": [
+ !     {
+ !      "name": "stdout",
+ !      "output_type": "stream",
+ !      "text": [
+ !       "Model: \"simplecnn\"\n",
+ !       "_________________________________________________________________\n",
+ !       " Layer (type)                Output Shape              Param #   \n",
+ !       "=================================================================\n",
+ !       " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
+ !       "                                                                 \n",
+ !       " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
+ !       " )                                                               \n",
+ !       "                                                                 \n",
+ !       " batch_normalization (BatchN  (None, 13, 13, 32)       128       \n",
+ !       " ormalization)                                                   \n",
+ !       "                                                                 \n",
+ !       " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
+ !       "                                                                 \n",
+ !       " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
+ !       " 2D)                                                             \n",
+ !       "                                                                 \n",
+ !       " batch_normalization_1 (Batc  (None, 5, 5, 64)         256       \n",
+ !       " hNormalization)                                                 \n",
+ !       "                                                                 \n",
+ !       " flatten (Flatten)           (None, 1600)              0         \n",
+ !       "                                                                 \n",
+ !       " dense (Dense)               (None, 10)                16010     \n",
+ !       "                                                                 \n",
+ !       "=================================================================\n",
+ !       "Total params: 35,210\n",
+ !       "Trainable params: 35,018\n",
+ !       "Non-trainable params: 192\n",
+ !       "_________________________________________________________________\n"
+ !      ]
+ !     },
+ !     {
+ !      "name": "stderr",
+ !      "output_type": "stream",
+ !      "text": [
+ !       "2022-06-14 09:59:02.346918: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
+ !       "2022-06-14 09:59:02.347038: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
+ !       "2022-06-14 09:59:02.347128: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
+ !       "2022-06-14 09:59:02.347214: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
+ !       "2022-06-14 09:59:02.347298: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
+ !       "2022-06-14 09:59:02.347383: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
+ !       "2022-06-14 09:59:02.347467: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
+ !       "2022-06-14 09:59:02.347552: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
+ !       "2022-06-14 09:59:02.347566: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
+ !       "Skipping registering GPU devices...\n",
+ !       "2022-06-14 09:59:02.348028: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
+ !       "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
+ !      ]
+ !     }
+ !    ],
+ !    "source": [
+ !     "# Define model\n",
+ !     "model = tf.keras.Sequential([\n",
+ !     "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
+ !     "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
+ !     "    tf.keras.layers.BatchNormalization(),\n",
+ !     "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
+ !     "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
+ !     "    tf.keras.layers.BatchNormalization(),\n",
+ !     "    tf.keras.layers.Flatten(),\n",
+ !     "    tf.keras.layers.Dense(10, activation=None),\n",
+ !     "], name='simplecnn')\n",
+ !     "model.summary()\n",
+ !     "\n",
+ !     "# Define optimizer\n",
+ !     "optimizer = tf.optimizers.Adam(learning_rate=1e-3)\n",
+ !     "\n",
+ !     "# Loss and metrics. These will be used later.\n",
+ !     "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
+ !     "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
+ !     "val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
+ !     "\n",
+ !     "# Create ModelInterface\n",
+       "framework_adapter = 'openfl.plugins.frameworks_adapters.keras_adapter.FrameworkAdapterPlugin'\n",
+       "MI = ModelInterface(model=model, optimizer=optimizer, framework_plugin=framework_adapter)"
+      ]
+     },
+ ***************
+ *** 143,149 ****
+     },
+     {
+      "cell_type": "code",
+ !    "execution_count": null,
+      "id": "d8c9eb50",
+      "metadata": {},
+      "outputs": [],
+ --- 315,321 ----
+     },
+     {
+      "cell_type": "code",
+ !    "execution_count": 8,
+      "id": "d8c9eb50",
+      "metadata": {},
+      "outputs": [],
+ ***************
+ *** 151,160 ****
+ --- 323,339 ----
+       "import numpy as np\n",
+       "from tensorflow.keras.utils import Sequence\n",
+       "\n",
+ +     "from openfl.interface.interactive_api.experiment import DataInterface\n",
+ +     "\n",
+ +     "\n",
+       "class DataGenerator(Sequence):\n",
+       "\n",
+       "    def __init__(self, shard_descriptor, batch_size):\n",
+       "        self.shard_descriptor = shard_descriptor\n",
+ +     "        print('------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
+ +     "        print(len(shard_descriptor))\n",
+ +     "        print(self.shard_descriptor[0][0].shape)\n",
+ +     "        test\n",
+       "        self.batch_size = batch_size\n",
+       "        self.indices = np.arange(len(shard_descriptor))\n",
+       "        self.on_epoch_end()\n",
+ ***************
+ *** 163,170 ****
+ --- 342,352 ----
+       "        return len(self.indices) // self.batch_size\n",
+       "\n",
+       "    def __getitem__(self, index):\n",
+ +     "        print('index',index)\n",
+       "        index = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
+ +     "        print('index',index)\n",
+       "        batch = [self.indices[k] for k in index]\n",
+ +     "        print('batch',batch, type(batch))\n",
+       "\n",
+       "        X, y = self.shard_descriptor[batch]\n",
+       "        return X, y\n",
+ ***************
+ *** 246,252 ****
+     },
+     {
+      "cell_type": "code",
+ !    "execution_count": null,
+      "id": "4af5c4c2",
+      "metadata": {},
+      "outputs": [],
+ --- 428,434 ----
+     },
+     {
+      "cell_type": "code",
+ !    "execution_count": 9,
+      "id": "4af5c4c2",
+      "metadata": {},
+      "outputs": [],
+ ***************
+ *** 264,279 ****
+     },
+     {
+      "cell_type": "code",
+ !    "execution_count": null,
+      "id": "b9649385",
+      "metadata": {},
+      "outputs": [],
+      "source": [
+ -     "TI = TaskInterface()\n",
+ -     "\n",
+       "import time\n",
+ !     "import tensorflow as tf\n",
+ !     "from layers import train_acc_metric, val_acc_metric, loss_fn\n",
+       "\n",
+       "# from openfl.component.aggregation_functions import AdagradAdaptiveAggregation    # Uncomment this lines to use \n",
+       "# agg_fn = AdagradAdaptiveAggregation(model_interface=MI, learning_rate=0.4)       # Adaptive Federated Optimization\n",
+ --- 446,461 ----
+     },
+     {
+      "cell_type": "code",
+ !    "execution_count": 10,
+      "id": "b9649385",
+      "metadata": {},
+      "outputs": [],
+      "source": [
+       "import time\n",
+ !     "\n",
+ !     "\n",
+ !     "\n",
+ !     "TI = TaskInterface()\n",
+       "\n",
+       "# from openfl.component.aggregation_functions import AdagradAdaptiveAggregation    # Uncomment this lines to use \n",
+       "# agg_fn = AdagradAdaptiveAggregation(model_interface=MI, learning_rate=0.4)       # Adaptive Federated Optimization\n",
+ ***************
+ *** 281,288 ****
+       "#                                                                                  # See details in the:\n",
+       "#                                                                                  # https://arxiv.org/abs/2003.00295\n",
+       "\n",
+ !     "@TI.register_fl_task(model='model', data_loader='train_dataset', \\\n",
+ !     "                     device='device', optimizer='optimizer')     \n",
+       "def train(model, train_dataset, optimizer, device, loss_fn=loss_fn, warmup=False):\n",
+       "    start_time = time.time()\n",
+       "\n",
+ --- 463,469 ----
+       "#                                                                                  # See details in the:\n",
+       "#                                                                                  # https://arxiv.org/abs/2003.00295\n",
+       "\n",
+ !     "@TI.register_fl_task(model='model', data_loader='train_dataset', device='device', optimizer='optimizer')     \n",
+       "def train(model, train_dataset, optimizer, device, loss_fn=loss_fn, warmup=False):\n",
+       "    start_time = time.time()\n",
+       "\n",
+ ***************
+ *** 342,348 ****
+     },
+     {
+      "cell_type": "code",
+ !    "execution_count": null,
+      "id": "d41b7896",
+      "metadata": {},
+      "outputs": [],
+ --- 523,529 ----
+     },
+     {
+      "cell_type": "code",
+ !    "execution_count": 11,
+      "id": "d41b7896",
+      "metadata": {},
+      "outputs": [],
+ ***************
+ *** 354,363 ****
+     },
+     {
+      "cell_type": "code",
+ !    "execution_count": null,
+      "id": "41b44de9",
+      "metadata": {},
+ !    "outputs": [],
+      "source": [
+       "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
+       "fl_experiment.start(model_provider=MI, \n",
+ --- 535,753 ----
+     },
+     {
+      "cell_type": "code",
+ !    "execution_count": 12,
+      "id": "41b44de9",
+      "metadata": {},
+ !    "outputs": [
+ !     {
+ !      "data": {
+ !       "text/html": [
+ !        "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09:59:02] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Building <span style=\"color: #800000; text-decoration-color: #800000\">🡆</span> Object <span style=\"color: #800000; text-decoration-color: #800000\">CloudpickleSerializer</span> from <span style=\"color: #800000; text-decoration-color: #800000\">openfl.plugins.interface_serializer.cloudpickle_serializer</span> Module.                  <a href=\"file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/federated/plan/plan.py#171\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">171</span></a>\n",
+ !        "</pre>\n"
+ !       ],
+ !       "text/plain": [
+ !        "\u001b[2;36m[09:59:02]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Building \u001b[31m🡆\u001b[0m Object \u001b[31mCloudpickleSerializer\u001b[0m from \u001b[31mopenfl.plugins.interface_serializer.cloudpickle_serializer\u001b[0m Module.                  \u001b]8;id=139676;file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\u001b\\\u001b[2mplan.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=277131;file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/federated/plan/plan.py#171\u001b\\\u001b[2m171\u001b[0m\u001b]8;;\u001b\\\n"
+ !       ]
+ !      },
+ !      "metadata": {},
+ !      "output_type": "display_data"
+ !     },
+ !     {
+ !      "data": {
+ !       "text/html": [
+ !        "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Building <span style=\"color: #800000; text-decoration-color: #800000\">🡆</span> Object <span style=\"color: #800000; text-decoration-color: #800000\">FrameworkAdapterPlugin</span> from <span style=\"color: #800000; text-decoration-color: #800000\">openfl.plugins.frameworks_adapters.keras_adapter</span> Module.                           <a href=\"file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/federated/plan/plan.py#171\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">171</span></a>\n",
+ !        "</pre>\n"
+ !       ],
+ !       "text/plain": [
+ !        "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Building \u001b[31m🡆\u001b[0m Object \u001b[31mFrameworkAdapterPlugin\u001b[0m from \u001b[31mopenfl.plugins.frameworks_adapters.keras_adapter\u001b[0m Module.                           \u001b]8;id=455364;file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\u001b\\\u001b[2mplan.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=521727;file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/federated/plan/plan.py#171\u001b\\\u001b[2m171\u001b[0m\u001b]8;;\u001b\\\n"
+ !       ]
+ !      },
+ !      "metadata": {},
+ !      "output_type": "display_data"
+ !     },
+ !     {
+ !      "name": "stdout",
+ !      "output_type": "stream",
+ !      "text": [
+ !       "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
+ !      ]
+ !     },
+ !     {
+ !      "data": {
+ !       "text/html": [
+ !        "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until    <a href=\"file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/keras/saving/saving_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">saving_utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/keras/saving/saving_utils.py#328\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">328</span></a>\n",
+ !        "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         you train or evaluate the model.                                                                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
+ !        "</pre>\n"
+ !       ],
+ !       "text/plain": [
+ !        "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until    \u001b]8;id=518083;file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/keras/saving/saving_utils.py\u001b\\\u001b[2msaving_utils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=198463;file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/keras/saving/saving_utils.py#328\u001b\\\u001b[2m328\u001b[0m\u001b]8;;\u001b\\\n",
+ !        "\u001b[2;36m           \u001b[0m         you train or evaluate the model.                                                                                         \u001b[2m                   \u001b[0m\n"
+ !       ]
+ !      },
+ !      "metadata": {},
+ !      "output_type": "display_data"
+ !     },
+ !     {
+ !      "data": {
+ !       "text/html": [
+ !        "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09:59:03] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving <span style=\"font-weight: bold\">(</span>showing <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>. These <a href=\"file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">save.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py#233\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">233</span></a>\n",
+ !        "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         functions will not be directly callable after loading.                                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
+ !        "</pre>\n"
+ !       ],
+ !       "text/plain": [
+ !        "\u001b[2;36m[09:59:03]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving \u001b[1m(\u001b[0mshowing \u001b[1;36m2\u001b[0m of \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m. These \u001b]8;id=801416;file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py\u001b\\\u001b[2msave.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=679912;file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py#233\u001b\\\u001b[2m233\u001b[0m\u001b]8;;\u001b\\\n",
+ !        "\u001b[2;36m           \u001b[0m         functions will not be directly callable after loading.                                                                           \u001b[2m           \u001b[0m\n"
+ !       ]
+ !      },
+ !      "metadata": {},
+ !      "output_type": "display_data"
+ !     },
+ !     {
+ !      "name": "stdout",
+ !      "output_type": "stream",
+ !      "text": [
+ !       "INFO:tensorflow:Assets written to: ram://781c9786-c5f4-4826-9ee9-6b1f0eaa9617/assets\n"
+ !      ]
+ !     },
+ !     {
+ !      "data": {
+ !       "text/html": [
+ !        "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Assets written to: ram:<span style=\"color: #800080; text-decoration-color: #800080\">//781c9786-c5f4-4826-9ee9-6b1f0eaa9617/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">assets</span>                                                     <a href=\"file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/tensorflow/python/saved_model/builder_impl.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">builder_impl.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/tensorflow/python/saved_model/builder_impl.py#779\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">779</span></a>\n",
+ !        "</pre>\n"
+ !       ],
+ !       "text/plain": [
+ !        "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Assets written to: ram:\u001b[35m/\u001b[0m\u001b[35m/781c9786-c5f4-4826-9ee9-6b1f0eaa9617/\u001b[0m\u001b[95massets\u001b[0m                                                     \u001b]8;id=770178;file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/tensorflow/python/saved_model/builder_impl.py\u001b\\\u001b[2mbuilder_impl.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=213533;file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/tensorflow/python/saved_model/builder_impl.py#779\u001b\\\u001b[2m779\u001b[0m\u001b]8;;\u001b\\\n"
+ !       ]
+ !      },
+ !      "metadata": {},
+ !      "output_type": "display_data"
+ !     },
+ !     {
+ !      "name": "stderr",
+ !      "output_type": "stream",
+ !      "text": [
+ !       "/home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
+ !       "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
+ !      ]
+ !     },
+ !     {
+ !      "data": {
+ !       "text/html": [
+ !        "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Starting experiment!                                                                                                       <a href=\"file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py#213\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">213</span></a>\n",
+ !        "</pre>\n"
+ !       ],
+ !       "text/plain": [
+ !        "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting experiment!                                                                                                       \u001b]8;id=623975;file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\u001b\\\u001b[2mexperiment.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=567227;file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py#213\u001b\\\u001b[2m213\u001b[0m\u001b]8;;\u001b\\\n"
+ !       ]
+ !      },
+ !      "metadata": {},
+ !      "output_type": "display_data"
+ !     },
+ !     {
+ !      "data": {
+ !       "text/html": [
+ !        "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> FL-Plan hash is <span style=\"color: #000080; text-decoration-color: #000080\">2e6da2f40ec2cea9971750db2e231ecad5587ba72a1776d665a5985b7a2ed18be475c4bae935a665d2d3120e2d239771</span>                 <a href=\"file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/federated/plan/plan.py#233\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">233</span></a>\n",
+ !        "</pre>\n"
+ !       ],
+ !       "text/plain": [
+ !        "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m FL-Plan hash is \u001b[34m2e6da2f40ec2cea9971750db2e231ecad5587ba72a1776d665a5985b7a2ed18be475c4bae935a665d2d3120e2d239771\u001b[0m                 \u001b]8;id=753514;file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\u001b\\\u001b[2mplan.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=988079;file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/federated/plan/plan.py#233\u001b\\\u001b[2m233\u001b[0m\u001b]8;;\u001b\\\n"
+ !       ]
+ !      },
+ !      "metadata": {},
+ !      "output_type": "display_data"
+ !     },
+ !     {
+ !      "data": {
+ !       "text/html": [
+ !        "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> FL-Plan hash is <span style=\"color: #000080; text-decoration-color: #000080\">2e6da2f40ec2cea9971750db2e231ecad5587ba72a1776d665a5985b7a2ed18be475c4bae935a665d2d3120e2d239771</span>                 <a href=\"file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/federated/plan/plan.py#233\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">233</span></a>\n",
+ !        "</pre>\n"
+ !       ],
+ !       "text/plain": [
+ !        "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m FL-Plan hash is \u001b[34m2e6da2f40ec2cea9971750db2e231ecad5587ba72a1776d665a5985b7a2ed18be475c4bae935a665d2d3120e2d239771\u001b[0m                 \u001b]8;id=450848;file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\u001b\\\u001b[2mplan.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=823818;file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/federated/plan/plan.py#233\u001b\\\u001b[2m233\u001b[0m\u001b]8;;\u001b\\\n"
+ !       ]
+ !      },
+ !      "metadata": {},
+ !      "output_type": "display_data"
+ !     },
+ !     {
+ !      "data": {
+ !       "text/html": [
+ !        "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Building <span style=\"color: #800000; text-decoration-color: #800000\">🡆</span> Object <span style=\"color: #800000; text-decoration-color: #800000\">CoreTaskRunner</span> from <span style=\"color: #800000; text-decoration-color: #800000\">openfl.federated.task.task_runner</span> Module.                                                  <a href=\"file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/federated/plan/plan.py#171\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">171</span></a>\n",
+ !        "</pre>\n"
+ !       ],
+ !       "text/plain": [
+ !        "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Building \u001b[31m🡆\u001b[0m Object \u001b[31mCoreTaskRunner\u001b[0m from \u001b[31mopenfl.federated.task.task_runner\u001b[0m Module.                                                  \u001b]8;id=244208;file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\u001b\\\u001b[2mplan.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=436469;file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/federated/plan/plan.py#171\u001b\\\u001b[2m171\u001b[0m\u001b]8;;\u001b\\\n"
+ !       ]
+ !      },
+ !      "metadata": {},
+ !      "output_type": "display_data"
+ !     },
+ !     {
+ !      "data": {
+ !       "text/html": [
+ !        "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Building <span style=\"color: #800000; text-decoration-color: #800000\">🡆</span> Object <span style=\"color: #800000; text-decoration-color: #800000\">FrameworkAdapterPlugin</span> from <span style=\"color: #800000; text-decoration-color: #800000\">openfl.plugins.frameworks_adapters.keras_adapter</span> Module.                           <a href=\"file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/federated/plan/plan.py#171\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">171</span></a>\n",
+ !        "</pre>\n"
+ !       ],
+ !       "text/plain": [
+ !        "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Building \u001b[31m🡆\u001b[0m Object \u001b[31mFrameworkAdapterPlugin\u001b[0m from \u001b[31mopenfl.plugins.frameworks_adapters.keras_adapter\u001b[0m Module.                           \u001b]8;id=402568;file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\u001b\\\u001b[2mplan.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=919529;file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/federated/plan/plan.py#171\u001b\\\u001b[2m171\u001b[0m\u001b]8;;\u001b\\\n"
+ !       ]
+ !      },
+ !      "metadata": {},
+ !      "output_type": "display_data"
+ !     },
+ !     {
+ !      "data": {
+ !       "text/html": [
+ !        "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> tried to remove tensor: __opt_state_needed not present in the tensor dict                                                       <a href=\"file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/utilities/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/utilities/utils.py#170\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">170</span></a>\n",
+ !        "</pre>\n"
+ !       ],
+ !       "text/plain": [
+ !        "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m tried to remove tensor: __opt_state_needed not present in the tensor dict                                                       \u001b]8;id=744436;file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/utilities/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=341283;file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/utilities/utils.py#170\u001b\\\u001b[2m170\u001b[0m\u001b]8;;\u001b\\\n"
+ !       ]
+ !      },
+ !      "metadata": {},
+ !      "output_type": "display_data"
+ !     },
+ !     {
+ !      "data": {
+ !       "text/html": [
+ !        "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> tried to remove tensor: __opt_state_needed not present in the tensor dict                                                       <a href=\"file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/utilities/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/utilities/utils.py#170\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">170</span></a>\n",
+ !        "</pre>\n"
+ !       ],
+ !       "text/plain": [
+ !        "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m tried to remove tensor: __opt_state_needed not present in the tensor dict                                                       \u001b]8;id=593886;file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/utilities/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=30091;file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/utilities/utils.py#170\u001b\\\u001b[2m170\u001b[0m\u001b]8;;\u001b\\\n"
+ !       ]
+ !      },
+ !      "metadata": {},
+ !      "output_type": "display_data"
+ !     },
+ !     {
+ !      "data": {
+ !       "text/html": [
+ !        "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> SetNewExperiment                                                                                                      <a href=\"file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/transport/grpc/director_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">director_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/transport/grpc/director_client.py#203\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">203</span></a>\n",
+ !        "</pre>\n"
+ !       ],
+ !       "text/plain": [
+ !        "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m SetNewExperiment                                                                                                      \u001b]8;id=29356;file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/transport/grpc/director_client.py\u001b\\\u001b[2mdirector_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=853050;file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/transport/grpc/director_client.py#203\u001b\\\u001b[2m203\u001b[0m\u001b]8;;\u001b\\\n"
+ !       ]
+ !      },
+ !      "metadata": {},
+ !      "output_type": "display_data"
+ !     },
+ !     {
+ !      "data": {
+ !       "text/html": [
+ !        "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Experiment was accepted and launched.                                                                                      <a href=\"file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py#227\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">227</span></a>\n",
+ !        "</pre>\n"
+ !       ],
+ !       "text/plain": [
+ !        "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Experiment was accepted and launched.                                                                                      \u001b]8;id=448351;file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\u001b\\\u001b[2mexperiment.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=425704;file:///home/inteluser/anaconda3/envs/openfl/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py#227\u001b\\\u001b[2m227\u001b[0m\u001b]8;;\u001b\\\n"
+ !       ]
+ !      },
+ !      "metadata": {},
+ !      "output_type": "display_data"
+ !     }
+ !    ],
+      "source": [
+       "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
+       "fl_experiment.start(model_provider=MI, \n",
+ ***************
+ *** 369,375 ****
+     },
+     {
+      "cell_type": "code",
+ !    "execution_count": null,
+      "id": "01fa7cea",
+      "metadata": {},
+      "outputs": [],
+ --- 759,765 ----
+     },
+     {
+      "cell_type": "code",
+ !    "execution_count": 13,
+      "id": "01fa7cea",
+      "metadata": {},
+      "outputs": [],
+ ***************
+ *** 379,386 ****
+     }
+    ],
+    "metadata": {
+     "language_info": {
+ !    "name": "python"
+     }
+    },
+    "nbformat": 4,
+ --- 769,793 ----
+     }
+    ],
+    "metadata": {
+ +   "interpreter": {
+ +    "hash": "f82a63373a71051274245dbf52f7a790e1979bab025fdff4da684b10eb9978bd"
+ +   },
+ +   "kernelspec": {
+ +    "display_name": "Python 3 (ipykernel)",
+ +    "language": "python",
+ +    "name": "python3"
+ +   },
+     "language_info": {
+ !    "codemirror_mode": {
+ !     "name": "ipython",
+ !     "version": 3
+ !    },
+ !    "file_extension": ".py",
+ !    "mimetype": "text/x-python",
+ !    "name": "python",
+ !    "nbconvert_exporter": "python",
+ !    "pygments_lexer": "ipython3",
+ !    "version": "3.8.13"
+     }
+    },
+    "nbformat": 4,
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/workspace: Tensorflow_MNIST.py
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/director: c732e7da-f3c3-43fb-8dda-798eda8e71ff
+ diff -crB ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/director/start_director.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/director/start_director.sh
+ *** ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/director/start_director.sh	2022-11-18 11:06:29.743187476 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/director/start_director.sh	2022-11-18 12:02:35.131022401 -0800
+ ***************
+ *** 1,4 ****
+   #!/bin/bash
+   set -e
+   
+ ! fx director start --disable-tls -c director_config.yaml
+ \ No newline at end of file
+ --- 1,4 ----
+   #!/bin/bash
+   set -e
+   
+ ! fx --log-level critical director start --disable-tls -c director_config.yaml
+ \ No newline at end of file
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/director: word_prediction_test_experiment
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy: American Fairy Tales.txt
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy: carlaInterface.py
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy: English Fairy Tales.txt
+ diff -crB ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/envoy_config_one.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/envoy_config_one.yaml
+ *** ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/envoy_config_one.yaml	2022-11-18 11:06:29.743187476 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/envoy_config_one.yaml	2022-08-16 21:12:29.300125029 -0700
+ ***************
+ *** 3,11 ****
+     cuda_devices: []
+   
+   optional_plugin_components: {}
+ ! 
+   shard_descriptor:
+     template: shard_descriptor.NextWordShardDescriptor
+     params:
+       title: Polish Fairy Tales
+ !     author: A. J. Gliński
+ \ No newline at end of file
+ --- 3,18 ----
+     cuda_devices: []
+   
+   optional_plugin_components: {}
+ ! mlsim_controller_interface: 
+ !   ip_address: 127.0.0.1
+ !   port_number: 5556
+   shard_descriptor:
+     template: shard_descriptor.NextWordShardDescriptor
+     params:
+       title: Polish Fairy Tales
+ !     author: A. J. Gliński
+ !     envoy_name: env_one
+ !     ip_address: 10.54.84.176
+ !     port: 5000
+ !     tm_port: 5050
+ !     town_map: Town05
+ \ No newline at end of file
+ diff -crB ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/envoy_config_three.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/envoy_config_three.yaml
+ *** ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/envoy_config_three.yaml	2022-11-18 11:06:29.743187476 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/envoy_config_three.yaml	2022-08-16 21:12:50.224124561 -0700
+ ***************
+ *** 3,11 ****
+     cuda_devices: []
+   
+   optional_plugin_components: {}
+ ! 
+   shard_descriptor:
+     template: shard_descriptor.NextWordShardDescriptor
+     params:
+       title: American Fairy Tales
+ !     author: L. FRANK BAUM
+ \ No newline at end of file
+ --- 3,18 ----
+     cuda_devices: []
+   
+   optional_plugin_components: {}
+ ! mlsim_controller_interface: 
+ !   ip_address: 127.0.0.1
+ !   port_number: 5558
+   shard_descriptor:
+     template: shard_descriptor.NextWordShardDescriptor
+     params:
+       title: American Fairy Tales
+ !     author: L. FRANK BAUM
+ !     envoy_name: env_three
+ !     ip_address: 10.54.84.176
+ !     port: 5000
+ !     tm_port: 5050
+ !     town_map: Town05
+ \ No newline at end of file
+ diff -crB ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/envoy_config_two.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/envoy_config_two.yaml
+ *** ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/envoy_config_two.yaml	2022-11-18 11:06:29.743187476 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/envoy_config_two.yaml	2022-08-16 21:12:35.244124896 -0700
+ ***************
+ *** 3,11 ****
+     cuda_devices: []
+   
+   optional_plugin_components: {}
+ ! 
+   shard_descriptor:
+     template: shard_descriptor.NextWordShardDescriptor
+     params:
+       title: English Fairy Tales
+ !     author: Joseph Jacobs
+ \ No newline at end of file
+ --- 3,18 ----
+     cuda_devices: []
+   
+   optional_plugin_components: {}
+ ! mlsim_controller_interface: 
+ !   ip_address: 127.0.0.1
+ !   port_number: 5557
+   shard_descriptor:
+     template: shard_descriptor.NextWordShardDescriptor
+     params:
+       title: English Fairy Tales
+ !     author: Joseph Jacobs
+ !     envoy_name: env_two
+ !     ip_address: 10.54.84.176
+ !     port: 5000
+ !     tm_port: 5050
+ !     town_map: Town05
+ \ No newline at end of file
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy: keyed_vectors.feather
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy: Polish Fairy Tales.txt
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy: __pycache__
+ diff -crB ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/shard_descriptor.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/shard_descriptor.py
+ *** ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/shard_descriptor.py	2022-11-18 11:08:33.039181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/shard_descriptor.py	2022-11-18 12:02:35.135022401 -0800
+ ***************
+ *** 13,19 ****
+   
+   from openfl.interface.interactive_api.shard_descriptor import ShardDataset
+   from openfl.interface.interactive_api.shard_descriptor import ShardDescriptor
+ ! 
+   
+   class NextWordShardDataset(ShardDataset):
+       """Shard Dataset for text."""
+ --- 13,19 ----
+   
+   from openfl.interface.interactive_api.shard_descriptor import ShardDataset
+   from openfl.interface.interactive_api.shard_descriptor import ShardDescriptor
+ ! from carlaInterface import CarlaInterface
+   
+   class NextWordShardDataset(ShardDataset):
+       """Shard Dataset for text."""
+ ***************
+ *** 35,43 ****
+   class NextWordShardDescriptor(ShardDescriptor):
+       """Data is any text."""
+   
+ !     def __init__(self, title: str = '', author: str = '') -> None:
+           """Initialize NextWordShardDescriptor."""
+           super().__init__()
+   
+           self.title = title
+           self.author = author
+ --- 35,45 ----
+   class NextWordShardDescriptor(ShardDescriptor):
+       """Data is any text."""
+   
+ !     def __init__(self, title: str = '', author: str = '', envoy_name: str = '', ip_address: str = '127.0.0.1', port: int = 2000, tm_port: int = 8000, town_map: str = '') -> None:
+           """Initialize NextWordShardDescriptor."""
+           super().__init__()
+ +         
+ +         self.carlaInterface = CarlaInterface(envoy_name, ip_address, port, tm_port, town_map)
+   
+           self.title = title
+           self.author = author
+ diff -crB ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/start_envoy.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/start_envoy.sh
+ *** ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/start_envoy.sh	2022-11-18 11:06:29.743187476 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/start_envoy.sh	2022-11-18 12:02:35.135022401 -0800
+ ***************
+ *** 1,4 ****
+   #!/bin/bash
+   set -e
+   
+ ! fx envoy start -n env_one --disable-tls -dh localhost -dp 50051 -ec envoy_config_one.yaml
+ \ No newline at end of file
+ --- 1,6 ----
+   #!/bin/bash
+   set -e
+ + ENVOY_NAME=$1
+ + ENVOY_CONF=$2
+   
+ ! fx --log-level critical envoy start -n "$ENVOY_NAME" --disable-tls --envoy-config-path "$ENVOY_CONF" -dh localhost -dp 50051
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction: _out
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/workspace: aggregation_function_obj.pkl
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/workspace: loader_obj.pkl
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/workspace: logs
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/workspace: model_obj.pkl
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/workspace: plan
+ diff -crB ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/workspace/requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/workspace/requirements.txt
+ *** ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/workspace/requirements.txt	2022-11-18 11:08:33.039181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/workspace/requirements.txt	2022-11-18 12:02:35.135022401 -0800
+ ***************
+ *** 1,2 ****
+ ! tensorflow==2.7.0
+ ! numpy==1.19.5
+ \ No newline at end of file
+ --- 1,144 ----
+ ! absl-py==1.1.0
+ ! anyio==3.6.1
+ ! argon2-cffi==21.3.0
+ ! argon2-cffi-bindings==21.2.0
+ ! asttokens==2.0.5
+ ! astunparse==1.6.3
+ ! Babel==2.10.3
+ ! backcall==0.2.0
+ ! beautifulsoup4==4.11.1
+ ! bleach==5.0.1
+ ! Brotli==1.0.9
+ ! bs4==0.0.1
+ ! cachetools==5.2.0
+ ! certifi==2022.6.15
+ ! cffi==1.15.0
+ ! charset-normalizer==2.1.0
+ ! click==8.0.1
+ ! cloudpickle==2.1.0
+ ! commonmark==0.9.1
+ ! cryptography==37.0.4
+ ! cssselect2==0.4.1
+ ! cycler==0.11.0
+ ! debugpy==1.6.2
+ ! decorator==5.1.1
+ ! docker==5.0.3
+ ! dynaconf==3.1.7
+ ! executing==0.8.3
+ ! fastjsonschema==2.15.3
+ ! filelock==3.7.1
+ ! flatbuffers==1.12
+ ! flatten-json==0.1.13
+ ! fonttools==4.33.3
+ ! gast==0.4.0
+ ! gdown==4.5.1
+ ! google-auth==2.9.1
+ ! google-auth-oauthlib==0.4.6
+ ! google-pasta==0.2.0
+ ! grpcio==1.34.1
+ ! h5py==3.7.0
+ ! html5lib==1.1
+ ! idna==3.3
+ ! imageio==2.21.1
+ ! imgaug==0.4.0
+ ! importlib-metadata==4.12.0
+ ! ipykernel==6.15.1
+ ! ipython==8.4.0
+ ! ipython-genutils==0.2.0
+ ! jedi==0.18.1
+ ! joblib==1.1.0
+ ! json5==0.9.8
+ ! jupyter-client==7.3.4
+ ! jupyter-core==4.11.1
+ ! jupyter-server==1.18.1
+ ! jupyterlab==3.4.3
+ ! jupyterlab-pygments==0.2.2
+ ! jupyterlab-server==2.15.0
+ ! keras==2.9.0
+ ! Keras-Preprocessing==1.1.2
+ ! kiwisolver==1.4.4
+ ! libclang==14.0.1
+ ! Markdown==3.3.7
+ ! matplotlib==3.5.3
+ ! matplotlib-inline==0.1.3
+ ! mistune==0.8.4
+ ! nbclassic==0.4.3
+ ! nbclient==0.6.6
+ ! nbconvert==6.5.0
+ ! nbformat==5.4.0
+ ! nest-asyncio==1.5.5
+ ! networkx==2.8.5
+ ! notebook-shim==0.1.0
+ ! numpy==1.23.1
+ ! oauthlib==3.2.0
+ ! opencv-python==4.6.0.66
+ ! opt-einsum==3.3.0
+ ! packaging==21.3
+ ! pandas==1.4.3
+ ! pandocfilters==1.5.0
+ ! parso==0.8.3
+ ! pascal-voc-writer==0.1.4
+ ! pickleshare==0.7.5
+ ! Pillow==9.1.0
+ ! pip==22.1.2
+ ! prometheus-client==0.14.1
+ ! prompt-toolkit==3.0.30
+ ! protobuf==3.16.0
+ ! psutil==5.9.1
+ ! ptyprocess==0.7.0
+ ! pure-eval==0.2.2
+ ! pyarrow==8.0.0
+ ! pyasn1==0.4.8
+ ! pyasn1-modules==0.2.8
+ ! pycparser==2.21
+ ! pydyf==0.1.2
+ ! Pygments==2.12.0
+ ! pyparsing==3.0.9
+ ! pyphen==0.12.0
+ ! PySocks==1.7.1
+ ! python-dateutil==2.8.2
+ ! pytz==2022.1
+ ! PyWavelets==1.3.0
+ ! PyYAML==6.0
+ ! pyzmq==23.2.0
+ ! requests==2.28.1
+ ! requests-oauthlib==1.3.1
+ ! rich==12.5.1
+ ! rsa==4.8
+ ! scikit-image==0.19.3
+ ! scikit-learn==1.1.1
+ ! scipy==1.8.1
+ ! Send2Trash==1.8.0
+ ! setuptools==61.2.0
+ ! Shapely==1.8.2
+ ! sip==4.19.13
+ ! sniffio==1.2.0
+ ! soupsieve==2.3.2.post1
+ ! stack-data==0.3.0
+ ! tensorboard==2.9.1
+ ! tensorboard-data-server==0.6.1
+ ! tensorboard-plugin-wit==1.8.1
+ ! tensorboardX==2.5.1
+ ! tensorflow==2.9.1
+ ! tensorflow-estimator==2.9.0
+ ! tensorflow-io-gcs-filesystem==0.26.0
+ ! termcolor==1.1.0
+ ! terminado==0.15.0
+ ! threadpoolctl==3.1.0
+ ! tifffile==2022.8.12
+ ! tinycss2==1.1.1
+ ! tornado==6.2
+ ! tqdm==4.64.0
+ ! traitlets==5.3.0
+ ! typing_extensions==4.3.0
+ ! urllib3==1.26.10
+ ! wcwidth==0.2.5
+ ! weasyprint==54.3
+ ! webencodings==0.5.1
+ ! websocket-client==1.3.3
+ ! Werkzeug==2.1.2
+ ! wheel==0.37.1
+ ! wrapt==1.14.1
+ ! zipp==3.8.1
+ ! zmq==0.0.0
+ ! zopfli==0.2.1
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/workspace: save
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/workspace: task_assigner_obj.pkl
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/workspace: tasks_obj.pkl
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/workspace: Tensorflow_Word_Prediction.py
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace: fets_challenge_seg_test
+ diff -crB ./openfl/openfl-workspace/keras_nlp/src/dataloader_utils.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp/src/dataloader_utils.py
+ *** ./openfl/openfl-workspace/keras_nlp/src/dataloader_utils.py	2022-11-18 11:08:33.043181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp/src/dataloader_utils.py	2022-08-15 11:42:21.390825319 -0700
+ ***************
+ *** 8,13 ****
+ --- 8,15 ----
+   from os import getcwd
+   from os import path
+   from os import remove
+ + from typing import Dict
+ + from typing import Tuple
+   from zipfile import ZipFile
+   
+   import numpy as np
+ ***************
+ *** 16,22 ****
+   logger = getLogger(__name__)
+   
+   
+ ! def download_data_():
+       """Download data.
+   
+       Returns:
+ --- 18,24 ----
+   logger = getLogger(__name__)
+   
+   
+ ! def download_data_() -> str:
+       """Download data.
+   
+       Returns:
+ ***************
+ *** 60,66 ****
+           return ''
+   
+   
+ ! def import_raw_data_(data_path='', num_samples=0):
+       """Import data.
+   
+       Returns:
+ --- 62,71 ----
+           return ''
+   
+   
+ ! def import_raw_data_(
+ !     data_path: str = '',
+ !     num_samples: int = 0
+ ! ) -> Tuple[Dict[str, int], np.ndarray, np.ndarray, np.ndarray]:
+       """Import data.
+   
+       Returns:
+ ***************
+ *** 147,154 ****
+       return details, encoder_input_data, decoder_input_data, decoder_target_data
+   
+   
+ ! def get_datasets_(encoder_input_data, decoder_input_data,
+ !                   decoder_target_data, num_samples, split_ratio):
+       """Create train/val.
+   
+       Returns:
+ --- 152,160 ----
+       return details, encoder_input_data, decoder_input_data, decoder_target_data
+   
+   
+ ! def get_datasets_(encoder_input_data: np.ndarray, decoder_input_data: np.ndarray,
+ !                   decoder_target_data: np.ndarray,
+ !                   num_samples: int, split_ratio: float) -> Dict[str, np.ndarray]:
+       """Create train/val.
+   
+       Returns:
+ ***************
+ *** 182,188 ****
+       return results
+   
+   
+ ! def load_shard(collaborator_count, shard_num, data_path, num_samples, split_ratio):
+       """Load data-shards.
+   
+       Returns:
+ --- 188,197 ----
+       return results
+   
+   
+ ! def load_shard(
+ !     collaborator_count: int, shard_num: str, data_path: str,
+ !     num_samples: int, split_ratio: float
+ ! ) -> Tuple[Tuple[np.ndarray, ...], Tuple[np.ndarray, ...], Dict[str, int]]:
+       """Load data-shards.
+   
+       Returns:
+ diff -crB ./openfl/openfl-workspace/keras_nlp/src/nlp_dataloader.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp/src/nlp_dataloader.py
+ *** ./openfl/openfl-workspace/keras_nlp/src/nlp_dataloader.py	2022-11-18 11:08:33.043181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp/src/nlp_dataloader.py	2022-08-15 11:42:21.390825319 -0700
+ ***************
+ *** 5,10 ****
+ --- 5,15 ----
+   license agreement between Intel Corporation and you.
+   """
+   from logging import getLogger
+ + from typing import Iterator
+ + from typing import List
+ + from typing import Optional
+ + from typing import Tuple
+ + from typing import Union
+   
+   import numpy as np
+   import src.dataloader_utils as dlu
+ ***************
+ *** 17,24 ****
+   class NLPDataLoader(KerasDataLoader):
+       """NLP Dataloader template."""
+   
+ !     def __init__(self, collaborator_count, split_ratio,
+ !                  num_samples, data_path, batch_size, **kwargs):
+           """Instantiate the data object.
+   
+           Args:
+ --- 22,29 ----
+   class NLPDataLoader(KerasDataLoader):
+       """NLP Dataloader template."""
+   
+ !     def __init__(self, collaborator_count: int, split_ratio: float,
+ !                  num_samples: int, data_path: str, batch_size: int, **kwargs) -> None:
+           """Instantiate the data object.
+   
+           Args:
+ ***************
+ *** 48,58 ****
+           self.X_valid = [valid[0], valid[1]]
+           self.y_valid = valid[2]
+   
+ !     def get_feature_shape(self):
+           """Get the shape of an example feature array."""
+           return self.X_train[0].shape
+   
+ !     def get_train_loader(self, batch_size=None):
+           """
+           Get training data loader.
+   
+ --- 53,63 ----
+           self.X_valid = [valid[0], valid[1]]
+           self.y_valid = valid[2]
+   
+ !     def get_feature_shape(self) -> Tuple[int, ...]:
+           """Get the shape of an example feature array."""
+           return self.X_train[0].shape
+   
+ !     def get_train_loader(self, batch_size: Optional[int] = None) -> Iterator[List[np.ndarray]]:
+           """
+           Get training data loader.
+   
+ ***************
+ *** 63,69 ****
+           return self._get_batch_generator(X1=self.X_train[0], X2=self.X_train[1],
+                                            y=self.y_train, batch_size=batch_size)
+   
+ !     def get_valid_loader(self, batch_size=None):
+           """
+           Get validation data loader.
+   
+ --- 68,74 ----
+           return self._get_batch_generator(X1=self.X_train[0], X2=self.X_train[1],
+                                            y=self.y_train, batch_size=batch_size)
+   
+ !     def get_valid_loader(self, batch_size: Optional[int] = None) -> Iterator[List[np.ndarray]]:
+           """
+           Get validation data loader.
+   
+ ***************
+ *** 73,79 ****
+           return self._get_batch_generator(X1=self.X_valid[0], X2=self.X_valid[1],
+                                            y=self.y_valid, batch_size=batch_size)
+   
+ !     def get_train_data_size(self):
+           """
+           Get total number of training samples.
+   
+ --- 78,84 ----
+           return self._get_batch_generator(X1=self.X_valid[0], X2=self.X_valid[1],
+                                            y=self.y_valid, batch_size=batch_size)
+   
+ !     def get_train_data_size(self) -> int:
+           """
+           Get total number of training samples.
+   
+ ***************
+ *** 82,88 ****
+           """
+           return self.X_train[0].shape[0]
+   
+ !     def get_valid_data_size(self):
+           """
+           Get total number of validation samples.
+   
+ --- 87,93 ----
+           """
+           return self.X_train[0].shape[0]
+   
+ !     def get_valid_data_size(self) -> int:
+           """
+           Get total number of validation samples.
+   
+ ***************
+ *** 92,98 ****
+           return self.X_valid[0].shape[0]
+   
+       @staticmethod
+ !     def _batch_generator(X1, X2, y, idxs, batch_size, num_batches):
+           """
+           Generate batch of data.
+   
+ --- 97,106 ----
+           return self.X_valid[0].shape[0]
+   
+       @staticmethod
+ !     def _batch_generator(X1: np.ndarray, X2: np.ndarray,
+ !                          y: np.ndarray, idxs: np.ndarray,
+ !                          batch_size: int,
+ !                          num_batches: int) -> Iterator[List[np.ndarray]]:
+           """
+           Generate batch of data.
+   
+ ***************
+ *** 110,116 ****
+               b = a + batch_size
+               yield [X1[idxs[a:b]], X2[idxs[a:b]]], y[idxs[a:b]]
+   
+ !     def _get_batch_generator(self, X1, X2, y, batch_size):
+           """
+           Return the dataset generator.
+   
+ --- 118,126 ----
+               b = a + batch_size
+               yield [X1[idxs[a:b]], X2[idxs[a:b]]], y[idxs[a:b]]
+   
+ !     def _get_batch_generator(self, X1: np.ndarray, X2: np.ndarray,
+ !                              y: np.ndarray,
+ !                              batch_size: Union[int, None]) -> Iterator[List[np.ndarray]]:
+           """
+           Return the dataset generator.
+   
+ diff -crB ./openfl/openfl-workspace/workspace/plan/defaults/aggregator.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/plan/defaults/aggregator.yaml
+ *** ./openfl/openfl-workspace/workspace/plan/defaults/aggregator.yaml	2022-11-18 11:08:33.043181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/plan/defaults/aggregator.yaml	2022-08-15 11:42:21.394825319 -0700
+ ***************
+ *** 1,4 ****
+   template : openfl.component.Aggregator
+   settings :
+       db_store_rounds   : 2
+ !     write_logs : false
+ --- 1,4 ----
+   template : openfl.component.Aggregator
+   settings :
+       db_store_rounds   : 2
+ !     write_logs : true
+ diff -crB ./openfl/README.md ../mlwins-simulation-framework/ml-frameworks/federated-learning/README.md
+ *** ./openfl/README.md	2022-11-18 11:08:33.039181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/README.md	2022-08-15 11:42:19.090825370 -0700
+ ***************
+ *** 1,13 ****
+   # OpenFL - An Open-Source Framework For Federated Learning
+   
+   [![PyPI - Python Version](https://img.shields.io/badge/python-3.6%20%7C%203.7%20%7C%203.8-blue)](https://pypi.org/project/openfl/)
+ ! [![Jenkins](https://img.shields.io/jenkins/build?jobUrl=http%3A%2F%2F213.221.44.203%2Fjob%2FFederated-Learning%2Fjob%2Fnightly%2F)](http://213.221.44.203/job/Federated-Learning/job/nightly/)
+   [![Documentation Status](https://readthedocs.org/projects/openfl/badge/?version=latest)](https://openfl.readthedocs.io/en/latest/?badge=latest)
+   [![Downloads](https://pepy.tech/badge/openfl)](https://pepy.tech/project/openfl)
+   [![PyPI version](https://img.shields.io/pypi/v/openfl)](https://pypi.org/project/openfl/)
+   [<img src="https://img.shields.io/badge/slack-@openfl-blue.svg?logo=slack">](https://join.slack.com/t/openfl/shared_invite/zt-ovzbohvn-T5fApk05~YS_iZhjJ5yaTw) 
+ ! [![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
+ ! [![Citation](https://img.shields.io/badge/cite-citation-blue)](https://arxiv.org/abs/2105.06413)
+   [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/intel/openfl/blob/develop/openfl-tutorials/interactive_api/numpy_linear_regression/workspace/SingleNotebook.ipynb)
+   
+   OpenFL is a Python 3 framework for Federated Learning. OpenFL is designed to be a _flexible_, _extensible_ and _easily learnable_ tool for data scientists. OpenFL is developed by Intel Internet of Things Group (IOTG) and Intel Labs. 
+ --- 1,14 ----
+   # OpenFL - An Open-Source Framework For Federated Learning
+   
+   [![PyPI - Python Version](https://img.shields.io/badge/python-3.6%20%7C%203.7%20%7C%203.8-blue)](https://pypi.org/project/openfl/)
+ ! [![Continuous Integration](https://github.com/intel/openfl/actions/workflows/python-app.yml/badge.svg?branch=develop)](https://github.com/intel/openfl/actions/workflows/python-app.yml)
+   [![Documentation Status](https://readthedocs.org/projects/openfl/badge/?version=latest)](https://openfl.readthedocs.io/en/latest/?badge=latest)
+   [![Downloads](https://pepy.tech/badge/openfl)](https://pepy.tech/project/openfl)
+ + [![DockerHub](https://img.shields.io/docker/pulls/intel/openfl.svg)](https://hub.docker.com/r/intel/openfl)
+   [![PyPI version](https://img.shields.io/pypi/v/openfl)](https://pypi.org/project/openfl/)
+   [<img src="https://img.shields.io/badge/slack-@openfl-blue.svg?logo=slack">](https://join.slack.com/t/openfl/shared_invite/zt-ovzbohvn-T5fApk05~YS_iZhjJ5yaTw) 
+ ! [![License](https://img.shields.io/badge/License-Apache%202.0-brightgreen.svg)](https://opensource.org/licenses/Apache-2.0)
+ ! [![Citation](https://img.shields.io/badge/cite-citation-brightgreen)](https://arxiv.org/abs/2105.06413)
+   [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/intel/openfl/blob/develop/openfl-tutorials/interactive_api/numpy_linear_regression/workspace/SingleNotebook.ipynb)
+   
+   OpenFL is a Python 3 framework for Federated Learning. OpenFL is designed to be a _flexible_, _extensible_ and _easily learnable_ tool for data scientists. OpenFL is developed by Intel Internet of Things Group (IOTG) and Intel Labs. 
+ ***************
+ *** 26,36 ****
+   
+   OpenFL enables data scientists to set up a federated learning experiment following one of the workflows:
+   
+ ! - [Director-based Workflow](https://openfl.readthedocs.io/en/latest/running_the_federation.html#director-based-workflow) [preferred]:
+ ! a federation created with this workflow continues to be available to distribute more experiments in series.
+   
+   - [Aggregator-based Workflow](https://openfl.readthedocs.io/en/latest/running_the_federation.html#aggregator-based-workflow):
+ ! with this workflow, the federation is terminated when the experiment is finished.
+   
+   The quickest way to test OpenFL is to follow our [tutorials](https://github.com/intel/openfl/tree/develop/openfl-tutorials). </br>
+   Read the [blog post](https://towardsdatascience.com/go-federated-with-openfl-8bc145a5ead1) explaining steps to train a model with OpenFL. </br>
+ --- 27,37 ----
+   
+   OpenFL enables data scientists to set up a federated learning experiment following one of the workflows:
+   
+ ! - [Director-based Workflow](https://openfl.readthedocs.io/en/latest/running_the_federation.html#director-based-workflow):
+ ! Setup long-lived components to run many experiments in series. Recommended for FL research when many changes to model, dataloader, or hyperparameters are expected
+   
+   - [Aggregator-based Workflow](https://openfl.readthedocs.io/en/latest/running_the_federation.html#aggregator-based-workflow):
+ ! Define an experiment and distribute it manually. All participants can verify model code and [FL plan](https://openfl.readthedocs.io/en/latest/running_the_federation.html#federated-learning-plan-fl-plan-settings) prior to execution. The federation is terminated when the experiment is finished
+   
+   The quickest way to test OpenFL is to follow our [tutorials](https://github.com/intel/openfl/tree/develop/openfl-tutorials). </br>
+   Read the [blog post](https://towardsdatascience.com/go-federated-with-openfl-8bc145a5ead1) explaining steps to train a model with OpenFL. </br>
+ ***************
+ *** 53,59 ****
+   
+   
+   ### Background
+ ! OpenFL builds on the [OpenFederatedLearning](https://github.com/IntelLabs/OpenFederatedLearning) framework, which was a collaboration between Intel and the University of Pennsylvania (UPenn) to develop the [Federated Tumor Segmentation (FeTS, www.fets.ai)](https://www.fets.ai/) platform (grant award number: U01-CA242871). 
+   
+   The grant for FeTS was awarded to the [Center for Biomedical Image Computing and Analytics (CBICA)](https://www.cbica.upenn.edu/) at UPenn (PI: S. Bakas) from the [Informatics Technology for Cancer Research (ITCR)](https://itcr.cancer.gov/) program of the National Cancer Institute (NCI) of the National Institutes of Health (NIH). 
+   
+ --- 54,60 ----
+   
+   
+   ### Background
+ ! OpenFL builds on a collaboration between Intel and the University of Pennsylvania (UPenn) to develop the [Federated Tumor Segmentation (FeTS, www.fets.ai)](https://www.fets.ai/) platform (grant award number: U01-CA242871). 
+   
+   The grant for FeTS was awarded to the [Center for Biomedical Image Computing and Analytics (CBICA)](https://www.cbica.upenn.edu/) at UPenn (PI: S. Bakas) from the [Informatics Technology for Cancer Research (ITCR)](https://itcr.cancer.gov/) program of the National Cancer Institute (NCI) of the National Institutes of Health (NIH). 
+   
+ diff -crB ./openfl/setup.cfg ../mlwins-simulation-framework/ml-frameworks/federated-learning/setup.cfg
+ *** ./openfl/setup.cfg	2022-11-18 11:08:33.047181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/setup.cfg	2022-08-15 11:42:21.398825319 -0700
+ ***************
+ *** 8,14 ****
+   inline-quotes = '
+   multiline-quotes = '
+   docstring-quotes = """
+ ! exclude = *_pb2*,tests/github/interactive_api,tests/github/interactive_api_director
+   max-line-length = 99
+   avoid-escape = False
+   import-order-style = smarkets
+ --- 8,14 ----
+   inline-quotes = '
+   multiline-quotes = '
+   docstring-quotes = """
+ ! exclude = *_pb2*,tests/github/interactive_api,tests/github/interactive_api_director,.eggs
+   max-line-length = 99
+   avoid-escape = False
+   import-order-style = smarkets
+ diff -crB ./openfl/setup.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/setup.py
+ *** ./openfl/setup.py	2022-11-18 11:08:33.047181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/setup.py	2022-08-15 11:42:21.398825319 -0700
+ ***************
+ *** 3,9 ****
+ --- 3,79 ----
+   
+   """This package includes dependencies of the openfl project."""
+   
+ + from setuptools import Command
+   from setuptools import setup
+ + from setuptools.command.build_py import build_py
+ + from setuptools.command.develop import develop
+ + 
+ + 
+ + class BuildPackageProtos(Command):
+ +     """Command to generate project *_pb2.py modules from proto files."""
+ + 
+ +     user_options = []
+ + 
+ +     def initialize_options(self):
+ +         """Set default values for all the options that this command supports.
+ + 
+ +         Note that these defaults may be overridden by other
+ +         commands, by the setup script, by config files, or by the
+ +         command-line.  Thus, this is not the place to code dependencies
+ +         between options; generally, 'initialize_options()' implementations
+ +         are just a bunch of "self.foo = None" assignments.
+ + 
+ +         This method must be implemented by all command classes.
+ +         """
+ +         pass
+ + 
+ +     def finalize_options(self):
+ +         """Set final values for all the options that this command supports.
+ + 
+ +         This is always called as late as possible, ie.  after any option
+ +         assignments from the command-line or from other commands have been
+ +         done.  Thus, this is the place to code option dependencies: if
+ +         'foo' depends on 'bar', then it is safe to set 'foo' from 'bar' as
+ +         long as 'foo' still has the same value it was assigned in
+ +         'initialize_options()'.
+ + 
+ +         This method must be implemented by all command classes.
+ +         """
+ +         pass
+ + 
+ +     def run(self):
+ +         """Build gRPC modules."""
+ +         from grpc.tools import command
+ +         command.build_package_protos('.')
+ + 
+ + 
+ + class BuildPyGRPC(build_py):
+ +     """Command for Python modules build."""
+ + 
+ +     def __init__(self, dist):
+ +         """Create a sub-command to execute."""
+ +         self.subcommand = BuildPackageProtos(dist)
+ +         super().__init__(dist)
+ + 
+ +     def run(self):
+ +         """Build Python and GRPC modules."""
+ +         self.subcommand.run()
+ +         super().run()
+ + 
+ + 
+ + class DevelopGRPC(develop):
+ +     """Command for develop installation."""
+ + 
+ +     def __init__(self, dist):
+ +         """Create a sub-command to execute."""
+ +         self.subcommand = BuildPackageProtos(dist)
+ +         super().__init__(dist)
+ + 
+ +     def run(self):
+ +         """Build GRPC modules before the default installation."""
+ +         self.subcommand.run()
+ +         super().run()
+ + 
+   
+   with open('README.md') as f:
+       long_description = f.read()
+ ***************
+ *** 21,26 ****
+ --- 91,97 ----
+           'openfl.component',
+           'openfl.component.aggregation_functions',
+           'openfl.component.aggregation_functions.core',
+ +         'openfl.component.aggregation_functions.experimental',
+           'openfl.component.aggregator',
+           'openfl.component.assigner',
+           'openfl.component.ca',
+ ***************
+ *** 29,34 ****
+ --- 100,106 ----
+           'openfl.component.envoy',
+           'openfl.cryptography',
+           'openfl.databases',
+ +         'openfl.databases.utilities',
+           'openfl.federated',
+           'openfl.federated.data',
+           'openfl.federated.plan',
+ ***************
+ *** 65,71 ****
+           'docker',
+           'dynaconf==3.1.7',
+           'flatten_json',
+ -         'grpcio-tools~=1.34.0',
+           'grpcio~=1.34.0',
+           'ipykernel',
+           'jupyterlab',
+ --- 137,142 ----
+ ***************
+ *** 73,84 ****
+           'pandas',
+           'protobuf',
+           'requests',
+ !         'rich==9.1.0',
+           'scikit-learn',
+           'tensorboard',
+           'tensorboardX',
+           'tqdm',
+       ],
+       python_requires='>=3.6, <3.9',
+       project_urls={
+           'Bug Tracker': 'https://github.com/intel/openfl/issues',
+ --- 144,156 ----
+           'pandas',
+           'protobuf',
+           'requests',
+ !         'rich',
+           'scikit-learn',
+           'tensorboard',
+           'tensorboardX',
+           'tqdm',
+       ],
+ +     setup_requires=['grpcio-tools~=1.34.0'],
+       python_requires='>=3.6, <3.9',
+       project_urls={
+           'Bug Tracker': 'https://github.com/intel/openfl/issues',
+ ***************
+ *** 106,110 ****
+       ],
+       entry_points={
+           'console_scripts': ['fx=openfl.interface.cli:entry']
+ !     }
+   )
+ --- 178,187 ----
+       ],
+       entry_points={
+           'console_scripts': ['fx=openfl.interface.cli:entry']
+ !     },
+ !     cmdclass={
+ !         'build_py': BuildPyGRPC,
+ !         'build_grpc': BuildPackageProtos,
+ !         'develop': DevelopGRPC
+ !     },
+   )
+ Only in ./openfl: .signatures
+ diff -crB ./openfl/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/run.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/run.sh
+ *** ./openfl/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/run.sh	2022-11-18 11:08:33.047181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/run.sh	2022-08-15 11:42:21.398825319 -0700
+ ***************
+ *** 17,23 ****
+   pip install -r sd_requirements.txt
+   bash start_envoy.sh &
+   PID=$!
+ ! sleep 3
+   if ! ps -p $PID > /dev/null
+   then
+     echo 'Error: failed to create envoy'
+ --- 17,23 ----
+   pip install -r sd_requirements.txt
+   bash start_envoy.sh &
+   PID=$!
+ ! sleep 10
+   if ! ps -p $PID > /dev/null
+   then
+     echo 'Error: failed to create envoy'
+ ***************
+ *** 28,31 ****
+   
+   
+   cd ../../../../../..
+ ! python -m tests.github.interactive_api_director.experiments.pytorch_kvasir_unet.experiment
+ \ No newline at end of file
+ --- 28,31 ----
+   
+   
+   cd ../../../../../..
+ ! python -m tests.github.interactive_api_director.experiments.pytorch_kvasir_unet.experiment
+ diff -crB ./openfl/tests/github/interactive_api_director/experiments/tensorflow_mnist/envoy/sd_requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/tensorflow_mnist/envoy/sd_requirements.txt
+ *** ./openfl/tests/github/interactive_api_director/experiments/tensorflow_mnist/envoy/sd_requirements.txt	2022-11-18 11:08:33.047181428 -0800
+ --- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/tensorflow_mnist/envoy/sd_requirements.txt	2022-08-15 11:42:21.398825319 -0700
+ ***************
+ *** 0 ****
+ --- 1 ----
+ + tensorflow
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github: test_fets_challenge.sh
+ Only in ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/utilities: test_change_tags.py
diff -crB --new-file ./openfl/openfl-tutorials/Federated_FastEstimator_FGSM_Tutorial.ipynb ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/Federated_FastEstimator_FGSM_Tutorial.ipynb
*** ./openfl/openfl-tutorials/Federated_FastEstimator_FGSM_Tutorial.ipynb	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/Federated_FastEstimator_FGSM_Tutorial.ipynb	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,119 ****
- {
-  "cells": [
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "# Federated FastEstimator FGSM Tutorial"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Install dependencies if not already installed\n",
-     "!pip install tensorflow'>=2.3' torch'>=1.6' fastestimator"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import fastestimator as fe\n",
-     "import tempfile\n",
-     "from fastestimator.architecture.pytorch import LeNet\n",
-     "from fastestimator.backend import to_tensor, argmax\n",
-     "from fastestimator.dataset.data import cifar10\n",
-     "from fastestimator.op.numpyop.meta import Sometimes\n",
-     "from fastestimator.op.numpyop.multivariate import HorizontalFlip\n",
-     "from fastestimator.op.numpyop.univariate import CoarseDropout, Normalize, Onehot\n",
-     "from fastestimator.op.tensorop import Average\n",
-     "from fastestimator.op.tensorop.gradient import Watch, FGSM\n",
-     "from fastestimator.op.tensorop.loss import CrossEntropy\n",
-     "from fastestimator.op.tensorop.model import ModelOp, UpdateOp\n",
-     "from fastestimator.trace.io import BestModelSaver\n",
-     "from fastestimator.trace.metric import Accuracy\n",
-     "from fastestimator.util import ImgData, to_number\n",
-     "from openfl.native.fastestimator import FederatedFastEstimator\n",
-     "from fastestimator.dataset.data import cifar10\n",
-     "from fastestimator.trace.adapt import LRScheduler,ReduceLROnPlateau\n",
-     "from fastestimator.op.numpyop.univariate import Normalize, ChannelTranspose\n",
-     "\n",
-     "batch_size=128\n",
-     "\n",
-     "train_data, eval_data = cifar10.load_data()\n",
-     "test_data = eval_data.split(0.5)\n",
-     "\n",
-     "pipeline = fe.Pipeline(train_data=train_data,\n",
-     "                     eval_data=eval_data,\n",
-     "                     test_data=test_data,\n",
-     "                     batch_size=batch_size,\n",
-     "                     ops=[Normalize(inputs=\"x\", outputs=\"x\",\n",
-     "                             mean=(0.4914, 0.4822, 0.4465), \n",
-     "                             std=(0.2471, 0.2435, 0.2616)),\n",
-     "                          ChannelTranspose(inputs=\"x\", outputs=\"x\")])\n",
-     "model = fe.build(model_fn=lambda: LeNet(input_shape=(3, 32, 32)), \\\n",
-     "                         optimizer_fn=\"adam\", model_name=\"adv_model\")\n",
-     "\n",
-     "network = fe.Network(ops=[\n",
-     "                Watch(inputs=\"x\"),\n",
-     "                ModelOp(model=model, inputs=\"x\", outputs=\"y_pred\"),\n",
-     "                CrossEntropy(inputs=(\"y_pred\", \"y\"), outputs=\"base_ce\"),\n",
-     "                FGSM(data=\"x\", loss=\"base_ce\", outputs=\"x_adverse\", epsilon=0.04),\n",
-     "                ModelOp(model=model, inputs=\"x_adverse\", outputs=\"y_pred_adv\"),\n",
-     "                CrossEntropy(inputs=(\"y_pred_adv\", \"y\"), outputs=\"adv_ce\"),\n",
-     "                Average(inputs=(\"base_ce\", \"adv_ce\"), outputs=\"avg_ce\"),\n",
-     "                UpdateOp(model=model, loss_name=\"avg_ce\")\n",
-     "            ])\n",
-     "\n",
-     "estimator = fe.Estimator(pipeline=pipeline,\n",
-     "                         network=network,\n",
-     "                         epochs=1,\n",
-     "                         traces=[Accuracy(true_key=\"y\", pred_key=\"y_pred\", output_name=\"clean_accuracy\"),\n",
-     "                                Accuracy(true_key=\"y\", pred_key=\"y_pred_adv\", output_name=\"adversarial_accuracy\"),\n",
-     "                                ReduceLROnPlateau(model=model,metric='base_ce',patience=2),\n",
-     "                                BestModelSaver(model=model, save_dir=tempfile.mkdtemp(), metric=\"base_ce\", save_best_mode=\"min\",load_best_final=True),],\n",
-     "                         max_train_steps_per_epoch=None,\n",
-     "                         max_eval_steps_per_epoch=None,\n",
-     "                         monitor_names=[\"base_ce\", \"adv_ce\"],\n",
-     "                         log_steps=50)\n",
-     "openfl_estimator = FederatedFastEstimator(estimator, override_config={'aggregator.settings.rounds_to_train':5})\n",
-     "model=openfl_estimator.fit()"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "model.state_dict()"
-    ]
-   }
-  ],
-  "metadata": {
-   "kernelspec": {
-    "display_name": "demo_venv",
-    "language": "python",
-    "name": "demo_venv"
-   },
-   "language_info": {
-    "codemirror_mode": {
-     "name": "ipython",
-     "version": 3
-    },
-    "file_extension": ".py",
-    "mimetype": "text/x-python",
-    "name": "python",
-    "nbconvert_exporter": "python",
-    "pygments_lexer": "ipython3",
-    "version": "3.6.9"
-   }
-  },
-  "nbformat": 4,
-  "nbformat_minor": 4
- }
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/Federated_FedProx_Keras_MNIST_Tutorial.ipynb ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/Federated_FedProx_Keras_MNIST_Tutorial.ipynb
*** ./openfl/openfl-tutorials/Federated_FedProx_Keras_MNIST_Tutorial.ipynb	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/Federated_FedProx_Keras_MNIST_Tutorial.ipynb	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,376 ****
- {
-  "cells": [
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "# Federated Keras MNIST Tutorial"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {
-     "scrolled": true
-    },
-    "outputs": [],
-    "source": [
-     "#Install Tensorflow and MNIST dataset if not installed\n",
-     "!pip install tensorflow==2.7.0\n",
-     "#Alternatively you could use the intel-tensorflow build\n",
-     "# !pip install intel-tensorflow==2.3.0"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import numpy as np\n",
-     "import tensorflow as tf\n",
-     "import tensorflow.keras as keras\n",
-     "from tensorflow.keras import backend as K\n",
-     "from tensorflow.keras import Sequential\n",
-     "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D\n",
-     "from tensorflow.keras.utils import to_categorical\n",
-     "from tensorflow.keras.datasets import mnist\n",
-     "\n",
-     "import openfl.native as fx\n",
-     "from openfl.federated import FederatedModel,FederatedDataSet\n",
-     "tf.config.run_functions_eagerly(True)\n",
-     "tf.random.set_seed(0)\n",
-     "np.random.seed(0)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "def test_intel_tensorflow():\n",
-     "    \"\"\"\n",
-     "    Check if Intel version of TensorFlow is installed\n",
-     "    \"\"\"\n",
-     "    import tensorflow as tf\n",
-     "\n",
-     "    print(\"We are using Tensorflow version {}\".format(tf.__version__))\n",
-     "\n",
-     "    major_version = int(tf.__version__.split(\".\")[0])\n",
-     "    if major_version >= 2:\n",
-     "        from tensorflow.python.util import _pywrap_util_port\n",
-     "        print(\"Intel-optimizations (DNNL) enabled:\",\n",
-     "              _pywrap_util_port.IsMklEnabled())\n",
-     "    else:\n",
-     "        print(\"Intel-optimizations (DNNL) enabled:\")\n",
-     "\n",
-     "test_intel_tensorflow()"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "After importing the required packages, the next step is setting up our openfl workspace. To do this, simply run the `fx.init()` command as follows:"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Setup default workspace, logging, etc.\n",
-     "fx.init('keras_cnn_mnist')"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "Now we are ready to define our dataset and model to perform federated learning on. The dataset should be composed of a numpy arrayWe start with a simple fully connected model that is trained on the MNIST dataset. "
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Import and process training, validation, and test images/labels\n",
-     "\n",
-     "# Set the ratio of validation imgs, can't be 0.0\n",
-     "VALID_PERCENT = 0.3\n",
-     "\n",
-     "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
-     "split_on = int((1 - VALID_PERCENT) * len(X_train))\n",
-     "\n",
-     "train_images = X_train[0:split_on,:,:]\n",
-     "train_labels = to_categorical(y_train)[0:split_on,:]\n",
-     "\n",
-     "valid_images = X_train[split_on:,:,:]\n",
-     "valid_labels = to_categorical(y_train)[split_on:,:]\n",
-     "\n",
-     "test_images = X_test\n",
-     "test_labels = to_categorical(y_test)\n",
-     "\n",
-     "def preprocess(images):\n",
-     "    #Normalize\n",
-     "    images = (images / 255) - 0.5\n",
-     "    images = images.reshape(images.shape[0], -1)\n",
-     "#     images = np.expand_dims(images, axis=-1)\n",
-     "    return images\n",
-     "\n",
-     "# Preprocess the images.\n",
-     "train_images = preprocess(train_images)\n",
-     "valid_images = preprocess(valid_images)\n",
-     "test_images = preprocess(test_images)\n",
-     "\n",
-     "feature_shape = train_images.shape[1:]\n",
-     "classes = 10\n",
-     "\n",
-     "class UnbalancedFederatedDataset(FederatedDataSet):\n",
-     "    def split(self, num_collaborators, shuffle=True, equally=False):\n",
-     "        train_idx = self.split_lognormal(self.y_train, num_collaborators)\n",
-     "        X_train = np.array([self.X_train[idx] for idx in train_idx])\n",
-     "        y_train = np.array([self.y_train[idx] for idx in train_idx])\n",
-     "        \n",
-     "        valid_idx = self.split_lognormal(self.y_valid, num_collaborators)\n",
-     "        X_valid = np.array([self.X_valid[idx] for idx in valid_idx])\n",
-     "        y_valid = np.array([self.y_valid[idx] for idx in valid_idx])\n",
-     "        \n",
-     "        return [\n",
-     "            FederatedDataSet(\n",
-     "                X_train[i],\n",
-     "                y_train[i],\n",
-     "                X_valid[i],\n",
-     "                y_valid[i],\n",
-     "                batch_size=self.batch_size,\n",
-     "                num_classes=self.num_classes\n",
-     "            ) for i in range(num_collaborators)\n",
-     "        ]\n",
-     "    \n",
-     "    def split_lognormal(self, labels, num_collaborators):\n",
-     "        from tqdm import trange\n",
-     "        labels = np.argmax(labels, axis=1)\n",
-     "        idx = [[np.nonzero(labels == (col + j) % self.num_classes)[0][np.arange(5) + (col // 10 * 10 + 5 * j)] \\\n",
-     "            for j in range(2)] for col in range(num_collaborators)]\n",
-     "        idx = [np.hstack(tup) for tup in idx]\n",
-     "        assert all([len(i) == 10 for i in idx]), 'All collaborators should have 10 elements at this stage'\n",
-     "        props = np.random.lognormal(0, 2.0, (10,100,2))\n",
-     "        props = np.array([[[len(np.nonzero(labels==label)[0])-1000]] for label in range(10)])*props/np.sum(props,(1,2), keepdims=True)\n",
-     "        #idx = 1000*np.ones(10, dtype=np.int64)\n",
-     "        for user in trange(1000):\n",
-     "            for j in range(2):\n",
-     "                l = (user+j)%10\n",
-     "                num_samples = int(props[l,user//10,j])\n",
-     "                if np.count_nonzero(labels[np.hstack(idx)] == l) + num_samples < len(np.nonzero(labels==l)[0]):\n",
-     "                    idx_to_append = np.nonzero(labels == (user + j) % 10)[0][np.arange(num_samples) + np.count_nonzero(labels[np.hstack(idx)] == l)]\n",
-     "                    idx[user] = np.append(idx[user], idx_to_append)\n",
-     "        return idx\n",
-     "\n",
-     "fl_data = UnbalancedFederatedDataset(train_images,train_labels,valid_images,valid_labels,batch_size=32,num_classes=classes)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from openfl.utilities.optimizers.keras import FedProxOptimizer"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "def build_model(input_shape,\n",
-     "                num_classes,\n",
-     "                **kwargs):\n",
-     "    \"\"\"\n",
-     "    Define the model architecture.\n",
-     "\n",
-     "    Args:\n",
-     "        input_shape (numpy.ndarray): The shape of the data\n",
-     "        num_classes (int): The number of classes of the dataset\n",
-     "\n",
-     "    Returns:\n",
-     "        tensorflow.python.keras.engine.sequential.Sequential: The model defined in Keras\n",
-     "\n",
-     "    \"\"\"\n",
-     "    model = Sequential()\n",
-     "    \n",
-     "    model.add(tf.keras.Input(shape=input_shape))\n",
-     "    model.add(Dense(num_classes, activation='softmax'))\n",
-     "\n",
-     "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
-     "                  optimizer=FedProxOptimizer(mu=1),\n",
-     "                  metrics=['accuracy'])\n",
-     "\n",
-     "    return model   "
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Create a federated model using the build model function and dataset\n",
-     "fl_model = FederatedModel(build_model, data_loader=fl_data)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "The `FederatedModel` object is a wrapper around your Keras, Tensorflow or PyTorch model that makes it compatible with openfl. It provides built in federated training and validation functions that we will see used below. Using it's `setup` function, collaborator models and datasets can be automatically defined for the experiment. "
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "collaborator_models = fl_model.setup(num_collaborators=1000)\n",
-     " \n",
-     "collaborators = {f'col{col}':collaborator_models[col] for col in range(len(collaborator_models))}#, 'three':collaborator_models[2]}"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Original MNIST dataset\n",
-     "print(f'Original training data size: {len(train_images)}')\n",
-     "print(f'Original validation data size: {len(valid_images)}\\n')\n",
-     "\n",
-     "#Collaborator one's data\n",
-     "print(f'Collaborator one\\'s training data size: {len(collaborator_models[0].data_loader.X_train)}')\n",
-     "print(f'Collaborator one\\'s validation data size: {len(collaborator_models[0].data_loader.X_valid)}\\n')\n",
-     "\n",
-     "#Collaborator two's data\n",
-     "print(f'Collaborator two\\'s training data size: {len(collaborator_models[1].data_loader.X_train)}')\n",
-     "print(f'Collaborator two\\'s validation data size: {len(collaborator_models[1].data_loader.X_valid)}\\n')\n",
-     "\n",
-     "#Collaborator three's data\n",
-     "#print(f'Collaborator three\\'s training data size: {len(collaborator_models[2].data_loader.X_train)}')\n",
-     "#print(f'Collaborator three\\'s validation data size: {len(collaborator_models[2].data_loader.X_valid)}')"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "We can see the current plan values by running the `fx.get_plan()` function"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Get the current values of the plan. Each of these can be overridden\n",
-     "import json\n",
-     "print(json.dumps(fx.get_plan(), indent=4, sort_keys=True))"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "Now we are ready to run our experiment. If we want to pass in custom plan settings, we can easily do that with the `override_config` parameter"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {
-     "scrolled": true
-    },
-    "outputs": [],
-    "source": [
-     "#Run experiment, return trained FederatedModel\n",
-     "final_fl_model = fx.run_experiment(collaborators,override_config={'aggregator.settings.rounds_to_train':5, 'collaborator.settings.opt_treatment': 'CONTINUE_GLOBAL'})"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Save final model and load into keras\n",
-     "final_fl_model.save_native('final_model')\n",
-     "model = tf.keras.models.load_model('./final_model')"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Test the final model on our test set\n",
-     "model.evaluate(test_images,test_labels)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import matplotlib.pyplot as plt\n",
-     "import numpy as np\n",
-     "\n",
-     "plt.figure(figsize=(9,6), dpi=150)\n",
-     "plt.title('Keras MNIST unbalanced split')\n",
-     "plt.plot([0.07627802075538784, 0.07518334008473902, 0.09541350667830556, 0.13141966053564103, 0.15887578643299638], label='FedAvg')\n",
-     "plt.plot([0.07627802075538784, 0.07518334008473902, 0.09541350667830556, 0.1314459763141349, 0.15887578643299638], linestyle='--', label='FedProx (mu=1e-2)')\n",
-     "plt.plot([0.07627802075538784, 0.0751056043850258, 0.09555227747093886, 0.131649036151357, 0.15966261748969554], linestyle='--', label='FedProx (mu=1e-1)')\n",
-     "plt.plot([0.07627802075538784, 0.07517912408802659, 0.09641592293512076, 0.13676991989742965, 0.1684917744528502], linestyle='--', label='FedProx (mu=1e1)')\n",
-     "\n",
-     "plt.legend()\n",
-     "plt.xticks(range(5))\n",
-     "plt.show()"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": []
-   }
-  ],
-  "metadata": {
-   "kernelspec": {
-    "display_name": "Python 3",
-    "language": "python",
-    "name": "python3"
-   },
-   "language_info": {
-    "codemirror_mode": {
-     "name": "ipython",
-     "version": 3
-    },
-    "file_extension": ".py",
-    "mimetype": "text/x-python",
-    "name": "python",
-    "nbconvert_exporter": "python",
-    "pygments_lexer": "ipython3",
-    "version": "3.8.8"
-   }
-  },
-  "nbformat": 4,
-  "nbformat_minor": 4
- }
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/Federated_FedProx_PyTorch_MNIST_Tutorial.ipynb ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/Federated_FedProx_PyTorch_MNIST_Tutorial.ipynb
*** ./openfl/openfl-tutorials/Federated_FedProx_PyTorch_MNIST_Tutorial.ipynb	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/Federated_FedProx_PyTorch_MNIST_Tutorial.ipynb	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,511 ****
- {
-  "cells": [
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "# Federated FedProx PyTorch MNIST Tutorial\n",
-     "The only difference between this notebook and Federated_Pytorch_MNIST_Tutorial.ipynb is overriding of the `train_epoch` function in model definition. [See details](#FedProx)\n"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Install dependencies if not already installed\n",
-     "!pip install torch torchvision"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import numpy as np\n",
-     "import torch\n",
-     "import torch.nn as nn\n",
-     "import torch.nn.functional as F\n",
-     "import torch.optim as optim\n",
-     "\n",
-     "import torchvision\n",
-     "import torchvision.transforms as transforms\n",
-     "import openfl.native as fx\n",
-     "from openfl.federated import FederatedModel,FederatedDataSet\n",
-     "import random\n",
-     "import warnings\n",
-     "warnings.filterwarnings('ignore')\n",
-     "def set_seed(seed):\n",
-     "    torch.manual_seed(seed)\n",
-     "    torch.cuda.manual_seed_all(seed)\n",
-     "    torch.backends.cudnn.deterministic = True\n",
-     "    torch.backends.cudnn.benchmark = False\n",
-     "    np.random.seed(seed)\n",
-     "    random.seed(seed)\n",
-     "set_seed(10)\n"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "After importing the required packages, the next step is setting up our openfl workspace. To do this, simply run the `fx.init()` command as follows:"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Setup default workspace, logging, etc.\n",
-     "fx.init('torch_cnn_mnist')"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "Now we are ready to define our dataset and model to perform federated learning on. The dataset should be composed of a numpy arrayWe start with a simple fully connected model that is trained on the MNIST dataset. "
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "def one_hot(labels, classes):\n",
-     "    return np.eye(classes)[labels]\n",
-     "\n",
-     "transform = transforms.Compose(\n",
-     "    [transforms.ToTensor(),\n",
-     "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
-     "\n",
-     "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
-     "                                        download=True, transform=transform)\n",
-     "\n",
-     "train_images,train_labels = trainset.train_data, np.array(trainset.train_labels)\n",
-     "train_images = torch.from_numpy(np.expand_dims(train_images, axis=1)).float()\n",
-     "train_labels = one_hot(train_labels,10)\n",
-     "\n",
-     "validset = torchvision.datasets.MNIST(root='./data', train=False,\n",
-     "                                       download=True, transform=transform)\n",
-     "\n",
-     "valid_images,valid_labels = validset.test_data, np.array(validset.test_labels)\n",
-     "valid_images = torch.from_numpy(np.expand_dims(valid_images, axis=1)).float()\n",
-     "valid_labels = one_hot(valid_labels,10)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "# FedProx"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from openfl.utilities.optimizers.torch import FedProxOptimizer"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "feature_shape = train_images.shape[1]\n",
-     "classes       = 10\n",
-     "\n",
-     "fl_data = FederatedDataSet(train_images,train_labels,valid_images,valid_labels,batch_size=32,num_classes=classes)\n",
-     "\n",
-     "class Net(nn.Module):\n",
-     "    def __init__(self):\n",
-     "        super(Net, self).__init__()\n",
-     "        self.conv1 = nn.Conv2d(1, 16, 3)\n",
-     "        self.pool = nn.MaxPool2d(2, 2)\n",
-     "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
-     "        self.fc1 = nn.Linear(32 * 5 * 5, 32)\n",
-     "        self.fc2 = nn.Linear(32, 84)\n",
-     "        self.fc3 = nn.Linear(84, 10)\n",
-     "\n",
-     "    def forward(self, x):\n",
-     "        x = self.pool(F.relu(self.conv1(x)))\n",
-     "        x = self.pool(F.relu(self.conv2(x)))\n",
-     "        x = x.view(x.size(0),-1)\n",
-     "        x = F.relu(self.fc1(x))\n",
-     "        x = F.relu(self.fc2(x))\n",
-     "        x = self.fc3(x)\n",
-     "        return F.log_softmax(x, dim=1)\n",
-     "    \n",
-     "    def train_epoch(self, batch_generator):\n",
-     "        from openfl.federated.task import PyTorchTaskRunner\n",
-     "        self.optimizer.set_old_weights([p for p in self.parameters()])\n",
-     "        return PyTorchTaskRunner.train_epoch(self, batch_generator)\n",
-     "\n",
-     "    \n",
-     "optimizer = lambda x: FedProxOptimizer(x, lr=1e-3, mu=0.1)\n",
-     "\n",
-     "def cross_entropy(output, target):\n",
-     "    \"\"\"Binary cross-entropy metric\n",
-     "    \"\"\"\n",
-     "    return F.binary_cross_entropy_with_logits(input=output,target=target.float())"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "\n",
-     "#Create a federated model using the pytorch class, lambda optimizer function, and loss function\n",
-     "fl_model = FederatedModel(build_model=Net,optimizer=optimizer,loss_fn=cross_entropy,data_loader=fl_data)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "The `FederatedModel` object is a wrapper around your Keras, Tensorflow or PyTorch model that makes it compatible with openfl. It provides built in federated training and validation functions that we will see used below. Using it's `setup` function, collaborator models and datasets can be automatically defined for the experiment. "
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "collaborator_models = fl_model.setup(num_collaborators=2)\n",
-     "collaborators = {'one':collaborator_models[0],'two':collaborator_models[1]}#, 'three':collaborator_models[2]}"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Original MNIST dataset\n",
-     "print(f'Original training data size: {len(train_images)}')\n",
-     "print(f'Original validation data size: {len(valid_images)}\\n')\n",
-     "\n",
-     "#Collaborator one's data\n",
-     "print(f'Collaborator one\\'s training data size: {len(collaborator_models[0].data_loader.X_train)}')\n",
-     "print(f'Collaborator one\\'s validation data size: {len(collaborator_models[0].data_loader.X_valid)}\\n')\n",
-     "\n",
-     "#Collaborator two's data\n",
-     "print(f'Collaborator two\\'s training data size: {len(collaborator_models[1].data_loader.X_train)}')\n",
-     "print(f'Collaborator two\\'s validation data size: {len(collaborator_models[1].data_loader.X_valid)}\\n')\n",
-     "\n",
-     "#Collaborator three's data\n",
-     "#print(f'Collaborator three\\'s training data size: {len(collaborator_models[2].data_loader.X_train)}')\n",
-     "#print(f'Collaborator three\\'s validation data size: {len(collaborator_models[2].data_loader.X_valid)}')"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "We can see the current plan values by running the `fx.get_plan()` function"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     " #Get the current values of the plan. Each of these can be overridden\n",
-     "import json\n",
-     "print(json.dumps(fx.get_plan(), indent=4, sort_keys=True))"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "Now we are ready to run our experiment. If we want to pass in custom plan settings, we can easily do that with the `override_config` parameter"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Run experiment, return trained FederatedModel\n",
-     "final_fl_model = fx.run_experiment(collaborators,{'aggregator.settings.rounds_to_train':5})"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Save final model\n",
-     "final_fl_model.save_native('final_pytorch_model')"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "# FedProxAdam"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {
-     "code_folding": []
-    },
-    "outputs": [],
-    "source": [
-     "classes = 10\n",
-     "collaborator_num = 300\n",
-     "NUM_USER = collaborator_num\n",
-     "\n",
-     "def one_hot(labels, classes):\n",
-     "    return np.eye(classes)[labels]\n",
-     "\n",
-     "\n",
-     "def softmax(x):\n",
-     "    ex = np.exp(x)\n",
-     "    sum_ex = np.sum(np.exp(x))\n",
-     "    return ex/sum_ex\n",
-     "\n",
-     "\n",
-     "def generate_synthetic(alpha, beta, iid):\n",
-     "\n",
-     "    dimension = 60\n",
-     "    NUM_CLASS = 10\n",
-     "\n",
-     "    samples_per_user = np.random.lognormal(4, 2, (NUM_USER)).astype(int) + 50\n",
-     "    num_samples = np.sum(samples_per_user)\n",
-     "\n",
-     "    X_split = [[] for _ in range(NUM_USER)]\n",
-     "    y_split = [[] for _ in range(NUM_USER)]\n",
-     "\n",
-     "    #### define some eprior ####\n",
-     "    mean_W = np.random.normal(0, alpha, NUM_USER)\n",
-     "    mean_b = mean_W\n",
-     "    B = np.random.normal(0, beta, NUM_USER)\n",
-     "    mean_x = np.zeros((NUM_USER, dimension))\n",
-     "\n",
-     "    diagonal = np.zeros(dimension)\n",
-     "    for j in range(dimension):\n",
-     "        diagonal[j] = np.power((j+1), -1.2)\n",
-     "    cov_x = np.diag(diagonal)\n",
-     "\n",
-     "    for i in range(NUM_USER):\n",
-     "        if iid == 1:\n",
-     "            mean_x[i] = np.ones(dimension) * B[i]  # all zeros\n",
-     "        else:\n",
-     "            mean_x[i] = np.random.normal(B[i], 1, dimension)\n",
-     "\n",
-     "    if iid == 1:\n",
-     "        W_global = np.random.normal(0, 1, (dimension, NUM_CLASS))\n",
-     "        b_global = np.random.normal(0, 1,  NUM_CLASS)\n",
-     "\n",
-     "    for i in range(NUM_USER):\n",
-     "\n",
-     "        W = np.random.normal(mean_W[i], 1, (dimension, NUM_CLASS))\n",
-     "        b = np.random.normal(mean_b[i], 1,  NUM_CLASS)\n",
-     "\n",
-     "        if iid == 1:\n",
-     "            W = W_global\n",
-     "            b = b_global\n",
-     "\n",
-     "        xx = np.random.multivariate_normal(\n",
-     "            mean_x[i], cov_x, samples_per_user[i])\n",
-     "        yy = np.zeros(samples_per_user[i])\n",
-     "\n",
-     "        for j in range(samples_per_user[i]):\n",
-     "            tmp = np.dot(xx[j], W) + b\n",
-     "            yy[j] = np.argmax(softmax(tmp))\n",
-     "\n",
-     "        X_split[i] = xx.tolist()\n",
-     "        y_split[i] = yy.tolist()\n",
-     "\n",
-     "#         print(\"{}-th users has {} exampls\".format(i, len(y_split[i])))\n",
-     "\n",
-     "    return X_split, y_split\n",
-     "\n",
-     "\n",
-     "class SyntheticFederatedDataset(FederatedDataSet):\n",
-     "    def __init__(self, batch_size=1, num_classes=None, **kwargs):\n",
-     "        X, y = generate_synthetic(0.0, 0.0, 0)\n",
-     "        X = [np.array([np.array(sample).astype(np.float32)\n",
-     "                      for sample in col]) for col in X]\n",
-     "        y = [np.array([np.array(one_hot(int(sample), classes))\n",
-     "                      for sample in col]) for col in y]\n",
-     "        self.X_train_all = np.array([col[:int(0.9 * len(col))] for col in X])\n",
-     "        self.X_valid_all = np.array([col[int(0.9 * len(col)):] for col in X])\n",
-     "        self.y_train_all = np.array([col[:int(0.9 * len(col))] for col in y])\n",
-     "        self.y_valid_all = np.array([col[int(0.9 * len(col)):] for col in y])\n",
-     "        super().__init__(self.X_train_all[0], self.y_train_all[0], self.X_valid_all[0],\n",
-     "                         self.y_valid_all[0], batch_size, num_classes)\n",
-     "\n",
-     "    def split(self, num_collaborators, shuffle=True, equally=False):\n",
-     "        return [\n",
-     "            FederatedDataSet(\n",
-     "                self.X_train_all[i],\n",
-     "                self.y_train_all[i],\n",
-     "                self.X_valid_all[i],\n",
-     "                self.y_valid_all[i],\n",
-     "                batch_size=self.batch_size,\n",
-     "                num_classes=self.num_classes\n",
-     "            ) for i in range(num_collaborators)\n",
-     "        ]"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from openfl.utilities.optimizers.torch import FedProxAdam "
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "class Net(nn.Module):\n",
-     "    def __init__(self):\n",
-     "        super(Net, self).__init__()\n",
-     "        self.linear1 = nn.Linear(60, 100)\n",
-     "        self.linear2 = nn.Linear(100, 10)\n",
-     "\n",
-     "    def forward(self, x):\n",
-     "        x = self.linear1(x)\n",
-     "        x = self.linear2(x)\n",
-     "        return x\n",
-     "\n",
-     "    def train_epoch(self, batch_generator):\n",
-     "        from openfl.federated.task import PyTorchTaskRunner\n",
-     "        self.optimizer.set_old_weights(\n",
-     "            [p.clone().detach() for p in self.parameters()])\n",
-     "        return PyTorchTaskRunner.train_epoch(self, batch_generator)\n",
-     "\n",
-     "\n",
-     "def optimizer(x): return FedProxAdam(x, lr=1e-3, mu=0.01)\n",
-     "# optimizer = lambda x: torch.optim.Adam(x, lr=1e-3)\n",
-     "\n",
-     "\n",
-     "def cross_entropy(output, target):\n",
-     "    \"\"\"Binary cross-entropy metric\n",
-     "     \"\"\"\n",
-     "    return F.cross_entropy(output, torch.max(target, 1)[1])\n",
-     "#     return F.binary_cross_entropy_with_logits(input=output,target=target.float())\n"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "fl_data = SyntheticFederatedDataset(batch_size=32, num_classes=classes)\n",
-     "#Create a federated model using the pytorch class, lambda optimizer function, and loss function\n",
-     "fl_model = FederatedModel(build_model=Net,optimizer=optimizer,loss_fn=cross_entropy,data_loader=fl_data)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "The `FederatedModel` object is a wrapper around your Keras, Tensorflow or PyTorch model that makes it compatible with openfl. It provides built in federated training and validation functions that we will see used below. Using it's `setup` function, collaborator models and datasets can be automatically defined for the experiment. "
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "collaborator_models = fl_model.setup(num_collaborators=collaborator_num,device='cpu')\n",
-     "collaborators = {f'col{i}':collaborator_models[i] for i in range(collaborator_num)}#, 'three':collaborator_models[2]}"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "a = np.argmax(collaborators['col3'].data_loader.y_valid, axis =1)\n",
-     "import matplotlib.pyplot as plt\n",
-     "plt.hist(a)\n",
-     "collaborator_models[1].data_loader.y_valid.shape"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "We can see the current plan values by running the `fx.get_plan()` function"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "Now we are ready to run our experiment. If we want to pass in custom plan settings, we can easily do that with the `override_config` parameter"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Run experiment, return trained FederatedModel\n",
-     "final_fl_model = fx.run_experiment(collaborators,{'aggregator.settings.rounds_to_train':20})"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Save final model\n",
-     "final_fl_model.save_native('final_pytorch_model')"
-    ]
-   }
-  ],
-  "metadata": {
-   "kernelspec": {
-    "display_name": "Python 3",
-    "language": "python",
-    "name": "python3"
-   },
-   "language_info": {
-    "codemirror_mode": {
-     "name": "ipython",
-     "version": 3
-    },
-    "file_extension": ".py",
-    "mimetype": "text/x-python",
-    "name": "python",
-    "nbconvert_exporter": "python",
-    "pygments_lexer": "ipython3",
-    "version": "3.8.10"
-   }
-  },
-  "nbformat": 4,
-  "nbformat_minor": 4
- }
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/Federated_Keras_MNIST_Tutorial.ipynb ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/Federated_Keras_MNIST_Tutorial.ipynb
*** ./openfl/openfl-tutorials/Federated_Keras_MNIST_Tutorial.ipynb	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/Federated_Keras_MNIST_Tutorial.ipynb	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,280 ****
- {
-  "cells": [
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "# Federated Keras MNIST Tutorial"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {
-     "scrolled": true
-    },
-    "outputs": [],
-    "source": [
-     "#Install Tensorflow and MNIST dataset if not installed\n",
-     "!pip install tensorflow==2.7.0\n",
-     "\n",
-     "#Alternatively you could use the intel-tensorflow build\n",
-     "# !pip install intel-tensorflow==2.3.0"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import numpy as np\n",
-     "import tensorflow as tf\n",
-     "import tensorflow.keras as keras\n",
-     "from tensorflow.keras import backend as K\n",
-     "from tensorflow.keras import Sequential\n",
-     "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
-     "from tensorflow.keras.utils import to_categorical\n",
-     "from tensorflow.keras.datasets import mnist\n",
-     "\n",
-     "import openfl.native as fx\n",
-     "from openfl.federated import FederatedModel,FederatedDataSet"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "def test_intel_tensorflow():\n",
-     "    \"\"\"\n",
-     "    Check if Intel version of TensorFlow is installed\n",
-     "    \"\"\"\n",
-     "    import tensorflow as tf\n",
-     "\n",
-     "    print(\"We are using Tensorflow version {}\".format(tf.__version__))\n",
-     "\n",
-     "    major_version = int(tf.__version__.split(\".\")[0])\n",
-     "    if major_version >= 2:\n",
-     "        from tensorflow.python.util import _pywrap_util_port\n",
-     "        print(\"Intel-optimizations (DNNL) enabled:\",\n",
-     "              _pywrap_util_port.IsMklEnabled())\n",
-     "    else:\n",
-     "        print(\"Intel-optimizations (DNNL) enabled:\")\n",
-     "\n",
-     "test_intel_tensorflow()"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "After importing the required packages, the next step is setting up our openfl workspace. To do this, simply run the `fx.init()` command as follows:"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Setup default workspace, logging, etc.\n",
-     "fx.init('keras_cnn_mnist')"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "Now we are ready to define our dataset and model to perform federated learning on. The dataset should be composed of a numpy arrayWe start with a simple fully connected model that is trained on the MNIST dataset. "
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Import and process training, validation, and test images/labels\n",
-     "\n",
-     "# Set the ratio of validation imgs, can't be 0.0\n",
-     "VALID_PERCENT = 0.3\n",
-     "\n",
-     "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
-     "split_on = int((1 - VALID_PERCENT) * len(X_train))\n",
-     "\n",
-     "train_images = X_train[0:split_on,:,:]\n",
-     "train_labels = to_categorical(y_train)[0:split_on,:]\n",
-     "\n",
-     "valid_images = X_train[split_on:,:,:]\n",
-     "valid_labels = to_categorical(y_train)[split_on:,:]\n",
-     "\n",
-     "test_images = X_test\n",
-     "test_labels = to_categorical(y_test)\n",
-     "\n",
-     "def preprocess(images):\n",
-     "    #Normalize\n",
-     "    images = (images / 255) - 0.5\n",
-     "    #Flatten\n",
-     "    images = images.reshape((-1, 784))\n",
-     "    return images\n",
-     "\n",
-     "# Preprocess the images.\n",
-     "train_images = preprocess(train_images)\n",
-     "valid_images = preprocess(valid_images)\n",
-     "test_images = preprocess(test_images)\n",
-     "\n",
-     "feature_shape = train_images.shape[1]\n",
-     "classes = 10\n",
-     "\n",
-     "fl_data = FederatedDataSet(train_images,train_labels,valid_images,valid_labels,batch_size=32,num_classes=classes)\n",
-     "\n",
-     "def build_model(feature_shape,classes):\n",
-     "    #Defines the MNIST model\n",
-     "    model = Sequential()\n",
-     "    model.add(Dense(64, input_shape=feature_shape, activation='relu'))\n",
-     "    model.add(Dense(64, activation='relu'))\n",
-     "    model.add(Dense(classes, activation='softmax'))\n",
-     "    \n",
-     "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'],)\n",
-     "    return model"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Create a federated model using the build model function and dataset\n",
-     "fl_model = FederatedModel(build_model,data_loader=fl_data)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "The `FederatedModel` object is a wrapper around your Keras, Tensorflow or PyTorch model that makes it compatible with openfl. It provides built in federated training and validation functions that we will see used below. Using it's `setup` function, collaborator models and datasets can be automatically defined for the experiment. "
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "collaborator_models = fl_model.setup(num_collaborators=2)\n",
-     "collaborators = {'one':collaborator_models[0],'two':collaborator_models[1]}#, 'three':collaborator_models[2]}"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Original MNIST dataset\n",
-     "print(f'Original training data size: {len(train_images)}')\n",
-     "print(f'Original validation data size: {len(valid_images)}\\n')\n",
-     "\n",
-     "#Collaborator one's data\n",
-     "print(f'Collaborator one\\'s training data size: {len(collaborator_models[0].data_loader.X_train)}')\n",
-     "print(f'Collaborator one\\'s validation data size: {len(collaborator_models[0].data_loader.X_valid)}\\n')\n",
-     "\n",
-     "#Collaborator two's data\n",
-     "print(f'Collaborator two\\'s training data size: {len(collaborator_models[1].data_loader.X_train)}')\n",
-     "print(f'Collaborator two\\'s validation data size: {len(collaborator_models[1].data_loader.X_valid)}\\n')\n",
-     "\n",
-     "#Collaborator three's data\n",
-     "#print(f'Collaborator three\\'s training data size: {len(collaborator_models[2].data_loader.X_train)}')\n",
-     "#print(f'Collaborator three\\'s validation data size: {len(collaborator_models[2].data_loader.X_valid)}')"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "We can see the current plan values by running the `fx.get_plan()` function"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Get the current values of the plan. Each of these can be overridden\n",
-     "print(fx.get_plan())"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "Now we are ready to run our experiment. If we want to pass in custom plan settings, we can easily do that with the `override_config` parameter"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {
-     "scrolled": true
-    },
-    "outputs": [],
-    "source": [
-     "#Run experiment, return trained FederatedModel\n",
-     "final_fl_model = fx.run_experiment(collaborators,override_config={'aggregator.settings.rounds_to_train':5})"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Save final model and load into keras\n",
-     "final_fl_model.save_native('final_model')\n",
-     "model = tf.keras.models.load_model('./final_model')"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Test the final model on our test set\n",
-     "model.evaluate(test_images,test_labels)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": []
-   }
-  ],
-  "metadata": {
-   "kernelspec": {
-    "display_name": "Python 3",
-    "language": "python",
-    "name": "python3"
-   },
-   "language_info": {
-    "codemirror_mode": {
-     "name": "ipython",
-     "version": 3
-    },
-    "file_extension": ".py",
-    "mimetype": "text/x-python",
-    "name": "python",
-    "nbconvert_exporter": "python",
-    "pygments_lexer": "ipython3",
-    "version": "3.8.8"
-   }
-  },
-  "nbformat": 4,
-  "nbformat_minor": 4
- }
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/Federated_Pytorch_MNIST_custom_aggregation_Tutorial.ipynb ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/Federated_Pytorch_MNIST_custom_aggregation_Tutorial.ipynb
*** ./openfl/openfl-tutorials/Federated_Pytorch_MNIST_custom_aggregation_Tutorial.ipynb	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/Federated_Pytorch_MNIST_custom_aggregation_Tutorial.ipynb	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,475 ****
- {
-  "cells": [
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "# Federated PyTorch MNIST Tutorial"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Install dependencies if not already installed\n",
-     "!pip install torch torchvision"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import numpy as np\n",
-     "import torch\n",
-     "import torch.nn as nn\n",
-     "import torch.nn.functional as F\n",
-     "import torch.optim as optim\n",
-     "\n",
-     "import torchvision\n",
-     "import torchvision.transforms as transforms\n",
-     "import openfl.native as fx\n",
-     "from openfl.federated import FederatedModel,FederatedDataSet\n",
-     "\n",
-     "torch.manual_seed(0)\n",
-     "np.random.seed(0)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "After importing the required packages, the next step is setting up our openfl workspace. To do this, simply run the `fx.init()` command as follows:"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Setup default workspace, logging, etc.\n",
-     "fx.init('torch_cnn_mnist')"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "Now we are ready to define our dataset and model to perform federated learning on. The dataset should be composed of a numpy arrayWe start with a simple fully connected model that is trained on the MNIST dataset. "
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "def one_hot(labels, classes):\n",
-     "    return np.eye(classes)[labels]\n",
-     "\n",
-     "transform = transforms.Compose(\n",
-     "    [transforms.ToTensor(),\n",
-     "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
-     "\n",
-     "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
-     "                                        download=True, transform=transform)\n",
-     "\n",
-     "train_images,train_labels = trainset.train_data, np.array(trainset.train_labels)\n",
-     "train_images = torch.from_numpy(np.expand_dims(train_images, axis=1)).float()\n",
-     "train_labels = one_hot(train_labels,10)\n",
-     "\n",
-     "validset = torchvision.datasets.MNIST(root='./data', train=False,\n",
-     "                                       download=True, transform=transform)\n",
-     "\n",
-     "valid_images,valid_labels = validset.test_data, np.array(validset.test_labels)\n",
-     "valid_images = torch.from_numpy(np.expand_dims(valid_images, axis=1)).float()\n",
-     "valid_labels = one_hot(valid_labels,10)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "feature_shape = train_images.shape[1]\n",
-     "classes       = 10\n",
-     "\n",
-     "fl_data = FederatedDataSet(train_images,train_labels,valid_images,valid_labels,batch_size=32,num_classes=classes)\n",
-     "\n",
-     "class Net(nn.Module):\n",
-     "    def __init__(self):\n",
-     "        super(Net, self).__init__()\n",
-     "        self.conv1 = nn.Conv2d(1, 16, 3)\n",
-     "        self.pool = nn.MaxPool2d(2, 2)\n",
-     "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
-     "        self.fc1 = nn.Linear(32 * 5 * 5, 32)\n",
-     "        self.fc2 = nn.Linear(32, 84)\n",
-     "        self.fc3 = nn.Linear(84, 10)\n",
-     "\n",
-     "    def forward(self, x):\n",
-     "        x = self.pool(F.relu(self.conv1(x)))\n",
-     "        x = self.pool(F.relu(self.conv2(x)))\n",
-     "        x = x.view(x.size(0),-1)\n",
-     "        x = F.relu(self.fc1(x))\n",
-     "        x = F.relu(self.fc2(x))\n",
-     "        x = self.fc3(x)\n",
-     "        return x\n",
-     "    \n",
-     "optimizer = lambda x: optim.Adam(x, lr=1e-4)\n",
-     "\n",
-     "def cross_entropy(output, target):\n",
-     "    \"\"\"Binary cross-entropy metric\n",
-     "    \"\"\"\n",
-     "    return F.cross_entropy(input=output,target=torch.argmax(target, dim=1))"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "\n",
-     "#Create a federated model using the pytorch class, lambda optimizer function, and loss function\n",
-     "fl_model = FederatedModel(build_model=Net,optimizer=optimizer,loss_fn=cross_entropy,data_loader=fl_data)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "The `FederatedModel` object is a wrapper around your Keras, Tensorflow or PyTorch model that makes it compatible with openfl. It provides built in federated training and validation functions that we will see used below. Using it's `setup` function, collaborator models and datasets can be automatically defined for the experiment. "
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "collaborator_models = fl_model.setup(num_collaborators=10)\n",
-     "collaborators = {str(i): collaborator_models[i] for i in range(10)}#, 'three':collaborator_models[2]}"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Original MNIST dataset\n",
-     "print(f'Original training data size: {len(train_images)}')\n",
-     "print(f'Original validation data size: {len(valid_images)}\\n')\n",
-     "\n",
-     "#Collaborator one's data\n",
-     "print(f'Collaborator one\\'s training data size: {len(collaborator_models[0].data_loader.X_train)}')\n",
-     "print(f'Collaborator one\\'s validation data size: {len(collaborator_models[0].data_loader.X_valid)}\\n')\n",
-     "\n",
-     "#Collaborator two's data\n",
-     "print(f'Collaborator two\\'s training data size: {len(collaborator_models[1].data_loader.X_train)}')\n",
-     "print(f'Collaborator two\\'s validation data size: {len(collaborator_models[1].data_loader.X_valid)}\\n')\n",
-     "\n",
-     "#Collaborator three's data\n",
-     "#print(f'Collaborator three\\'s training data size: {len(collaborator_models[2].data_loader.X_train)}')\n",
-     "#print(f'Collaborator three\\'s validation data size: {len(collaborator_models[2].data_loader.X_valid)}')"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "We can see the current plan values by running the `fx.get_plan()` function"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     " #Get the current values of the plan. Each of these can be overridden\n",
-     "print(fx.get_plan())"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "Now we are ready to run our experiment. If we want to pass in custom plan settings, we can easily do that with the `override_config` parameter"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from openfl.component.aggregation_functions import AggregationFunction\n",
-     "import numpy as np\n",
-     "\n",
-     "class ExponentialSmoothingAveraging(AggregationFunction):\n",
-     "    \"\"\"\n",
-     "        Averaging via exponential smoothing.\n",
-     "        \n",
-     "        In order to use this mechanism properly you should specify `aggregator.settings.db_store_rounds` \n",
-     "        in `override_config` keyword argument of `run_experiment` function. \n",
-     "        It should be equal to the number of rounds you want to include in smoothing window.\n",
-     "        \n",
-     "        Args:\n",
-     "            alpha(float): Smoothing term.\n",
-     "    \"\"\"\n",
-     "    def __init__(self, alpha=0.9):\n",
-     "        self.alpha = alpha\n",
-     "        \n",
-     "    def call(self,\n",
-     "             local_tensors,\n",
-     "             db_iterator,\n",
-     "             tensor_name,\n",
-     "             fl_round,\n",
-     "             tags):\n",
-     "        \"\"\"Aggregate tensors.\n",
-     "\n",
-     "        Args:\n",
-     "            local_tensors(list[openfl.utilities.LocalTensor]): List of local tensors to aggregate.\n",
-     "            db_iterator: iterator over history of all tensors. Columns:\n",
-     "                - 'tensor_name': name of the tensor.\n",
-     "                    Examples for `torch.nn.Module`s: 'conv1.weight', 'fc2.bias'.\n",
-     "                - 'round': 0-based number of round corresponding to this tensor.\n",
-     "                - 'tags': tuple of tensor tags. Tags that can appear:\n",
-     "                    - 'model' indicates that the tensor is a model parameter.\n",
-     "                    - 'trained' indicates that tensor is a part of a training result.\n",
-     "                        These tensors are passed to the aggregator node after local learning.\n",
-     "                    - 'aggregated' indicates that tensor is a result of aggregation.\n",
-     "                        These tensors are sent to collaborators for the next round.\n",
-     "                    - 'delta' indicates that value is a difference between rounds\n",
-     "                        for a specific tensor.\n",
-     "                    also one of the tags is a collaborator name\n",
-     "                    if it corresponds to a result of a local task.\n",
-     "\n",
-     "                - 'nparray': value of the tensor.\n",
-     "            tensor_name: name of the tensor\n",
-     "            fl_round: round number\n",
-     "            tags: tuple of tags for this tensor\n",
-     "        Returns:\n",
-     "            np.ndarray: aggregated tensor\n",
-     "        \"\"\"\n",
-     "        tensors, weights = zip(*[(x.tensor, x.weight) for x in local_tensors])\n",
-     "        tensors, weights = np.array(tensors), np.array(weights)\n",
-     "        average = np.average(tensors, weights=weights, axis=0)\n",
-     "        previous_tensor_values = []\n",
-     "        for record in db_iterator:\n",
-     "            if (\n",
-     "                record['tensor_name'] == tensor_name\n",
-     "                and 'aggregated' in record['tags']\n",
-     "                and 'delta' not in record['tags']\n",
-     "               ):\n",
-     "                previous_tensor_values.append(record['nparray'])\n",
-     "        for i, x in enumerate(previous_tensor_values):\n",
-     "            previous_tensor_values[i] = x * self.alpha * (1 - self.alpha) ** i\n",
-     "        smoothing_term = np.sum(previous_tensor_values, axis=0)\n",
-     "        return self.alpha * average + (1 - self.alpha) * smoothing_term"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from openfl.component.aggregation_functions import AggregationFunction\n",
-     "import numpy as np\n",
-     "\n",
-     "class ClippedAveraging(AggregationFunction):\n",
-     "    def __init__(self, ratio):\n",
-     "        \"\"\"Average clipped tensors.\n",
-     "            \n",
-     "            Args:\n",
-     "                ratio(float): Ratio to multiply with a tensor for clipping\n",
-     "        \"\"\"\n",
-     "        self.ratio = ratio\n",
-     "        \n",
-     "    def call(self,\n",
-     "             local_tensors,\n",
-     "             db_iterator,\n",
-     "             tensor_name,\n",
-     "             fl_round,\n",
-     "             *__):\n",
-     "        \"\"\"Aggregate tensors.\n",
-     "\n",
-     "        Args:\n",
-     "            local_tensors(list[openfl.utilities.LocalTensor]): List of local tensors to aggregate.\n",
-     "            db_iterator: iterator over history of all tensors. Columns:\n",
-     "                - 'tensor_name': name of the tensor.\n",
-     "                    Examples for `torch.nn.Module`s: 'conv1.weight', 'fc2.bias'.\n",
-     "                - 'round': 0-based number of round corresponding to this tensor.\n",
-     "                - 'tags': tuple of tensor tags. Tags that can appear:\n",
-     "                    - 'model' indicates that the tensor is a model parameter.\n",
-     "                    - 'trained' indicates that tensor is a part of a training result.\n",
-     "                        These tensors are passed to the aggregator node after local learning.\n",
-     "                    - 'aggregated' indicates that tensor is a result of aggregation.\n",
-     "                        These tensors are sent to collaborators for the next round.\n",
-     "                    - 'delta' indicates that value is a difference between rounds\n",
-     "                        for a specific tensor.\n",
-     "                    also one of the tags is a collaborator name\n",
-     "                    if it corresponds to a result of a local task.\n",
-     "\n",
-     "                - 'nparray': value of the tensor.\n",
-     "            tensor_name: name of the tensor\n",
-     "            fl_round: round number\n",
-     "            tags: tuple of tags for this tensor\n",
-     "        Returns:\n",
-     "            np.ndarray: aggregated tensor\n",
-     "        \"\"\"\n",
-     "        clipped_tensors = []\n",
-     "        previous_tensor_value = None\n",
-     "        for record in db_iterator:\n",
-     "            if (\n",
-     "                record['round'] == (fl_round - 1)\n",
-     "                and record['tensor_name'] == tensor_name\n",
-     "                and record['tags'] == ('trained',)\n",
-     "               ):\n",
-     "                previous_tensor_value = record['nparray']\n",
-     "        weights = []\n",
-     "        for local_tensor in local_tensors:\n",
-     "            prev_tensor = previous_tensor_value if previous_tensor_value is not None else local_tensor.tensor\n",
-     "            delta = local_tensor.tensor - prev_tensor\n",
-     "            new_tensor = prev_tensor + delta * self.ratio\n",
-     "            clipped_tensors.append(new_tensor)\n",
-     "            weights.append(local_tensor.weight)\n",
-     "\n",
-     "        return np.average(clipped_tensors, weights=weights, axis=0)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from openfl.component.aggregation_functions import AggregationFunction\n",
-     "\n",
-     "class ConditionalThresholdAveraging(AggregationFunction):\n",
-     "    def __init__(self, threshold_fn, metric_name='acc', tags=['metric', 'validate_local']):\n",
-     "        \"\"\"Average tensors by metric value on previous round.\n",
-     "        If no tensors match threshold condition, a simple weighted averaging will be performed.\n",
-     "           \n",
-     "           Args:\n",
-     "               threshold_fn(callable): function to define a threshold for each round.\n",
-     "                   Has single argument `round_number`. \n",
-     "                   Returns threshold value above which collaborators are allowed to participate in aggregation.\n",
-     "               metric_name(str): name of the metric to trace. Can be either 'acc' or 'loss'.\n",
-     "               tags(Tuple[str]): tags of the metric tensor.\n",
-     "        \"\"\"\n",
-     "        self.metric_name = metric_name\n",
-     "        self.threshold_fn = threshold_fn\n",
-     "        self.tags = tags\n",
-     "        self.logged_round = -1\n",
-     "        \n",
-     "    def call(self,\n",
-     "             local_tensors,\n",
-     "             db_iterator,\n",
-     "             tensor_name,\n",
-     "             fl_round,\n",
-     "             *__):\n",
-     "        \"\"\"Aggregate tensors.\n",
-     "\n",
-     "        Args:\n",
-     "            local_tensors(list[openfl.utilities.LocalTensor]): List of local tensors to aggregate.\n",
-     "            db_iterator: iterator over history of all tensors. Columns:\n",
-     "                - 'tensor_name': name of the tensor.\n",
-     "                    Examples for `torch.nn.Module`s: 'conv1.weight', 'fc2.bias'.\n",
-     "                - 'round': 0-based number of round corresponding to this tensor.\n",
-     "                - 'tags': tuple of tensor tags. Tags that can appear:\n",
-     "                    - 'model' indicates that the tensor is a model parameter.\n",
-     "                    - 'trained' indicates that tensor is a part of a training result.\n",
-     "                        These tensors are passed to the aggregator node after local learning.\n",
-     "                    - 'aggregated' indicates that tensor is a result of aggregation.\n",
-     "                        These tensors are sent to collaborators for the next round.\n",
-     "                    - 'delta' indicates that value is a difference between rounds\n",
-     "                        for a specific tensor.\n",
-     "                    also one of the tags is a collaborator name\n",
-     "                    if it corresponds to a result of a local task.\n",
-     "\n",
-     "                - 'nparray': value of the tensor.\n",
-     "            tensor_name: name of the tensor\n",
-     "            fl_round: round number\n",
-     "            tags: tuple of tags for this tensor\n",
-     "        Returns:\n",
-     "            np.ndarray: aggregated tensor\n",
-     "        \"\"\"\n",
-     "        selected_tensors = []\n",
-     "        selected_weights = []\n",
-     "        for record in db_iterator:\n",
-     "            for local_tensor in local_tensors:\n",
-     "                tags = set(self.tags + [local_tensor.col_name])\n",
-     "                if (\n",
-     "                    tags <= set(record['tags']) \n",
-     "                    and record['round'] == fl_round\n",
-     "                    and record['tensor_name'] == self.metric_name\n",
-     "                    and record['nparray'] >= self.threshold_fn(fl_round)\n",
-     "                ):\n",
-     "                    selected_tensors.append(local_tensor.tensor)\n",
-     "                    selected_weights.append(local_tensor.weight)\n",
-     "        if not selected_tensors:\n",
-     "            if self.logged_round < fl_round:\n",
-     "                fx.logger.warning('No collaborators match threshold condition. Performing simple averaging...')\n",
-     "            selected_tensors = [local_tensor.tensor for local_tensor in local_tensors]\n",
-     "            selected_weights = [local_tensor.weight for local_tensor in local_tensors]\n",
-     "        if self.logged_round < fl_round:\n",
-     "            self.logged_round += 1\n",
-     "        return np.average(selected_tensors, weights=selected_weights, axis=0)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Run experiment, return trained FederatedModel\n",
-     "final_fl_model = fx.run_experiment(collaborators,\n",
-     "                                   {\n",
-     "                                       'aggregator.settings.rounds_to_train':5,\n",
-     "                                       'aggregator.settings.db_store_rounds':5,\n",
-     "                                       'tasks.train.aggregation_type': ConditionalThresholdAveraging(lambda round_num: 0.85 + 0.03 * round_num)\n",
-     "                                   })"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Save final model\n",
-     "final_fl_model.save_native('final_pytorch_model')"
-    ]
-   }
-  ],
-  "metadata": {
-   "kernelspec": {
-    "display_name": "Python 3",
-    "language": "python",
-    "name": "python3"
-   },
-   "language_info": {
-    "codemirror_mode": {
-     "name": "ipython",
-     "version": 3
-    },
-    "file_extension": ".py",
-    "mimetype": "text/x-python",
-    "name": "python",
-    "nbconvert_exporter": "python",
-    "pygments_lexer": "ipython3",
-    "version": "3.8.12"
-   }
-  },
-  "nbformat": 4,
-  "nbformat_minor": 4
- }
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/Federated_Pytorch_MNIST_Tutorial.ipynb ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/Federated_Pytorch_MNIST_Tutorial.ipynb
*** ./openfl/openfl-tutorials/Federated_Pytorch_MNIST_Tutorial.ipynb	2022-11-18 11:06:29.735187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/Federated_Pytorch_MNIST_Tutorial.ipynb	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,271 ****
- {
-  "cells": [
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "# Federated PyTorch MNIST Tutorial"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Install dependencies if not already installed\n",
-     "!pip install torch torchvision"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import numpy as np\n",
-     "import torch\n",
-     "import torch.nn as nn\n",
-     "import torch.nn.functional as F\n",
-     "import torch.optim as optim\n",
-     "\n",
-     "import torchvision\n",
-     "import torchvision.transforms as transforms\n",
-     "import openfl.native as fx\n",
-     "from openfl.federated import FederatedModel,FederatedDataSet\n"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "After importing the required packages, the next step is setting up our openfl workspace. To do this, simply run the `fx.init()` command as follows:"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Setup default workspace, logging, etc.\n",
-     "fx.init('torch_cnn_mnist', log_level='METRIC', log_file='./spam_metric.log')"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "Now we are ready to define our dataset and model to perform federated learning on. The dataset should be composed of a numpy arrayWe start with a simple fully connected model that is trained on the MNIST dataset. "
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "def one_hot(labels, classes):\n",
-     "    return np.eye(classes)[labels]\n",
-     "\n",
-     "transform = transforms.Compose(\n",
-     "    [transforms.ToTensor(),\n",
-     "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
-     "\n",
-     "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
-     "                                        download=True, transform=transform)\n",
-     "\n",
-     "train_images,train_labels = trainset.train_data, np.array(trainset.train_labels)\n",
-     "train_images = torch.from_numpy(np.expand_dims(train_images, axis=1)).float()\n",
-     "\n",
-     "validset = torchvision.datasets.MNIST(root='./data', train=False,\n",
-     "                                       download=True, transform=transform)\n",
-     "\n",
-     "valid_images,valid_labels = validset.test_data, np.array(validset.test_labels)\n",
-     "valid_images = torch.from_numpy(np.expand_dims(valid_images, axis=1)).float()\n",
-     "valid_labels = one_hot(valid_labels,10)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "feature_shape = train_images.shape[1]\n",
-     "classes       = 10\n",
-     "\n",
-     "fl_data = FederatedDataSet(train_images,train_labels,valid_images,valid_labels,batch_size=32,num_classes=classes)\n",
-     "\n",
-     "class Net(nn.Module):\n",
-     "    def __init__(self):\n",
-     "        super(Net, self).__init__()\n",
-     "        self.conv1 = nn.Conv2d(1, 16, 3)\n",
-     "        self.pool = nn.MaxPool2d(2, 2)\n",
-     "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
-     "        self.fc1 = nn.Linear(32 * 5 * 5, 32)\n",
-     "        self.fc2 = nn.Linear(32, 84)\n",
-     "        self.fc3 = nn.Linear(84, 10)\n",
-     "\n",
-     "    def forward(self, x):\n",
-     "        x = self.pool(F.relu(self.conv1(x)))\n",
-     "        x = self.pool(F.relu(self.conv2(x)))\n",
-     "        x = x.view(x.size(0),-1)\n",
-     "        x = F.relu(self.fc1(x))\n",
-     "        x = F.relu(self.fc2(x))\n",
-     "        x = self.fc3(x)\n",
-     "        return F.log_softmax(x, dim=1)\n",
-     "    \n",
-     "optimizer = lambda x: optim.Adam(x, lr=1e-4)\n",
-     "\n",
-     "def cross_entropy(output, target):\n",
-     "    \"\"\"Binary cross-entropy metric\n",
-     "    \"\"\"\n",
-     "    return F.cross_entropy(input=output,target=target)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "Here we can define metric logging function. It should has the following signature described below. You can use it to write metrics to tensorboard or some another specific logging."
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from torch.utils.tensorboard import SummaryWriter\n",
-     "\n",
-     "writer = SummaryWriter('./logs/cnn_mnist', flush_secs=5)\n",
-     "\n",
-     "\n",
-     "def write_metric(node_name, task_name, metric_name, metric, round_number):\n",
-     "    writer.add_scalar(\"{}/{}/{}\".format(node_name, task_name, metric_name),\n",
-     "                      metric, round_number)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "\n",
-     "#Create a federated model using the pytorch class, lambda optimizer function, and loss function\n",
-     "fl_model = FederatedModel(build_model=Net,optimizer=optimizer,loss_fn=cross_entropy,data_loader=fl_data)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "The `FederatedModel` object is a wrapper around your Keras, Tensorflow or PyTorch model that makes it compatible with openfl. It provides built in federated training and validation functions that we will see used below. Using it's `setup` function, collaborator models and datasets can be automatically defined for the experiment. "
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "collaborator_models = fl_model.setup(num_collaborators=2)\n",
-     "collaborators = {'one':collaborator_models[0],'two':collaborator_models[1]}#, 'three':collaborator_models[2]}"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Original MNIST dataset\n",
-     "print(f'Original training data size: {len(train_images)}')\n",
-     "print(f'Original validation data size: {len(valid_images)}\\n')\n",
-     "\n",
-     "#Collaborator one's data\n",
-     "print(f'Collaborator one\\'s training data size: {len(collaborator_models[0].data_loader.X_train)}')\n",
-     "print(f'Collaborator one\\'s validation data size: {len(collaborator_models[0].data_loader.X_valid)}\\n')\n",
-     "\n",
-     "#Collaborator two's data\n",
-     "print(f'Collaborator two\\'s training data size: {len(collaborator_models[1].data_loader.X_train)}')\n",
-     "print(f'Collaborator two\\'s validation data size: {len(collaborator_models[1].data_loader.X_valid)}\\n')\n",
-     "\n",
-     "#Collaborator three's data\n",
-     "#print(f'Collaborator three\\'s training data size: {len(collaborator_models[2].data_loader.X_train)}')\n",
-     "#print(f'Collaborator three\\'s validation data size: {len(collaborator_models[2].data_loader.X_valid)}')"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "We can see the current plan values by running the `fx.get_plan()` function"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     " #Get the current values of the plan. Each of these can be overridden\n",
-     "print(fx.get_plan())"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "Now we are ready to run our experiment. If we want to pass in custom plan settings, we can easily do that with the `override_config` parameter"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Run experiment, return trained FederatedModel\n",
-     "\n",
-     "final_fl_model = fx.run_experiment(collaborators, override_config={\n",
-     "    'aggregator.settings.rounds_to_train': 5,\n",
-     "    'aggregator.settings.log_metric_callback': write_metric,\n",
-     "})"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Save final model\n",
-     "final_fl_model.save_native('final_pytorch_model')"
-    ]
-   }
-  ],
-  "metadata": {
-   "kernelspec": {
-    "display_name": "Python 3",
-    "language": "python",
-    "name": "python3"
-   },
-   "language_info": {
-    "codemirror_mode": {
-     "name": "ipython",
-     "version": 3
-    },
-    "file_extension": ".py",
-    "mimetype": "text/x-python",
-    "name": "python",
-    "nbconvert_exporter": "python",
-    "pygments_lexer": "ipython3",
-    "version": "3.8.1"
-   }
-  },
-  "nbformat": 4,
-  "nbformat_minor": 4
- }
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/Federated_PyTorch_TinyImageNet.ipynb ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/Federated_PyTorch_TinyImageNet.ipynb
*** ./openfl/openfl-tutorials/Federated_PyTorch_TinyImageNet.ipynb	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/Federated_PyTorch_TinyImageNet.ipynb	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,378 ****
- {
-  "cells": [
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "# Federated PyTorch TinyImageNet Tutorial"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "This notebook is an example of Transfer Learning \n",
-     "\n",
-     "Custom DataLoader is used with OpenFL Python API"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Install dependencies if not already installed\n",
-     "!pip install torch torchvision\n",
-     "%load_ext autoreload\n",
-     "%autoreload 2"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import os\n",
-     "import glob\n",
-     "from torch.utils.data import Dataset, DataLoader\n",
-     "from PIL import Image\n",
-     "\n",
-     "import numpy as np\n",
-     "import torch\n",
-     "import torch.nn as nn\n",
-     "import torch.nn.functional as F\n",
-     "import torch.optim as optim\n",
-     "\n",
-     "import torchvision\n",
-     "from torchvision import transforms as T\n",
-     "\n",
-     "import openfl.native as fx\n",
-     "from openfl.federated import FederatedModel, FederatedDataSet"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "After importing the required packages, the next step is setting up our openfl workspace. To do this, simply run the `fx.init()` command as follows:"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Setup default workspace, logging, etc.\n",
-     "fx.init('torch_cnn_mnist')"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "Now we are ready to define our dataset and model to perform federated learning on. The dataset should be composed of a numpy arrayWe start with a simple fully connected model that is trained on the MNIST dataset. "
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "#### Download the data"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "!wget --no-clobber http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
-     "!unzip -n tiny-imagenet-200.zip\n",
-     "TINY_IMAGENET_ROOT = './tiny-imagenet-200/'"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "#### Describe the dataset"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "class TinyImageNet(Dataset):\n",
-     "    \"\"\"\n",
-     "    Contains 200 classes for training. Each class has 500 images. \n",
-     "    Parameters\n",
-     "    ----------\n",
-     "    root: string\n",
-     "        Root directory including `train` and `val` subdirectories.\n",
-     "    split: string\n",
-     "        Indicating which split to return as a data set.\n",
-     "        Valid option: [`train`, `val`]\n",
-     "    transform: torchvision.transforms\n",
-     "        A (series) of valid transformation(s).\n",
-     "    \"\"\"\n",
-     "    def __init__(self, root, split='train', transform=None, target_transform=None):\n",
-     "        NUM_IMAGES_PER_CLASS = 500\n",
-     "        self.root = os.path.expanduser(root)\n",
-     "        self.transform = transform\n",
-     "        self.target_transform = target_transform\n",
-     "        self.split_dir = os.path.join(self.root, split)\n",
-     "        self.image_paths = sorted(glob.iglob(os.path.join(self.split_dir, '**', '*.JPEG'), recursive=True))\n",
-     "        \n",
-     "        self.labels = {}  # fname - label number mapping\n",
-     "\n",
-     "        # build class label - number mapping\n",
-     "        with open(os.path.join(self.root, 'wnids.txt'), 'r') as fp:\n",
-     "            self.label_texts = sorted([text.strip() for text in fp.readlines()])\n",
-     "        self.label_text_to_number = {text: i for i, text in enumerate(self.label_texts)}\n",
-     "\n",
-     "        if split == 'train':\n",
-     "            for label_text, i in self.label_text_to_number.items():\n",
-     "                for cnt in range(NUM_IMAGES_PER_CLASS):\n",
-     "                    self.labels[f'{label_text}_{cnt}.JPEG'] = i\n",
-     "        elif split == 'val':\n",
-     "            with open(os.path.join(self.split_dir, 'val_annotations.txt'), 'r') as fp:\n",
-     "                for line in fp.readlines():\n",
-     "                    terms = line.split('\\t')\n",
-     "                    file_name, label_text = terms[0], terms[1]\n",
-     "                    self.labels[file_name] = self.label_text_to_number[label_text]\n",
-     "                    \n",
-     "    \n",
-     "    def __len__(self):\n",
-     "        return len(self.image_paths)\n",
-     "\n",
-     "    def __getitem__(self, index):\n",
-     "        file_path = self.image_paths[index]\n",
-     "        label = self.labels[os.path.basename(file_path)]\n",
-     "        label = self.target_transform(label) if self.target_transform else label\n",
-     "        return self.read_image(file_path), label\n",
-     "\n",
-     "    def read_image(self, path):\n",
-     "        img = Image.open(path)\n",
-     "        return self.transform(img) if self.transform else img\n",
-     "\n",
-     "def one_hot(labels, classes):\n",
-     "    return np.eye(classes)[labels]"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "normalize = T.Normalize(mean=[0.485, 0.456, 0.406],\n",
-     "                                 std=[0.229, 0.224, 0.225])\n",
-     "\n",
-     "augmentation = T.RandomApply([\n",
-     "    T.RandomHorizontalFlip(),\n",
-     "    T.RandomRotation(10),\n",
-     "    T.RandomResizedCrop(64)], p=.8)\n",
-     "\n",
-     "training_transform = T.Compose([\n",
-     "    T.Lambda(lambda x: x.convert(\"RGB\")),\n",
-     "    augmentation,\n",
-     "    T.ToTensor(),\n",
-     "    normalize])\n",
-     "\n",
-     "valid_transform = T.Compose([\n",
-     "    T.Lambda(lambda x: x.convert(\"RGB\")),\n",
-     "    T.ToTensor(),\n",
-     "    normalize])"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "#### Implement Federated dataset\n",
-     "We have to implement `split` method"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from openfl.utilities.data_splitters import EqualNumPyDataSplitter\n",
-     "from torch.utils.data import Subset\n",
-     "\n",
-     "\n",
-     "train_set = TinyImageNet(TINY_IMAGENET_ROOT, 'train', transform=training_transform)\n",
-     "valid_set = TinyImageNet(TINY_IMAGENET_ROOT, 'val', transform=valid_transform, \\\n",
-     "                                      target_transform=lambda target: one_hot(target, 200))\n",
-     "\n",
-     "class TinyImageNetFederatedDataset(DataLoader):\n",
-     "    def __init__(self, train_set, valid_set, batch_size):\n",
-     "        self.data_splitter = EqualNumPyDataSplitter()\n",
-     "        self.train_set = train_set\n",
-     "        self.valid_set = valid_set\n",
-     "        self.batch_size = batch_size\n",
-     "    \n",
-     "    def split(self, num_collaborators):\n",
-     "        train_split = self.data_splitter.split([label for _, label in self.train_set], num_collaborators)\n",
-     "        valid_split = self.data_splitter.split([label for _, label in self.valid_set], num_collaborators)\n",
-     "        return [\n",
-     "            TinyImageNetFederatedDataset(\n",
-     "                Subset(self.train_set, train_split[i]),\n",
-     "                Subset(self.valid_set, valid_split[i]),\n",
-     "                self.batch_size\n",
-     "            )\n",
-     "            for i in range(num_collaborators)\n",
-     "        ]\n",
-     "    \n",
-     "    def get_feature_shape(self):\n",
-     "        return self.train_set[0][0].shape\n",
-     "    \n",
-     "    def get_train_loader(self, num_batches):\n",
-     "        return DataLoader(self.train_set, batch_size=self.batch_size)\n",
-     "    \n",
-     "    def get_valid_loader(self):\n",
-     "        return DataLoader(self.valid_set)\n",
-     "    \n",
-     "    def get_train_data_size(self):\n",
-     "        return len(self.train_set)\n",
-     "    \n",
-     "    def get_valid_data_size(self):\n",
-     "        return len(self.valid_set)\n",
-     "    \n",
-     "fl_data = TinyImageNetFederatedDataset(train_set, valid_set, batch_size=32)\n",
-     "\n",
-     "num_classes = 200"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "#### Define model"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "class Net(nn.Module):\n",
-     "    def __init__(self):\n",
-     "        super(Net, self).__init__()\n",
-     "        self.model = torchvision.models.mobilenet_v2(pretrained=True)\n",
-     "        self.model.requires_grad_(False)\n",
-     "        self.model.classifier[1] = torch.nn.Linear(in_features=1280, \\\n",
-     "                        out_features=num_classes, bias=True)\n",
-     "\n",
-     "    def forward(self, x):\n",
-     "        x = self.model.forward(x)\n",
-     "        return x\n",
-     "\n",
-     "    \n",
-     "optimizer = lambda x: optim.Adam(x, lr=1e-4)\n",
-     "\n",
-     "def cross_entropy(output, target):\n",
-     "    \"\"\"Binary cross-entropy metric\n",
-     "    \"\"\"\n",
-     "    return F.cross_entropy(input=output,target=target)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Create a federated model using the pytorch class, lambda optimizer function, and loss function\n",
-     "fl_model = FederatedModel(build_model=Net,optimizer=optimizer,loss_fn=cross_entropy, \\\n",
-     "                        data_loader=fl_data)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "The `FederatedModel` object is a wrapper around your Keras, Tensorflow or PyTorch model that makes it compatible with openfl. It provides built in federated training and validation functions that we will see used below. Using it's `setup` function, collaborator models and datasets can be automatically defined for the experiment. "
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "collaborator_models = fl_model.setup(num_collaborators=10)\n",
-     "collaborators = {'one':collaborator_models[0],'two':collaborator_models[1]}#, 'three':collaborator_models[2]}"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Original TinyImageNet dataset\n",
-     "print(f'Original training data size: {len(fl_data.train_set)}')\n",
-     "print(f'Original validation data size: {len(fl_data.valid_set)}\\n')\n",
-     "\n",
-     "#Collaborator one's data\n",
-     "for i, model in enumerate(collaborator_models):\n",
-     "    print(f'Collaborator {i}\\'s training data size: {len(model.data_loader.train_set)}')\n",
-     "    print(f'Collaborator {i}\\'s validation data size: {len(model.data_loader.valid_set)}\\n')\n",
-     "\n",
-     "#Collaborator three's data\n",
-     "#print(f'Collaborator three\\'s training data size: {len(collaborator_models[2].data_loader.X_train)}')\n",
-     "#print(f'Collaborator three\\'s validation data size: {len(collaborator_models[2].data_loader.X_valid)}')"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Run experiment, return trained FederatedModel\n",
-     "final_fl_model = fx.run_experiment(collaborators,{'aggregator.settings.rounds_to_train':10})"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "#Save final model\n",
-     "final_fl_model.save_native('final_model.pth')"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": []
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": []
-   }
-  ],
-  "metadata": {
-   "language_info": {
-    "name": "python"
-   }
-  },
-  "nbformat": 4,
-  "nbformat_minor": 4
- }
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/Federated_PyTorch_UNET_Tutorial.ipynb ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/Federated_PyTorch_UNET_Tutorial.ipynb
*** ./openfl/openfl-tutorials/Federated_PyTorch_UNET_Tutorial.ipynb	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/Federated_PyTorch_UNET_Tutorial.ipynb	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,534 ****
- {
-  "cells": [
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "# Federated PyTorch UNET Tutorial"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Install dependencies if not already installed\n",
-     "!pip install torch"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "First of all we need to set up our OpenFL workspace. To do this, simply run the `fx.init()` command as follows:"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import openfl.native as fx\n",
-     "\n",
-     "# Setup default workspace, logging, etc. Install additional requirements\n",
-     "fx.init('torch_unet_kvasir')"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Import installed modules\n",
-     "import PIL\n",
-     "import json\n",
-     "import torch\n",
-     "import torch.nn as nn\n",
-     "import torch.nn.functional as F\n",
-     "import torch.optim as optim\n",
-     "import numpy as np\n",
-     "from skimage import io\n",
-     "from torchvision import transforms as tsf\n",
-     "import matplotlib.pyplot as plt\n",
-     "from torch.utils.data import Dataset, DataLoader\n",
-     "\n",
-     "from os import listdir\n",
-     "\n",
-     "from openfl.federated import FederatedModel, FederatedDataSet\n",
-     "from openfl.utilities import TensorKey\n",
-     "from openfl.utilities import validate_file_hash"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "Download Kvasir dataset"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "!wget 'https://datasets.simula.no/downloads/hyper-kvasir/hyper-kvasir-segmented-images.zip' -O kvasir.zip\n",
-     "ZIP_SHA384 = 'e30d18a772c6520476e55b610a4db457237f151e'\\\n",
-     "    '19182849d54b49ae24699881c1e18e0961f77642be900450ef8b22e7'\n",
-     "validate_file_hash('./kvasir.zip', ZIP_SHA384)\n",
-     "!unzip -n kvasir.zip -d ./data"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "Now we are ready to define our dataset and model to perform federated learning on."
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "DATA_PATH = './data/segmented-images/'"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "def read_data(image_path, mask_path):\n",
-     "    \"\"\"\n",
-     "    Read image and mask from disk.\n",
-     "    \"\"\"\n",
-     "    img = io.imread(image_path)\n",
-     "    assert(img.shape[2] == 3)\n",
-     "    mask = io.imread(mask_path)\n",
-     "    return (img, mask[:, :, 0].astype(np.uint8))\n",
-     "\n",
-     "\n",
-     "class KvasirDataset(Dataset):\n",
-     "    \"\"\"\n",
-     "    Kvasir dataset contains 1000 images for all collaborators.\n",
-     "    Args:\n",
-     "        data_path: path to dataset on disk\n",
-     "        collaborator_count: total number of collaborators\n",
-     "        collaborator_num: number of current collaborator\n",
-     "        is_validation: validation option\n",
-     "    \"\"\"\n",
-     "\n",
-     "    def __init__(self, data_path, collaborator_count, collaborator_num, is_validation):\n",
-     "        self.images_path = './data/segmented-images/images/'\n",
-     "        self.masks_path = './data/segmented-images/masks/'\n",
-     "        self.images_names = [\n",
-     "            img_name\n",
-     "            for img_name in sorted(listdir(self.images_path))\n",
-     "            if len(img_name) > 3 and img_name[-3:] == 'jpg'\n",
-     "        ]\n",
-     "\n",
-     "        self.images_names = self.images_names[collaborator_num:: collaborator_count]\n",
-     "        self.is_validation = is_validation\n",
-     "        assert(len(self.images_names) > 8)\n",
-     "        validation_size = len(self.images_names) // 8\n",
-     "        if is_validation:\n",
-     "            self.images_names = self.images_names[-validation_size:]\n",
-     "        else:\n",
-     "            self.images_names = self.images_names[: -validation_size]\n",
-     "\n",
-     "        self.img_trans = tsf.Compose([\n",
-     "            tsf.ToPILImage(),\n",
-     "            tsf.Resize((332, 332)),\n",
-     "            tsf.ToTensor(),\n",
-     "            tsf.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
-     "        self.mask_trans = tsf.Compose([\n",
-     "            tsf.ToPILImage(),\n",
-     "            tsf.Resize((332, 332), interpolation=PIL.Image.NEAREST),\n",
-     "            tsf.ToTensor()])\n",
-     "\n",
-     "    def __getitem__(self, index):\n",
-     "        name = self.images_names[index]\n",
-     "        img, mask = read_data(self.images_path + name, self.masks_path + name)\n",
-     "        img = self.img_trans(img).numpy()\n",
-     "        mask = self.mask_trans(mask).numpy()\n",
-     "        return img, mask\n",
-     "\n",
-     "    def __len__(self):\n",
-     "        return len(self.images_names)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "Here we redefine `FederatedDataSet` methods, if we don't want to use default batch generator from `FederatedDataSet`. "
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "class KvasirFederatedDataset(FederatedDataSet):\n",
-     "    def __init__(self, collaborator_count=1, collaborator_num=0, batch_size=1, **kwargs):\n",
-     "        \"\"\"Instantiate the data object\n",
-     "        Args:\n",
-     "            collaborator_count: total number of collaborators\n",
-     "            collaborator_num: number of current collaborator\n",
-     "            batch_size:  the batch size of the data loader\n",
-     "            **kwargs: additional arguments, passed to super init\n",
-     "        \"\"\"\n",
-     "        super().__init__([], [], [], [], batch_size, num_classes=2, **kwargs)\n",
-     "\n",
-     "        self.collaborator_num = int(collaborator_num)\n",
-     "\n",
-     "        self.batch_size = batch_size\n",
-     "\n",
-     "        self.training_set = KvasirDataset(\n",
-     "            DATA_PATH, collaborator_count, collaborator_num, is_validation=False\n",
-     "        )\n",
-     "        self.valid_set = KvasirDataset(\n",
-     "            DATA_PATH, collaborator_count, collaborator_num, is_validation=True\n",
-     "        )\n",
-     "\n",
-     "        self.train_loader = self.get_train_loader()\n",
-     "        self.val_loader = self.get_valid_loader()\n",
-     "\n",
-     "    def get_valid_loader(self, num_batches=None):\n",
-     "        return DataLoader(self.valid_set, num_workers=8, batch_size=self.batch_size)\n",
-     "\n",
-     "    def get_train_loader(self, num_batches=None):\n",
-     "        return DataLoader(\n",
-     "            self.training_set, num_workers=8, batch_size=self.batch_size, shuffle=True\n",
-     "        )\n",
-     "\n",
-     "    def get_train_data_size(self):\n",
-     "        return len(self.training_set)\n",
-     "\n",
-     "    def get_valid_data_size(self):\n",
-     "        return len(self.valid_set)\n",
-     "\n",
-     "    def get_feature_shape(self):\n",
-     "        return self.valid_set[0][0].shape\n",
-     "\n",
-     "    def split(self, collaborator_count, shuffle=True, equally=True):\n",
-     "        return [\n",
-     "            KvasirFederatedDataset(collaborator_count,\n",
-     "                           collaborator_num, self.batch_size)\n",
-     "            for collaborator_num in range(collaborator_count)\n",
-     "        ]"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "Our Unet model"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "def soft_dice_loss(output, target):\n",
-     "    num = target.size(0)\n",
-     "    m1 = output.view(num, -1)\n",
-     "    m2 = target.view(num, -1)\n",
-     "    intersection = m1 * m2\n",
-     "    score = 2.0 * (intersection.sum(1) + 1) / (m1.sum(1) + m2.sum(1) + 1)\n",
-     "    score = 1 - score.sum() / num\n",
-     "    return score\n",
-     "\n",
-     "\n",
-     "def soft_dice_coef(output, target):\n",
-     "    num = target.size(0)\n",
-     "    m1 = output.view(num, -1)\n",
-     "    m2 = target.view(num, -1)\n",
-     "    intersection = m1 * m2\n",
-     "    score = 2.0 * (intersection.sum(1) + 1) / (m1.sum(1) + m2.sum(1) + 1)\n",
-     "    return score.sum()\n",
-     "\n",
-     "\n",
-     "class DoubleConv(nn.Module):\n",
-     "    def __init__(self, in_ch, out_ch):\n",
-     "        super(DoubleConv, self).__init__()\n",
-     "        self.in_ch = in_ch\n",
-     "        self.out_ch = out_ch\n",
-     "        self.conv = nn.Sequential(\n",
-     "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
-     "            nn.BatchNorm2d(out_ch),\n",
-     "            nn.ReLU(inplace=True),\n",
-     "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
-     "            nn.BatchNorm2d(out_ch),\n",
-     "            nn.ReLU(inplace=True),\n",
-     "        )\n",
-     "\n",
-     "    def forward(self, x):\n",
-     "        x = self.conv(x)\n",
-     "        return x\n",
-     "\n",
-     "\n",
-     "class Down(nn.Module):\n",
-     "    def __init__(self, in_ch, out_ch):\n",
-     "        super(Down, self).__init__()\n",
-     "        self.mpconv = nn.Sequential(\n",
-     "            nn.MaxPool2d(2),\n",
-     "            DoubleConv(in_ch, out_ch)\n",
-     "        )\n",
-     "\n",
-     "    def forward(self, x):\n",
-     "        x = self.mpconv(x)\n",
-     "        return x\n",
-     "\n",
-     "\n",
-     "class Up(nn.Module):\n",
-     "    def __init__(self, in_ch, out_ch, bilinear=False):\n",
-     "        super(Up, self).__init__()\n",
-     "        self.in_ch = in_ch\n",
-     "        self.out_ch = out_ch\n",
-     "        if bilinear:\n",
-     "            self.Up = nn.Upsample(\n",
-     "                scale_factor=2,\n",
-     "                mode=\"bilinear\",\n",
-     "                align_corners=True\n",
-     "            )\n",
-     "        else:\n",
-     "            self.Up = nn.ConvTranspose2d(in_ch, in_ch // 2, 2, stride=2)\n",
-     "        self.conv = DoubleConv(in_ch, out_ch)\n",
-     "\n",
-     "    def forward(self, x1, x2):\n",
-     "        x1 = self.Up(x1)\n",
-     "        diffY = x2.size()[2] - x1.size()[2]\n",
-     "        diffX = x2.size()[3] - x1.size()[3]\n",
-     "\n",
-     "        x1 = F.pad(x1, (diffX // 2, diffX - diffX //\n",
-     "                        2, diffY // 2, diffY - diffY // 2))\n",
-     "\n",
-     "        x = torch.cat([x2, x1], dim=1)\n",
-     "        x = self.conv(x)\n",
-     "        return x\n",
-     "\n",
-     "\n",
-     "class UNet(nn.Module):\n",
-     "    def __init__(self, n_channels=3, n_classes=1):\n",
-     "        super().__init__()\n",
-     "        self.inc = DoubleConv(n_channels, 64)\n",
-     "        self.down1 = Down(64, 128)\n",
-     "        self.down2 = Down(128, 256)\n",
-     "        self.down3 = Down(256, 512)\n",
-     "        self.down4 = Down(512, 1024)\n",
-     "        self.up1 = Up(1024, 512)\n",
-     "        self.up2 = Up(512, 256)\n",
-     "        self.up3 = Up(256, 128)\n",
-     "        self.up4 = Up(128, 64)\n",
-     "        self.outc = nn.Conv2d(64, n_classes, 1)\n",
-     "\n",
-     "    def forward(self, x):\n",
-     "        x1 = self.inc(x)\n",
-     "        x2 = self.down1(x1)\n",
-     "        x3 = self.down2(x2)\n",
-     "        x4 = self.down3(x3)\n",
-     "        x5 = self.down4(x4)\n",
-     "        x = self.up1(x5, x4)\n",
-     "        x = self.up2(x, x3)\n",
-     "        x = self.up3(x, x2)\n",
-     "        x = self.up4(x, x1)\n",
-     "        x = self.outc(x)\n",
-     "        x = torch.sigmoid(x)\n",
-     "        return x\n",
-     "\n",
-     "    def validate(\n",
-     "        self, col_name, round_num, input_tensor_dict, use_tqdm=False, **kwargs\n",
-     "    ):\n",
-     "        \"\"\" Validate. Redifine function from PyTorchTaskRunner, to use our validation\"\"\"\n",
-     "        self.rebuild_model(round_num, input_tensor_dict, validation=True)\n",
-     "        self.eval()\n",
-     "        self.to(self.device)\n",
-     "        val_score = 0\n",
-     "        total_samples = 0\n",
-     "\n",
-     "        loader = self.data_loader.get_valid_loader()\n",
-     "        if use_tqdm:\n",
-     "            loader = tqdm.tqdm(loader, desc=\"validate\")\n",
-     "\n",
-     "        with torch.no_grad():\n",
-     "            for data, target in loader:\n",
-     "                samples = target.shape[0]\n",
-     "                total_samples += samples\n",
-     "                data, target = (\n",
-     "                    torch.tensor(data).to(self.device),\n",
-     "                    torch.tensor(target).to(self.device),\n",
-     "                )\n",
-     "                output = self(data)\n",
-     "                # get the index of the max log-probability\n",
-     "                val = soft_dice_coef(output, target)\n",
-     "                val_score += val.sum().cpu().numpy()\n",
-     "\n",
-     "        origin = col_name\n",
-     "        suffix = \"validate\"\n",
-     "        if kwargs[\"apply\"] == \"local\":\n",
-     "            suffix += \"_local\"\n",
-     "        else:\n",
-     "            suffix += \"_agg\"\n",
-     "        tags = (\"metric\", suffix)\n",
-     "        output_tensor_dict = {\n",
-     "            TensorKey(\"dice_coef\", origin, round_num, True, tags): np.array(\n",
-     "                val_score / total_samples\n",
-     "            )\n",
-     "        }\n",
-     "        return output_tensor_dict, {}\n",
-     "\n",
-     "\n",
-     "def optimizer(x): return optim.Adam(x, lr=1e-3)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "Create `KvasirFederatedDataset`, federated datasets for collaborators will be created in `split()` method of this object"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "fl_data = KvasirFederatedDataset(batch_size=6)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "The `FederatedModel` object is a wrapper around your Keras, Tensorflow or PyTorch model that makes it compatible with OpenFL. It provides built-in federated training function which will be used while training. Using its `setup` function, collaborator models and datasets can be automatically obtained for the experiment. "
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Create a federated model using the pytorch class, optimizer function, and loss function\n",
-     "fl_model = FederatedModel(build_model=UNet, optimizer=optimizer,\n",
-     "                          loss_fn=soft_dice_loss, data_loader=fl_data)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "collaborator_models = fl_model.setup(num_collaborators=2)\n",
-     "collaborators = {'one': collaborator_models[0], 'two': collaborator_models[1]}"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "We can see the current FL plan values by running the `fx.get_plan()` function"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Get the current values of the FL plan. Each of these can be overridden\n",
-     "print(fx.get_plan())"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "Now we are ready to run our experiment. If we want to pass in custom FL plan settings, we can easily do that with the `override_config` parameter"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Run experiment, return trained FederatedModel\n",
-     "final_fl_model = fx.run_experiment(\n",
-     "    collaborators, override_config={'aggregator.settings.rounds_to_train': 30})"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Save final model\n",
-     "final_fl_model.save_native('final_pytorch_model')"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "Let's visually evaluate the results"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "collaborator = collaborator_models[0]\n",
-     "loader = collaborator.runner.data_loader.get_valid_loader()\n",
-     "model = final_fl_model.model\n",
-     "model.eval()\n",
-     "device = final_fl_model.runner.device\n",
-     "model.to(device)\n",
-     "with torch.no_grad():\n",
-     "    for batch, _ in zip(loader, range(5)):\n",
-     "        preds = model(batch[0].to(device))\n",
-     "        for image, pred, target in zip(batch[0], preds, batch[1]):\n",
-     "            plt.figure(figsize=(10, 10))\n",
-     "            plt.subplot(131)\n",
-     "            plt.imshow(image.permute(1, 2, 0).data.cpu().numpy() * 0.5 + 0.5)\n",
-     "            plt.title(\"img\")\n",
-     "            plt.subplot(132)\n",
-     "            plt.imshow(pred[0].data.cpu().numpy())\n",
-     "            plt.title(\"pred\")\n",
-     "            plt.subplot(133)\n",
-     "            plt.imshow(target[0].data.cpu().numpy())\n",
-     "            plt.title(\"targ\")\n",
-     "            plt.show()"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": []
-   }
-  ],
-  "metadata": {
-   "language_info": {
-    "name": "python"
-   }
-  },
-  "nbformat": 4,
-  "nbformat_minor": 4
- }
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/MXNet_landmarks/director/director_config.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/MXNet_landmarks/director/director_config.yaml
*** ./openfl/openfl-tutorials/interactive_api/MXNet_landmarks/director/director_config.yaml	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/MXNet_landmarks/director/director_config.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,5 ****
- settings:
-   listen_host: localhost
-   listen_port: 50051
-   sample_shape: ['96', '96']
-   target_shape: ['1']
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/MXNet_landmarks/director/start_director.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/MXNet_landmarks/director/start_director.sh
*** ./openfl/openfl-tutorials/interactive_api/MXNet_landmarks/director/start_director.sh	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/MXNet_landmarks/director/start_director.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- 
- fx director start --disable-tls -c director_config.yaml
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/MXNet_landmarks/envoy/envoy_config_one.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/MXNet_landmarks/envoy/envoy_config_one.yaml
*** ./openfl/openfl-tutorials/interactive_api/MXNet_landmarks/envoy/envoy_config_one.yaml	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/MXNet_landmarks/envoy/envoy_config_one.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,12 ****
- params:
-   cuda_devices: [0]
- 
- optional_plugin_components:
-  cuda_device_monitor:
-    template: openfl.plugins.processing_units_monitor.pynvml_monitor.PynvmlCUDADeviceMonitor
-    settings: []
- 
- shard_descriptor:
-   template: landmark_shard_descriptor.LandmarkShardDescriptor
-   params:
-     rank_worldsize: 1, 2
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/MXNet_landmarks/envoy/envoy_config_two.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/MXNet_landmarks/envoy/envoy_config_two.yaml
*** ./openfl/openfl-tutorials/interactive_api/MXNet_landmarks/envoy/envoy_config_two.yaml	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/MXNet_landmarks/envoy/envoy_config_two.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,12 ****
- params:
-   cuda_devices: [1]
- 
- optional_plugin_components:
-  cuda_device_monitor:
-    template: openfl.plugins.processing_units_monitor.pynvml_monitor.PynvmlCUDADeviceMonitor
-    settings: []
- 
- shard_descriptor:
-   template: landmark_shard_descriptor.LandmarkShardDescriptor
-   params:
-     rank_worldsize: 2, 2
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/MXNet_landmarks/envoy/landmark_shard_descriptor.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/MXNet_landmarks/envoy/landmark_shard_descriptor.py
*** ./openfl/openfl-tutorials/interactive_api/MXNet_landmarks/envoy/landmark_shard_descriptor.py	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/MXNet_landmarks/envoy/landmark_shard_descriptor.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,170 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Landmarks Shard Descriptor."""
- 
- import json
- import shutil
- from hashlib import md5
- from logging import getLogger
- from pathlib import Path
- from random import shuffle
- from typing import Dict
- from typing import List
- from zipfile import ZipFile
- 
- import numpy as np
- import pandas as pd
- from kaggle.api.kaggle_api_extended import KaggleApi
- 
- from openfl.interface.interactive_api.shard_descriptor import ShardDataset
- from openfl.interface.interactive_api.shard_descriptor import ShardDescriptor
- 
- logger = getLogger(__name__)
- 
- 
- class LandmarkShardDataset(ShardDataset):
-     """Landmark Shard dataset class."""
- 
-     def __init__(self, dataset_dir: Path,
-                  rank: int = 1, worldsize: int = 1) -> None:
-         """Initialize LandmarkShardDataset."""
-         self.rank = rank
-         self.worldsize = worldsize
-         self.dataset_dir = dataset_dir
-         self.img_names = list(self.dataset_dir.glob('img_*.npy'))
- 
-         # Sharding
-         self.img_names = self.img_names[self.rank - 1::self.worldsize]
-         # Shuffling the results dataset after choose half pictures of each class
-         shuffle(self.img_names)
- 
-     def __getitem__(self, index) -> np.ndarray:
-         """Return a item by the index."""
-         # Get name key points file
-         # f.e. image name:  'img_123.npy, corresponding name of the key points: 'keypoints_123.npy'
-         kp_name = str(self.img_names[index]).replace('img', 'keypoints')
-         return np.load(self.img_names[index]), np.load(self.dataset_dir / kp_name)
- 
-     def __len__(self) -> int:
-         """Return the len of the dataset."""
-         return len(self.img_names)
- 
- 
- class LandmarkShardDescriptor(ShardDescriptor):
-     """Landmark Shard descriptor class."""
- 
-     def __init__(self, data_folder: str = 'data',
-                  rank_worldsize: str = '1, 1',
-                  **kwargs) -> None:
-         """Initialize LandmarkShardDescriptor."""
-         super().__init__()
-         # Settings for sharding the dataset
-         self.rank, self.worldsize = map(int, rank_worldsize.split(','))
- 
-         self.data_folder = Path.cwd() / data_folder
-         self.download_data()
- 
-         # Calculating data and target shapes
-         ds = self.get_dataset()
-         sample, target = ds[0]
-         self._sample_shape = [str(dim) for dim in sample.shape]
-         self._target_shape = [str(len(target.shape))]
- 
-         if self._target_shape[0] != '1':
-             raise ValueError('Target has a wrong shape')
- 
-     def process_data(self, name_csv_file) -> None:
-         """Process data from csv to numpy format and save it in the same folder."""
-         data_df = pd.read_csv(self.data_folder / name_csv_file)
-         data_df.fillna(method='ffill', inplace=True)
-         keypoints = data_df.drop('Image', axis=1)
-         cur_folder = self.data_folder.relative_to(Path.cwd())
- 
-         for i in range(data_df.shape[0]):
-             img = data_df['Image'][i].split(' ')
-             img = np.array(['0' if x == '' else x for x in img], dtype='float32').reshape(96, 96)
-             np.save(str(cur_folder / f'img_{i}.npy'), img)
-             y = np.array(keypoints.iloc[i, :], dtype='float32')
-             np.save(str(cur_folder / f'keypoints_{i}.npy'), y)
- 
-     def download_data(self) -> None:
-         """Download dataset from Kaggle."""
-         if self.is_dataset_complete():
-             return
- 
-         self.data_folder.mkdir(parents=True, exist_ok=True)
- 
-         logger.info('Your dataset is absent or damaged. Downloading ... ')
-         api = KaggleApi()
-         api.authenticate()
- 
-         if Path('data').exists():
-             shutil.rmtree('data')
- 
-         api.competition_download_file(
-             'facial-keypoints-detection',
-             'training.zip', path=self.data_folder
-         )
- 
-         with ZipFile(self.data_folder / 'training.zip', 'r') as zipobj:
-             zipobj.extractall(self.data_folder)
- 
-         (self.data_folder / 'training.zip').unlink()
- 
-         self.process_data('training.csv')
-         (self.data_folder / 'training.csv').unlink()
-         self.save_all_md5()
- 
-     def get_dataset(self, dataset_type='train') -> LandmarkShardDataset:
-         """Return a shard dataset by type."""
-         return LandmarkShardDataset(
-             dataset_dir=self.data_folder,
-             rank=self.rank,
-             worldsize=self.worldsize
-         )
- 
-     def calc_all_md5(self) -> Dict[str, str]:
-         """Calculate hash of all dataset."""
-         md5_dict = {}
-         for root in self.data_folder.glob('*.npy'):
-             md5_calc = md5()
-             rel_file = root.relative_to(self.data_folder)
- 
-             with open(self.data_folder / rel_file, 'rb') as f:
-                 for chunk in iter(lambda: f.read(4096), b''):
-                     md5_calc.update(chunk)
-                 md5_dict[str(rel_file)] = md5_calc.hexdigest()
-         return md5_dict
- 
-     def save_all_md5(self) -> None:
-         """Save dataset hash."""
-         all_md5 = self.calc_all_md5()
-         with open(self.data_folder / 'dataset.json', 'w') as f:
-             json.dump(all_md5, f)
- 
-     def is_dataset_complete(self) -> bool:
-         """Check dataset integrity."""
-         dataset_md5_path = self.data_folder / 'dataset.json'
-         if dataset_md5_path.exists():
-             with open(dataset_md5_path, 'r') as f:
-                 old_md5 = json.load(f)
-             new_md5 = self.calc_all_md5()
-             return new_md5 == old_md5
-         return False
- 
-     @property
-     def sample_shape(self) -> List[str]:
-         """Return the sample shape info."""
-         return self._sample_shape
- 
-     @property
-     def target_shape(self) -> List[str]:
-         """Return the target shape info."""
-         return self._target_shape
- 
-     @property
-     def dataset_description(self) -> str:
-         """Return the dataset description."""
-         return (f'Dogs and Cats dataset, shard number {self.rank} '
-                 f'out of {self.worldsize}')
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/MXNet_landmarks/envoy/sd_requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/MXNet_landmarks/envoy/sd_requirements.txt
*** ./openfl/openfl-tutorials/interactive_api/MXNet_landmarks/envoy/sd_requirements.txt	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/MXNet_landmarks/envoy/sd_requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- pynvml
- kaggle
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/MXNet_landmarks/envoy/start_envoy.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/MXNet_landmarks/envoy/start_envoy.sh
*** ./openfl/openfl-tutorials/interactive_api/MXNet_landmarks/envoy/start_envoy.sh	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/MXNet_landmarks/envoy/start_envoy.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,6 ****
- #!/bin/bash
- set -e
- ENVOY_NAME=$1
- SHARD_CONF=$2
- 
- fx envoy start -n "$ENVOY_NAME" --disable-tls --envoy-config-path "$SHARD_CONF" -dh localhost -dp 50051
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/MXNet_landmarks/README.md ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/MXNet_landmarks/README.md
*** ./openfl/openfl-tutorials/interactive_api/MXNet_landmarks/README.md	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/MXNet_landmarks/README.md	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,122 ****
- # MXNet Facial Keypoints Detection tutorial
- ---
- **Note:**
- 
- Please pay attention that this task uses the dataset from Kaggle. To get the dataset you
- will need a Kaggle account and accept "Facial Keypoints Detection" [competition rules](https://www.kaggle.com/c/facial-keypoints-detection/rules).
- 
- ---
- 
- This tutorial shows how to use any other framework, different from already supported PyTorch and TensorFlow, together with OpenFl.
- 
- ## Installation of Kaggle API credentials
- 
- **Before the start please make sure that you installed sd_requirements.txt on your virtual
- environment on an envoy machine.**
- 
- To use the [Kaggle API](https://github.com/Kaggle/kaggle-api), sign up for
- a [Kaggle account](https://www.kaggle.com). Then go to the `'Account'` tab of your user
- profile `(https://www.kaggle.com/<username>/account)` and select `'Create API Token'`. This will
- trigger the download of `kaggle.json`, a file containing your API credentials. Place this file in
- the location `~/.kaggle/kaggle.json`
- 
- For your security, ensure that other users of your computer do not have read access to your
- credentials. On Unix-based systems you can do this with the following command:
- 
- `chmod 600 ~/.kaggle/kaggle.json`
- 
- If you need proxy add "proxy": `"http://<ip_addr:port>" in kaggle.json`. It should looks like
- that: `{"username":"your_username","key":"token", "proxy": "ip_addr:port"}`
- 
- *Information about Kaggle API settings has been taken from kagge-api [readme](https://github.com/Kaggle/kaggle-api).*
- 
- *Useful [link](https://github.com/Kaggle/kaggle-api/issues/6) for a problem with proxy settings.*
- 
- ### 1. About dataset
- 
- All information about the dataset you may find
- on [link](https://www.kaggle.com/c/facial-keypoints-detection/data)
- 
- ### 2. Adding support for a third-party framework
- 
- You need to write your own adapter class which is based on `FrameworkAdapterPluginInterface` [class](https://github.com/intel/openfl/blob/develop/openfl/plugins/frameworks_adapters/framework_adapter_interface.py). This class should contain at least two methods:
- 
-  - `get_tensor_dict(model, optimizer=None)` - extracts tensor dict from a model and optionally[^1] an optimizer. The resulting tensors must be converted to **dict{str: numpy.array}** for forwarding and aggregation.
- 
-   - `set_tensor_dict(model, tensor_dict, optimizer=None, device=None)` - sets aggregated numpy arrays into the model or model and optimizer. To do so it gets `tensor_dict` variable as **dict{str: numpy.array}** and should convert it into suitable for your model or model and optimizer tensors. After that, it must load the prepared parameters into the model/model and optimizer. 
- 
-  Your adapter should be placed in workspace directory. When you create `ModelInterface` class object at the `'***.ipunb'`, place the name of your adapter to the input parameter `framework_plugin`. Example: 
-  ```py
-  framework_adapter = 'mxnet_adapter.FrameworkAdapterPlugin'
- 
-  MI = ModelInterface(model=model, optimizer=optimizer,
-                     framework_plugin=framework_adapter)
- ```
- 
- [^1]: Whether or not to forward the optimizer parameters is set in the `start` method (FLExperiment [class](https://github.com/intel/openfl/blob/develop/openfl/interface/interactive_api/experiment.py) object, parameter `opt_treatment`).
- 
- ### Run experiment
- 
- 1. Create a folder for each `envoy`.
- 2. Put a relevant envoy_config in each of the n folders (n - number of envoys which you would like
-    to use, in this tutorial there is two of them, but you may use any number of envoys) and copy
-    other files from `envoy` folder there as well.
- 3. Modify each `envoy` accordingly:
- 
-     - At `start_envoy.sh` change env_one to env_two (or any unique `envoy` names you like)
- 
-     - Put a relevant envoy_config `envoy_config_one.yaml` or `envoy_config_two.yaml` (or any other
-       config file name consistent to the configuration file that is called in `start_envoy.sh`).
- 4. Make sure that you installed requirements for each `envoy` in your virtual
-    environment: `pip install -r sd_requirements.txt`
- 5. Run the `director`: 
-     ```sh
-     cd director_folder
-     ./start_director.sh
-     ```
- 
- 6. Run the `envoys`: 
-     ```sh
-     cd envoy_folder
-     ./start_envoy.sh env_one shard_config_one.yaml
-     ```
-     If kaggle-API setting are
-     correct the download of the dataset will be started. If this is not the first `envoy` launch
-     then the dataset will be redownloaded only if some part of the data are missing.
- 
- 7. Run the [MXNet_landmarks.ipynb](workspace/MXNet_landmarks.ipynb) notebook using
-    Jupyter lab in a prepared virtual environment. For more information about preparation virtual
-    environment look **[
-    Preparation virtual environment](#preparation-virtual-environment)**
-    .
-    
-     * Install [MXNet 1.9.0](https://pypi.org/project/mxnet/1.9.0/) framework with CPU or GPU (preferred) support and [verify](https://mxnet.apache.org/versions/1.4.1/install/validate_mxnet.html) it:
-     ```bash
-     pip install mxnet-cuXXX==1.9.0
-     ```
- 
-     * Run jupyter-lab:
-     ```bash
-     cd workspare
-     jupyter-lab
-     ```
- 
- ### Preparation virtual environment
- 
- * Create virtual environment
- 
- ```sh
-     python3 -m venv venv
- ```
- 
- * To activate virtual environment
- 
- ```sh
-     source venv/bin/activate
- ```
- 
- * To deactivate virtual environment
- 
- ```sh
-     deactivate
- ```
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/MXNet_landmarks/workspace/mxnet_adapter.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/MXNet_landmarks/workspace/mxnet_adapter.py
*** ./openfl/openfl-tutorials/interactive_api/MXNet_landmarks/workspace/mxnet_adapter.py	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/MXNet_landmarks/workspace/mxnet_adapter.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,107 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """MXNet Framework Adapter plugin."""
- 
- from pickle import dumps
- from pickle import loads
- from typing import Dict
- 
- import mxnet as mx
- import numpy as np
- from mxnet import nd
- 
- from openfl.plugins.frameworks_adapters.framework_adapter_interface import (
-     FrameworkAdapterPluginInterface
- )
- 
- 
- class FrameworkAdapterPlugin(FrameworkAdapterPluginInterface):
-     """Framework adapter plugin class."""
- 
-     def __init__(self) -> None:
-         """Initialize framework adapter."""
- 
-     @staticmethod
-     def get_tensor_dict(model, optimizer=None) -> Dict[str, np.ndarray]:
-         """
-         Extract tensor dict from a model and an optimizer.
- 
-         Returns:
-         dict {weight name: numpy ndarray}
-         """
-         state = {}
-         if optimizer is not None:
-             state = _get_optimizer_state(optimizer)
- 
-         model_params = model.collect_params()
- 
-         for param_name, param_tensor in model_params.items():
-             if isinstance(param_tensor.data(), mx.ndarray.ndarray.NDArray):
-                 state[param_name] = param_tensor.list_data()[0].asnumpy()
- 
-         return state
- 
-     @staticmethod
-     def set_tensor_dict(model, tensor_dict: Dict[str, np.ndarray],
-                         optimizer=None, device=None) -> None:
-         """
-         Set tensor dict from a model and an optimizer.
- 
-         Given a dict {weight name: numpy ndarray} sets weights to
-         the model and optimizer objects inplace.
-         """
-         if device is not None:
-             device = mx.cpu() if device.startswith('cpu') else (
-                 mx.gpu(int(device.split(':')[1].strip()))
-             )
- 
-         if optimizer is not None:
-             _set_optimizer_state(optimizer, device, tensor_dict)
-         model.collect_params().reset_ctx(device)
- 
-         model_params = model.collect_params()
- 
-         for param_name in model_params:
-             model_params[param_name].set_data(nd.array(tensor_dict.pop(param_name), ctx=device))
- 
- 
- def _get_optimizer_state(optimizer):
-     """Return the optimizer state.
- 
-     Args:
-         optimizer
-     """
-     states = loads(optimizer._updaters[0].get_states(dump_optimizer=False))
-     result_states = {}
-     for state_key, state_tuple in states.items():
-         for state_ind, state in enumerate(state_tuple):
-             result_states[f'opt_state__{state_key}__{state_ind}'] = state.asnumpy()
- 
-     return result_states
- 
- 
- def _set_optimizer_state(optimizer, device, opt_state_dict):
-     """Set the optimizer state.
- 
-     Args:
-         optimizer:
-         device:
- 
-     """
-     state_keys, max_numstates = set(), 0
-     for key in opt_state_dict.keys():
-         if not key.startswith('opt_state'):
-             continue
-         _, part1, part2 = key.split('__')
-         state_keys.add(int(part1))
-         max_numstates = max(max_numstates, int(part2))
- 
-     out_state = {}
-     for _ in range(len(state_keys)):
-         key = state_keys.pop()
-         state_vals = []
-         for i in range(max_numstates + 1):
-             state_vals.append(nd.array(opt_state_dict.pop(f'opt_state__{key}__{i}'), ctx=device))
-         out_state[key] = tuple(state_vals)
- 
-     optimizer._updaters[0].set_states(dumps(out_state))
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/MXNet_landmarks/workspace/MXNet_landmarks.ipynb ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/MXNet_landmarks/workspace/MXNet_landmarks.ipynb
*** ./openfl/openfl-tutorials/interactive_api/MXNet_landmarks/workspace/MXNet_landmarks.ipynb	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/MXNet_landmarks/workspace/MXNet_landmarks.ipynb	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,583 ****
- {
-  "cells": [
-   {
-    "cell_type": "markdown",
-    "id": "26fdd9ed",
-    "metadata": {},
-    "source": [
-     "# Federated MXNex Landmarks Tutorial\n"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "dd7fe23e",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Install dependencies if not already installed\n",
-     "!pip install -r requirements.txt"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "246f9c98",
-    "metadata": {},
-    "source": [
-     "## Connect to the Federation"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "d657e463",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Create a federation\n",
-     "from openfl.interface.interactive_api.federation import Federation\n",
-     "\n",
-     "# please use the same identificator that was used in signed certificate\n",
-     "client_id = \"api\"\n",
-     "cert_dir = \"cert\"\n",
-     "director_node_fqdn = \"localhost\"\n",
-     "# 1) Run with API layer - Director mTLS\n",
-     "# If the user wants to enable mTLS their must provide CA root chain, and signed key pair to the federation interface\n",
-     "# cert_chain = f'{cert_dir}/root_ca.crt'\n",
-     "# api_certificate = f'{cert_dir}/{client_id}.crt'\n",
-     "# api_private_key = f'{cert_dir}/{client_id}.key'\n",
-     "\n",
-     "# federation = Federation(client_id=client_id,\n",
-     "#                         director_node_fqdn=director_node_fqdn,\n",
-     "#                         director_port='50051',\n",
-     "#                         cert_chain=cert_chain,\n",
-     "#                         api_cert=api_certificate,\n",
-     "#                         api_private_key=api_private_key)\n",
-     "\n",
-     "# --------------------------------------------------------------------------------------------------------------------\n",
-     "\n",
-     "# 2) Run with TLS disabled (trusted environment)\n",
-     "# Federation can also determine local fqdn automatically\n",
-     "federation = Federation(\n",
-     "    client_id=client_id,\n",
-     "    director_node_fqdn=director_node_fqdn,\n",
-     "    director_port=\"50051\",\n",
-     "    tls=False,\n",
-     ")"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "47dcfab3",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "shard_registry = federation.get_shard_registry()\n",
-     "shard_registry"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "21d89d2c",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "federation.target_shape"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "a2a6c237",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# First, request a dummy_shard_desc that holds information about the federated dataset\n",
-     "dummy_shard_desc = federation.get_dummy_shard_descriptor(size=10)\n",
-     "dummy_shard_dataset = dummy_shard_desc.get_dataset(\"train\")\n",
-     "sample, target = dummy_shard_dataset[0]\n",
-     "f\"Sample shape: {sample.shape}, target shape: {target.shape}\""
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "cc0dbdbd",
-    "metadata": {},
-    "source": [
-     "## Describing FL experimen"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "fc88700a",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from openfl.interface.interactive_api.experiment import (\n",
-     "    DataInterface,\n",
-     "    FLExperiment,\n",
-     "    ModelInterface,\n",
-     "    TaskInterface,\n",
-     ")"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "feee0dff",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import mxnet as mx\n",
-     "import numpy as np\n",
-     "import pandas as pd\n",
-     "import tqdm\n",
-     "from matplotlib import pyplot as plt\n",
-     "from mxnet.gluon import data as gdata\n",
-     "from mxnet.gluon import loss as gloss\n",
-     "from mxnet.gluon import nn"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "3b468ae1",
-    "metadata": {},
-    "source": [
-     "### Describe a model and optimizer"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "d3ce192b",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "\"\"\"\n",
-     "MXNet model definition\n",
-     "\"\"\"\n",
-     "model = nn.Sequential()\n",
-     "model.add(\n",
-     "    nn.Conv2D(channels=64, kernel_size=3, padding=1, activation=\"relu\"),\n",
-     "    nn.BatchNorm(),\n",
-     "    nn.MaxPool2D(),\n",
-     "    nn.Conv2D(channels=128, kernel_size=3, padding=1, activation=\"relu\"),\n",
-     "    nn.BatchNorm(),\n",
-     "    nn.MaxPool2D(),\n",
-     "    nn.Conv2D(channels=256, kernel_size=3, padding=1, activation=\"relu\"),\n",
-     "    nn.BatchNorm(),\n",
-     "    nn.MaxPool2D(),\n",
-     "    nn.Flatten(),\n",
-     "    nn.Dense(64),\n",
-     "    nn.Activation(\"relu\"),\n",
-     "    nn.Dropout(rate=0.005),\n",
-     "    nn.Dense(30),\n",
-     ")\n",
-     "\n",
-     "model.initialize(force_reinit=True, ctx=None, init=mx.init.Xavier())\n",
-     "model(\n",
-     "    mx.nd.ones((1, 1, 96, 96), ctx=None)\n",
-     ")  # first forward pass for weight initialization"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "20c39cce",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# optimizer\n",
-     "optimizer = mx.optimizer.Adam(learning_rate=0.001)\n",
-     "trainer = mx.gluon.Trainer(model.collect_params(), optimizer=optimizer)\n",
-     "# loss function\n",
-     "loss_fn = gloss.L2Loss()"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "88b9dbf6",
-    "metadata": {},
-    "source": [
-     "### Register model"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "d73f5518",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "framework_adapter = \"mxnet_adapter.FrameworkAdapterPlugin\"\n",
-     "\n",
-     "MI = ModelInterface(model=model, optimizer=trainer, framework_plugin=framework_adapter)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "b0979470",
-    "metadata": {},
-    "source": [
-     "### Register dataset"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "d8c9eb50",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "class LandmarkShardDataset(gdata.Dataset):\n",
-     "    def __init__(self, dataset):\n",
-     "        self._dataset = dataset\n",
-     "\n",
-     "    def __len__(self):\n",
-     "        self.filelength = len(self._dataset)\n",
-     "        return self.filelength\n",
-     "\n",
-     "    def __getitem__(self, idx):\n",
-     "        return self._dataset[idx]\n",
-     "\n",
-     "\n",
-     "class LandmarkShardDescriptor(DataInterface):\n",
-     "    def __init__(self, validation_fraction=1 / 5, **kwargs):\n",
-     "        super().__init__(**kwargs)\n",
-     "        self.validation_fraction = validation_fraction\n",
-     "\n",
-     "    @property\n",
-     "    def shard_descriptor(self):\n",
-     "        return self._shard_descriptor\n",
-     "\n",
-     "    @shard_descriptor.setter\n",
-     "    def shard_descriptor(self, shard_descriptor):\n",
-     "        \"\"\"\n",
-     "        Describe per-collaborator procedures or sharding.\n",
-     "\n",
-     "        This method will be called during a collaborator initialization.\n",
-     "        Local shard_descriptor will be set by Envoy.\n",
-     "        \"\"\"\n",
-     "        self._shard_descriptor = shard_descriptor\n",
-     "        self._shard_dataset = LandmarkShardDataset(\n",
-     "            shard_descriptor.get_dataset(\"train\")\n",
-     "        )\n",
-     "\n",
-     "        self.validation_size = max(\n",
-     "            1, int(len(self._shard_dataset) * self.validation_fraction)\n",
-     "        )\n",
-     "\n",
-     "        self.train_indexes = len(self._shard_dataset) - self.validation_size\n",
-     "        self.val_indexes = [self.validation_size, self.train_indexes]\n",
-     "\n",
-     "    def get_train_loader(self):\n",
-     "        \"\"\"\n",
-     "        Output of this method will be provided to tasks with optimizer in contract\n",
-     "        \"\"\"\n",
-     "        return gdata.DataLoader(\n",
-     "            self._shard_dataset,\n",
-     "            batch_size=self.kwargs[\"train_bs\"],\n",
-     "            sampler=gdata.RandomSampler(self.train_indexes),\n",
-     "            last_batch=\"keep\",\n",
-     "        )\n",
-     "\n",
-     "    def get_valid_loader(self):\n",
-     "        \"\"\"\n",
-     "        Output of this method will be provided to tasks without optimizer in contract\n",
-     "        \"\"\"\n",
-     "        return gdata.DataLoader(\n",
-     "            self._shard_dataset,\n",
-     "            batch_size=self.kwargs[\"valid_bs\"],\n",
-     "            sampler=gdata.SequentialSampler(*self.val_indexes),\n",
-     "            last_batch=\"keep\",\n",
-     "        )\n",
-     "\n",
-     "    def get_train_data_size(self):\n",
-     "        \"\"\"\n",
-     "        Information for aggregation\n",
-     "        \"\"\"\n",
-     "        return self.train_indexes\n",
-     "\n",
-     "    def get_valid_data_size(self):\n",
-     "        \"\"\"\n",
-     "        Information for aggregation\n",
-     "        \"\"\"\n",
-     "        return self.validation_size"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "b0dfb459",
-    "metadata": {},
-    "source": [
-     "### Create Mnist federated dataset"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "4af5c4c2",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "train_bs, valid_bs = 64, 64\n",
-     "fed_dataset = LandmarkShardDescriptor(train_bs=train_bs, valid_bs=valid_bs)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "849c165b",
-    "metadata": {},
-    "source": [
-     "## Define and register FL tasks"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "b9649385",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "TI = TaskInterface()\n",
-     "\n",
-     "\n",
-     "@TI.register_fl_task(\n",
-     "    model=\"model\",\n",
-     "    data_loader=\"train_dataset\",\n",
-     "    device=\"device\",\n",
-     "    optimizer=\"optimizer\",\n",
-     "    round_num=\"round_num\",\n",
-     ")\n",
-     "def train(model, train_dataset, optimizer, round_num, device, loss_fn=loss_fn):\n",
-     "    device = (\n",
-     "        mx.cpu()\n",
-     "        if device.startswith(\"cpu\")\n",
-     "        else mx.gpu(int(device.split(\":\")[1].strip()))\n",
-     "    )\n",
-     "\n",
-     "    print(\"train on:\", device)\n",
-     "\n",
-     "    if round_num == 0:\n",
-     "        optimizer._contexts = [device]\n",
-     "\n",
-     "    train_dataset = tqdm.tqdm(train_dataset, desc=\"train\")\n",
-     "    train_sum_l = 0\n",
-     "    for X, y in train_dataset:\n",
-     "        X, y = X.expand_dims(axis=1).as_in_context(device), y.as_in_context(device)\n",
-     "        with mx.autograd.record():\n",
-     "            pred = model(X)\n",
-     "            l = loss_fn(pred, y).mean()\n",
-     "        l.backward()\n",
-     "        optimizer.step(train_bs)\n",
-     "        train_sum_l += l.mean().asscalar()\n",
-     "    train_loss = train_sum_l / len(train_dataset)\n",
-     "    return {\n",
-     "        \"train_mse\": train_loss,\n",
-     "    }\n",
-     "\n",
-     "\n",
-     "@TI.register_fl_task(model=\"model\", data_loader=\"val_dataset\", device=\"device\")\n",
-     "def validate(model, val_dataset, device):\n",
-     "    device = (\n",
-     "        mx.cpu()\n",
-     "        if device.startswith(\"cpu\")\n",
-     "        else mx.gpu(int(device.split(\":\")[1].strip()))\n",
-     "    )\n",
-     "\n",
-     "    # Run a validation loop at the end of each epoch.\n",
-     "    test_sum_l = 0\n",
-     "    for X, y in val_dataset:\n",
-     "        X, y = X.expand_dims(axis=1).as_in_context(device), y.as_in_context(device)\n",
-     "        pred = model(X)\n",
-     "        l = loss_fn(pred, y)\n",
-     "        test_sum_l += l.mean().asscalar()\n",
-     "    test_loss = test_sum_l / len(val_dataset)\n",
-     "    return {\n",
-     "        \"val_mse\": test_loss,\n",
-     "    }"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "8f0ebf2d",
-    "metadata": {},
-    "source": [
-     "## Time to start a federated learning experiment"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "d41b7896",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# create an experimnet in federation\n",
-     "experiment_name = \"landmark_experiment\"\n",
-     "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "41b44de9",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
-     "fl_experiment.start(\n",
-     "    model_provider=MI,\n",
-     "    task_keeper=TI,\n",
-     "    data_loader=fed_dataset,\n",
-     "    rounds_to_train=10,\n",
-     "    opt_treatment=\"CONTINUE_GLOBAL\",\n",
-     "    device_assignment_policy=\"CUDA_PREFERRED\",\n",
-     ")"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "01fa7cea",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "fl_experiment.stream_metrics()"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "e6055103",
-    "metadata": {},
-    "source": [
-     "## Let's have a look at the results"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "ff804102",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import os\n",
-     "from zipfile import ZipFile\n",
-     "\n",
-     "from kaggle.api.kaggle_api_extended import KaggleApi"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "37dc7f56",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "if not os.path.exists(\"./test\"):\n",
-     "    api = KaggleApi()\n",
-     "    api.authenticate()\n",
-     "    api.competition_download_file(\"facial-keypoints-detection\", \"test.zip\")\n",
-     "    with ZipFile(\"test.zip\", \"r\") as zipobj:\n",
-     "        zipobj.extractall(\"./test\")\n",
-     "    os.remove(\"test.zip\")"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "08fc3a7a",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "last_model = fl_experiment.get_last_model()"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "13f6cfd7",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "Test_Dir = \"./test/test.csv\""
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "796c8e37",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "def get_data(path_to_csv_file):\n",
-     "    data_df = pd.read_csv(path_to_csv_file)\n",
-     "    data_df.fillna(method=\"ffill\", inplace=True)\n",
-     "    labels = data_df.drop(\"Image\", axis=1)\n",
-     "    imag, keypoints = [], []\n",
-     "    for i in range(data_df.shape[0]):\n",
-     "        img = data_df[\"Image\"][i].split(\" \")\n",
-     "        img = [\"0\" if x == \"\" else x for x in img]\n",
-     "        imag.append(img)\n",
-     "        y = labels.iloc[i, :]\n",
-     "        keypoints.append(y)\n",
-     "\n",
-     "    X = np.array(imag, dtype=\"float\").reshape(-1, 96, 96)\n",
-     "    y = np.array(keypoints, dtype=\"float\")\n",
-     "\n",
-     "    return X, y"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "6ed1ce74",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "test_imgs, _ = get_data(Test_Dir)  # prepare test dataset"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "7cc6bed7",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "fig = plt.figure(figsize=(10, 10))\n",
-     "for i in range(9):\n",
-     "    ax = fig.add_subplot(3, 3, i + 1)\n",
-     "    in_for_net = (\n",
-     "        mx.nd.array([test_imgs[i + 1]]).expand_dims(axis=1).as_in_context(mx.cpu())\n",
-     "    )\n",
-     "    pred = last_model(in_for_net)[0].asnumpy().reshape(-1, 2)\n",
-     "    ax.imshow(test_imgs[i + 1], cmap=\"gray\")\n",
-     "    x_cords = pred[:, 0]\n",
-     "    y_cords = pred[:, 1]\n",
-     "    plt.scatter(x_cords, y_cords, label='Predicted keypoints')\n",
-     "plt.legend(bbox_to_anchor=(2.1, 3.4), prop={'size': 12})\n",
-     "\n",
-     "plt.show()"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "1ddc51e2",
-    "metadata": {},
-    "outputs": [],
-    "source": []
-   }
-  ],
-  "metadata": {
-   "language_info": {
-    "name": "python"
-   }
-  },
-  "nbformat": 4,
-  "nbformat_minor": 5
- }
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/MXNet_landmarks/workspace/requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/MXNet_landmarks/workspace/requirements.txt
*** ./openfl/openfl-tutorials/interactive_api/MXNet_landmarks/workspace/requirements.txt	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/MXNet_landmarks/workspace/requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- kaggle
- matplotlib
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/numpy_linear_regression/director/director_config.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/numpy_linear_regression/director/director_config.yaml
*** ./openfl/openfl-tutorials/interactive_api/numpy_linear_regression/director/director_config.yaml	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/numpy_linear_regression/director/director_config.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,6 ****
- settings:
-   listen_host: localhost
-   listen_port: 50049
-   sample_shape: ['1']
-   target_shape: ['1']
-   envoy_health_check_period: 5  # in seconds
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/numpy_linear_regression/envoy/envoy_config.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/numpy_linear_regression/envoy/envoy_config.yaml
*** ./openfl/openfl-tutorials/interactive_api/numpy_linear_regression/envoy/envoy_config.yaml	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/numpy_linear_regression/envoy/envoy_config.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,12 ****
- params:
-   cuda_devices: []
- 
- optional_plugin_components: {}
- 
- shard_descriptor:
-   template: linreg_shard_descriptor.LinRegSD
-   params:
-     rank: 1
-     n_samples: 80
-     noise: 0.15
-   
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/numpy_linear_regression/envoy/linreg_shard_descriptor.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/numpy_linear_regression/envoy/linreg_shard_descriptor.py
*** ./openfl/openfl-tutorials/interactive_api/numpy_linear_regression/envoy/linreg_shard_descriptor.py	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/numpy_linear_regression/envoy/linreg_shard_descriptor.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,60 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Noisy-Sin Shard Descriptor."""
- 
- from typing import List
- 
- import numpy as np
- 
- from openfl.interface.interactive_api.shard_descriptor import ShardDescriptor
- 
- 
- class LinRegSD(ShardDescriptor):
-     """Shard descriptor class."""
- 
-     def __init__(self, rank: int, n_samples: int = 10, noise: float = 0.15) -> None:
-         """
-         Initialize LinReg Shard Descriptor.
- 
-         This Shard Descriptor generate random data. Sample features are
-         floats between pi/3 and 5*pi/3, and targets are calculated
-         calculated as sin(feature) + normal_noise.
-         """
-         np.random.seed(rank)  # Setting seed for reproducibility
-         self.n_samples = max(n_samples, 5)
-         self.interval = 240
-         self.x_start = 60
-         x = np.random.rand(n_samples, 1) * self.interval + self.x_start
-         x *= np.pi / 180
-         y = np.sin(x) + np.random.normal(0, noise, size=(n_samples, 1))
-         self.data = np.concatenate((x, y), axis=1)
- 
-     def get_dataset(self, dataset_type: str) -> np.ndarray:
-         """
-         Return a shard dataset by type.
- 
-         A simple list with elements (x, y) implemets the Shard Dataset interface.
-         """
-         if dataset_type == 'train':
-             return self.data[:self.n_samples // 2]
-         elif dataset_type == 'val':
-             return self.data[self.n_samples // 2:]
-         else:
-             pass
- 
-     @property
-     def sample_shape(self) -> List[str]:
-         """Return the sample shape info."""
-         (*x, _) = self.data[0]
-         return [str(i) for i in np.array(x, ndmin=1).shape]
- 
-     @property
-     def target_shape(self) -> List[str]:
-         """Return the target shape info."""
-         (*_, y) = self.data[0]
-         return [str(i) for i in np.array(y, ndmin=1).shape]
- 
-     @property
-     def dataset_description(self) -> str:
-         """Return the dataset description."""
-         return 'Allowed dataset types are `train` and `val`'
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/numpy_linear_regression/envoy/requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/numpy_linear_regression/envoy/requirements.txt
*** ./openfl/openfl-tutorials/interactive_api/numpy_linear_regression/envoy/requirements.txt	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/numpy_linear_regression/envoy/requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- openfl==1.2.1
- numpy
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/numpy_linear_regression/README.md ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/numpy_linear_regression/README.md
*** ./openfl/openfl-tutorials/interactive_api/numpy_linear_regression/README.md	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/numpy_linear_regression/README.md	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,24 ****
- # Linear Regression with Numpy and OpenFL
- 
- This example is devoted to demonstrating several techniques of working with OpenFL.
- 
- 1. Envoy workspace contains a Shard Descriptor designed to generate 1-dimensional noisy data for linear regression of sinusoid. The random seed for generation for a specific Envoy is parametrized by the `rank` argument in shard_config. 
- 2. The LinReg frontend jupyter notebook (data scientist's entry point) features a simple numpy-based model for linear regression trained with Ridge regularization.
- 3. The data scientist's workspace also contains a custom framework adapter allowing extracting and setting weights to the custom model.
- 4. The start_federation notebook provides shortcut methods to start a Federation with an arbitrary number of Envoys with different datasets. It may save time for people willing to conduct one-node experiments.
- 5. The SingleNotebook jupyter notebook combines two aforementioned notebooks and allows to run the whole pipeline in Google colab. Besides previously mentioned components, it contains scripts for pulling the OpenFL repo with the example workspaces and installing dependencies.
- 
- ## How to use this example
- ### Locally:
- 1. Start a Federation
- Distributed experiments:
- Use OpenFL CLI to start the Director and Envoy services from corresponding folders. 
- Single-node experiments:
- Users may use the same path or benefit from the start_federation notebook in the workspace folder
- 
- 2. Submit an experiment
- Follow LinReg jupyter notebook.
- 
- ### Google Colab:
- 
- [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/intel/openfl/blob/develop/openfl-tutorials/interactive_api/numpy_linear_regression/workspace/SingleNotebook.ipynb)
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/numpy_linear_regression/workspace/custom_adapter.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/numpy_linear_regression/workspace/custom_adapter.py
*** ./openfl/openfl-tutorials/interactive_api/numpy_linear_regression/workspace/custom_adapter.py	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/numpy_linear_regression/workspace/custom_adapter.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,21 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Custom model numpy adapter."""
- 
- from openfl.plugins.frameworks_adapters.framework_adapter_interface import (
-     FrameworkAdapterPluginInterface,
- )
- 
- 
- class CustomFrameworkAdapter(FrameworkAdapterPluginInterface):
-     """Framework adapter plugin class."""
- 
-     @staticmethod
-     def get_tensor_dict(model, optimizer=None):
-         """Extract tensors from a model."""
-         return {'w': model.weights}
- 
-     @staticmethod
-     def set_tensor_dict(model, tensor_dict, optimizer=None, device='cpu'):
-         """Load tensors to a model."""
-         model.weights = tensor_dict['w']
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/numpy_linear_regression/workspace/LinReg.ipynb ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/numpy_linear_regression/workspace/LinReg.ipynb
*** ./openfl/openfl-tutorials/interactive_api/numpy_linear_regression/workspace/LinReg.ipynb	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/numpy_linear_regression/workspace/LinReg.ipynb	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,485 ****
- {
-  "cells": [
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "689ee822",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "!pip install -r requirements.txt"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "d63e64c6-9955-4afc-8d04-d8c85bb28edc",
-    "metadata": {},
-    "source": [
-     "# Linear Regression with Numpy and OpenFL"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "6c9eee14-22a1-4d48-a7da-e68d01037cd4",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from typing import List, Union\n",
-     "import numpy as np\n",
-     "import random\n",
-     "import matplotlib.pyplot as plt\n",
-     "%matplotlib inline\n",
-     "from matplotlib.pylab import rcParams\n",
-     "rcParams['figure.figsize'] = 7, 5"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "c4b334ef-6a72-4b82-b978-1401973d0512",
-    "metadata": {
-     "tags": []
-    },
-    "source": [
-     "# We will use MSE as loss function and Ridge weights regularization\n",
-     "![image.png](https://www.analyticsvidhya.com/wp-content/uploads/2016/01/eq5-1.png)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "f4cc8ec2-b818-4db8-8700-39c1a12917df",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "class LinRegLasso:\n",
-     "    def __init__(self, n_feat: int) -> None:\n",
-     "        self.weights = np.ones((n_feat + 1)) # (n_feat + 1,) weights + bias\n",
-     "        \n",
-     "    def predict(self, feature_vector: Union[np.ndarray, List[int]]) -> float:\n",
-     "        '''\n",
-     "        feature_vector may be a list or have shape (n_feat,)\n",
-     "        or it may be a bunch of vectors (n_vec, nfeat)\n",
-     "        '''\n",
-     "        feature_vector = np.array(feature_vector)\n",
-     "        if len(feature_vector.shape) == 1:\n",
-     "            feature_vector = feature_vector[:,np.newaxis]\n",
-     "        assert feature_vector.shape[-1] == self.weights.shape[0] - 1, \\\n",
-     "            f\"sample shape is {feature_vector.shape} and weights shape is f{self.weights}\"\n",
-     "        \n",
-     "        return self.weights @ np.concatenate((feature_vector.T, [[1]*feature_vector.shape[0]]))\n",
-     "    \n",
-     "    def mse(self, X: np.ndarray, Y: np.ndarray) -> float:\n",
-     "        Y_hat = self.predict(X)\n",
-     "        return np.sum((Y - Y_hat)**2) / Y.shape[0]\n",
-     "\n",
-     "    def _update_weights(self, X: np.ndarray, Y: np.ndarray, lr: float, wd: float) -> None:\n",
-     "        '''\n",
-     "        X: (n_samples, n_features)\n",
-     "        Y: (n_samples,)\n",
-     "        self.weights: (n_features + 1)\n",
-     "        \n",
-     "        Cost function is MSE: (y - W*X - b)**2;\n",
-     "        its derivative with resp to any x is -2*X*(y - W*X - b),\n",
-     "        and with resp to b is -2*(y - W*X - b).\n",
-     "        \n",
-     "        Regularisation function is L1 |W|;\n",
-     "        its derivative is SIGN(w)\n",
-     "        '''\n",
-     "        predictions = self.predict(X)\n",
-     "        error = Y - predictions # (n_samples,)\n",
-     "        X_with_bias = np.concatenate((X.T, [[1]*X.shape[0]])).T\n",
-     "        updates = -2 * X_with_bias.T @ error / Y.shape[0]\n",
-     "        regression_term = np.sign(self.weights)\n",
-     "        \n",
-     "        self.weights = self.weights - lr * updates + wd * regression_term\n",
-     "    \n",
-     "    def fit(self, X: np.ndarray, Y: np.ndarray,\n",
-     "            n_epochs: int, lr: float, wd: float,\n",
-     "            silent: bool=False) -> None:\n",
-     "        for i in range(n_epochs):\n",
-     "            self._update_weights(X, Y, lr, wd)\n",
-     "            mse = self.mse(X, Y)\n",
-     "            if not silent:\n",
-     "                print(f'epoch: {i}, \\t MSE: {mse}')\n",
-     "            "
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "af89e7e5-6cfc-46bc-acd2-7d5bfb373091",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Define input array with angles from 60deg to 300deg converted to radians\n",
-     "x = np.array([i*np.pi/180 for i in range(60,300,4)])\n",
-     "np.random.seed(10)  # Setting seed for reproducibility\n",
-     "y = np.sin(x) + np.random.normal(0,0.15,len(x))\n",
-     "# plt.plot(x,y,'.')"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "ffefca2b-d7f6-4111-8872-c017c182a2de",
-    "metadata": {
-     "tags": []
-    },
-    "outputs": [],
-    "source": [
-     "lr_model = LinRegLasso(1)\n",
-     "wd = 0.0001\n",
-     "lr = 0.08\n",
-     "epochs = 100\n",
-     "\n",
-     "print(f\"Initila MSE: {lr_model.mse(x,y)}\")\n",
-     "lr_model.fit(x[:,np.newaxis],y, epochs, lr, wd, silent=True)\n",
-     "print(f\"Final MSE: {lr_model.mse(x,y)}\")\n",
-     "print(f\"Final parameters: {lr_model.weights}\")"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "410f2d80-989a-43ab-958f-7b68fd8f2e90",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# We can also solve this 1D problem using Numpy\n",
-     "numpy_solution = np.polyfit(x,y,1)\n",
-     "predictor_np = np.poly1d(numpy_solution)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "6cb323db-9f3a-42af-94da-4b170adef867",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "y_hat = lr_model.predict(x)\n",
-     "y_np = predictor_np(x)\n",
-     "plt.plot(x,y,'.')\n",
-     "plt.plot(x,y_hat,'.')\n",
-     "plt.plot(x,y_np,'--')"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "ffd4d2d7-5537-496a-88c1-301da87d979c",
-    "metadata": {},
-    "source": [
-     "# Now we run the same training on federated data"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "09cf7090-da51-4f4e-9d28-2a5c6e3bca02",
-    "metadata": {},
-    "source": [
-     "## Connect to a Federation"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "1b3c0039-e1f7-4047-b98b-a2d4bd42f015",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Create a federation\n",
-     "from openfl.interface.interactive_api.federation import Federation\n",
-     "\n",
-     "# please use the same identificator that was used in signed certificate\n",
-     "client_id = 'frontend'\n",
-     "director_node_fqdn = 'localhost'\n",
-     "director_port = 50049\n",
-     "\n",
-     "federation = Federation(\n",
-     "    client_id=client_id,\n",
-     "    director_node_fqdn=director_node_fqdn,\n",
-     "    director_port=director_port,\n",
-     "    tls=False\n",
-     ")"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "7815120e-b704-4a7d-a65a-3c7542023ead",
-    "metadata": {
-     "tags": []
-    },
-    "outputs": [],
-    "source": [
-     "shard_registry = federation.get_shard_registry()\n",
-     "shard_registry"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "b011dd95-64a7-4a8b-91ec-e61cdf885bbb",
-    "metadata": {},
-    "source": [
-     "### Data"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "b1985ac9-a2b1-4561-a962-6adfe35c3b97",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment\n",
-     "\n",
-     "class LinRegDataSet(DataInterface):\n",
-     "    def __init__(self, **kwargs):\n",
-     "        \"\"\"Initialize DataLoader.\"\"\"\n",
-     "        self.kwargs = kwargs\n",
-     "        pass\n",
-     "\n",
-     "    @property\n",
-     "    def shard_descriptor(self):\n",
-     "        \"\"\"Return shard descriptor.\"\"\"\n",
-     "        return self._shard_descriptor\n",
-     "    \n",
-     "    @shard_descriptor.setter\n",
-     "    def shard_descriptor(self, shard_descriptor):\n",
-     "        \"\"\"\n",
-     "        Describe per-collaborator procedures or sharding.\n",
-     "\n",
-     "        This method will be called during a collaborator initialization.\n",
-     "        Local shard_descriptor  will be set by Envoy.\n",
-     "        \"\"\"\n",
-     "        self._shard_descriptor = shard_descriptor\n",
-     "        self.train_set = shard_descriptor.get_dataset(\"train\")\n",
-     "        self.val_set = shard_descriptor.get_dataset(\"val\")\n",
-     "\n",
-     "    def get_train_loader(self, **kwargs):\n",
-     "        \"\"\"Output of this method will be provided to tasks with optimizer in contract.\"\"\"\n",
-     "        return self.train_set\n",
-     "\n",
-     "    def get_valid_loader(self, **kwargs):\n",
-     "        \"\"\"Output of this method will be provided to tasks without optimizer in contract.\"\"\"\n",
-     "        return self.val_set\n",
-     "\n",
-     "    def get_train_data_size(self):\n",
-     "        \"\"\"Information for aggregation.\"\"\"\n",
-     "        return len(self.train_set)\n",
-     "\n",
-     "    def get_valid_data_size(self):\n",
-     "        \"\"\"Information for aggregation.\"\"\"\n",
-     "        return len(self.val_set)\n",
-     "    \n",
-     "lin_reg_dataset = LinRegDataSet()"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "b8909127-99d1-4dba-86fe-01a1b86585e7",
-    "metadata": {},
-    "source": [
-     "### Model"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "9523c9a2-a259-461f-937f-1fb054bd2886",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "framework_adapter = 'custom_adapter.CustomFrameworkAdapter'\n",
-     "fed_model = LinRegLasso(1)\n",
-     "MI = ModelInterface(model=fed_model, optimizer=None, framework_plugin=framework_adapter)\n",
-     "\n",
-     "# Save the initial model state\n",
-     "initial_model = LinRegLasso(1)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "2e3558bb-b21b-48ac-b07e-43cf75e6907b",
-    "metadata": {},
-    "source": [
-     "### Tasks\n",
-     "We need to employ a trick reporting metrics. OpenFL decides which model is the best based on an *increasing* metric."
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "f73e1ff9-d54a-49b5-9ce8-8bc72c6a2c6f",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "TI = TaskInterface()\n",
-     "\n",
-     "@TI.add_kwargs(**{'lr': 0.001,\n",
-     "                   'wd': 0.0001,\n",
-     "                   'epoches': 1})\n",
-     "@TI.register_fl_task(model='my_model', data_loader='train_data', \\\n",
-     "                     device='device', optimizer='optimizer')     \n",
-     "def train(my_model, train_data, optimizer, device, lr, wd, epoches):\n",
-     "    X, Y = train_data[:,:-1], train_data[:,-1]\n",
-     "    my_model.fit(X, Y, epochs, lr, wd, silent=True)\n",
-     "    return {'train_MSE': my_model.mse(X, Y),}\n",
-     "\n",
-     "@TI.register_fl_task(model='my_model', data_loader='val_data', device='device')     \n",
-     "def validate(my_model, val_data, device):\n",
-     "    X, Y = val_data[:,:-1], val_data[:,-1]        \n",
-     "    return {'validation_MSE': my_model.mse(X, Y),}"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "ee7659cc-6e03-43f5-9078-95707fa0e4d5",
-    "metadata": {
-     "tags": []
-    },
-    "source": [
-     "### Run"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "749100e8-05ce-418c-a980-545e3beb900b",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "experiment_name = 'linear_regression_experiment'\n",
-     "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name,\n",
-     "                            )"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "16bf1df7-8ca8-4a5e-a833-47c265c11e05",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "fl_experiment.start(model_provider=MI, \n",
-     "                    task_keeper=TI,\n",
-     "                    data_loader=lin_reg_dataset,\n",
-     "                    rounds_to_train=10,)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "1178d1ea-05e6-46be-ac07-21620bd6ec76",
-    "metadata": {
-     "tags": []
-    },
-    "outputs": [],
-    "source": [
-     "fl_experiment.stream_metrics()"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "af331ccd-66b4-4925-8627-52cf03ceea5e",
-    "metadata": {
-     "tags": []
-    },
-    "source": [
-     "### Optional: start tensorboard"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "fde4ed4d-dda5-4bab-8dd3-e1ac44f5acf9",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "%%script /bin/bash --bg\n",
-     "tensorboard --host $(hostname --all-fqdns | awk '{print $1}') --logdir logs"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "7aa78602-b66a-4378-bea9-e915f2a1fdd8",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "last_model = fl_experiment.get_last_model()\n",
-     "best_model = fl_experiment.get_best_model()\n",
-     "print(best_model.weights)\n",
-     "print(last_model.weights)\n",
-     "print(f\"last model MSE: {last_model.mse(x,y)}\")\n",
-     "print(f\"best model MSE: {best_model.mse(x,y)}\")"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "ae66d688",
-    "metadata": {},
-    "source": [
-     "### Evaluate results"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "573417e0",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "n_cols = 20\n",
-     "n_samples = 4\n",
-     "interval = 240\n",
-     "x_start = 60\n",
-     "noise = 0.3\n",
-     "\n",
-     "X = None\n",
-     "\n",
-     "for rank in range(n_cols):\n",
-     "    np.random.seed(rank)  # Setting seed for reproducibility\n",
-     "    x = np.random.rand(n_samples, 1) * interval + x_start\n",
-     "    x *= np.pi / 180\n",
-     "    X = x if X is None else np.vstack((X,x))\n",
-     "    y = np.sin(x) + np.random.normal(0, noise, size=(n_samples, 1))\n",
-     "    plt.plot(x,y,'+')\n",
-     "    \n",
-     "X.sort()    \n",
-     "Y_hat = last_model.predict(X)\n",
-     "plt.plot(X,Y_hat,'--')"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "84e927c8",
-    "metadata": {},
-    "outputs": [],
-    "source": []
-   }
-  ],
-  "metadata": {
-   "kernelspec": {
-    "display_name": "Python 3 (ipykernel)",
-    "language": "python",
-    "name": "python3"
-   },
-   "language_info": {
-    "codemirror_mode": {
-     "name": "ipython",
-     "version": 3
-    },
-    "file_extension": ".py",
-    "mimetype": "text/x-python",
-    "name": "python",
-    "nbconvert_exporter": "python",
-    "pygments_lexer": "ipython3",
-    "version": "3.8.10"
-   }
-  },
-  "nbformat": 4,
-  "nbformat_minor": 5
- }
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/numpy_linear_regression/workspace/requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/numpy_linear_regression/workspace/requirements.txt
*** ./openfl/openfl-tutorials/interactive_api/numpy_linear_regression/workspace/requirements.txt	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/numpy_linear_regression/workspace/requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- openfl==1.2.1
- numpy
- jupyterlab
- matplotlib
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/numpy_linear_regression/workspace/SingleNotebook.ipynb ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/numpy_linear_regression/workspace/SingleNotebook.ipynb
*** ./openfl/openfl-tutorials/interactive_api/numpy_linear_regression/workspace/SingleNotebook.ipynb	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/numpy_linear_regression/workspace/SingleNotebook.ipynb	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,790 ****
- {
-  "cells": [
-   {
-    "cell_type": "markdown",
-    "id": "4dd5da0c-1ae1-43e6-8ad9-360c8974476c",
-    "metadata": {},
-    "source": [
-     "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/intel/openfl/blob/develop/openfl-tutorials/interactive_api/numpy_linear_regression/workspace/SingleNotebook.ipynb)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "ee73e205-d273-4b6c-878a-5ea958bfe267",
-    "metadata": {},
-    "source": [
-     "### Preparations in colab:\n",
-     "We need to clone the repository to run a federation because it contains director and envoy configs to start from.\n",
-     "\n",
-     "1. Clone the OpenFL repository\n",
-     "2. Install OpenFL \n",
-     "3. Go to the linreg workspace"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "c6fafe9e",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# For right now, install from source, later we would migrate to PyPI install\n",
-     "# !pip install openfl==1.2.1\n",
-     "!git clone https://github.com/intel/openfl.git\n",
-     "!cd openfl && pip install ."
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "2698f1da-fa69-4543-bb15-c7c0dcb776b9",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import os\n",
-     "from time import sleep\n",
-     "\n",
-     "os.chdir('./openfl/openfl-tutorials/interactive_api/numpy_linear_regression/workspace')"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "1637381d-84d0-4132-92c3-bf1a1e9c7f7a",
-    "metadata": {},
-    "source": [
-     "# Linear Regression with Numpy and OpenFL"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "fde856d8-da4e-4d2f-bee2-85e673050623",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from typing import List, Union\n",
-     "import numpy as np\n",
-     "import random\n",
-     "import matplotlib.pyplot as plt\n",
-     "%matplotlib inline\n",
-     "from matplotlib.pylab import rcParams\n",
-     "rcParams['figure.figsize'] = 7, 5"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "5e06d979-c582-4f44-b092-e5d60cce88bf",
-    "metadata": {
-     "tags": []
-    },
-    "source": [
-     "# We will use MSE as loss function and Ridge weights regularization\n",
-     "![image.png](https://www.analyticsvidhya.com/wp-content/uploads/2016/01/eq5-1.png)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "c9a860ab-91a5-410e-9d1e-4b9bd5a33d70",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "class LinRegLasso:\n",
-     "    def __init__(self, n_feat: int) -> None:\n",
-     "        self.weights = np.ones((n_feat + 1)) # (n_feat + 1,) weights + bias\n",
-     "        \n",
-     "    def predict(self, feature_vector: Union[np.ndarray, List[int]]) -> float:\n",
-     "        '''\n",
-     "        feature_vector may be a list or have shape (n_feat,)\n",
-     "        or it may be a bunch of vectors (n_vec, nfeat)\n",
-     "        '''\n",
-     "        feature_vector = np.array(feature_vector)\n",
-     "        if len(feature_vector.shape) == 1:\n",
-     "            feature_vector = feature_vector[:,np.newaxis]\n",
-     "        assert feature_vector.shape[-1] == self.weights.shape[0] - 1, \\\n",
-     "            f\"sample shape is {feature_vector.shape} and weights shape is f{self.weights}\"\n",
-     "        \n",
-     "        return self.weights @ np.concatenate((feature_vector.T, [[1]*feature_vector.shape[0]]))\n",
-     "    \n",
-     "    def mse(self, X: np.ndarray, Y: np.ndarray) -> float:\n",
-     "        Y_hat = self.predict(X)\n",
-     "        return np.sum((Y - Y_hat)**2) / Y.shape[0]\n",
-     "\n",
-     "    def _update_weights(self, X: np.ndarray, Y: np.ndarray, lr: float, wd: float) -> None:\n",
-     "        '''\n",
-     "        X: (n_samples, n_features)\n",
-     "        Y: (n_samples,)\n",
-     "        self.weights: (n_features + 1)\n",
-     "        \n",
-     "        Cost function is MSE: (y - W*X - b)**2;\n",
-     "        its derivative with resp to any x is -2*X*(y - W*X - b),\n",
-     "        and with resp to b is -2*(y - W*X - b).\n",
-     "        \n",
-     "        Regularisation function is L1 |W|;\n",
-     "        its derivative is SIGN(w)\n",
-     "        '''\n",
-     "        predictions = self.predict(X)\n",
-     "        error = Y - predictions # (n_samples,)\n",
-     "        X_with_bias = np.concatenate((X.T, [[1]*X.shape[0]])).T\n",
-     "        updates = -2 * X_with_bias.T @ error / Y.shape[0]\n",
-     "        regression_term = np.sign(self.weights)\n",
-     "        \n",
-     "        self.weights = self.weights - lr * updates + wd * regression_term\n",
-     "    \n",
-     "    def fit(self, X: np.ndarray, Y: np.ndarray,\n",
-     "            n_epochs: int, lr: float, wd: float,\n",
-     "            silent: bool=False) -> None:\n",
-     "        for i in range(n_epochs):\n",
-     "            self._update_weights(X, Y, lr, wd)\n",
-     "            mse = self.mse(X, Y)\n",
-     "            if not silent:\n",
-     "                print(f'epoch: {i}, \\t MSE: {mse}')\n",
-     "            "
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "796b0de6-cb80-4ca6-91e9-503011d6851f",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Define input array with angles from 60deg to 300deg converted to radians\n",
-     "noise=0.2\n",
-     "\n",
-     "x = np.array([i*np.pi/180 for i in range(60,300,4)])\n",
-     "np.random.seed(10)  # Setting seed for reproducibility\n",
-     "y = np.sin(x) + np.random.normal(0, noise, len(x))\n",
-     "# plt.plot(x,y,'.')"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "033a74b4-3bc2-4a19-b734-007ad8a4c037",
-    "metadata": {
-     "tags": []
-    },
-    "outputs": [],
-    "source": [
-     "lr_model = LinRegLasso(1)\n",
-     "wd = 0.0001\n",
-     "lr = 0.08\n",
-     "epochs = 100\n",
-     "\n",
-     "print(f\"Initila MSE: {lr_model.mse(x,y)}\")\n",
-     "lr_model.fit(x[:,np.newaxis],y, epochs, lr, wd, silent=True)\n",
-     "print(f\"Final MSE: {lr_model.mse(x,y)}\")\n",
-     "print(f\"Final parameters: {lr_model.weights}\")"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "25873a87-7564-4e4a-8ef5-79a9415b209f",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# We can also solve this 1D problem using Numpy\n",
-     "numpy_solution = np.polyfit(x,y,1)\n",
-     "predictor_np = np.poly1d(numpy_solution)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "2e5b7a9b-4d4b-4222-8eef-4ef4ba63434a",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "y_hat = lr_model.predict(x)\n",
-     "y_np = predictor_np(x)\n",
-     "plt.plot(x,y,'.')\n",
-     "plt.plot(x,y_hat,'.')\n",
-     "plt.plot(x,y_np,'--')"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "cd2e26a5-9f4e-4011-a999-e428246aa8c1",
-    "metadata": {},
-    "source": [
-     "# Now we run the same training on federated data"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "83378ece-9cd5-4d40-a134-24cf68bdb79a",
-    "metadata": {
-     "tags": []
-    },
-    "source": [
-     "## 1. Start the Director service and several envoys with generated data"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "b0d105a0-04c4-4c26-81c7-a350e14393c2",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Here are the main parameters for our Federation\n",
-     "n_cols=10\n",
-     "n_samples_per_col=10\n",
-     "noise=0.2"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "c0c3e78b-6e9d-4efc-9b30-3ddc413c0423",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import os\n",
-     "from pathlib import Path\n",
-     "import yaml\n",
-     "from typing import Dict, List, Union"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "463a2821-b657-4e12-90ac-33b7810c5ff4",
-    "metadata": {},
-    "source": [
-     "### Start the Director service"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "e736d33f-5df2-4a2f-8210-f1feba9fd367",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "cwd = Path.cwd()\n",
-     "director_workspace_path = Path('../director/').absolute()\n",
-     "director_config_file = director_workspace_path / 'director_config.yaml'\n",
-     "director_logfile = director_workspace_path / 'director.log'\n",
-     "if director_logfile.is_file(): director_logfile.unlink()\n",
-     "\n",
-     "os.environ['main_folder'] = str(cwd)\n",
-     "os.environ['director_workspace_path'] = str(director_workspace_path)\n",
-     "os.environ['director_logfile'] = str(director_logfile)\n",
-     "os.environ['director_config_file'] = str(director_config_file)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "bb950328-c1e6-4062-8b36-b42486d60241",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "%%script /bin/bash --bg\n",
-     "cd $director_workspace_path\n",
-     "fx director start --disable-tls -c $director_config_file > $director_logfile &\n",
-     "cd $main_folder"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "223f0037-c87e-440d-b8df-8fe9211c34dc",
-    "metadata": {
-     "tags": []
-    },
-    "source": [
-     "## Start Envoys"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "f6deeee4-5dc8-433d-a4ea-c464c74b1b2b",
-    "metadata": {},
-    "source": [
-     "#### First, we create several envoy config files "
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "c0e65a39-15f7-4cca-90bb-a2970b7be9f0",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Read the original envoy config file content\n",
-     "with open(Path('../envoy/envoy_config.yaml'), \"r\") as stream:\n",
-     "    orig_config = yaml.safe_load(stream)\n",
-     "\n",
-     "def generate_envoy_configs(config: Dict,\n",
-     "                           save_path: Union[str, Path] = '../envoy/',\n",
-     "                           n_cols: int = 10,\n",
-     "                           n_samples_per_col: int = 10,\n",
-     "                           noise: float = 0.15) -> List[Path]:\n",
-     "\n",
-     "    config['shard_descriptor']['params']['n_samples'] = n_samples_per_col\n",
-     "    config['shard_descriptor']['params']['noise'] = noise\n",
-     "    \n",
-     "    config_paths = [(Path(save_path) / f'{i}_envoy_config.yaml').absolute()\n",
-     "                for i in range(1, n_cols + 1)]\n",
-     "\n",
-     "    for i, path in enumerate(config_paths):\n",
-     "        config['shard_descriptor']['params']['rank'] = i\n",
-     "        with open(path, \"w\") as stream:\n",
-     "            yaml.safe_dump(config, stream)\n",
-     "            \n",
-     "    return config_paths\n",
-     "            \n",
-     "def remove_configs(config_paths):\n",
-     "    for path in config_paths:\n",
-     "        path.unlink()"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "90109c5b-c785-4af7-ace9-dcd913018dca",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "config_paths = generate_envoy_configs(orig_config,\n",
-     "                                      n_cols=n_cols,\n",
-     "                                      n_samples_per_col=n_samples_per_col,\n",
-     "                                      noise=noise)\n",
-     "# remove_configs(config_paths)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "70c3078a-7beb-47c5-bcee-2de264ef3266",
-    "metadata": {},
-    "source": [
-     "#### Now start Envoy processes in a loop"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "843f698e-5582-4918-828c-cf095988da92",
-    "metadata": {
-     "tags": []
-    },
-    "outputs": [],
-    "source": [
-     "# envoy_workspace_path = Path('../envoy/').absolute()\n",
-     "def start_envoys(config_paths: List[Path]) -> None:\n",
-     "    envoy_workspace_path = config_paths[0].parent\n",
-     "    cwd = Path.cwd()\n",
-     "    os.chdir(envoy_workspace_path)\n",
-     "    for i, path in enumerate(config_paths):\n",
-     "        os.system(f'fx envoy start -n env_{i + 1} --disable-tls '\n",
-     "                  f'--envoy-config-path {path} -dh localhost -dp 50049 '\n",
-     "                  f'>env_{i + 1}.log &')\n",
-     "    os.chdir(cwd)\n",
-     "\n",
-     "sleep(5)\n",
-     "\n",
-     "start_envoys(config_paths)\n",
-     "\n",
-     "sleep(25)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "6216f14c-78d8-444c-9144-ee8316d1487b",
-    "metadata": {},
-    "source": [
-     "## 2. Connect to the Director service of out Federation as Data scientist"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "b9d3b764-cb86-4eec-ba8e-df119da7a27f",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Create a federation\n",
-     "from openfl.interface.interactive_api.federation import Federation\n",
-     "\n",
-     "# please use the same identificator that was used in signed certificate\n",
-     "client_id = 'frontend'\n",
-     "director_node_fqdn = 'localhost'\n",
-     "director_port = 50049\n",
-     "\n",
-     "federation = Federation(\n",
-     "    client_id=client_id,\n",
-     "    director_node_fqdn=director_node_fqdn,\n",
-     "    director_port=director_port,\n",
-     "    tls=False\n",
-     ")"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "1bed370b-d0c0-46bc-8114-ea8255b2478b",
-    "metadata": {
-     "tags": []
-    },
-    "outputs": [],
-    "source": [
-     "# Data scientist may request a list of connected envoys\n",
-     "shard_registry = federation.get_shard_registry()\n",
-     "\n",
-     "# WARNING!\n",
-     "\n",
-     "# Make sure shard registry contains all the envoys you started!\n",
-     "# In other case try rereconnecting to the Director (the cell above).\n",
-     "shard_registry"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "c6401026-795f-491e-90cb-dd59b451df5f",
-    "metadata": {},
-    "source": [
-     "### Now we will prepare an FL experimnet using OpenFL Python API"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "8166c689-9dde-4500-b05c-5b1ddf968978",
-    "metadata": {},
-    "source": [
-     "### Data"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "55fb1a98-b44f-47ff-950d-5a40a1cca0d8",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment\n",
-     "\n",
-     "class LinRegDataSet(DataInterface):\n",
-     "    def __init__(self, **kwargs):\n",
-     "        \"\"\"Initialize DataLoader.\"\"\"\n",
-     "        self.kwargs = kwargs\n",
-     "        pass\n",
-     "\n",
-     "    @property\n",
-     "    def shard_descriptor(self):\n",
-     "        \"\"\"Return shard descriptor.\"\"\"\n",
-     "        return self._shard_descriptor\n",
-     "    \n",
-     "    @shard_descriptor.setter\n",
-     "    def shard_descriptor(self, shard_descriptor):\n",
-     "        \"\"\"\n",
-     "        Describe per-collaborator procedures or sharding.\n",
-     "\n",
-     "        This method will be called during a collaborator initialization.\n",
-     "        Local shard_descriptor  will be set by Envoy.\n",
-     "        \"\"\"\n",
-     "        self._shard_descriptor = shard_descriptor\n",
-     "        self.train_set = shard_descriptor.get_dataset(\"train\")\n",
-     "        self.val_set = shard_descriptor.get_dataset(\"val\")\n",
-     "\n",
-     "    def get_train_loader(self, **kwargs):\n",
-     "        \"\"\"Output of this method will be provided to tasks with optimizer in contract.\"\"\"\n",
-     "        return self.train_set\n",
-     "\n",
-     "    def get_valid_loader(self, **kwargs):\n",
-     "        \"\"\"Output of this method will be provided to tasks without optimizer in contract.\"\"\"\n",
-     "        return self.val_set\n",
-     "\n",
-     "    def get_train_data_size(self):\n",
-     "        \"\"\"Information for aggregation.\"\"\"\n",
-     "        return len(self.train_set)\n",
-     "\n",
-     "    def get_valid_data_size(self):\n",
-     "        \"\"\"Information for aggregation.\"\"\"\n",
-     "        return len(self.val_set)\n",
-     "    \n",
-     "lin_reg_dataset = LinRegDataSet()"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "6233e1ed-a2f2-456f-9417-f35a2c27b236",
-    "metadata": {},
-    "source": [
-     "### Model"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "885a8530-6248-4060-a30a-45cdc79bc41a",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "framework_adapter = 'custom_adapter.CustomFrameworkAdapter'\n",
-     "fed_model = LinRegLasso(1)\n",
-     "MI = ModelInterface(model=fed_model, optimizer=None, framework_plugin=framework_adapter)\n",
-     "\n",
-     "# Save the initial model state\n",
-     "initial_model = LinRegLasso(1)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "dc9da235-02a8-4e7a-9455-5fe2462aa317",
-    "metadata": {
-     "tags": []
-    },
-    "source": [
-     "### Tasks\n",
-     "Using an Optimizer does not make sense for this experiment. Yet it is a required part of a training task contract in the current version of OpenFL, so we just pass None.\n",
-     "We need to employ a trick reporting metrics. OpenFL decides which model is the best based on an *increasing* metric."
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "7e101689-8a63-4562-98ff-09443b1ab9f2",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "TI = TaskInterface()\n",
-     "\n",
-     "@TI.add_kwargs(**{'lr': 0.001,\n",
-     "                   'wd': 0.0001,\n",
-     "                   'epoches': 1})\n",
-     "@TI.register_fl_task(model='my_model', data_loader='train_data', \\\n",
-     "                     device='device', optimizer='optimizer')     \n",
-     "def train(my_model, train_data, optimizer, device, lr, wd, epoches):\n",
-     "    X, Y = train_data[:,:-1], train_data[:,-1]\n",
-     "    my_model.fit(X, Y, epochs, lr, wd, silent=True)\n",
-     "    return {'train_MSE': my_model.mse(X, Y),}\n",
-     "\n",
-     "@TI.register_fl_task(model='my_model', data_loader='val_data', device='device')     \n",
-     "def validate(my_model, val_data, device):\n",
-     "    X, Y = val_data[:,:-1], val_data[:,-1]        \n",
-     "    return {'validation_MSE': my_model.mse(X, Y),}"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "40a4623e-6559-4d4c-b199-f9afe16c0bbd",
-    "metadata": {
-     "tags": []
-    },
-    "source": [
-     "### Run"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "fb357a88-7098-45b2-85f4-71fe2f2e0f82",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "experiment_name = 'linear_regression_experiment'\n",
-     "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name,\n",
-     "                            )"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "db20124a-949d-4218-abfd-aaf4d0758284",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "fl_experiment.start(model_provider=MI, \n",
-     "                    task_keeper=TI,\n",
-     "                    data_loader=lin_reg_dataset,\n",
-     "                    rounds_to_train=10,)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "4909be2b-d23b-4356-b2af-10a212382d52",
-    "metadata": {
-     "tags": []
-    },
-    "outputs": [],
-    "source": [
-     "# This method not only prints messages recieved from the director, \n",
-     "# but also saves logs in the tensorboard format (by default)\n",
-     "fl_experiment.stream_metrics()"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "dd479019-1579-42c4-a446-f7d0a12596df",
-    "metadata": {
-     "tags": []
-    },
-    "source": [
-     "### Optional: start tensorboard"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "a6faaaea",
-    "metadata": {},
-    "source": [
-     "Locally, start tensorboard in background and open localhost:6006 in your browser:"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "c5f4b673-e6b1-4bbe-8294-d2b61a65d40b",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "%%script /bin/bash --bg\n",
-     "tensorboard --host $(hostname --all-fqdns | awk '{print $1}') --logdir logs"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "68867a02",
-    "metadata": {},
-    "source": [
-     "In Google Colab you may use the inline extension "
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "f3684b26",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "%load_ext tensorboard\n",
-     "%tensorboard --logdir logs"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "b4d27834-ec5b-4290-8c9d-4c3c5589a7e6",
-    "metadata": {},
-    "source": [
-     "### 3. Retrieve the trained model from the Director"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "ad915ab3-0032-4a06-b2c0-00710585e24d",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "last_model = fl_experiment.get_last_model()\n",
-     "best_model = fl_experiment.get_best_model()\n",
-     "print(best_model.weights)\n",
-     "print(last_model.weights)\n",
-     "print(f\"last model MSE: {last_model.mse(x,y)}\")\n",
-     "print(f\"best model MSE: {best_model.mse(x,y)}\")"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "1930789e-b7b5-415e-844d-14ccc3844482",
-    "metadata": {},
-    "source": [
-     "## Lets see what does the unified dataset looks like\n",
-     "And see how the trained model performs."
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "c51e8a56-d2f1-4758-a5a1-6d6652e4355e",
-    "metadata": {
-     "tags": []
-    },
-    "outputs": [],
-    "source": [
-     "n_cols = n_cols\n",
-     "n_samples = n_samples_per_col\n",
-     "interval = 240\n",
-     "x_start = 60\n",
-     "noise = noise\n",
-     "\n",
-     "X = None\n",
-     "\n",
-     "for rank in range(n_cols):\n",
-     "    np.random.seed(rank)  # Setting seed for reproducibility\n",
-     "    x = np.random.rand(n_samples, 1) * interval + x_start\n",
-     "    x *= np.pi / 180\n",
-     "    X = x if X is None else np.vstack((X,x))\n",
-     "    y = np.sin(x) + np.random.normal(0, noise, size=(n_samples, 1))\n",
-     "    plt.plot(x,y,'+')\n",
-     "    \n",
-     "X.sort()    \n",
-     "Y_hat = last_model.predict(X)\n",
-     "plt.plot(X,Y_hat,'--')"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "9e365766-4ea6-40bc-96ae-a183274e8b8c",
-    "metadata": {},
-    "source": [
-     "## Cleaning"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "e5d793be-6c20-4a22-bad7-c082c1ee76ca",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# To stop all services run\n",
-     "!pkill fx"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "809b8eb3-4775-43d9-8f96-de84a089a54e",
-    "metadata": {
-     "tags": []
-    },
-    "outputs": [],
-    "source": [
-     "remove_configs(config_paths)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "d0b28b29-48d3-4f21-bc69-40259b83f93b",
-    "metadata": {},
-    "outputs": [],
-    "source": []
-   }
-  ],
-  "metadata": {
-   "kernelspec": {
-    "display_name": "Python 3 (ipykernel)",
-    "language": "python",
-    "name": "python3"
-   },
-   "language_info": {
-    "codemirror_mode": {
-     "name": "ipython",
-     "version": 3
-    },
-    "file_extension": ".py",
-    "mimetype": "text/x-python",
-    "name": "python",
-    "nbconvert_exporter": "python",
-    "pygments_lexer": "ipython3",
-    "version": "3.8.10"
-   }
-  },
-  "nbformat": 4,
-  "nbformat_minor": 5
- }
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/numpy_linear_regression/workspace/start_federation.ipynb ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/numpy_linear_regression/workspace/start_federation.ipynb
*** ./openfl/openfl-tutorials/interactive_api/numpy_linear_regression/workspace/start_federation.ipynb	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/numpy_linear_regression/workspace/start_federation.ipynb	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,193 ****
- {
-  "cells": [
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "f813b6ae-b082-49bb-b64f-fd619b6de14a",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import os\n",
-     "from pathlib import Path\n",
-     "import yaml\n",
-     "from typing import Dict, List, Union"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "d1ee62ab-09e4-4f4c-984f-bdb6909d6106",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Read the original envoy config file content\n",
-     "with open(Path('../envoy/envoy_config.yaml'), \"r\") as stream:\n",
-     "    orig_config = yaml.safe_load(stream)\n",
-     "\n",
-     "def generate_envoy_configs(config: Dict,\n",
-     "                           save_path: Union[str, Path] = '../envoy/',\n",
-     "                           n_cols: int = 10,\n",
-     "                           n_samples_per_col: int = 10,\n",
-     "                           noise: float = 0.15) -> List[Path]:\n",
-     "\n",
-     "    config['shard_descriptor']['params']['n_samples'] = n_samples_per_col\n",
-     "    config['shard_descriptor']['params']['noise'] = noise\n",
-     "    \n",
-     "    config_paths = [(Path(save_path) / f'{i}_envoy_config.yaml').absolute()\n",
-     "                for i in range(1, n_cols + 1)]\n",
-     "\n",
-     "    for i, path in enumerate(config_paths):\n",
-     "        config['shard_descriptor']['params']['rank'] = i\n",
-     "        with open(path, \"w\") as stream:\n",
-     "            yaml.safe_dump(config, stream)\n",
-     "            \n",
-     "    return config_paths\n",
-     "            \n",
-     "def remove_configs(config_paths):\n",
-     "    for path in config_paths:\n",
-     "        path.unlink()"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "0d058340-22d4-4630-b8e3-9c3fc29198ab",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "config_paths = generate_envoy_configs(orig_config, n_cols=20, n_samples_per_col=8, noise=0.3)\n",
-     "# remove_configs(config_paths)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "ec065be9-c2c6-4a81-9a2a-ea54794e52ba",
-    "metadata": {},
-    "source": [
-     "## Start the Director service"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "60bcaa49-aabb-42ec-a279-9e32b31ce6ca",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "cwd = Path.cwd()\n",
-     "director_workspace_path = Path('../director/').absolute()\n",
-     "director_config_file = director_workspace_path / 'director_config.yaml'\n",
-     "director_logfile = director_workspace_path / 'director.log'\n",
-     "director_logfile.unlink(missing_ok=True)\n",
-     "# \n",
-     "\n",
-     "os.environ['main_folder'] = str(cwd)\n",
-     "os.environ['director_workspace_path'] = str(director_workspace_path)\n",
-     "os.environ['director_logfile'] = str(director_logfile)\n",
-     "os.environ['director_config_file'] = str(director_config_file)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "72a9268a-ee1e-4dda-a4c4-cfb29428f45e",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "%%script /bin/bash --bg\n",
-     "cd $director_workspace_path\n",
-     "fx director start --disable-tls -c $director_config_file > $director_logfile &\n",
-     "cd $main_folder"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "e0a634ea-9c62-4048-bb91-099fe9097b55",
-    "metadata": {},
-    "source": [
-     "## Start Envoys"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "13470bfd-d67e-48dc-b1ff-10c7ff526c0c",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# envoy_workspace_path = Path('../envoy/').absolute()\n",
-     "def start_envoys(config_paths: List[Path]) -> None:\n",
-     "    envoy_workspace_path = config_paths[0].parent\n",
-     "    cwd = Path.cwd()\n",
-     "    os.chdir(envoy_workspace_path)\n",
-     "    for i, path in enumerate(config_paths):\n",
-     "        os.system(f'fx envoy start -n env_{i + 1} --disable-tls '\n",
-     "                  f'--envoy-config-path {path} -dh localhost -dp 50049 '\n",
-     "                  f'>env_{i + 1}.log &')\n",
-     "    os.chdir(cwd)\n",
-     "    \n",
-     "start_envoys(config_paths)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "2fc8a569-6978-4c80-88d1-741799407239",
-    "metadata": {},
-    "outputs": [],
-    "source": []
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "a5fdc3af-63b5-41b5-b9d6-be2aac8626e0",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# To stop all services run\n",
-     "!pkill fx"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "4e69ae57-bfa3-4047-af7f-3e1cf24ac35e",
-    "metadata": {
-     "tags": []
-    },
-    "outputs": [],
-    "source": [
-     "remove_configs(config_paths)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "46095127-f116-4ae3-a3b4-6be24064b49f",
-    "metadata": {},
-    "outputs": [],
-    "source": []
-   }
-  ],
-  "metadata": {
-   "kernelspec": {
-    "display_name": "Python 3 (ipykernel)",
-    "language": "python",
-    "name": "python3"
-   },
-   "language_info": {
-    "codemirror_mode": {
-     "name": "ipython",
-     "version": 3
-    },
-    "file_extension": ".py",
-    "mimetype": "text/x-python",
-    "name": "python",
-    "nbconvert_exporter": "python",
-    "pygments_lexer": "ipython3",
-    "version": "3.8.10"
-   }
-  },
-  "nbformat": 4,
-  "nbformat_minor": 5
- }
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/director/director_config.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/director/director_config.yaml
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/director/director_config.yaml	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/director/director_config.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,5 ****
- settings:
-   listen_host: localhost
-   listen_port: 50051
-   sample_shape: ['300', '300', '3']
-   target_shape: ['1']
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/director/start_director.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/director/start_director.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/director/start_director.sh	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/director/start_director.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- 
- fx director start --disable-tls -c director_config.yaml
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/envoy/dogs_cats_shard_descriptor.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/envoy/dogs_cats_shard_descriptor.py
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/envoy/dogs_cats_shard_descriptor.py	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/envoy/dogs_cats_shard_descriptor.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,183 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Cats and dogs shard descriptor."""
- 
- import json
- import os
- import shutil
- from hashlib import md5
- from logging import getLogger
- from pathlib import Path
- from random import shuffle
- from typing import Optional
- from zipfile import ZipFile
- 
- import numpy as np
- from kaggle.api.kaggle_api_extended import KaggleApi
- from PIL import Image
- 
- from openfl.interface.interactive_api.shard_descriptor import ShardDataset
- from openfl.interface.interactive_api.shard_descriptor import ShardDescriptor
- 
- logger = getLogger(__name__)
- 
- 
- class DogsCatsShardDataset(ShardDataset):
-     """Dogs and cats Shard dataset class."""
- 
-     def __init__(self, data_type: str, dataset_dir: Path,
-                  rank: int = 1, worldsize: int = 1, enforce_image_hw=None):
-         """Initialize DogsCatsShardDataset."""
-         self.rank = rank
-         self.worldsize = worldsize
-         self.dataset_dir = dataset_dir
-         self.enforce_image_hw = enforce_image_hw
-         self.img_path = self.dataset_dir / data_type
- 
-         self.img_names = [
-             img.name
-             for img in sorted(self.img_path.iterdir())
-             if img.suffix == '.jpg'
-         ]
- 
-         # Sharding
-         self.img_names = self.img_names[self.rank - 1::self.worldsize]
-         # Shuffling the results dataset after choose half pictures of each class
-         shuffle(self.img_names)
- 
-     def __getitem__(self, index):
-         """Return a item by the index."""
-         name = self.img_names[index]
-         # Reading data
-         img = Image.open(self.img_path / name)
-         img_class = 1 if name[:3] == 'dog' else 0
-         assert name[:3] in {'cat', 'dog'}, 'Wrong object classification'
- 
-         if self.enforce_image_hw is not None:
-             # If we need to resize data
-             # PIL accepts (w,h) tuple, not (h,w)
-             img = img.resize(self.enforce_image_hw[::-1])
- 
-         img = np.asarray(img)
- 
-         assert img.shape[2] == 3
- 
-         return img, np.asarray([img_class], dtype=np.uint8)
- 
-     def __len__(self):
-         """Return the len of the dataset."""
-         return len(self.img_names)
- 
- 
- class DogsCatsShardDescriptor(ShardDescriptor):
-     """Shard descriptor class."""
- 
-     def __init__(self, data_folder: str = 'data',
-                  rank_worldsize: str = '1,3',
-                  enforce_image_hw: Optional[str] = None) -> None:
-         """Initialize DogsCatsShardDescriptor."""
-         super().__init__()
-         # Settings for sharding the dataset
-         self.rank, self.worldsize = map(int, rank_worldsize.split(','))
- 
-         self.data_folder = Path.cwd() / data_folder
-         self.download_dataset()
- 
-         # Settings for resizing data
-         self.enforce_image_hw = None
-         if enforce_image_hw is not None:
-             self.enforce_image_hw = tuple(map(int, enforce_image_hw.split(',')))
- 
-         # Calculating data and target shapes
-         ds = self.get_dataset()
-         sample, target = ds[0]
-         self._sample_shape = [str(dim) for dim in sample.shape]
-         self._target_shape = [str(*target.shape)]
- 
-         assert self._target_shape[0] == '1', 'Target shape Error'
- 
-     def download_dataset(self):
-         """Download dataset from Kaggle."""
-         if not os.path.exists(self.data_folder):
-             os.mkdir(self.data_folder)
- 
-         if not self.is_dataset_complete():
-             logger.info('Your dataset is absent or damaged. Downloading ... ')
-             api = KaggleApi()
-             api.authenticate()
- 
-             if os.path.exists('data/train'):
-                 shutil.rmtree('data/train')
- 
-             api.competition_download_file(
-                 'dogs-vs-cats-redux-kernels-edition',
-                 'train.zip', path=self.data_folder
-             )
- 
-             with ZipFile(self.data_folder / 'train.zip', 'r') as zipobj:
-                 zipobj.extractall(self.data_folder)
- 
-             os.remove(self.data_folder / 'train.zip')
- 
-             self.save_all_md5()
- 
-     def get_dataset(self, dataset_type='train'):
-         """Return a shard dataset by type."""
-         return DogsCatsShardDataset(
-             data_type=dataset_type,
-             dataset_dir=self.data_folder,
-             rank=self.rank,
-             worldsize=self.worldsize,
-             enforce_image_hw=self.enforce_image_hw
-         )
- 
-     def calc_all_md5(self):
-         """Calculate hash of all dataset."""
-         md5_dict = {}
-         for root, _, files in os.walk(self.data_folder):
-             for file in files:
-                 if file == 'dataset.json':
-                     continue
-                 md5_calc = md5()
-                 rel_dir = os.path.relpath(root, self.data_folder)
-                 rel_file = os.path.join(rel_dir, file)
- 
-                 with open(self.data_folder / rel_file, 'rb') as f:
-                     for chunk in iter(lambda: f.read(4096), b''):
-                         md5_calc.update(chunk)
-                     md5_dict[rel_file] = md5_calc.hexdigest()
-         return md5_dict
- 
-     def save_all_md5(self):
-         """Save dataset hash."""
-         all_md5 = self.calc_all_md5()
-         with open(os.path.join(self.data_folder, 'dataset.json'), 'w') as f:
-             json.dump(all_md5, f)
- 
-     def is_dataset_complete(self):
-         """Check dataset integrity."""
-         new_md5 = self.calc_all_md5()
-         try:
-             with open(os.path.join(self.data_folder, 'dataset.json'), 'r') as f:
-                 old_md5 = json.load(f)
-         except FileNotFoundError:
-             return False
- 
-         return new_md5 == old_md5
- 
-     @property
-     def sample_shape(self):
-         """Return the sample shape info."""
-         return self._sample_shape
- 
-     @property
-     def target_shape(self):
-         """Return the target shape info."""
-         return self._target_shape
- 
-     @property
-     def dataset_description(self) -> str:
-         """Return the dataset description."""
-         return (f'Dogs and Cats dataset, shard number {self.rank} '
-                 f'out of {self.worldsize}')
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/envoy/envoy_config_one.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/envoy/envoy_config_one.yaml
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/envoy/envoy_config_one.yaml	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/envoy/envoy_config_one.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,14 ****
- params:
-   cuda_devices: [0]
-   
- optional_plugin_components:
-  cuda_device_monitor:
-    template: openfl.plugins.processing_units_monitor.pynvml_monitor.PynvmlCUDADeviceMonitor
-    settings: []
- 
- shard_descriptor:
-   template: dogs_cats_shard_descriptor.DogsCatsShardDescriptor
-   params:
-     data_folder: data
-     rank_worldsize: 1,2
-     enforce_image_hw: '300,300'
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/envoy/envoy_config_two.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/envoy/envoy_config_two.yaml
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/envoy/envoy_config_two.yaml	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/envoy/envoy_config_two.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,14 ****
- params:
-   cuda_devices: [1]
-   
- optional_plugin_components:
-  cuda_device_monitor:
-    template: openfl.plugins.processing_units_monitor.pynvml_monitor.PynvmlCUDADeviceMonitor
-    settings: []
- 
- shard_descriptor:
-   template: dogs_cats_shard_descriptor.DogsCatsShardDescriptor
-   params:
-     data_folder: data
-     rank_worldsize: 2,2
-     enforce_image_hw: '300,300'
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/envoy/sd_requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/envoy/sd_requirements.txt
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/envoy/sd_requirements.txt	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/envoy/sd_requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- numpy
- pillow
- pynvml
- kaggle
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/envoy/start_envoy.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/envoy/start_envoy.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/envoy/start_envoy.sh	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/envoy/start_envoy.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- 
- fx envoy start -n env_one --disable-tls --envoy-config-path envoy_config_one.yaml -dh localhost -dp 50051
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/README.md ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/README.md
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/README.md	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/README.md	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,84 ****
- # Dogs vs. Cats tutorial based on [vit_pytorch](https://github.com/lucidrains/vit-pytorch) library
- 
- ***Note: Please pay attention that this task uses the dataset from Kaggle. To get the dataset you
- will need a Kaggle account and accept "Dogs vs. Cats" competition rules.***
- 
- Visual Transformers are gaining popularity among the Data Science community, so this tutorial is
- intended to examine Visual Transformer behavior in Federated Learning setup.
- 
- ## Installation of Kaggle API credentials
- 
- **Before the start please make sure that you installed sd_requirements.txt on your virtual
- environment on an envoy machine.**
- 
- To use the [Kaggle API](https://github.com/Kaggle/kaggle-api), sign up for
- a [Kaggle account](https://www.kaggle.com). Then go to the `'Account'` tab of your user
- profile `(https://www.kaggle.com/<username>/account)` and select `'Create API Token'`. This will
- trigger the download of `kaggle.json`, a file containing your API credentials. Place this file in
- the location `cd ~/.kaggle/kaggle.json`
- 
- **Note: you will need to accept competition rules
- at** https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/rules
- 
- For your security, ensure that other users of your computer do not have read access to your
- credentials. On Unix-based systems you can do this with the following command:
- 
- `chmod 600 ~/.kaggle/kaggle.json`
- 
- If you need proxy add "proxy": `"http://<ip_addr:port>" in kaggle.json`. It should looks like
- that: `{"username":"your_username","key":"token", "proxy": "ip_addr:port"}`
- 
- *Information about Kaggle API settings has been taken from kagge-api readme. For more information
- visit:* https://github.com/Kaggle/kaggle-api
- 
- *Useful link for a problem with proxy settings:* https://github.com/Kaggle/kaggle-api/issues/6
- 
- ### Data
- 
- All information about the dataset you may find
- on https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/overview
- 
- ### Run experiment
- 
- 1. Create a folder for each `envoy`.
- 2. Put a relevant envoy_config in each of the n folders (n - number of envoys which you would like
-    to use, in this tutorial there is two of them, but you may use any number of envoys) and copy
-    other files from `envoy` folder there as well.
- 3. Modify each `envoy` accordingly:
- 
-     - At `start_envoy.sh` change env_one to env_two (or any unique `envoy` names you like)
- 
-     - Put a relevant envoy_config `envoy_config_one.yaml` or `envoy_config_two.yaml` (or any other
-       config file name consistent to the configuration file that is called in `start_envoy.sh`).
- 4. Make sure that you installed requirements for each `envoy` in your virtual
-    environment: `pip install -r sd_requirements.txt`
- 5. Run the `director`: execute `start_director.sh` in director folder
- 6. Run the `envoys`: execute `start_envoy.sh` in each envoy folder. If kaggle-API setting are
-    correct the download of the dataset will be started. If this is not the first `envoy` launch
-    then the dataset will be redownloaded only if some part of the data are missing.
- 7. Run the [PyTorch_DogsCats_ViT.ipynb](workspace/PyTorch_DogsCats_ViT.ipynb) notebook using
-    Jupyter lab in a prepared virtual environment. For more information about preparation virtual
-    environment look [**
-    Preparation virtual environment**](#preparation-virtual-environment)
-    .
- 8. Congratulations! You've started your federated learning of Visual Transformer with OpenFL.
- 
- ### Preparation virtual environment
- 
- * Create virtual environment
- 
- ```sh
-     python3 -m venv venv
- ```
- 
- * To activate virtual environment
- 
- ```sh
-     source venv/bin/activate
- ```
- 
- * To deactivate virtual environment
- 
- ```sh
-     deactivate
- ```
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/workspace/PyTorch_DogsCats_ViT.ipynb ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/workspace/PyTorch_DogsCats_ViT.ipynb
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/workspace/PyTorch_DogsCats_ViT.ipynb	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/workspace/PyTorch_DogsCats_ViT.ipynb	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,558 ****
- {
-  "cells": [
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "# Visual Transformer + OpenFL for Dogs & Cats classification"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Install dependencies if not already installed\n",
-     "!pip install -r requirements.txt"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "## Import Libraries"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import os\n",
-     "import random\n",
-     "from copy import deepcopy\n",
-     "\n",
-     "from linformer import Linformer\n",
-     "\n",
-     "import numpy as np\n",
-     "\n",
-     "import torch\n",
-     "import torch.nn as nn\n",
-     "import torch.optim as optim\n",
-     "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
-     "from torch.optim.lr_scheduler import StepLR\n",
-     "\n",
-     "from torchvision import transforms\n",
-     "\n",
-     "import tqdm\n",
-     "\n",
-     "from vit_pytorch.efficient import ViT"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "# Connect to the Federation"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Create a federation\n",
-     "from openfl.interface.interactive_api.federation import Federation\n",
-     "\n",
-     "# please use the same identificator that was used in signed certificate\n",
-     "client_id = 'api'\n",
-     "director_node_fqdn = 'localhost'\n",
-     "director_port = 50051\n",
-     "\n",
-     "# 1) Run with API layer - Director mTLS\n",
-     "# If the user wants to enable mTLS their must provide CA root chain,\n",
-     "# and signed key pair to the federation interface\n",
-     "# cert_chain = 'cert/root_ca.crt'\n",
-     "# API_certificate = 'cert/frontend.crt'\n",
-     "# API_private_key = 'cert/frontend.key'\n",
-     "\n",
-     "# federation = Federation(\n",
-     "#     client_id=client_id,\n",
-     "#     director_node_fqdn=director_node_fqdn,\n",
-     "#     director_port=director_port,\n",
-     "#     tls=True,\n",
-     "#     cert_chain=cert_chain,\n",
-     "#     api_cert=api_certificate,\n",
-     "#     api_private_key=api_private_key\n",
-     "# )\n",
-     "\n",
-     "# --------------------------------------------------------------------------------------------------------------------\n",
-     "\n",
-     "# 2) Run with TLS disabled (trusted environment)\n",
-     "# Federation can also determine local fqdn automatically\n",
-     "federation = Federation(\n",
-     "    client_id=client_id,\n",
-     "    director_node_fqdn=director_node_fqdn,\n",
-     "    director_port=director_port,\n",
-     "    tls=False\n",
-     ")"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "shard_registry = federation.get_shard_registry()\n",
-     "shard_registry"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "federation.target_shape"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# First, request a dummy_shard_desc that holds information about the federated dataset\n",
-     "dummy_shard_desc = federation.get_dummy_shard_descriptor(size=10)\n",
-     "dummy_shard_dataset = dummy_shard_desc.get_dataset('train')\n",
-     "sample, target = dummy_shard_dataset[0]\n",
-     "f\"Sample shape: {sample.shape}, target shape: {target.shape}\""
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "## Creating a FL experiment using Interactive API"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from openfl.interface.interactive_api.experiment import DataInterface, FLExperiment, ModelInterface, TaskInterface"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Training settings\n",
-     "batch_size = 64\n",
-     "lr = 3e-5\n",
-     "seed = 42"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "def seed_everything(seed):\n",
-     "    random.seed(seed)\n",
-     "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
-     "    np.random.seed(seed)\n",
-     "    torch.manual_seed(seed)\n",
-     "    torch.cuda.manual_seed(seed)\n",
-     "    torch.cuda.manual_seed_all(seed)\n",
-     "    torch.backends.cudnn.deterministic = True\n",
-     "\n",
-     "\n",
-     "seed_everything(seed)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "### Register dataset"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "class DogsCatsShardDataset(Dataset):\n",
-     "    def __init__(self, dataset, transform_type=\"train\"):\n",
-     "        self._dataset = dataset\n",
-     "\n",
-     "        # Image Augumentation\n",
-     "        if transform_type == \"train\":\n",
-     "            self.transform = transforms.Compose(\n",
-     "                [\n",
-     "                    transforms.ToPILImage(),\n",
-     "                    transforms.Resize((224, 224)),\n",
-     "                    transforms.RandomResizedCrop(224),\n",
-     "                    transforms.RandomHorizontalFlip(),\n",
-     "                    transforms.ToTensor(),\n",
-     "                ]\n",
-     "            )\n",
-     "        elif transform_type == \"val\":\n",
-     "            self.transform = transforms.Compose(\n",
-     "                [\n",
-     "                    transforms.ToPILImage(),\n",
-     "                    transforms.Resize(256),\n",
-     "                    transforms.CenterCrop(224),\n",
-     "                    transforms.ToTensor(),\n",
-     "                ]\n",
-     "            )\n",
-     "        elif transform_type == \"test\":\n",
-     "            self.transform = transforms.Compose(\n",
-     "                [\n",
-     "                    transforms.ToPILImage(),\n",
-     "                    transforms.Resize(256),\n",
-     "                    transforms.CenterCrop(224),\n",
-     "                    transforms.ToTensor(),\n",
-     "                ]\n",
-     "            )\n",
-     "        else:\n",
-     "            raise ValueError(\"Invalid transform type: {}\".format(transform_type))\n",
-     "\n",
-     "    def __len__(self):\n",
-     "        self.filelength = len(self._dataset)\n",
-     "        return self.filelength\n",
-     "\n",
-     "    def __getitem__(self, idx):\n",
-     "        img, label = self._dataset[idx]\n",
-     "        img_transformed = self.transform(img).numpy()\n",
-     "        return img_transformed, label[0]\n",
-     "\n",
-     "\n",
-     "# Now you can implement your data loaders using dummy_shard_desc\n",
-     "class DogsCatsSD(DataInterface):\n",
-     "\n",
-     "    def __init__(self, validation_fraction=1/5, **kwargs):\n",
-     "        super().__init__(**kwargs)\n",
-     "\n",
-     "        self.validation_fraction = validation_fraction\n",
-     "\n",
-     "    @property\n",
-     "    def shard_descriptor(self):\n",
-     "        return self._shard_descriptor\n",
-     "\n",
-     "    @shard_descriptor.setter\n",
-     "    def shard_descriptor(self, shard_descriptor):\n",
-     "        \"\"\"\n",
-     "        Describe per-collaborator procedures or sharding.\n",
-     "\n",
-     "        This method will be called during a collaborator initialization.\n",
-     "        Local shard_descriptor  will be set by Envoy.\n",
-     "        \"\"\"\n",
-     "        self._shard_descriptor = shard_descriptor\n",
-     "        self._shard_dataset = DogsCatsShardDataset(shard_descriptor.get_dataset('train'))\n",
-     "\n",
-     "        validation_size = max(1, int(len(self._shard_dataset) * self.validation_fraction))\n",
-     "\n",
-     "        self.train_indexes = np.arange(len(self._shard_dataset) - validation_size)\n",
-     "        self.val_indexes = np.arange(len(self._shard_dataset) - validation_size, len(self._shard_dataset))\n",
-     "\n",
-     "    def get_train_loader(self, **kwargs):\n",
-     "        \"\"\"\n",
-     "        Output of this method will be provided to tasks with optimizer in contract\n",
-     "        \"\"\"\n",
-     "        train_sampler = SubsetRandomSampler(self.train_indexes)\n",
-     "\n",
-     "        return DataLoader(\n",
-     "            self._shard_dataset,\n",
-     "            num_workers=8,\n",
-     "            batch_size=self.kwargs['train_bs'],\n",
-     "            sampler=train_sampler\n",
-     "        )\n",
-     "\n",
-     "    def get_valid_loader(self, **kwargs):\n",
-     "        \"\"\"\n",
-     "        Output of this method will be provided to tasks without optimizer in contract\n",
-     "        \"\"\"\n",
-     "        val_sampler = SubsetRandomSampler(self.val_indexes)\n",
-     "        return DataLoader(\n",
-     "            self._shard_dataset,\n",
-     "            num_workers=8,\n",
-     "            batch_size=self.kwargs['valid_bs'],\n",
-     "            sampler=val_sampler\n",
-     "        )\n",
-     "\n",
-     "    def get_train_data_size(self):\n",
-     "        \"\"\"\n",
-     "        Information for aggregation\n",
-     "        \"\"\"\n",
-     "        return len(self.train_indexes)\n",
-     "\n",
-     "    def get_valid_data_size(self):\n",
-     "        \"\"\"\n",
-     "        Information for aggregation\n",
-     "        \"\"\"\n",
-     "        return len(self.val_indexes)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "fed_dataset = DogsCatsSD(train_bs=batch_size, valid_bs=batch_size)\n",
-     "fed_dataset.shard_descriptor = dummy_shard_desc\n",
-     "for i, (sample, target) in enumerate(fed_dataset.get_train_loader()):\n",
-     "    print(sample.shape)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "### Describe a model and optimizer"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "#### Linformer"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "efficient_transformer = Linformer(\n",
-     "    dim=128,\n",
-     "    seq_len=49 + 1,  # 7x7 patches + 1 cls-token\n",
-     "    depth=12,\n",
-     "    heads=8,\n",
-     "    k=64\n",
-     ")"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "#### Visual Transformer"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "model = ViT(\n",
-     "    dim=128,\n",
-     "    image_size=224,\n",
-     "    patch_size=32,\n",
-     "    num_classes=2,\n",
-     "    transformer=efficient_transformer,\n",
-     "    channels=3,\n",
-     ")"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# loss function\n",
-     "criterion = nn.CrossEntropyLoss()\n",
-     "# optimizer\n",
-     "optimizer = optim.Adam(model.parameters(), lr=lr)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "#### Register model"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "framework_adapter = 'openfl.plugins.frameworks_adapters.pytorch_adapter.FrameworkAdapterPlugin'\n",
-     "MI = ModelInterface(model=model, optimizer=optimizer, framework_plugin=framework_adapter)\n",
-     "\n",
-     "# Save the initial model state\n",
-     "initial_model = deepcopy(model)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "### Define and register FL tasks"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from openfl.component.aggregation_functions import Median\n",
-     "\n",
-     "\n",
-     "TI = TaskInterface()\n",
-     "\n",
-     "\n",
-     "# The Interactive API supports registering functions definied in main module or imported.\n",
-     "def function_defined_in_notebook(some_parameter):\n",
-     "    print(f'Also I accept a parameter and it is {some_parameter}')\n",
-     "\n",
-     "\n",
-     "# The Interactive API supports overriding of the aggregation function\n",
-     "aggregation_function = Median()\n",
-     "\n",
-     "\n",
-     "# Task interface currently supports only standalone functions.\n",
-     "@TI.add_kwargs(**{'some_parameter': 42})\n",
-     "@TI.register_fl_task(model='model', data_loader='train_loader',\n",
-     "                     device='device', optimizer='optimizer', round_num='round_num')\n",
-     "@TI.set_aggregation_function(aggregation_function)\n",
-     "def train(model, train_loader, optimizer, round_num, device, loss_fn=criterion, some_parameter=None):\n",
-     "    function_defined_in_notebook(some_parameter)\n",
-     "    epoch_loss = 0\n",
-     "    epoch_accuracy = 0\n",
-     "\n",
-     "    # Be careful at the scheduler initialization stage makes 'step()', that's why: \n",
-     "    # * if you have one epoch per round DO NOT do 'scheduler.step()' at all.\n",
-     "    # * if you have several epoch per round, makes 'scheduler.step()' for all of them EXCEPT the last one.\n",
-     "    scheduler = StepLR(optimizer, step_size=1, gamma=0.1, verbose=True, last_epoch=round_num-1)\n",
-     "    train_loader = tqdm.tqdm(train_loader, desc=\"train\")\n",
-     "    model.train()\n",
-     "    model.to(device)\n",
-     "\n",
-     "    for data, target in train_loader:\n",
-     "        data, target = torch.tensor(data).to(device), torch.tensor(target).to(device, dtype=torch.long)\n",
-     "        optimizer.zero_grad()\n",
-     "        output = model(data)\n",
-     "        loss = loss_fn(output, target)\n",
-     "        loss.backward()\n",
-     "        optimizer.step()\n",
-     "\n",
-     "        acc = (output.argmax(dim=1) == target).float().mean()\n",
-     "        epoch_accuracy += acc.cpu().numpy() / len(train_loader)\n",
-     "        epoch_loss += loss.detach().cpu().numpy() / len(train_loader)\n",
-     "\n",
-     "    return {'loss': epoch_loss, 'accuracy': epoch_accuracy}\n",
-     "\n",
-     "\n",
-     "@TI.register_fl_task(model='model', data_loader='val_loader', device='device')\n",
-     "def validate(model, val_loader, device):\n",
-     "\n",
-     "    model.eval()\n",
-     "    model.to(device)\n",
-     "\n",
-     "    val_loader = tqdm.tqdm(val_loader, desc=\"validate\")\n",
-     "\n",
-     "    with torch.no_grad():\n",
-     "        epoch_val_accuracy = 0\n",
-     "        epoch_val_loss = 0\n",
-     "        for data, target in val_loader:\n",
-     "            data, target = torch.tensor(data).to(device), torch.tensor(target).to(device, dtype=torch.long)\n",
-     "            val_output = model(data)\n",
-     "            val_loss = criterion(val_output, target)\n",
-     "\n",
-     "            acc = (val_output.argmax(dim=1) == target).float().mean()\n",
-     "            epoch_val_accuracy += acc.cpu().numpy() / len(val_loader)\n",
-     "            epoch_val_loss += val_loss.detach().cpu().numpy() / len(val_loader)\n",
-     "\n",
-     "    return {'val_loss': epoch_val_loss, 'val_accuracy': epoch_val_accuracy}"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "metadata": {},
-    "source": [
-     "## Time to start a federated learning experiment"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# create an experimnet in federation\n",
-     "experiment_name = 'ViT_DogsCats_experiment'\n",
-     "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
-     "fl_experiment.start(model_provider=MI,\n",
-     "                    task_keeper=TI,\n",
-     "                    data_loader=fed_dataset,\n",
-     "                    rounds_to_train=5,\n",
-     "                    opt_treatment='CONTINUE_GLOBAL',\n",
-     "                    device_assignment_policy='CUDA_PREFERRED')"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# If user want to stop IPython session, then reconnect and check how experiment is going\n",
-     "# fl_experiment.restore_experiment_state(MI)\n",
-     "\n",
-     "fl_experiment.stream_metrics()"
-    ]
-   }
-  ],
-  "metadata": {
-   "interpreter": {
-    "hash": "9967838c9b78b23db9544bb47605a6e8593c36ad0f41631a68de5734b7160f0f"
-   },
-   "kernelspec": {
-    "display_name": "Python 3.8.9 64-bit ('openfl_Kvasir': venv)",
-    "name": "python3"
-   },
-   "language_info": {
-    "codemirror_mode": {
-     "name": "ipython",
-     "version": 3
-    },
-    "file_extension": ".py",
-    "mimetype": "text/x-python",
-    "name": "python",
-    "nbconvert_exporter": "python",
-    "pygments_lexer": "ipython3",
-    "version": "3.8.10"
-   },
-   "orig_nbformat": 4
-  },
-  "nbformat": 4,
-  "nbformat_minor": 2
- }
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/workspace/requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/workspace/requirements.txt
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/workspace/requirements.txt	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_DogsCats_ViT/workspace/requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- linformer==0.2.1
- torchvision==0.8.1
- vit-pytorch==0.22.0
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology/director/director_config.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology/director/director_config.yaml
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology/director/director_config.yaml	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology/director/director_config.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,5 ****
- settings:
-   listen_host: localhost
-   listen_port: 50051
-   sample_shape: ['150', '150']
-   target_shape: ['1']
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology/director/start_director.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology/director/start_director.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology/director/start_director.sh	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology/director/start_director.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- 
- fx director start --disable-tls -c director_config.yaml
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology/director/start_director_with_tls.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology/director/start_director_with_tls.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology/director/start_director_with_tls.sh	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology/director/start_director_with_tls.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- FQDN=$1
- fx director start -c director_config.yaml -rc cert/root_ca.crt -pk cert/"${FQDN}".key -oc cert/"${FQDN}".crt
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology/envoy/envoy_config.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology/envoy/envoy_config.yaml
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology/envoy/envoy_config.yaml	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology/envoy/envoy_config.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,10 ****
- params:
-   cuda_devices: []
- 
- optional_plugin_components: {}
- 
- shard_descriptor:
-   template: histology_shard_descriptor.HistologyShardDescriptor
-   params:
-     data_folder: histology_data
-     rank_worldsize: 1,2
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology/envoy/.gitignore ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology/envoy/.gitignore
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology/envoy/.gitignore	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology/envoy/.gitignore	1969-12-31 16:00:00.000000000 -0800
***************
*** 1 ****
- histology_data
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology/envoy/histology_shard_descriptor.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology/envoy/histology_shard_descriptor.py
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology/envoy/histology_shard_descriptor.py	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology/envoy/histology_shard_descriptor.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,130 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Histology Shard Descriptor."""
- 
- import logging
- import os
- from pathlib import Path
- from typing import Tuple
- from urllib.request import urlretrieve
- from zipfile import ZipFile
- 
- import numpy as np
- from PIL import Image
- 
- from openfl.interface.interactive_api.shard_descriptor import ShardDataset
- from openfl.interface.interactive_api.shard_descriptor import ShardDescriptor
- from openfl.utilities import tqdm_report_hook
- from openfl.utilities import validate_file_hash
- 
- 
- logger = logging.getLogger(__name__)
- 
- 
- class HistologyShardDataset(ShardDataset):
-     """Histology shard dataset class."""
- 
-     TRAIN_SPLIT_RATIO = 0.8
- 
-     def __init__(self, data_folder: Path, data_type='train', rank=1, worldsize=1):
-         """Histology shard dataset class."""
-         self.data_type = data_type
-         root = Path(data_folder) / 'Kather_texture_2016_image_tiles_5000'
-         classes = [d.name for d in root.iterdir() if d.is_dir()]
-         class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}
-         self.samples = []
-         root = root.expanduser()
-         for target_class in sorted(class_to_idx.keys()):
-             class_index = class_to_idx[target_class]
-             target_dir = os.path.join(root, target_class)
-             for class_root, _, fnames in sorted(os.walk(target_dir, followlinks=True)):
-                 for fname in sorted(fnames):
-                     path = os.path.join(class_root, fname)
-                     item = path, class_index
-                     self.samples.append(item)
- 
-         idx_range = list(range(len(self.samples)))
-         idx_sep = int(len(idx_range) * HistologyShardDataset.TRAIN_SPLIT_RATIO)
-         train_idx, test_idx = np.split(idx_range, [idx_sep])
-         if data_type == 'train':
-             self.idx = train_idx[rank - 1::worldsize]
-         else:
-             self.idx = test_idx[rank - 1::worldsize]
- 
-     def __len__(self) -> int:
-         """Return the len of the shard dataset."""
-         return len(self.idx)
- 
-     def load_pil(self, path):
-         """Load image."""
-         with open(path, 'rb') as f:
-             img = Image.open(f)
-             return img.convert('RGB')
- 
-     def __getitem__(self, index: int) -> Tuple['Image', int]:
-         """Return an item by the index."""
-         path, target = self.samples[self.idx[index]]
-         sample = self.load_pil(path)
-         return sample, target
- 
- 
- class HistologyShardDescriptor(ShardDescriptor):
-     """Shard descriptor class."""
- 
-     URL = ('https://zenodo.org/record/53169/files/Kather_'
-            'texture_2016_image_tiles_5000.zip?download=1')
-     FILENAME = 'Kather_texture_2016_image_tiles_5000.zip'
-     ZIP_SHA384 = ('7d86abe1d04e68b77c055820c2a4c582a1d25d2983e38ab724e'
-                   'ac75affce8b7cb2cbf5ba68848dcfd9d84005d87d6790')
-     DEFAULT_PATH = Path.home() / '.openfl' / 'data'
- 
-     def __init__(
-             self,
-             data_folder: Path = DEFAULT_PATH,
-             rank_worldsize: str = '1,1',
-             **kwargs
-     ):
-         """Initialize HistologyShardDescriptor."""
-         self.data_folder = Path.cwd() / data_folder
-         self.download_data()
-         self.rank, self.worldsize = tuple(int(num) for num in rank_worldsize.split(','))
- 
-     def download_data(self):
-         """Download prepared shard dataset."""
-         os.makedirs(self.data_folder, exist_ok=True)
-         filepath = self.data_folder / HistologyShardDescriptor.FILENAME
-         if not filepath.exists():
-             reporthook = tqdm_report_hook()
-             urlretrieve(HistologyShardDescriptor.URL, filepath, reporthook)  # nosec
-             validate_file_hash(filepath, HistologyShardDescriptor.ZIP_SHA384)
-             with ZipFile(filepath, 'r') as f:
-                 f.extractall(self.data_folder)
- 
-     def get_dataset(self, dataset_type):
-         """Return a shard dataset by type."""
-         return HistologyShardDataset(
-             data_folder=self.data_folder,
-             data_type=dataset_type,
-             rank=self.rank,
-             worldsize=self.worldsize
-         )
- 
-     @property
-     def sample_shape(self):
-         """Return the sample shape info."""
-         shape = self.get_dataset('train')[0][0].size
-         return [str(dim) for dim in shape]
- 
-     @property
-     def target_shape(self):
-         """Return the target shape info."""
-         target = self.get_dataset('train')[0][1]
-         shape = np.array([target]).shape
-         return [str(dim) for dim in shape]
- 
-     @property
-     def dataset_description(self) -> str:
-         """Return the shard dataset description."""
-         return (f'Histology dataset, shard number {self.rank}'
-                 f' out of {self.worldsize}')
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology/envoy/requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology/envoy/requirements.txt
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology/envoy/requirements.txt	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology/envoy/requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- Pillow==8.3.2
- tqdm==4.48.2
- numpy==1.19.1
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology/envoy/start_envoy.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology/envoy/start_envoy.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology/envoy/start_envoy.sh	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology/envoy/start_envoy.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- 
- fx envoy start -n env_one --disable-tls --envoy-config-path envoy_config.yaml -dh localhost -dp 50051
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology/envoy/start_envoy_with_tls.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology/envoy/start_envoy_with_tls.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology/envoy/start_envoy_with_tls.sh	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology/envoy/start_envoy_with_tls.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,6 ****
- #!/bin/bash
- set -e
- ENVOY_NAME=$1
- DIRECTOR_FQDN=$2
- 
- fx envoy start -n "$ENVOY_NAME" --envoy-config-path envoy_config.yaml -dh "$DIRECTOR_FQDN" -dp 50051 -rc cert/root_ca.crt -pk cert/"$ENVOY_NAME".key -oc cert/"$ENVOY_NAME".crt
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology/workspace/pytorch_histology.ipynb ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology/workspace/pytorch_histology.ipynb
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology/workspace/pytorch_histology.ipynb	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology/workspace/pytorch_histology.ipynb	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,496 ****
- {
-  "cells": [
-   {
-    "cell_type": "markdown",
-    "id": "26fdd9ed",
-    "metadata": {},
-    "source": [
-     "# Federated PyTorch Histology Tutorial"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "895288d0",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "!pip install torchvision==0.8.1"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "246f9c98",
-    "metadata": {},
-    "source": [
-     "## Connect to the Federation"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "d657e463",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Create a federation\n",
-     "from openfl.interface.interactive_api.federation import Federation\n",
-     "\n",
-     "# please use the same identificator that was used in signed certificate\n",
-     "client_id = 'api'\n",
-     "cert_dir = 'cert'\n",
-     "director_node_fqdn = 'localhost'\n",
-     "# 1) Run with API layer - Director mTLS \n",
-     "# If the user wants to enable mTLS their must provide CA root chain, and signed key pair to the federation interface\n",
-     "# cert_chain = f'{cert_dir}/root_ca.crt'\n",
-     "# api_certificate = f'{cert_dir}/{client_id}.crt'\n",
-     "# api_private_key = f'{cert_dir}/{client_id}.key'\n",
-     "\n",
-     "# federation = Federation(client_id=client_id, director_node_fqdn=director_node_fqdn, director_port='50051',\n",
-     "#                        cert_chain=cert_chain, api_cert=api_certificate, api_private_key=api_private_key)\n",
-     "\n",
-     "# --------------------------------------------------------------------------------------------------------------------\n",
-     "\n",
-     "# 2) Run with TLS disabled (trusted environment)\n",
-     "# Federation can also determine local fqdn automatically\n",
-     "federation = Federation(client_id=client_id, director_node_fqdn=director_node_fqdn, director_port='50051', tls=False)\n"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "1abebd90",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "federation.target_shape"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "47dcfab3",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "shard_registry = federation.get_shard_registry()\n",
-     "shard_registry"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "a2a6c237",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# First, request a dummy_shard_desc that holds information about the federated dataset \n",
-     "dummy_shard_desc = federation.get_dummy_shard_descriptor(size=10)\n",
-     "sample, target = dummy_shard_desc.get_dataset('train')[0]"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "cc0dbdbd",
-    "metadata": {},
-    "source": [
-     "## Creating a FL experiment using Interactive API"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "fc88700a",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "b0979470",
-    "metadata": {},
-    "source": [
-     "### Register dataset"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "7dda1680",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import torchvision\n",
-     "from torchvision import transforms as T\n",
-     "\n",
-     "normalize = T.Normalize(mean=[0.485, 0.456, 0.406],\n",
-     "                                 std=[0.229, 0.224, 0.225])\n",
-     "\n",
-     "augmentation = T.RandomApply(\n",
-     "    [T.RandomHorizontalFlip(),\n",
-     "     T.RandomRotation(10),\n",
-     "     T.RandomResizedCrop(64)], \n",
-     "    p=.8\n",
-     ")\n",
-     "\n",
-     "training_transform = T.ToTensor()\n",
-     "\n",
-     "valid_transform = T.ToTensor()\n"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "0314d5bf",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from torch.utils.data import Dataset\n",
-     "\n",
-     "\n",
-     "class TransformedDataset(Dataset):\n",
-     "    \"\"\"Image Person ReID Dataset.\"\"\"\n",
-     "\n",
-     "    def __init__(self, dataset, transform=None, target_transform=None):\n",
-     "        \"\"\"Initialize Dataset.\"\"\"\n",
-     "        self.dataset = dataset\n",
-     "        self.transform = transform\n",
-     "        self.target_transform = target_transform\n",
-     "\n",
-     "    def __len__(self):\n",
-     "        \"\"\"Length of dataset.\"\"\"\n",
-     "        return len(self.dataset)\n",
-     "\n",
-     "    def __getitem__(self, index):\n",
-     "        img, label = self.dataset[index]\n",
-     "        label = self.target_transform(label) if self.target_transform else label\n",
-     "        img = self.transform(img) if self.transform else img\n",
-     "        return img, label\n"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "01369e3b",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "class HistologyDataset(DataInterface):\n",
-     "    def __init__(self, **kwargs):\n",
-     "        self.kwargs = kwargs\n",
-     "    \n",
-     "    @property\n",
-     "    def shard_descriptor(self):\n",
-     "        return self._shard_descriptor\n",
-     "        \n",
-     "    @shard_descriptor.setter\n",
-     "    def shard_descriptor(self, shard_descriptor):\n",
-     "        \"\"\"\n",
-     "        Describe per-collaborator procedures or sharding.\n",
-     "\n",
-     "        This method will be called during a collaborator initialization.\n",
-     "        Local shard_descriptor  will be set by Envoy.\n",
-     "        \"\"\"\n",
-     "        self._shard_descriptor = shard_descriptor\n",
-     "        \n",
-     "        self.train_set = TransformedDataset(\n",
-     "            self._shard_descriptor.get_dataset('train'),\n",
-     "            transform=training_transform\n",
-     "        )\n",
-     "        self.valid_set = TransformedDataset(\n",
-     "            self._shard_descriptor.get_dataset('val'),\n",
-     "            transform=valid_transform\n",
-     "        )\n",
-     "        \n",
-     "    def get_train_loader(self, **kwargs):\n",
-     "        \"\"\"\n",
-     "        Output of this method will be provided to tasks with optimizer in contract\n",
-     "        \"\"\"\n",
-     "        return DataLoader(\n",
-     "            self.train_set, num_workers=8, batch_size=self.kwargs['train_bs'], shuffle=True\n",
-     "            )\n",
-     "\n",
-     "    def get_valid_loader(self, **kwargs):\n",
-     "        \"\"\"\n",
-     "        Output of this method will be provided to tasks without optimizer in contract\n",
-     "        \"\"\"\n",
-     "        return DataLoader(self.valid_set, num_workers=8, batch_size=self.kwargs['valid_bs'])\n",
-     "\n",
-     "    def get_train_data_size(self):\n",
-     "        \"\"\"\n",
-     "        Information for aggregation\n",
-     "        \"\"\"\n",
-     "        return len(self.train_set)\n",
-     "\n",
-     "    def get_valid_data_size(self):\n",
-     "        \"\"\"\n",
-     "        Information for aggregation\n",
-     "        \"\"\"\n",
-     "        return len(self.valid_set)\n",
-     "    "
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "4a6cedef",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "fed_dataset = HistologyDataset(train_bs=64, valid_bs=64)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "74cac654",
-    "metadata": {},
-    "source": [
-     "### Describe the model and optimizer"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "4949e16d",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import os\n",
-     "import glob\n",
-     "from torch.utils.data import Dataset, DataLoader\n",
-     "from PIL import Image\n",
-     "\n",
-     "import numpy as np\n",
-     "import torch\n",
-     "import torch.nn as nn\n",
-     "import torch.nn.functional as F\n",
-     "import torch.optim as optim"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "43e25fe3",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "\"\"\"\n",
-     "MobileNetV2 model\n",
-     "\"\"\"\n",
-     "\n",
-     "class Net(nn.Module):\n",
-     "    def __init__(self):\n",
-     "        super(Net, self).__init__()\n",
-     "        conv_kwargs = {'kernel_size': 3, 'stride': 1, 'padding': 1}\n",
-     "        self.conv1 = nn.Conv2d(3, 16, **conv_kwargs)\n",
-     "        self.conv2 = nn.Conv2d(16, 32, **conv_kwargs)\n",
-     "        self.conv3 = nn.Conv2d(32, 64, **conv_kwargs)\n",
-     "        self.conv4 = nn.Conv2d(64, 128, **conv_kwargs)\n",
-     "        self.conv5 = nn.Conv2d(128 + 32, 256, **conv_kwargs)\n",
-     "        self.conv6 = nn.Conv2d(256, 512, **conv_kwargs)\n",
-     "        self.conv7 = nn.Conv2d(512 + 128 + 32, 256, **conv_kwargs)\n",
-     "        self.conv8 = nn.Conv2d(256, 512, **conv_kwargs)\n",
-     "        self.fc1 = nn.Linear(1184 * 9 * 9, 128)\n",
-     "        self.fc2 = nn.Linear(128, 8)\n",
-     "\n",
-     "\n",
-     "    def forward(self, x):\n",
-     "        x = F.relu(self.conv1(x))\n",
-     "        x = F.relu(self.conv2(x))\n",
-     "        maxpool = F.max_pool2d(x, 2, 2)\n",
-     "\n",
-     "        x = F.relu(self.conv3(maxpool))\n",
-     "        x = F.relu(self.conv4(x))\n",
-     "        concat = torch.cat([maxpool, x], dim=1)\n",
-     "        maxpool = F.max_pool2d(concat, 2, 2)\n",
-     "\n",
-     "        x = F.relu(self.conv5(maxpool))\n",
-     "        x = F.relu(self.conv6(x))\n",
-     "        concat = torch.cat([maxpool, x], dim=1)\n",
-     "        maxpool = F.max_pool2d(concat, 2, 2)\n",
-     "\n",
-     "        x = F.relu(self.conv7(maxpool))\n",
-     "        x = F.relu(self.conv8(x))\n",
-     "        concat = torch.cat([maxpool, x], dim=1)\n",
-     "        maxpool = F.max_pool2d(concat, 2, 2)\n",
-     "\n",
-     "        x = maxpool.flatten(start_dim=1)\n",
-     "        x = F.dropout(self.fc1(x), p=0.5)\n",
-     "        x = self.fc2(x)\n",
-     "        return x\n",
-     "\n",
-     "model_net = Net()"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "79021778",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "optimizer_adam = optim.Adam(model_net.parameters(), lr=1e-4)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "f097cdc5",
-    "metadata": {},
-    "source": [
-     "### Register model"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "06a8cca8",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from copy import deepcopy\n",
-     "\n",
-     "framework_adapter = 'openfl.plugins.frameworks_adapters.pytorch_adapter.FrameworkAdapterPlugin'\n",
-     "model_interface = ModelInterface(model=model_net, optimizer=optimizer_adam, framework_plugin=framework_adapter)\n",
-     "\n",
-     "# Save the initial model state\n",
-     "initial_model = deepcopy(model_net)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "849c165b",
-    "metadata": {},
-    "source": [
-     "## Define and register FL tasks"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "b9649385",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "task_interface = TaskInterface()\n",
-     "import torch\n",
-     "\n",
-     "import tqdm\n",
-     "\n",
-     "# The Interactive API supports registering functions definied in main module or imported.\n",
-     "def function_defined_in_notebook(some_parameter):\n",
-     "    print(f'Also I accept a parameter and it is {some_parameter}')\n",
-     "\n",
-     "# Task interface currently supports only standalone functions.\n",
-     "@task_interface.add_kwargs(**{'some_parameter': 42})\n",
-     "@task_interface.register_fl_task(model='net_model', data_loader='train_loader', \\\n",
-     "                     device='device', optimizer='optimizer')     \n",
-     "def train(net_model, train_loader, optimizer, device, loss_fn=F.cross_entropy, some_parameter=None):\n",
-     "    device = torch.device('cuda')\n",
-     "    if not torch.cuda.is_available():\n",
-     "        device = 'cpu'\n",
-     "    \n",
-     "    function_defined_in_notebook(some_parameter)\n",
-     "    \n",
-     "    train_loader = tqdm.tqdm(train_loader, desc=\"train\")\n",
-     "    net_model.train()\n",
-     "    net_model.to(device)\n",
-     "\n",
-     "    losses = []\n",
-     "\n",
-     "    for data, target in train_loader:\n",
-     "        data, target = torch.tensor(data).to(device), torch.tensor(\n",
-     "            target).to(device) \n",
-     "        optimizer.zero_grad()\n",
-     "        output = net_model(data)\n",
-     "        loss = loss_fn(output, target)\n",
-     "        loss.backward()\n",
-     "        optimizer.step()\n",
-     "        losses.append(loss.detach().cpu().numpy())\n",
-     "        \n",
-     "    return {'train_loss': np.mean(losses),}\n",
-     "\n",
-     "\n",
-     "@task_interface.register_fl_task(model='net_model', data_loader='val_loader', device='device')     \n",
-     "def validate(net_model, val_loader, device):\n",
-     "    device = torch.device('cuda')\n",
-     "    net_model.eval()\n",
-     "    net_model.to(device)\n",
-     "    \n",
-     "    val_loader = tqdm.tqdm(val_loader, desc=\"validate\")\n",
-     "    val_score = 0\n",
-     "    total_samples = 0\n",
-     "\n",
-     "    with torch.no_grad():\n",
-     "        for data, target in val_loader:\n",
-     "            samples = target.shape[0]\n",
-     "            total_samples += samples\n",
-     "            data, target = torch.tensor(data).to(device), \\\n",
-     "                torch.tensor(target).to(device, dtype=torch.int64)\n",
-     "            output = net_model(data)\n",
-     "            pred = output.argmax(dim=1)\n",
-     "            val_score += pred.eq(target).sum().cpu().numpy()\n",
-     "            \n",
-     "    return {'acc': val_score / total_samples,}"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "8f0ebf2d",
-    "metadata": {},
-    "source": [
-     "## Time to start a federated learning experiment"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "d41b7896",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# create an experimnet in federation\n",
-     "experiment_name = 'histology_test_experiment'\n",
-     "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "41b44de9",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
-     "fl_experiment.start(\n",
-     "    model_provider=model_interface, \n",
-     "    task_keeper=task_interface,\n",
-     "    data_loader=fed_dataset,\n",
-     "    rounds_to_train=5,\n",
-     "    opt_treatment='CONTINUE_GLOBAL'\n",
-     ")"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "acting-immunology",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# If user want to stop IPython session, then reconnect and check how experiment is going\n",
-     "# fl_experiment.restore_experiment_state(model_interface)\n",
-     "\n",
-     "fl_experiment.stream_metrics(tensorboard_logs=False)"
-    ]
-   }
-  ],
-  "metadata": {
-   "language_info": {
-    "name": "python"
-   }
-  },
-  "nbformat": 4,
-  "nbformat_minor": 5
- }
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/director/director_config.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/director/director_config.yaml
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/director/director_config.yaml	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/director/director_config.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,5 ****
- settings:
-   listen_host: localhost
-   listen_port: 50051
-   sample_shape: ['150', '150']
-   target_shape: ['1']
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/director/start_director.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/director/start_director.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/director/start_director.sh	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/director/start_director.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- 
- fx director start --disable-tls -c director_config.yaml
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/director/start_director_with_tls.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/director/start_director_with_tls.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/director/start_director_with_tls.sh	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/director/start_director_with_tls.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- FQDN=$1
- fx director start -c director_config.yaml -rc cert/root_ca.crt -pk cert/"${FQDN}".key -oc cert/"${FQDN}".crt
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/envoy_config.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/envoy_config.yaml
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/envoy_config.yaml	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/envoy_config.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,10 ****
- params:
-   cuda_devices: []
- 
- optional_plugin_components: {}
- 
- shard_descriptor:
-   template: histology_shard_descriptor.HistologyShardDescriptor
-   params:
-     data_folder: histology_data
-     rank_worldsize: 1,8
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/.gitignore ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/.gitignore
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/.gitignore	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/.gitignore	1969-12-31 16:00:00.000000000 -0800
***************
*** 1 ****
- histology_data
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/histology_shard_descriptor.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/histology_shard_descriptor.py
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/histology_shard_descriptor.py	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/histology_shard_descriptor.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,138 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Histology Shard Descriptor."""
- 
- import logging
- import os
- from pathlib import Path
- from typing import Tuple
- from urllib.request import urlretrieve
- from zipfile import ZipFile
- 
- import numpy as np
- from PIL import Image
- 
- from openfl.interface.interactive_api.shard_descriptor import ShardDataset
- from openfl.interface.interactive_api.shard_descriptor import ShardDescriptor
- from openfl.utilities import tqdm_report_hook
- from openfl.utilities import validate_file_hash
- from openfl.utilities.data_splitters.numpy import LogNormalNumPyDataSplitter
- 
- 
- logger = logging.getLogger(__name__)
- 
- 
- class HistologyShardDataset(ShardDataset):
-     """Histology shard dataset class."""
- 
-     TRAIN_SPLIT_RATIO = 0.8
- 
-     def __init__(self, data_folder: Path, data_type='train', rank=1, worldsize=1):
-         """Histology shard dataset class."""
-         self.data_type = data_type
-         root = Path(data_folder) / 'Kather_texture_2016_image_tiles_5000'
-         classes = [d.name for d in root.iterdir() if d.is_dir()]
-         class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}
-         self.samples = []
-         root = root.absolute()
-         for target_class in sorted(class_to_idx.keys()):
-             class_index = class_to_idx[target_class]
-             target_dir = root / target_class
-             for path in sorted(target_dir.glob('*')):
-                 item = path, class_index
-                 self.samples.append(item)
-         np.random.seed(0)
-         np.random.shuffle(self.samples)
-         idx_range = list(range(len(self.samples)))
-         idx_sep = int(len(idx_range) * HistologyShardDataset.TRAIN_SPLIT_RATIO)
-         train_idx, test_idx = np.split(idx_range, [idx_sep])
-         data_splitter = LogNormalNumPyDataSplitter(
-             mu=0,
-             sigma=2,
-             num_classes=8,
-             classes_per_col=2,
-             min_samples_per_class=5)
-         if data_type == 'train':
-             labels = np.array(self.samples)[train_idx][:, 1].astype(int)
-             self.idx = data_splitter.split(labels, worldsize)[rank - 1]
-         else:
-             labels = np.array(self.samples)[test_idx][:, 1].astype(int)
-             self.idx = data_splitter.split(labels, worldsize)[rank - 1]
- 
-     def __len__(self) -> int:
-         """Return the len of the shard dataset."""
-         return len(self.idx)
- 
-     def load_pil(self, path):
-         """Load image."""
-         with open(path, 'rb') as f:
-             img = Image.open(f)
-             return img.convert('RGB')
- 
-     def __getitem__(self, index: int) -> Tuple['Image', int]:
-         """Return an item by the index."""
-         path, target = self.samples[self.idx[index]]
-         sample = self.load_pil(path)
-         return sample, target
- 
- 
- class HistologyShardDescriptor(ShardDescriptor):
-     """Shard descriptor class."""
- 
-     URL = ('https://zenodo.org/record/53169/files/Kather_'
-            'texture_2016_image_tiles_5000.zip?download=1')
-     FILENAME = 'Kather_texture_2016_image_tiles_5000.zip'
-     ZIP_SHA384 = ('7d86abe1d04e68b77c055820c2a4c582a1d25d2983e38ab724e'
-                   'ac75affce8b7cb2cbf5ba68848dcfd9d84005d87d6790')
-     DEFAULT_PATH = Path('.') / 'data'
- 
-     def __init__(
-             self,
-             data_folder: Path = DEFAULT_PATH,
-             rank_worldsize: str = '1,1',
-             **kwargs
-     ):
-         """Initialize HistologyShardDescriptor."""
-         self.data_folder = Path.cwd() / data_folder
-         self.download_data()
-         self.rank, self.worldsize = tuple(int(num) for num in rank_worldsize.split(','))
- 
-     def download_data(self):
-         """Download prepared shard dataset."""
-         os.makedirs(self.data_folder, exist_ok=True)
-         filepath = self.data_folder / HistologyShardDescriptor.FILENAME
-         if not filepath.exists():
-             reporthook = tqdm_report_hook()
-             urlretrieve(HistologyShardDescriptor.URL, filepath, reporthook)  # nosec
-             validate_file_hash(filepath, HistologyShardDescriptor.ZIP_SHA384)
-             with ZipFile(filepath, 'r') as f:
-                 f.extractall(self.data_folder)
- 
-     def get_dataset(self, dataset_type):
-         """Return a shard dataset by type."""
-         return HistologyShardDataset(
-             data_folder=self.data_folder,
-             data_type=dataset_type,
-             rank=self.rank,
-             worldsize=self.worldsize
-         )
- 
-     @property
-     def sample_shape(self):
-         """Return the sample shape info."""
-         shape = self.get_dataset('train')[0][0].size
-         return [str(dim) for dim in shape]
- 
-     @property
-     def target_shape(self):
-         """Return the target shape info."""
-         target = self.get_dataset('train')[0][1]
-         shape = np.array([target]).shape
-         return [str(dim) for dim in shape]
- 
-     @property
-     def dataset_description(self) -> str:
-         """Return the shard dataset description."""
-         return (f'Histology dataset, shard number {self.rank}'
-                 f' out of {self.worldsize}')
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/populate_envoys.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/populate_envoys.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/populate_envoys.sh	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/populate_envoys.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,26 ****
- #!/bin/bash
- DIRECTOR_HOST=${1:-'localhost'}
- DIRECTOR_PORT=${2:-'50051'}
- PYTHON=${3:-'python3.8'}
- 
- for i in {1..8}
- do
-     mkdir $i
-     cd $i
-     echo "shard_descriptor:
-     template: histology_shard_descriptor.HistologyShardDescriptor
-     params:
-         data_folder: histology_data
-         rank_worldsize: $i,8
- " > envoy_config.yaml
- 
-     eval ${PYTHON} '-m venv venv'
-     echo "source venv/bin/activate
-     pip install ../../../../.. # install OpenFL
-     pip install -r requirements.txt
-     fx envoy start -n env_$i --disable-tls --envoy-config-path envoy_config.yaml -dh ${DIRECTOR_HOST} -dp ${DIRECTOR_PORT}
-     " > start_envoy.sh
-     cp ../requirements.txt .
-     cp ../histology_shard_descriptor.py .
-     cd ..
- done
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/requirements.txt
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/requirements.txt	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- Pillow==8.3.2
- tqdm==4.48.2
- numpy==1.19.1
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/start_envoy.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/start_envoy.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/start_envoy.sh	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/start_envoy.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- 
- fx envoy start -n env_one --disable-tls --envoy-config-path envoy_config.yaml -dh localhost -dp 50051
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/start_envoys.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/start_envoys.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/start_envoys.sh	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/start_envoys.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,11 ****
- #!/bin/bash
- set -e
- 
- cd 1 && bash start_envoy.sh &
- cd 2 && bash start_envoy.sh &
- cd 3 && bash start_envoy.sh &
- cd 4 && bash start_envoy.sh &
- cd 5 && bash start_envoy.sh &
- cd 6 && bash start_envoy.sh &
- cd 7 && bash start_envoy.sh &
- cd 8 && bash start_envoy.sh 
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/start_envoy_with_tls.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/start_envoy_with_tls.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/start_envoy_with_tls.sh	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/envoy/start_envoy_with_tls.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,6 ****
- #!/bin/bash
- set -e
- ENVOY_NAME=$1
- DIRECTOR_FQDN=$2
- 
- fx envoy start -n "$ENVOY_NAME" --envoy-config-path envoy_config.yaml -dh "$DIRECTOR_FQDN" -dp 50051 -rc cert/root_ca.crt -pk cert/"$ENVOY_NAME".key -oc cert/"$ENVOY_NAME".crt
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/README.md ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/README.md
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/README.md	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/README.md	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,28 ****
- # PyTorch tutorial for FedCurv Federated Learning method on Histology dataset
- 
- To show results on non-iid data distribution, this tutorial contains shard descriptor with custom data splitter where data is split log-normally. Federation consists of 8 envoys.
- 
- Your Python environment must have OpenFL installed.
- 
- 1. Run Director instance:
- ```
- cd director
- bash start_director.sh
- ```
- 
- 2. In a separate terminal, execute:
- ```
- cd envoy
- bash populate_envoys.sh # This creates all envoys folders in current directory
- bash start_envoys.sh # This launches all envoy instances 
- ```
- 
- 3. In a separate terminal, launch a Jupyter Lab:
- ```
- cd workspace
- jupyter lab
- ```
- 
- 4. Open your browser at corresponding port and open `pytorch_histology.ipynb` from Jupyter web interface. 
- 
- 5. Execute all cells in order.
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/workspace/.gitignore ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/workspace/.gitignore
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/workspace/.gitignore	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/workspace/.gitignore	1969-12-31 16:00:00.000000000 -0800
***************
*** 1 ****
- logs
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/workspace/pytorch_histology.ipynb ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/workspace/pytorch_histology.ipynb
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/workspace/pytorch_histology.ipynb	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Histology_FedCurv/workspace/pytorch_histology.ipynb	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,521 ****
- {
-  "cells": [
-   {
-    "cell_type": "markdown",
-    "id": "26fdd9ed",
-    "metadata": {},
-    "source": [
-     "# Federated PyTorch Histology Tutorial"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "895288d0",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "!pip install torchvision==0.10.0"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "246f9c98",
-    "metadata": {},
-    "source": [
-     "## Connect to the Federation"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "d657e463",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Create a federation\n",
-     "from openfl.interface.interactive_api.federation import Federation\n",
-     "\n",
-     "# please use the same identificator that was used in signed certificate\n",
-     "client_id = 'api'\n",
-     "cert_dir = 'cert'\n",
-     "director_node_fqdn = 'localhost'\n",
-     "# 1) Run with API layer - Director mTLS \n",
-     "# If the user wants to enable mTLS their must provide CA root chain, and signed key pair to the federation interface\n",
-     "# cert_chain = f'{cert_dir}/root_ca.crt'\n",
-     "# api_certificate = f'{cert_dir}/{client_id}.crt'\n",
-     "# api_private_key = f'{cert_dir}/{client_id}.key'\n",
-     "\n",
-     "# federation = Federation(client_id=client_id, director_node_fqdn=director_node_fqdn, director_port='50051',\n",
-     "#                        cert_chain=cert_chain, api_cert=api_certificate, api_private_key=api_private_key)\n",
-     "\n",
-     "# --------------------------------------------------------------------------------------------------------------------\n",
-     "\n",
-     "# 2) Run with TLS disabled (trusted environment)\n",
-     "# Federation can also determine local fqdn automatically\n",
-     "federation = Federation(client_id=client_id, director_node_fqdn=director_node_fqdn, director_port='50051', tls=False)\n"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "1abebd90",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "federation.target_shape"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "47dcfab3",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "shard_registry = federation.get_shard_registry()\n",
-     "shard_registry"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "a2a6c237",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# First, request a dummy_shard_desc that holds information about the federated dataset \n",
-     "dummy_shard_desc = federation.get_dummy_shard_descriptor(size=10)\n",
-     "sample, target = dummy_shard_desc.get_dataset('train')[0]"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "cc0dbdbd",
-    "metadata": {},
-    "source": [
-     "## Creating a FL experiment using Interactive API"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "fc88700a",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "b0979470",
-    "metadata": {},
-    "source": [
-     "### Register dataset"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "7dda1680",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import torchvision\n",
-     "from torchvision import transforms as T\n",
-     "\n",
-     "normalize = T.Normalize(mean=[0.485, 0.456, 0.406],\n",
-     "                                 std=[0.229, 0.224, 0.225])\n",
-     "\n",
-     "augmentation = T.RandomApply(\n",
-     "    [T.RandomHorizontalFlip(),\n",
-     "     T.RandomRotation(10),\n",
-     "     T.RandomResizedCrop(64)], \n",
-     "    p=.8\n",
-     ")\n",
-     "\n",
-     "training_transform = T.ToTensor()\n",
-     "\n",
-     "valid_transform = T.ToTensor()\n"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "0314d5bf",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from torch.utils.data import Dataset\n",
-     "\n",
-     "\n",
-     "class TransformedDataset(Dataset):\n",
-     "    \"\"\"Image Person ReID Dataset.\"\"\"\n",
-     "\n",
-     "    def __init__(self, dataset, transform=None, target_transform=None):\n",
-     "        \"\"\"Initialize Dataset.\"\"\"\n",
-     "        self.dataset = dataset\n",
-     "        self.transform = transform\n",
-     "        self.target_transform = target_transform\n",
-     "\n",
-     "    def __len__(self):\n",
-     "        \"\"\"Length of dataset.\"\"\"\n",
-     "        return len(self.dataset)\n",
-     "\n",
-     "    def __getitem__(self, index):\n",
-     "        img, label = self.dataset[index]\n",
-     "        label = self.target_transform(label) if self.target_transform else label\n",
-     "        img = self.transform(img) if self.transform else img\n",
-     "        return img, label\n"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "01369e3b",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "class HistologyDataset(DataInterface):\n",
-     "    def __init__(self, **kwargs):\n",
-     "        self.kwargs = kwargs\n",
-     "    \n",
-     "    @property\n",
-     "    def shard_descriptor(self):\n",
-     "        return self._shard_descriptor\n",
-     "        \n",
-     "    @shard_descriptor.setter\n",
-     "    def shard_descriptor(self, shard_descriptor):\n",
-     "        \"\"\"\n",
-     "        Describe per-collaborator procedures or sharding.\n",
-     "\n",
-     "        This method will be called during a collaborator initialization.\n",
-     "        Local shard_descriptor  will be set by Envoy.\n",
-     "        \"\"\"\n",
-     "        self._shard_descriptor = shard_descriptor\n",
-     "        \n",
-     "        self.train_set = TransformedDataset(\n",
-     "            self._shard_descriptor.get_dataset('train'),\n",
-     "            transform=training_transform\n",
-     "        )\n",
-     "        self.valid_set = TransformedDataset(\n",
-     "            self._shard_descriptor.get_dataset('val'),\n",
-     "            transform=valid_transform\n",
-     "        )\n",
-     "        \n",
-     "    def get_train_loader(self, **kwargs):\n",
-     "        \"\"\"\n",
-     "        Output of this method will be provided to tasks with optimizer in contract\n",
-     "        \"\"\"\n",
-     "        return DataLoader(\n",
-     "            self.train_set, num_workers=8, batch_size=self.kwargs['train_bs'], shuffle=True\n",
-     "            )\n",
-     "\n",
-     "    def get_valid_loader(self, **kwargs):\n",
-     "        \"\"\"\n",
-     "        Output of this method will be provided to tasks without optimizer in contract\n",
-     "        \"\"\"\n",
-     "        return DataLoader(self.valid_set, num_workers=8, batch_size=self.kwargs['valid_bs'])\n",
-     "\n",
-     "    def get_train_data_size(self):\n",
-     "        \"\"\"\n",
-     "        Information for aggregation\n",
-     "        \"\"\"\n",
-     "        return len(self.train_set)\n",
-     "\n",
-     "    def get_valid_data_size(self):\n",
-     "        \"\"\"\n",
-     "        Information for aggregation\n",
-     "        \"\"\"\n",
-     "        return len(self.valid_set)\n",
-     "    "
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "4a6cedef",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "fed_dataset = HistologyDataset(train_bs=64, valid_bs=64)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "74cac654",
-    "metadata": {},
-    "source": [
-     "### Describe the model and optimizer"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "4949e16d",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import os\n",
-     "import glob\n",
-     "from torch.utils.data import Dataset, DataLoader\n",
-     "from PIL import Image\n",
-     "\n",
-     "import numpy as np\n",
-     "import torch\n",
-     "import torch.nn as nn\n",
-     "import torch.nn.functional as F\n",
-     "import torch.optim as optim"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "d6158e87",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "np.random.seed(0)\n",
-     "torch.manual_seed(0)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "43e25fe3",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "\"\"\"\n",
-     "MobileNetV2 model\n",
-     "\"\"\"\n",
-     "\n",
-     "class Net(nn.Module):\n",
-     "    def __init__(self):\n",
-     "        super(Net, self).__init__()\n",
-     "        conv_kwargs = {'kernel_size': 3, 'stride': 1, 'padding': 1}\n",
-     "        self.conv1 = nn.Conv2d(3, 16, **conv_kwargs)\n",
-     "        self.conv2 = nn.Conv2d(16, 32, **conv_kwargs)\n",
-     "        self.conv3 = nn.Conv2d(32, 64, **conv_kwargs)\n",
-     "        self.conv4 = nn.Conv2d(64, 128, **conv_kwargs)\n",
-     "        self.conv5 = nn.Conv2d(128 + 32, 256, **conv_kwargs)\n",
-     "        self.conv6 = nn.Conv2d(256, 512, **conv_kwargs)\n",
-     "        self.conv7 = nn.Conv2d(512 + 128 + 32, 256, **conv_kwargs)\n",
-     "        self.conv8 = nn.Conv2d(256, 512, **conv_kwargs)\n",
-     "        self.fc1 = nn.Linear(1184 * 9 * 9, 128)\n",
-     "        self.fc2 = nn.Linear(128, 8)\n",
-     "\n",
-     "\n",
-     "    def forward(self, x):\n",
-     "        torch.manual_seed(0)\n",
-     "        x = F.relu(self.conv1(x))\n",
-     "        x = F.relu(self.conv2(x))\n",
-     "        maxpool = F.max_pool2d(x, 2, 2)\n",
-     "\n",
-     "        x = F.relu(self.conv3(maxpool))\n",
-     "        x = F.relu(self.conv4(x))\n",
-     "        concat = torch.cat([maxpool, x], dim=1)\n",
-     "        maxpool = F.max_pool2d(concat, 2, 2)\n",
-     "\n",
-     "        x = F.relu(self.conv5(maxpool))\n",
-     "        x = F.relu(self.conv6(x))\n",
-     "        concat = torch.cat([maxpool, x], dim=1)\n",
-     "        maxpool = F.max_pool2d(concat, 2, 2)\n",
-     "\n",
-     "        x = F.relu(self.conv7(maxpool))\n",
-     "        x = F.relu(self.conv8(x))\n",
-     "        concat = torch.cat([maxpool, x], dim=1)\n",
-     "        maxpool = F.max_pool2d(concat, 2, 2)\n",
-     "\n",
-     "        x = maxpool.flatten(start_dim=1)\n",
-     "        x = F.dropout(self.fc1(x), p=0.5)\n",
-     "        x = self.fc2(x)\n",
-     "        return x\n",
-     "\n",
-     "model_net = Net()"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "79021778",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "optimizer_adam = optim.Adam(model_net.parameters(), lr=1e-4)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "f097cdc5",
-    "metadata": {},
-    "source": [
-     "### Register model"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "06a8cca8",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from copy import deepcopy\n",
-     "\n",
-     "framework_adapter = 'openfl.plugins.frameworks_adapters.pytorch_adapter.FrameworkAdapterPlugin'\n",
-     "model_interface = ModelInterface(model=model_net, optimizer=optimizer_adam, framework_plugin=framework_adapter)\n",
-     "\n",
-     "# Save the initial model state\n",
-     "initial_model = deepcopy(model_net)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "849c165b",
-    "metadata": {},
-    "source": [
-     "## Define and register FL tasks"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "b9649385",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "task_interface = TaskInterface()\n",
-     "import torch\n",
-     "\n",
-     "from openfl.utilities.fedcurv.torch import FedCurv\n",
-     "from openfl.component.aggregation_functions import FedCurvWeightedAverage\n",
-     "import tqdm\n",
-     "\n",
-     "fedcurv = FedCurv(model_interface.provide_model(), importance=1e7)\n",
-     "\n",
-     "@task_interface.register_fl_task(model='net_model', data_loader='train_loader', \\\n",
-     "                     device='device', optimizer='optimizer')\n",
-     "@task_interface.set_aggregation_function(FedCurvWeightedAverage())\n",
-     "def train(net_model, train_loader, optimizer, device, loss_fn=F.cross_entropy):\n",
-     "    torch.manual_seed(0)\n",
-     "    fedcurv.on_train_begin(net_model)\n",
-     "    device = 'cpu'\n",
-     "    \n",
-     "    train_loader = tqdm.tqdm(train_loader, desc=\"train\")\n",
-     "    net_model.train()\n",
-     "    net_model.to(device)\n",
-     "\n",
-     "    losses = []\n",
-     "\n",
-     "    for data, target in train_loader:\n",
-     "        data, target = torch.tensor(data).to(device), torch.tensor(\n",
-     "            target).to(device) \n",
-     "        optimizer.zero_grad()\n",
-     "        output = net_model(data)\n",
-     "        loss = loss_fn(output, target) + fedcurv.get_penalty(net_model)\n",
-     "        loss.backward()\n",
-     "        optimizer.step()\n",
-     "        losses.append(loss.detach().cpu().numpy())\n",
-     "    \n",
-     "    fedcurv.on_train_end(net_model, train_loader, device)\n",
-     "        \n",
-     "    return {'train_loss': np.mean(losses),}\n",
-     "\n",
-     "\n",
-     "@task_interface.register_fl_task(model='net_model', data_loader='val_loader', device='device')     \n",
-     "def validate(net_model, val_loader, device):\n",
-     "    device = torch.device('cpu')\n",
-     "    net_model.eval()\n",
-     "    net_model.to(device)\n",
-     "    \n",
-     "    val_loader = tqdm.tqdm(val_loader, desc=\"validate\")\n",
-     "    val_score = 0\n",
-     "    total_samples = 0\n",
-     "\n",
-     "    with torch.no_grad():\n",
-     "        for data, target in val_loader:\n",
-     "            samples = target.shape[0]\n",
-     "            total_samples += samples\n",
-     "            data, target = torch.tensor(data).to(device), \\\n",
-     "                torch.tensor(target).to(device, dtype=torch.int64)\n",
-     "            output = net_model(data)\n",
-     "            pred = output.argmax(dim=1)\n",
-     "            val_score += pred.eq(target).sum().cpu().numpy()\n",
-     "            \n",
-     "    return {'acc': val_score / total_samples,}"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "8f0ebf2d",
-    "metadata": {},
-    "source": [
-     "## Time to start a federated learning experiment"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "d41b7896",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# create an experimnet in federation\n",
-     "experiment_name = f'histology_test_experiment {fedcurv.importance=}'\n",
-     "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "41b44de9",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
-     "fl_experiment.start(\n",
-     "    model_provider=model_interface, \n",
-     "    task_keeper=task_interface,\n",
-     "    data_loader=fed_dataset,\n",
-     "    rounds_to_train=5,\n",
-     "    opt_treatment='CONTINUE_GLOBAL'\n",
-     ")"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "acting-immunology",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# If user want to stop IPython session, then reconnect and check how experiment is going\n",
-     "# fl_experiment.restore_experiment_state(model_interface)\n",
-     "\n",
-     "fl_experiment.stream_metrics()"
-    ]
-   }
-  ],
-  "metadata": {
-   "kernelspec": {
-    "display_name": "Python 3 (ipykernel)",
-    "language": "python",
-    "name": "python3"
-   },
-   "language_info": {
-    "codemirror_mode": {
-     "name": "ipython",
-     "version": 3
-    },
-    "file_extension": ".py",
-    "mimetype": "text/x-python",
-    "name": "python",
-    "nbconvert_exporter": "python",
-    "pygments_lexer": "ipython3",
-    "version": "3.8.12"
-   }
-  },
-  "nbformat": 4,
-  "nbformat_minor": 5
- }
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/director/director_config.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/director/director_config.yaml
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/director/director_config.yaml	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/director/director_config.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,5 ****
- settings:
-   listen_host: localhost
-   listen_port: 50050
-   sample_shape: ['1']
-   target_shape: ['1']
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/director/start_director.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/director/start_director.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/director/start_director.sh	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/director/start_director.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- 
- fx director start --disable-tls -c director_config.yaml
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/envoy/envoy_config.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/envoy/envoy_config.yaml
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/envoy/envoy_config.yaml	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/envoy/envoy_config.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,12 ****
- params:
-   cuda_devices: [0]
- 
- optional_plugin_components:
-  cuda_device_monitor:
-    template: openfl.plugins.processing_units_monitor.pynvml_monitor.PynvmlCUDADeviceMonitor
-    settings: []
- 
- shard_descriptor:
-   template: superb_shard_descriptor.SuperbShardDescriptor
-   params:
-     rank_worldsize: 1, 1000
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/envoy/sd_requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/envoy/sd_requirements.txt
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/envoy/sd_requirements.txt	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/envoy/sd_requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- datasets==1.14
- librosa
- pynvml
- numpy==1.21.5
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/envoy/start_envoy.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/envoy/start_envoy.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/envoy/start_envoy.sh	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/envoy/start_envoy.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- 
- fx envoy start -n env_one --disable-tls --envoy-config-path envoy_config.yaml -dh localhost -dp 50050
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/envoy/superb_shard_descriptor.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/envoy/superb_shard_descriptor.py
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/envoy/superb_shard_descriptor.py	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/envoy/superb_shard_descriptor.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,101 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Superb Shard Descriptor."""
- 
- from typing import Any
- from typing import Dict
- from typing import List
- from typing import Tuple
- 
- from datasets import load_dataset
- from datasets import load_metric
- 
- from openfl.interface.interactive_api.shard_descriptor import ShardDataset
- from openfl.interface.interactive_api.shard_descriptor import ShardDescriptor
- 
- 
- class SuperbShardDataset(ShardDataset):
-     """SUPERB Shard dataset class."""
- 
-     def __init__(self, dataset, rank: int = 1, worldsize: int = 1) -> None:
-         """Initialize Superb shard Dataset."""
-         self.rank = rank
-         self.worldsize = worldsize
-         self.dataset = dataset
-         self.x = self.dataset['audio'][self.rank - 1::self.worldsize]
-         self.y = self.dataset['label'][self.rank - 1::self.worldsize]
- 
-     def __getitem__(self, index: int) -> Tuple[Any, Any]:
-         """Return an item by the index."""
-         return self.x[index]['array'], self.y[index]
- 
-     def __len__(self) -> int:
-         """Return the len of the dataset."""
-         return len(self.x)
- 
- 
- class SuperbShardDescriptor(ShardDescriptor):
-     """Superb Shard descriptor class."""
- 
-     def __init__(
-             self,
-             rank_worldsize: str = '1, 1',
-             **kwargs
-     ) -> None:
-         """Initialize SuperbShardDescriptor."""
-         self.rank, self.worldsize = tuple(int(num) for num in rank_worldsize.split(','))
-         print('rank and worldsize', self.rank, self.worldsize)
-         train_set, val_set, test_set = self.download_data()
-         self.data_by_type = {
-             'train': train_set,
-             'val': val_set,
-             'test': test_set
-         }
- 
-     def get_shard_dataset_types(self) -> List[Dict[str, Any]]:
-         """Get available shard dataset types."""
-         return list(self.data_by_type)
- 
-     def get_dataset(self, dataset_type: str = 'train') -> SuperbShardDataset:
-         """Return a shard dataset by type."""
-         if dataset_type not in self.data_by_type:
-             raise Exception(f'Wrong dataset type: {dataset_type}')
-         return SuperbShardDataset(
-             self.data_by_type[dataset_type],
-             rank=self.rank,
-             worldsize=self.worldsize
-         )
- 
-     @property
-     def sample_shape(self) -> List[str]:
-         """Return the sample shape info."""
-         return ['1']
- 
-     @property
-     def target_shape(self) -> List[str]:
-         """Return the target shape info."""
-         return ['1']
- 
-     @property
-     def dataset_description(self) -> str:
-         """Return the dataset description."""
-         return (f'Superb dataset, shard number {self.rank}'
-                 f' out of {self.worldsize}')
- 
-     def download_data(self) -> Tuple[Tuple[Dict, List], Tuple[Dict, List], Tuple[Dict, List]]:
-         """Download dataset."""
-         dataset = load_dataset('superb', 'ks')
-         metric = load_metric('accuracy') # noqa
- 
-         # Train data
-         train_set = dataset['train']
- 
-         # Validation data
-         val_set = dataset['validation']
- 
-         # Test data
-         test_set = dataset['test']
- 
-         print('Superb data was loaded!')
-         return train_set, val_set, test_set
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/README.md ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/README.md
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/README.md	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/README.md	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,63 ****
- # Federated Hugging face :hugs: transformers tutorial for audio classification using PyTorch
- 
- Transformers have been a driving point for breakthrough developments in the Audio and Speech processing domain. Recently, Hugging Face dropped the State-of-the-art Natural Language Processing library Transformers v4.30 and extended its reach to Speech Recognition by adding one of the leading Automatic Speech Recognition models by Facebook called the Wav2Vec2.
- 
- ### About model: Wav2Vec2
- 
- This tutorial uses [Wav2Vec2](https://huggingface.co/docs/transformers/model_doc/wav2vec2#wav2vec2forsequenceclassification) model which is a speech model checkpoint from the [Model Hub](https://huggingface.co/models?pipeline_tag=automatic-speech-recognition&sort=downloads). The Wav2Vec2 model was proposed in [wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations](https://arxiv.org/abs/2006.11477) which shows that learning powerful representations from speech audio alone followed by fine-tuning on transcribed speech can outperform the best semi-supervised methods while being conceptually simpler. We will fine-tune this pretrained speech model for Automatic Speech Recognition in this tutorial.
- 
- ### About dataset: Keyword spotting (KS) from SUPERB
- 
- Keyword spotting subset from [SUPERB](https://huggingface.co/datasets/superb) dataset is used. Keyword Spotting (KS) detects preregistered keywords by classifying utterances into a predefined set of words. The dataset consists of ten classes of keywords, a class for silence, and an unknown class to include the false positive. The evaluation metric is accuracy (ACC).
- 
- ### Links
- 
- * [Huggingface transformers on Github](https://github.com/huggingface/transformers)
- * [Original Huggingface notebook audio classification example on Github](https://github.com/huggingface/notebooks/blob/master/examples/audio_classification.ipynb)
- 
- ### How to run this tutorial (without TLS and locally as a simulation):
- 
- Using hugging face models requires you to setup a [cache directory](https://huggingface.co/transformers/v4.0.1/installation.html#caching-models) at every node where the experiment is run, like XDG_CACHE_HOME.
- 
- In addition to this, the Trainer class in huggingface transformers is desgined to use all available GPUs on a node. Hence, to avoid [cuda runtime error](https://forums.developer.nvidia.com/t/cuda-peer-resources-error-when-running-on-more-than-8-k80s-aws-p2-16xlarge/45351/5) on nodes that have more than 8 GPUs, setting up CUDA_VISIBLE_DEVICES limits the number of GPUs participating in the experiment.
- 
- Go to example [folder](./)
- 
- ```sh
- export PYTORCH_HUGGINGFACE_TRANSFORMERS_SUPERB=<openfl_folder>/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB
- ```
- 
- 1. Run director:
- 
- ```sh
- cd $PYTORCH_HUGGINGFACE_TRANSFORMERS_SUPERB/director
- bash start_director.sh
- ```
- 
- 2. Run envoy:
- 
- ```sh
- cd $PYTORCH_HUGGINGFACE_TRANSFORMERS_SUPERB/envoy
- pip install -r sd_requirements.txt
- export XDG_CACHE_HOME=<cache_dir>
- CUDA_VISIBLE_DEVICES=<device_ids> bash start_envoy.sh
- ```
- 
- Optional: start second envoy:
- 
- - Copy `$PYTORCH_HUGGINGFACE_TRANSFORMERS_SUPERB/envoy` to another folder, change the config and envoy name in
-   start_envoy.sh and run from there:
- 
- ```sh
- cd $PYTORCH_HUGGINGFACE_TRANSFORMERS_SUPERB/envoy_two
- export XDG_CACHE_HOME=<cache_dir>
- CUDA_VISIBLE_DEVICES=<device_ids> bash start_envoy.sh
- ```
- 
- 3. Run `PyTorch_Huggingface_transformers_SUPERB.ipynb` jupyter notebook:
- 
- ```sh
- cd $PYTORCH_HUGGINGFACE_TRANSFORMERS_SUPERB/workspace
- export XDG_CACHE_HOME=<cache_dir>
- CUDA_VISIBLE_DEVICES=<device_ids> jupyter lab PyTorch_Huggingface_transformers_SUPERB.ipynb
- ```
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/workspace/PyTorch_Huggingface_transformers_SUPERB.ipynb ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/workspace/PyTorch_Huggingface_transformers_SUPERB.ipynb
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/workspace/PyTorch_Huggingface_transformers_SUPERB.ipynb	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Huggingface_transformers_SUPERB/workspace/PyTorch_Huggingface_transformers_SUPERB.ipynb	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,483 ****
- {
-  "cells": [
-   {
-    "cell_type": "markdown",
-    "id": "liquid-jacket",
-    "metadata": {},
-    "source": [
-     "# Federated Audio Classification tutorial with 🤗 Transformers"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "alike-sharing",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "!pip install \"datasets==1.14\" \"transformers==4.11.3\" \"librosa\" \"torch\" \"ipywidgets\" \"numpy==1.21.5\""
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "16986f22",
-    "metadata": {},
-    "source": [
-     "# Connect to the Federation"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "4485ac79",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from openfl.interface.interactive_api.federation import Federation\n",
-     "\n",
-     "client_id = \"frontend\"\n",
-     "director_node_fqdn = \"localhost\"\n",
-     "director_port = 50050\n",
-     "\n",
-     "federation = Federation(\n",
-     "    client_id=client_id,\n",
-     "    director_node_fqdn=director_node_fqdn,\n",
-     "    director_port=director_port,\n",
-     "    tls=False,\n",
-     ")"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "e35802d5",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "shard_registry = federation.get_shard_registry()\n",
-     "shard_registry"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "67ae50de",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "federation.target_shape"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "obvious-tyler",
-    "metadata": {},
-    "source": [
-     "## Creating a FL experiment using Interactive API"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "rubber-address",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from openfl.interface.interactive_api.experiment import (\n",
-     "    DataInterface,\n",
-     "    FLExperiment,\n",
-     "    ModelInterface,\n",
-     "    TaskInterface,\n",
-     ")"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "sustainable-public",
-    "metadata": {},
-    "source": [
-     "### Register dataset"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "8d9acb53",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import datasets\n",
-     "import numpy as np\n",
-     "import torch\n",
-     "from torch.utils.data import Dataset\n",
-     "from transformers import (\n",
-     "    AutoFeatureExtractor,\n",
-     "    AutoModelForAudioClassification,\n",
-     "    Trainer,\n",
-     "    TrainingArguments,\n",
-     ")"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "1eaecbb1",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "model_checkpoint = \"facebook/wav2vec2-base\"\n",
-     "\n",
-     "labels = [\n",
-     "    \"yes\",\n",
-     "    \"no\",\n",
-     "    \"up\",\n",
-     "    \"down\",\n",
-     "    \"left\",\n",
-     "    \"right\",\n",
-     "    \"on\",\n",
-     "    \"off\",\n",
-     "    \"stop\",\n",
-     "    \"go\",\n",
-     "    \"_silence_\",\n",
-     "    \"_unknown_\",\n",
-     "]\n",
-     "\n",
-     "label2id, id2label = dict(), dict()\n",
-     "for i, label in enumerate(labels):\n",
-     "    label2id[label] = str(i)\n",
-     "    id2label[str(i)] = label"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "151fdff2",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "feature_extractor = AutoFeatureExtractor.from_pretrained(model_checkpoint)\n",
-     "max_duration = 1.0\n",
-     "\n",
-     "\n",
-     "def preprocess_function(pre_processed_data):\n",
-     "    audio_arrays = pre_processed_data\n",
-     "    inputs = feature_extractor(\n",
-     "        audio_arrays,\n",
-     "        sampling_rate=feature_extractor.sampling_rate,\n",
-     "        max_length=int(feature_extractor.sampling_rate * max_duration),\n",
-     "        truncation=True,\n",
-     "    )\n",
-     "\n",
-     "    return inputs"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "64f37dcf",
-    "metadata": {
-     "tags": []
-    },
-    "outputs": [],
-    "source": [
-     "class SuperbShardDataset(Dataset):\n",
-     "    def __init__(self, dataset):\n",
-     "        self._dataset = dataset\n",
-     "\n",
-     "    def __getitem__(self, index):\n",
-     "        x, y = self._dataset[index]\n",
-     "        x = preprocess_function(x)\n",
-     "        return {\"input_values\": x[\"input_values\"][0], \"labels\": y}\n",
-     "\n",
-     "    def __len__(self):\n",
-     "        return len(self._dataset)\n",
-     "\n",
-     "\n",
-     "class SuperbFedDataset(DataInterface):\n",
-     "    def __init__(self, **kwargs):\n",
-     "        super().__init__(**kwargs)\n",
-     "\n",
-     "    @property\n",
-     "    def shard_descriptor(self):\n",
-     "        return self._shard_descriptor\n",
-     "\n",
-     "    @shard_descriptor.setter\n",
-     "    def shard_descriptor(self, shard_descriptor):\n",
-     "        \"\"\"\n",
-     "        Describe per-collaborator procedures for sharding.\n",
-     "\n",
-     "        This method will be called during a collaborator initialization.\n",
-     "        Local shard_descriptor will be set by Envoy.\n",
-     "        \"\"\"\n",
-     "        self._shard_descriptor = shard_descriptor\n",
-     "        self.train_set = SuperbShardDataset(\n",
-     "            self._shard_descriptor.get_dataset(\"train\"),\n",
-     "        )\n",
-     "        self.valid_set = SuperbShardDataset(\n",
-     "            self._shard_descriptor.get_dataset(\"val\"),\n",
-     "        )\n",
-     "        self.test_set = SuperbShardDataset(\n",
-     "            self._shard_descriptor.get_dataset(\"test\"),\n",
-     "        )\n",
-     "\n",
-     "    def __getitem__(self, index):\n",
-     "        return self.shard_descriptor[index]\n",
-     "\n",
-     "    def __len__(self):\n",
-     "        return len(self.shard_descriptor)\n",
-     "\n",
-     "    def get_train_loader(self):\n",
-     "        return self.train_set\n",
-     "\n",
-     "    def get_valid_loader(self):\n",
-     "        return self.valid_set\n",
-     "\n",
-     "    def get_train_data_size(self):\n",
-     "        return len(self.train_set)\n",
-     "\n",
-     "    def get_valid_data_size(self):\n",
-     "        return len(self.valid_set)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "d8df35f5",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "fed_dataset = SuperbFedDataset()"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "caring-distinction",
-    "metadata": {},
-    "source": [
-     "### Describe a model and optimizer"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "foreign-gospel",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "\"\"\"\n",
-     "Download the pretrained model and fine-tune it. For classification we use the AutoModelForAudioClassification class.\n",
-     "\"\"\"\n",
-     "\n",
-     "num_labels = len(id2label)\n",
-     "\n",
-     "model = AutoModelForAudioClassification.from_pretrained(\n",
-     "    model_checkpoint,\n",
-     "    num_labels=num_labels,\n",
-     "    label2id=label2id,\n",
-     "    id2label=id2label,\n",
-     ")"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "0d5afa68-4bd3-43d8-a86d-d59b5cad94bd",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from transformers import AdamW\n",
-     "\n",
-     "params_to_update = []\n",
-     "for param in model.parameters():\n",
-     "    if param.requires_grad == True:\n",
-     "        params_to_update.append(param)\n",
-     "\n",
-     "optimizer = AdamW(params_to_update, lr=3e-5)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "caroline-passion",
-    "metadata": {},
-    "source": [
-     "#### Register model"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "handled-teens",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "framework_adapter = (\n",
-     "    \"openfl.plugins.frameworks_adapters.pytorch_adapter.FrameworkAdapterPlugin\"\n",
-     ")\n",
-     "MI = ModelInterface(\n",
-     "    model=model, optimizer=optimizer, framework_plugin=framework_adapter\n",
-     ")"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "portuguese-groove",
-    "metadata": {},
-    "source": [
-     "### Define and register FL tasks"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "5d4ff313-a17f-4119-a4c7-afa898b0f304",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "batch_size = 16\n",
-     "args = TrainingArguments(\n",
-     "    \"finetuned_model\",\n",
-     "    save_strategy=\"epoch\",\n",
-     "    per_device_train_batch_size=batch_size,\n",
-     "    per_device_eval_batch_size=batch_size,\n",
-     "    num_train_epochs=1,\n",
-     "    warmup_ratio=0.1,\n",
-     "    logging_steps=10,\n",
-     "    push_to_hub=False,\n",
-     ")"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "fd011594-f16a-4569-ae4e-26977e94b8c2",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from datasets import load_metric\n",
-     "\n",
-     "metric = load_metric(\"accuracy\")\n",
-     "\n",
-     "\n",
-     "def compute_metrics(eval_pred):\n",
-     "    \"\"\"Computes accuracy on a batch of predictions\"\"\"\n",
-     "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
-     "    return metric.compute(predictions=predictions, references=eval_pred.label_ids)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "increasing-builder",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "TI = TaskInterface()\n",
-     "\n",
-     "import torch.nn as nn\n",
-     "import tqdm\n",
-     "\n",
-     "\n",
-     "@TI.register_fl_task(\n",
-     "    model=\"model\", data_loader=\"train_loader\", device=\"device\", optimizer=\"optimizer\"\n",
-     ")\n",
-     "def train(model, train_loader, optimizer, device):\n",
-     "\n",
-     "    print(f\"\\n\\n TASK TRAIN GOT DEVICE {device}\\n\\n\")\n",
-     "\n",
-     "    trainer = Trainer(\n",
-     "        model.to(device),\n",
-     "        args,\n",
-     "        train_dataset=train_loader,\n",
-     "        tokenizer=feature_extractor,\n",
-     "        optimizers=(optimizer, None),\n",
-     "        compute_metrics=compute_metrics,\n",
-     "    )\n",
-     "    train_metrics = trainer.train()\n",
-     "    return {\"train_loss\": train_metrics.metrics[\"train_loss\"]}\n",
-     "\n",
-     "\n",
-     "@TI.register_fl_task(model=\"model\", data_loader=\"val_loader\", device=\"device\")\n",
-     "def validate(model, val_loader, device):\n",
-     "\n",
-     "    print(f\"\\n\\n TASK VALIDATE GOT DEVICE {device}\\n\\n\")\n",
-     "\n",
-     "    trainer = Trainer(\n",
-     "        model.to(device),\n",
-     "        args,\n",
-     "        eval_dataset=val_loader,\n",
-     "        tokenizer=feature_extractor,\n",
-     "        compute_metrics=compute_metrics,\n",
-     "    )\n",
-     "    eval_metrics = trainer.evaluate()\n",
-     "    return {\"eval_accuracy\": eval_metrics[\"eval_accuracy\"]}"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "derived-bride",
-    "metadata": {},
-    "source": [
-     "## Time to start a federated learning experiment"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "mature-renewal",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "experiment_name = \"HF_audio_test_experiment\"\n",
-     "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "lightweight-causing",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "fl_experiment.start(\n",
-     "    model_provider=MI,\n",
-     "    task_keeper=TI,\n",
-     "    data_loader=fed_dataset,\n",
-     "    rounds_to_train=2,\n",
-     "    opt_treatment=\"CONTINUE_GLOBAL\",\n",
-     "    device_assignment_policy=\"CUDA_PREFERRED\",\n",
-     ")"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "f1543a36",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "fl_experiment.stream_metrics()"
-    ]
-   }
-  ],
-  "metadata": {
-   "kernelspec": {
-    "display_name": "Python 3 (ipykernel)",
-    "language": "python",
-    "name": "python3"
-   },
-   "language_info": {
-    "codemirror_mode": {
-     "name": "ipython",
-     "version": 3
-    },
-    "file_extension": ".py",
-    "mimetype": "text/x-python",
-    "name": "python",
-    "nbconvert_exporter": "python",
-    "pygments_lexer": "ipython3",
-    "version": "3.8.9"
-   }
-  },
-  "nbformat": 4,
-  "nbformat_minor": 5
- }
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/director/director_config.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/director/director_config.yaml
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/director/director_config.yaml	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/director/director_config.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,6 ****
- settings:
-   listen_host: localhost
-   listen_port: 50050
-   sample_shape: ['300', '400', '3']
-   target_shape: ['300', '400']
-   envoy_health_check_period: 5  # in seconds
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/director/start_director.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/director/start_director.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/director/start_director.sh	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/director/start_director.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- 
- fx director start --disable-tls -c director_config.yaml
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/director/start_director_with_tls.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/director/start_director_with_tls.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/director/start_director_with_tls.sh	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/director/start_director_with_tls.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- FQDN=$1
- fx director start -c director_config.yaml -rc cert/root_ca.crt -pk cert/"${FQDN}".key -oc cert/"${FQDN}".crt
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/envoy/envoy_config_no_gpu.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/envoy/envoy_config_no_gpu.yaml
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/envoy/envoy_config_no_gpu.yaml	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/envoy/envoy_config_no_gpu.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,12 ****
- params:
-   cuda_devices: []
- 
- optional_plugin_components: {}
- 
- shard_descriptor:
-   template: kvasir_shard_descriptor.KvasirShardDescriptor
-   params:
-     data_folder: kvasir_data
-     rank_worldsize: 2,10
-     enforce_image_hw: '300,400'
-   
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/envoy/envoy_config.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/envoy/envoy_config.yaml
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/envoy/envoy_config.yaml	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/envoy/envoy_config.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,14 ****
- params:
-   cuda_devices: [0,2]
-   
- optional_plugin_components:
-  cuda_device_monitor:
-    template: openfl.plugins.processing_units_monitor.pynvml_monitor.PynvmlCUDADeviceMonitor
-    settings: []
- 
- shard_descriptor:
-   template: kvasir_shard_descriptor.KvasirShardDescriptor
-   params:
-     data_folder: kvasir_data
-     rank_worldsize: 1,10
-     enforce_image_hw: '300,400'
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/envoy/kvasir_shard_descriptor.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/envoy/kvasir_shard_descriptor.py
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/envoy/kvasir_shard_descriptor.py	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/envoy/kvasir_shard_descriptor.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,160 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Kvasir shard descriptor."""
- 
- import os
- from pathlib import Path
- 
- import numpy as np
- from PIL import Image
- 
- from openfl.interface.interactive_api.shard_descriptor import ShardDataset
- from openfl.interface.interactive_api.shard_descriptor import ShardDescriptor
- from openfl.utilities import validate_file_hash
- 
- 
- class KvasirShardDataset(ShardDataset):
-     """Kvasir Shard dataset class."""
- 
-     def __init__(self, dataset_dir: Path, rank=1, worldsize=1, enforce_image_hw=None):
-         """Initialize KvasirShardDataset."""
-         self.rank = rank
-         self.worldsize = worldsize
-         self.dataset_dir = dataset_dir
-         self.enforce_image_hw = enforce_image_hw
-         self.images_path = self.dataset_dir / 'segmented-images' / 'images'
-         self.masks_path = self.dataset_dir / 'segmented-images' / 'masks'
- 
-         self.images_names = [
-             img_name
-             for img_name in sorted(os.listdir(self.images_path))
-             if len(img_name) > 3 and img_name[-3:] == 'jpg'
-         ]
-         # Sharding
-         self.images_names = self.images_names[self.rank - 1::self.worldsize]
- 
-     def __getitem__(self, index):
-         """Return a item by the index."""
-         name = self.images_names[index]
-         # Reading data
-         img = Image.open(self.images_path / name)
-         mask = Image.open(self.masks_path / name)
-         if self.enforce_image_hw is not None:
-             # If we need to resize data
-             # PIL accepts (w,h) tuple, not (h,w)
-             img = img.resize(self.enforce_image_hw[::-1])
-             mask = mask.resize(self.enforce_image_hw[::-1])
-         img = np.asarray(img)
-         mask = np.asarray(mask)
-         assert img.shape[2] == 3
- 
-         return img, mask[:, :, 0].astype(np.uint8)
- 
-     def __len__(self):
-         """Return the len of the dataset."""
-         return len(self.images_names)
- 
- 
- class KvasirShardDescriptor(ShardDescriptor):
-     """Shard descriptor class."""
- 
-     def __init__(self, data_folder: str = 'kvasir_data',
-                  rank_worldsize: str = '1,1',
-                  enforce_image_hw: str = None) -> None:
-         """Initialize KvasirShardDescriptor."""
-         super().__init__()
-         # Settings for sharding the dataset
-         self.rank, self.worldsize = tuple(int(num) for num in rank_worldsize.split(','))
- 
-         self.data_folder = Path.cwd() / data_folder
-         self.download_data(self.data_folder)
- 
-         # Settings for resizing data
-         self.enforce_image_hw = None
-         if enforce_image_hw is not None:
-             self.enforce_image_hw = tuple(int(size) for size in enforce_image_hw.split(','))
- 
-         # Calculating data and target shapes
-         ds = self.get_dataset()
-         sample, target = ds[0]
-         self._sample_shape = [str(dim) for dim in sample.shape]
-         self._target_shape = [str(dim) for dim in target.shape]
- 
-     def get_dataset(self, dataset_type='train'):
-         """Return a shard dataset by type."""
-         return KvasirShardDataset(
-             dataset_dir=self.data_folder,
-             rank=self.rank,
-             worldsize=self.worldsize,
-             enforce_image_hw=self.enforce_image_hw
-         )
- 
-     @staticmethod
-     def download_data(data_folder):
-         """Download data."""
-         zip_file_path = data_folder / 'kvasir.zip'
-         os.makedirs(data_folder, exist_ok=True)
-         os.system(
-             'wget -nc'
-             " 'https://datasets.simula.no/downloads/"
-             "hyper-kvasir/hyper-kvasir-segmented-images.zip'"
-             f' -O {zip_file_path.relative_to(Path.cwd())}'
-         )
-         zip_sha384 = ('e30d18a772c6520476e55b610a4db457237f151e'
-                       '19182849d54b49ae24699881c1e18e0961f77642be900450ef8b22e7')
-         validate_file_hash(zip_file_path, zip_sha384)
-         os.system(f'unzip -n {zip_file_path.relative_to(Path.cwd())}'
-                   f' -d {data_folder.relative_to(Path.cwd())}')
- 
-     @property
-     def sample_shape(self):
-         """Return the sample shape info."""
-         return self._sample_shape
- 
-     @property
-     def target_shape(self):
-         """Return the target shape info."""
-         return self._target_shape
- 
-     @property
-     def dataset_description(self) -> str:
-         """Return the dataset description."""
-         return (f'Kvasir dataset, shard number {self.rank} '
-                 f'out of {self.worldsize}')
- 
- 
- if __name__ == '__main__':
-     from openfl.interface.cli import setup_logging
- 
-     setup_logging()
- 
-     data_folder = 'data'
-     rank_worldsize = '1,100'
-     enforce_image_hw = '529,622'
- 
-     kvasir_sd = KvasirShardDescriptor(
-         data_folder,
-         rank_worldsize=rank_worldsize,
-         enforce_image_hw=enforce_image_hw)
- 
-     print(kvasir_sd.dataset_description)
-     print(kvasir_sd.sample_shape, kvasir_sd.target_shape)
- 
-     from openfl.component.envoy.envoy import Envoy
- 
-     shard_name = 'one'
-     director_host = 'localhost'
-     director_port = 50051
- 
-     keeper = Envoy(
-         shard_name=shard_name,
-         director_host=director_host,
-         director_port=director_port,
-         shard_descriptor=kvasir_sd,
-         tls=True,
-         root_certificate='./cert/root_ca.crt',
-         private_key='./cert/one.key',
-         certificate='./cert/one.crt',
-     )
- 
-     keeper.start()
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/envoy/kvasir_shard_descriptor_with_data_splitter.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/envoy/kvasir_shard_descriptor_with_data_splitter.py
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/envoy/kvasir_shard_descriptor_with_data_splitter.py	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/envoy/kvasir_shard_descriptor_with_data_splitter.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,119 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Kvasir shard descriptor."""
- 
- 
- import os
- from pathlib import Path
- 
- import numpy as np
- from PIL import Image
- 
- from openfl.interface.interactive_api.shard_descriptor import ShardDataset
- from openfl.interface.interactive_api.shard_descriptor import ShardDescriptor
- from openfl.utilities import validate_file_hash
- from openfl.utilities.data_splitters import RandomNumPyDataSplitter
- 
- 
- class KvasirShardDataset(ShardDataset):
-     """Kvasir Shard dataset class."""
- 
-     def __init__(self, dataset_dir: Path, rank=1, worldsize=1, enforce_image_hw=None):
-         """Initialize KvasirShardDataset."""
-         self.rank = rank
-         self.worldsize = worldsize
-         self.dataset_dir = dataset_dir
-         self.enforce_image_hw = enforce_image_hw
- 
-         self.images_path = self.dataset_dir / 'segmented-images' / 'images'
-         self.masks_path = self.dataset_dir / 'segmented-images' / 'masks'
- 
-         self.images_names = [
-             img_name
-             for img_name in sorted(os.listdir(self.images_path))
-             if len(img_name) > 3 and img_name[-3:] == 'jpg'
-         ]
-         # Sharding
-         data_splitter = RandomNumPyDataSplitter()
-         shard_idx = data_splitter.split(self.images_names, self.worldsize)[self.rank]
-         self.images_names = [self.images_names[i] for i in shard_idx]
- 
-     def __getitem__(self, index):
-         """Return a item by the index."""
-         name = self.images_names[index]
-         # Reading data
-         img = Image.open(self.images_path / name)
-         mask = Image.open(self.masks_path / name)
-         if self.enforce_image_hw is not None:
-             # If we need to resize data
-             # PIL accepts (w,h) tuple, not (h,w)
-             img = img.resize(self.enforce_image_hw[::-1])
-             mask = mask.resize(self.enforce_image_hw[::-1])
-         img = np.asarray(img)
-         mask = np.asarray(mask)
-         assert img.shape[2] == 3
- 
-         return img, mask[:, :, 0].astype(np.uint8)
- 
-     def __len__(self):
-         """Return the len of the dataset."""
-         return len(self.images_names)
- 
- 
- class KvasirShardDescriptor(ShardDescriptor):
-     """Shard descriptor class."""
- 
-     def __init__(self, data_folder: str = 'kvasir_data',
-                  rank_worldsize: str = '1,1',
-                  enforce_image_hw: str = None) -> None:
-         """Initialize KvasirShardDescriptor."""
-         super().__init__()
-         # Settings for sharding the dataset
-         self.rank, self.worldsize = tuple(int(num) for num in rank_worldsize.split(','))
- 
-         self.data_folder = Path.cwd() / data_folder
-         self.download_data(self.data_folder)
- 
-         # Settings for resizing data
-         self.enforce_image_hw = None
-         if enforce_image_hw is not None:
-             self.enforce_image_hw = tuple(int(size) for size in enforce_image_hw.split(','))
- 
-     def get_dataset(self, dataset_type='train'):
-         """Return a shard dataset by type."""
-         return KvasirShardDataset(
-             dataset_dir=self.data_folder,
-             rank=self.rank,
-             worldsize=self.worldsize,
-             enforce_image_hw=self.enforce_image_hw
-         )
- 
-     @staticmethod
-     def download_data(data_folder):
-         """Download data."""
-         zip_file_path = data_folder / 'kvasir.zip'
-         os.makedirs(data_folder, exist_ok=True)
-         os.system('wget -nc'
-                   " 'https://datasets.simula.no/downloads/hyper-kvasir/"
-                   "hyper-kvasir-segmented-images.zip'"
-                   f' -O {zip_file_path.relative_to(Path.cwd())}')
-         zip_sha384 = ('e30d18a772c6520476e55b610a4db457237f151e'
-                       '19182849d54b49ae24699881c1e18e0961f77642be900450ef8b22e7')
-         validate_file_hash(zip_file_path, zip_sha384)
-         os.system(f'unzip -n {zip_file_path.relative_to(Path.cwd())}'
-                   f' -d {data_folder.relative_to(Path.cwd())}')
- 
-     @property
-     def sample_shape(self):
-         """Return the sample shape info."""
-         return ['300', '400', '3']
- 
-     @property
-     def target_shape(self):
-         """Return the target shape info."""
-         return ['300', '400']
- 
-     @property
-     def dataset_description(self) -> str:
-         """Return the dataset description."""
-         return f'Kvasir dataset, shard number {self.rank} out of {self.worldsize}'
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/envoy/sd_requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/envoy/sd_requirements.txt
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/envoy/sd_requirements.txt	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/envoy/sd_requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- numpy
- pillow
- pynvml
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/envoy/start_envoy.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/envoy/start_envoy.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/envoy/start_envoy.sh	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/envoy/start_envoy.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- 
- fx envoy start -n env_one --disable-tls --envoy-config-path envoy_config.yaml -dh localhost -dp 50050
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/envoy/start_envoy_with_tls.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/envoy/start_envoy_with_tls.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/envoy/start_envoy_with_tls.sh	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/envoy/start_envoy_with_tls.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,6 ****
- #!/bin/bash
- set -e
- ENVOY_NAME=$1
- DIRECTOR_FQDN=$2
- 
- fx envoy start -n "$ENVOY_NAME" --envoy-config-path envoy_config.yaml -dh "$DIRECTOR_FQDN" -dp 50050 -rc cert/root_ca.crt -pk cert/"$ENVOY_NAME".key -oc cert/"$ENVOY_NAME".crt
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/workspace/layers.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/workspace/layers.py
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/workspace/layers.py	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/workspace/layers.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,103 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Layers for Unet model."""
- 
- import torch
- import torch.nn as nn
- import torch.nn.functional as F
- 
- 
- def soft_dice_loss(output, target):
-     """Calculate loss."""
-     num = target.size(0)
-     m1 = output.view(num, -1)
-     m2 = target.view(num, -1)
-     intersection = m1 * m2
-     score = 2.0 * (intersection.sum(1) + 1) / (m1.sum(1) + m2.sum(1) + 1)
-     score = 1 - score.sum() / num
-     return score
- 
- 
- def soft_dice_coef(output, target):
-     """Calculate soft DICE coefficient."""
-     num = target.size(0)
-     m1 = output.view(num, -1)
-     m2 = target.view(num, -1)
-     intersection = m1 * m2
-     score = 2.0 * (intersection.sum(1) + 1) / (m1.sum(1) + m2.sum(1) + 1)
-     return score.sum()
- 
- 
- class DoubleConv(nn.Module):
-     """Pytorch double conv class."""
- 
-     def __init__(self, in_ch, out_ch):
-         """Initialize layer."""
-         super(DoubleConv, self).__init__()
-         self.in_ch = in_ch
-         self.out_ch = out_ch
-         self.conv = nn.Sequential(
-             nn.Conv2d(in_ch, out_ch, 3, padding=1),
-             nn.BatchNorm2d(out_ch),
-             nn.ReLU(inplace=True),
-             nn.Conv2d(out_ch, out_ch, 3, padding=1),
-             nn.BatchNorm2d(out_ch),
-             nn.ReLU(inplace=True),
-         )
- 
-     def forward(self, x):
-         """Do forward pass."""
-         x = self.conv(x)
-         return x
- 
- 
- class Down(nn.Module):
-     """Pytorch nn module subclass."""
- 
-     def __init__(self, in_ch, out_ch):
-         """Initialize layer."""
-         super(Down, self).__init__()
-         self.mpconv = nn.Sequential(
-             nn.MaxPool2d(2),
-             DoubleConv(in_ch, out_ch)
-         )
- 
-     def forward(self, x):
-         """Do forward pass."""
-         x = self.mpconv(x)
-         return x
- 
- 
- class Up(nn.Module):
-     """Pytorch nn module subclass."""
- 
-     def __init__(self, in_ch, out_ch, bilinear=False):
-         """Initialize layer."""
-         super(Up, self).__init__()
-         self.in_ch = in_ch
-         self.out_ch = out_ch
-         if bilinear:
-             self.up = nn.Upsample(
-                 scale_factor=2,
-                 mode='bilinear',
-                 align_corners=True
-             )
-         else:
-             self.up = nn.ConvTranspose2d(in_ch, in_ch // 2, 2, stride=2)
-         self.conv = DoubleConv(in_ch, out_ch)
- 
-     def forward(self, x1, x2):
-         """Do forward pass."""
-         x1 = self.up(x1)
-         diff_y = x2.size()[2] - x1.size()[2]
-         diff_x = x2.size()[3] - x1.size()[3]
- 
-         x1 = F.pad(
-             x1,
-             (diff_x // 2, diff_x - diff_x // 2, diff_y // 2, diff_y - diff_y // 2)
-         )
- 
-         x = torch.cat([x2, x1], dim=1)
-         x = self.conv(x)
-         return x
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/workspace/PyTorch_Kvasir_UNet.ipynb ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/workspace/PyTorch_Kvasir_UNet.ipynb
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/workspace/PyTorch_Kvasir_UNet.ipynb	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/workspace/PyTorch_Kvasir_UNet.ipynb	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,610 ****
- {
-  "cells": [
-   {
-    "cell_type": "markdown",
-    "id": "liquid-jacket",
-    "metadata": {},
-    "source": [
-     "# Federated Kvasir with Director example"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "alike-sharing",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Install dependencies if not already installed\n",
-     "!pip install torchvision==0.8.1"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "16986f22",
-    "metadata": {},
-    "source": [
-     "# Connect to the Federation"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "4485ac79",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Create a federation\n",
-     "from openfl.interface.interactive_api.federation import Federation\n",
-     "\n",
-     "# please use the same identificator that was used in signed certificate\n",
-     "client_id = 'frontend'\n",
-     "director_node_fqdn = 'localhost'\n",
-     "director_port = 50050\n",
-     "\n",
-     "# 1) Run with API layer - Director mTLS \n",
-     "# If the user wants to enable mTLS their must provide CA root chain, and signed key pair to the federation interface\n",
-     "# cert_chain = 'cert/root_ca.crt'\n",
-     "# API_certificate = 'cert/frontend.crt'\n",
-     "# API_private_key = 'cert/frontend.key'\n",
-     "\n",
-     "# federation = Federation(\n",
-     "#     client_id=client_id,\n",
-     "#     director_node_fqdn=director_node_fqdn,\n",
-     "#     director_port=director_port,\n",
-     "#     tls=True,\n",
-     "#     cert_chain=cert_chain,\n",
-     "#     api_cert=api_certificate,\n",
-     "#     api_private_key=api_private_key\n",
-     "# )\n",
-     "\n",
-     "# --------------------------------------------------------------------------------------------------------------------\n",
-     "\n",
-     "# 2) Run with TLS disabled (trusted environment)\n",
-     "# Federation can also determine local fqdn automatically\n",
-     "federation = Federation(\n",
-     "    client_id=client_id,\n",
-     "    director_node_fqdn=director_node_fqdn,\n",
-     "    director_port=director_port,\n",
-     "    tls=False\n",
-     ")\n"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "e35802d5",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# import time\n",
-     "# while True:\n",
-     "#     shard_registry = federation.get_shard_registry()\n",
-     "#     print(shard_registry)\n",
-     "#     time.sleep(5)\n",
-     "shard_registry = federation.get_shard_registry()\n",
-     "shard_registry"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "67ae50de",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "federation.target_shape"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "920216d3",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# First, request a dummy_shard_desc that holds information about the federated dataset \n",
-     "dummy_shard_desc = federation.get_dummy_shard_descriptor(size=10)\n",
-     "dummy_shard_dataset = dummy_shard_desc.get_dataset('train')\n",
-     "sample, target = dummy_shard_dataset[0]\n",
-     "f\"Sample shape: {sample.shape}, target shape: {target.shape}\""
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "obvious-tyler",
-    "metadata": {},
-    "source": [
-     "## Creating a FL experiment using Interactive API"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "rubber-address",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "sustainable-public",
-    "metadata": {},
-    "source": [
-     "### Register dataset"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "unlike-texas",
-    "metadata": {},
-    "source": [
-     "We extract User dataset class implementation.\n",
-     "Is it convinient?\n",
-     "What if the dataset is not a class?"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "64f37dcf",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import os\n",
-     "import PIL\n",
-     "import numpy as np\n",
-     "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
-     "from torchvision import transforms as tsf\n",
-     "\n",
-     "\n",
-     "class KvasirShardDataset(Dataset):\n",
-     "    \n",
-     "    def __init__(self, dataset):\n",
-     "        self._dataset = dataset\n",
-     "        \n",
-     "        # Prepare transforms\n",
-     "        self.img_trans = tsf.Compose([\n",
-     "            tsf.ToPILImage(),\n",
-     "            tsf.Resize((332, 332)),\n",
-     "            tsf.ToTensor(),\n",
-     "            tsf.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
-     "        self.mask_trans = tsf.Compose([\n",
-     "            tsf.ToPILImage(),\n",
-     "            tsf.Resize((332, 332), interpolation=PIL.Image.NEAREST),\n",
-     "            tsf.ToTensor()])\n",
-     "        \n",
-     "    def __getitem__(self, index):\n",
-     "        img, mask = self._dataset[index]\n",
-     "        img = self.img_trans(img).numpy()\n",
-     "        mask = self.mask_trans(mask).numpy()\n",
-     "        return img, mask\n",
-     "    \n",
-     "    def __len__(self):\n",
-     "        return len(self._dataset)\n",
-     "\n",
-     "    \n",
-     "\n",
-     "# Now you can implement you data loaders using dummy_shard_desc\n",
-     "class KvasirSD(DataInterface):\n",
-     "\n",
-     "    def __init__(self, validation_fraction=1/8, **kwargs):\n",
-     "        super().__init__(**kwargs)\n",
-     "        \n",
-     "        self.validation_fraction = validation_fraction\n",
-     "        \n",
-     "    @property\n",
-     "    def shard_descriptor(self):\n",
-     "        return self._shard_descriptor\n",
-     "        \n",
-     "    @shard_descriptor.setter\n",
-     "    def shard_descriptor(self, shard_descriptor):\n",
-     "        \"\"\"\n",
-     "        Describe per-collaborator procedures or sharding.\n",
-     "\n",
-     "        This method will be called during a collaborator initialization.\n",
-     "        Local shard_descriptor  will be set by Envoy.\n",
-     "        \"\"\"\n",
-     "        self._shard_descriptor = shard_descriptor\n",
-     "        self._shard_dataset = KvasirShardDataset(shard_descriptor.get_dataset('train'))\n",
-     "        \n",
-     "        validation_size = max(1, int(len(self._shard_dataset) * self.validation_fraction))\n",
-     "        \n",
-     "        self.train_indeces = np.arange(len(self._shard_dataset) - validation_size)\n",
-     "        self.val_indeces = np.arange(len(self._shard_dataset) - validation_size, len(self._shard_dataset))\n",
-     "    \n",
-     "    def get_train_loader(self, **kwargs):\n",
-     "        \"\"\"\n",
-     "        Output of this method will be provided to tasks with optimizer in contract\n",
-     "        \"\"\"\n",
-     "        train_sampler = SubsetRandomSampler(self.train_indeces)\n",
-     "        return DataLoader(\n",
-     "            self._shard_dataset,\n",
-     "            num_workers=8,\n",
-     "            batch_size=self.kwargs['train_bs'],\n",
-     "            sampler=train_sampler\n",
-     "        )\n",
-     "\n",
-     "    def get_valid_loader(self, **kwargs):\n",
-     "        \"\"\"\n",
-     "        Output of this method will be provided to tasks without optimizer in contract\n",
-     "        \"\"\"\n",
-     "        val_sampler = SubsetRandomSampler(self.val_indeces)\n",
-     "        return DataLoader(\n",
-     "            self._shard_dataset,\n",
-     "            num_workers=8,\n",
-     "            batch_size=self.kwargs['valid_bs'],\n",
-     "            sampler=val_sampler\n",
-     "        )\n",
-     "\n",
-     "    def get_train_data_size(self):\n",
-     "        \"\"\"\n",
-     "        Information for aggregation\n",
-     "        \"\"\"\n",
-     "        return len(self.train_indeces)\n",
-     "\n",
-     "    def get_valid_data_size(self):\n",
-     "        \"\"\"\n",
-     "        Information for aggregation\n",
-     "        \"\"\"\n",
-     "        return len(self.val_indeces)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "d8df35f5",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "fed_dataset = KvasirSD(train_bs=4, valid_bs=8)\n",
-     "fed_dataset.shard_descriptor = dummy_shard_desc\n",
-     "for i, (sample, target) in enumerate(fed_dataset.get_train_loader()):\n",
-     "    print(sample.shape)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "caring-distinction",
-    "metadata": {},
-    "source": [
-     "### Describe a model and optimizer"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "visible-victor",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import torch\n",
-     "import torch.nn as nn\n",
-     "import torch.optim as optim"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "foreign-gospel",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "\"\"\"\n",
-     "UNet model definition\n",
-     "\"\"\"\n",
-     "from layers import soft_dice_coef, soft_dice_loss, DoubleConv, Down, Up\n",
-     "\n",
-     "\n",
-     "class UNet(nn.Module):\n",
-     "    def __init__(self, n_channels=3, n_classes=1):\n",
-     "        super().__init__()\n",
-     "        self.inc = DoubleConv(n_channels, 64)\n",
-     "        self.down1 = Down(64, 128)\n",
-     "        self.down2 = Down(128, 256)\n",
-     "        self.down3 = Down(256, 512)\n",
-     "        self.up1 = Up(512, 256)\n",
-     "        self.up2 = Up(256, 128)\n",
-     "        self.up3 = Up(128, 64)\n",
-     "        self.outc = nn.Conv2d(64, n_classes, 1)\n",
-     "\n",
-     "    def forward(self, x):\n",
-     "        x1 = self.inc(x)\n",
-     "        x2 = self.down1(x1)\n",
-     "        x3 = self.down2(x2)\n",
-     "        x4 = self.down3(x3)\n",
-     "        x = self.up1(x4, x3)\n",
-     "        x = self.up2(x, x2)\n",
-     "        x = self.up3(x, x1)\n",
-     "        x = self.outc(x)\n",
-     "        x = torch.sigmoid(x)\n",
-     "        return x\n",
-     "    \n",
-     "model_unet = UNet()"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "greater-activation",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "optimizer_adam = optim.Adam(model_unet.parameters(), lr=1e-4)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "caroline-passion",
-    "metadata": {},
-    "source": [
-     "#### Register model"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "handled-teens",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from copy import deepcopy\n",
-     "\n",
-     "framework_adapter = 'openfl.plugins.frameworks_adapters.pytorch_adapter.FrameworkAdapterPlugin'\n",
-     "MI = ModelInterface(model=model_unet, optimizer=optimizer_adam, framework_plugin=framework_adapter)\n",
-     "\n",
-     "# Save the initial model state\n",
-     "initial_model = deepcopy(model_unet)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "portuguese-groove",
-    "metadata": {},
-    "source": [
-     "### Define and register FL tasks"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "increasing-builder",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "TI = TaskInterface()\n",
-     "import torch\n",
-     "\n",
-     "import tqdm\n",
-     "from openfl.component.aggregation_functions import Median\n",
-     "\n",
-     "# The Interactive API supports registering functions definied in main module or imported.\n",
-     "def function_defined_in_notebook(some_parameter):\n",
-     "    print(f'Also I accept a parameter and it is {some_parameter}')\n",
-     "\n",
-     "#The Interactive API supports overriding of the aggregation function\n",
-     "aggregation_function = Median()\n",
-     "\n",
-     "# Task interface currently supports only standalone functions.\n",
-     "@TI.add_kwargs(**{'some_parameter': 42})\n",
-     "@TI.register_fl_task(model='unet_model', data_loader='train_loader', \\\n",
-     "                     device='device', optimizer='optimizer')     \n",
-     "@TI.set_aggregation_function(aggregation_function)\n",
-     "def train(unet_model, train_loader, optimizer, device, loss_fn=soft_dice_loss, some_parameter=None):\n",
-     "    \n",
-     "    \"\"\"    \n",
-     "    The following constructions, that may lead to resource race\n",
-     "    is no longer needed:\n",
-     "    \n",
-     "    if not torch.cuda.is_available():\n",
-     "        device = 'cpu'\n",
-     "    else:\n",
-     "        device = 'cuda'\n",
-     "        \n",
-     "    \"\"\"\n",
-     "\n",
-     "    print(f'\\n\\n TASK TRAIN GOT DEVICE {device}\\n\\n')\n",
-     "    \n",
-     "    function_defined_in_notebook(some_parameter)\n",
-     "    \n",
-     "    train_loader = tqdm.tqdm(train_loader, desc=\"train\")\n",
-     "    \n",
-     "    unet_model.train()\n",
-     "    unet_model.to(device)\n",
-     "\n",
-     "    losses = []\n",
-     "\n",
-     "    for data, target in train_loader:\n",
-     "        data, target = torch.tensor(data).to(device), torch.tensor(\n",
-     "            target).to(device, dtype=torch.float32)\n",
-     "        optimizer.zero_grad()\n",
-     "        output = unet_model(data)\n",
-     "        loss = loss_fn(output=output, target=target)\n",
-     "        loss.backward()\n",
-     "        optimizer.step()\n",
-     "        losses.append(loss.detach().cpu().numpy())\n",
-     "        \n",
-     "    return {'train_loss': np.mean(losses),}\n",
-     "\n",
-     "\n",
-     "@TI.register_fl_task(model='unet_model', data_loader='val_loader', device='device')     \n",
-     "def validate(unet_model, val_loader, device):\n",
-     "    print(f'\\n\\n TASK VALIDATE GOT DEVICE {device}\\n\\n')\n",
-     "    \n",
-     "    unet_model.eval()\n",
-     "    unet_model.to(device)\n",
-     "    \n",
-     "    val_loader = tqdm.tqdm(val_loader, desc=\"validate\")\n",
-     "\n",
-     "    val_score = 0\n",
-     "    total_samples = 0\n",
-     "\n",
-     "    with torch.no_grad():\n",
-     "        for data, target in val_loader:\n",
-     "            samples = target.shape[0]\n",
-     "            total_samples += samples\n",
-     "            data, target = torch.tensor(data).to(device), \\\n",
-     "                torch.tensor(target).to(device, dtype=torch.int64)\n",
-     "            output = unet_model(data)\n",
-     "            val = soft_dice_coef(output, target)\n",
-     "            val_score += val.sum().cpu().numpy()\n",
-     "            \n",
-     "    return {'dice_coef': val_score / total_samples,}"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "derived-bride",
-    "metadata": {},
-    "source": [
-     "## Time to start a federated learning experiment"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "mature-renewal",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# create an experimnet in federation\n",
-     "experiment_name = 'kvasir_test_experiment'\n",
-     "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "lightweight-causing",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# If I use autoreload I got a pickling error\n",
-     "\n",
-     "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
-     "fl_experiment.start(model_provider=MI, \n",
-     "                    task_keeper=TI,\n",
-     "                    data_loader=fed_dataset,\n",
-     "                    rounds_to_train=2,\n",
-     "                    opt_treatment='CONTINUE_GLOBAL',\n",
-     "                    device_assignment_policy='CUDA_PREFERRED')\n"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "f1543a36",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# If user want to stop IPython session, then reconnect and check how experiment is going \n",
-     "# fl_experiment.restore_experiment_state(MI)\n",
-     "\n",
-     "fl_experiment.stream_metrics()"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "8c30b301",
-    "metadata": {},
-    "source": [
-     "## Now we validate the best model!"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "55acff59",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "best_model = fl_experiment.get_best_model()"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "9479fb7f",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# We remove exremove_experiment_datamove_experiment_datamove_experiment_datariment data from director\n",
-     "fl_experiment.remove_experiment_data()"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "75c8aeab",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "best_model.inc.conv[0].weight\n",
-     "# model_unet.inc.conv[0].weight"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "a2acb7e6",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Validating initial model\n",
-     "validate(initial_model, fed_dataset.get_valid_loader(), 'cpu')"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "c12ca93f",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Validating trained model\n",
-     "validate(best_model, fed_dataset.get_valid_loader(), 'cpu')"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "1e6734f6",
-    "metadata": {},
-    "source": [
-     "## We can tune model further!"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "3940e75e",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "MI = ModelInterface(model=best_model, optimizer=optimizer_adam, framework_plugin=framework_adapter)\n",
-     "fl_experiment.start(model_provider=MI, task_keeper=TI, data_loader=fed_dataset, rounds_to_train=4, \\\n",
-     "                              opt_treatment='CONTINUE_GLOBAL')"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "1bd786d2",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "best_model = fl_experiment.get_best_model()\n",
-     "# Validating trained model\n",
-     "validate(best_model, fed_dataset.get_valid_loader(), 'cpu')"
-    ]
-   }
-  ],
-  "metadata": {
-   "language_info": {
-    "name": "python"
-   }
-  },
-  "nbformat": 4,
-  "nbformat_minor": 5
- }
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/director/director_config.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/director/director_config.yaml
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/director/director_config.yaml	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/director/director_config.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,5 ****
- settings:
-   listen_host: localhost
-   listen_port: 50050
-   sample_shape: ['28','28']
-   target_shape: ['1']
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/director/start_director.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/director/start_director.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/director/start_director.sh	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/director/start_director.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- 
- fx director start --disable-tls -c director_config.yaml
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/envoy/envoy_config_no_gpu.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/envoy/envoy_config_no_gpu.yaml
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/envoy/envoy_config_no_gpu.yaml	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/envoy/envoy_config_no_gpu.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,7 ****
- params:
-   cuda_devices: []
- 
- shard_descriptor:
-   template: mnist_shard_descriptor.MnistShardDescriptor
-   params:
-     rank_worldsize: 1,2
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/envoy/envoy_config.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/envoy/envoy_config.yaml
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/envoy/envoy_config.yaml	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/envoy/envoy_config.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,12 ****
- params:
-   cuda_devices: [0,2]
- 
- optional_plugin_components:
-  cuda_device_monitor:
-    template: openfl.plugins.processing_units_monitor.pynvml_monitor.PynvmlCUDADeviceMonitor
-    settings: []
- 
- shard_descriptor:
-   template: mnist_shard_descriptor.MnistShardDescriptor
-   params:
-     rank_worldsize: 1, 2
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/envoy/mnist_shard_descriptor.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/envoy/mnist_shard_descriptor.py
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/envoy/mnist_shard_descriptor.py	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/envoy/mnist_shard_descriptor.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,98 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Mnist Shard Descriptor."""
- 
- import logging
- from typing import Any
- from typing import Dict
- from typing import List
- from typing import Tuple
- 
- from torchvision import datasets
- 
- from openfl.interface.interactive_api.shard_descriptor import ShardDataset
- from openfl.interface.interactive_api.shard_descriptor import ShardDescriptor
- 
- logger = logging.getLogger(__name__)
- 
- 
- class MnistShardDataset(ShardDataset):
-     """Mnist Shard dataset class."""
- 
-     def __init__(self, x, y, data_type, rank: int = 1, worldsize: int = 1) -> None:
-         """Initialize Mnist shard Dataset."""
-         self.data_type = data_type
-         self.rank = rank
-         self.worldsize = worldsize
- 
-         self.x = x[self.rank - 1::self.worldsize]
-         self.y = y[self.rank - 1::self.worldsize]
- 
-     def __getitem__(self, index: int) -> Tuple[Any, Any]:
-         """Return an item by the index."""
-         return self.x[index], self.y[index]
- 
-     def __len__(self) -> int:
-         """Return the len of the dataset."""
-         return len(self.x)
- 
- 
- class MnistShardDescriptor(ShardDescriptor):
-     """Mnist Shard descriptor class."""
- 
-     def __init__(
-             self,
-             rank_worldsize: str = '1, 1',
-             **kwargs
-     ) -> None:
-         """Initialize MnistShardDescriptor."""
-         self.rank, self.worldsize = tuple(int(num) for num in rank_worldsize.split(','))
-         (x_train, y_train), (x_val, y_val) = self.download_data()
-         self.data_by_type = {
-             'train': (x_train, y_train),
-             'val': (x_val, y_val)
-         }
- 
-     def get_shard_dataset_types(self) -> List[Dict[str, Any]]:
-         """Get available shard dataset types."""
-         return list(self.data_by_type)
- 
-     def get_dataset(self, dataset_type: str = 'train') -> MnistShardDataset:
-         """Return a shard dataset by type."""
-         if dataset_type not in self.data_by_type:
-             raise Exception(f'Wrong dataset type: {dataset_type}')
-         return MnistShardDataset(
-             *self.data_by_type[dataset_type],
-             data_type=dataset_type,
-             rank=self.rank,
-             worldsize=self.worldsize
-         )
- 
-     @property
-     def sample_shape(self) -> List[str]:
-         """Return the sample shape info."""
-         return ['28', '28']
- 
-     @property
-     def target_shape(self) -> List[str]:
-         """Return the target shape info."""
-         return ['1']
- 
-     @property
-     def dataset_description(self) -> str:
-         """Return the dataset description."""
-         return (f'Mnist dataset, shard number {self.rank}'
-                 f' out of {self.worldsize}')
- 
-     def download_data(self) -> Tuple[Tuple[Any, Any], Tuple[Any, Any]]:
-         """Download prepared dataset."""
-         train_data, val_data = (
-             datasets.MNIST('data', train=train, download=True)
-             for train in (True, False)
-         )
-         x_train, y_train = train_data.train_data, train_data.train_labels
-         x_val, y_val = val_data.test_data, val_data.test_labels
- 
-         print('Mnist data was loaded!')
-         return (x_train, y_train), (x_val, y_val)
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/envoy/sd_requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/envoy/sd_requirements.txt
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/envoy/sd_requirements.txt	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/envoy/sd_requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,5 ****
- numpy
- pillow
- pynvml==11.4.1
- torch==1.9.1
- torchvision==0.10.1
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/envoy/start_envoy.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/envoy/start_envoy.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/envoy/start_envoy.sh	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/envoy/start_envoy.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- 
- fx envoy start -n env_one --disable-tls --envoy-config-path envoy_config.yaml -dh localhost -dp 50050
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/README.md ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/README.md
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/README.md	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/README.md	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,81 ****
- # PyTorch Lightining tutorial for Generative Adverserial Network (GAN) Dataset
- 
- ### 1. About model: Generative Adverserial Networks (GANs)
- 
- [Generative Adverserial Networks](https://arxiv.org/abs/1406.2661) or GANs were introduced to the
- machine learning community by Ian J. Goodfellow in 2014. The idea is to generate real-looking
- samples or images that resemble the training data. A GAN has three primary components: a Generator
- model for generating new data from random data (noise), a discriminator model for classifying
- whether generated data is real or fake, and the adversarial network that pits them against each
- other. The fundamental nature of these dual networks is to outplay each other until the generator
- starts generating real looking samples that the discriminator fails to differentiate.
- 
- ### 2. About framework: PyTorch Lightning
- 
- [Pytorch Lightning](https://www.pytorchlightning.ai/) is a framework built on top of PyTorch that
- allows the models to be scaled without the boilerplate.
- 
- ### 3. About dataset: MNIST
- 
- [MNIST](http://yann.lecun.com/exdb/mnist/) database is a database of handwritten digits that has a
- training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set
- available from NIST. The digits have been size-normalized and centered in a fixed-size image.
- 
- ### 4. Using multiple optimizers
- 
- The example uses two different optimizers: one for discriminator and one for generator.
- The [plugin](workspace/plugin_for_multiple_optimizers.py) to support multiple optimizers with
- OpenFL has been added. Note that in order to use PyTorch Lightning framework with a single
- optimizer, this plugin is NOT required.
- 
- ### 5. Training Generator and Discriminator models separately
- 
- Cuurently, the tutorial shows how to train both the generator and the discriminator models
- parallely. Individual models can be trained as well. To train only the generator, the flag '
- train_gen_only' should be set to 1 and to train only the discriminator, 'train_disc_only' should be
- set to 1.
- 
- ### 5. Links
- 
- * [Original GAN paper](https://arxiv.org/abs/1406.2661)
- * [Original PyTorch Lightning code](https://pytorch-lightning.readthedocs.io/en/stable/notebooks/lightning_examples/basic-gan.html)
- 
- ### 6. How to run this tutorial (without TLS and locally as a simulation):
- 
- Go to example [folder](./)
- 
- ```sh
- export PYTORCH_LIGHTNING_MNIST_GAN=<openfl_folder>/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN
- ```
- 
- 1. Run director:
- 
- ```sh
- cd $PYTORCH_LIGHTNING_MNIST_GAN/director
- bash start_director.sh
- ```
- 
- 2. Run envoy:
- 
- ```sh
- cd $PYTORCH_LIGHTNING_MNIST_GAN/envoy
- pip install -r sd_requirements.txt
- bash start_envoy.sh
- ```
- 
- Optional: start second envoy:
- 
- - Copy `$PYTORCH_LIGHTNING_MNIST_GAN/envoy` to another folder, change the config and envoy name in
-   start_envoy.sh and run from there:
- 
- ```sh
- cd $PYTORCH_LIGHTNING_MNIST_GAN/envoy_two
- bash start_envoy.sh
- ```
- 
- 3. Run `PyTorch_Lightning_GAN.ipynb` jupyter notebook:
- 
- ```sh
- cd $PYTORCH_LIGHTNING_MNIST_GAN/workspace
- jupyter lab PyTorch_Lightning_GAN.ipynb
- ```
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/workspace/plugin_for_multiple_optimizers.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/workspace/plugin_for_multiple_optimizers.py
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/workspace/plugin_for_multiple_optimizers.py	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/workspace/plugin_for_multiple_optimizers.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,37 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Pytorch Framework Adapter plugin for multiple optimizers."""
- 
- 
- from openfl.plugins.frameworks_adapters.pytorch_adapter import _get_optimizer_state
- from openfl.plugins.frameworks_adapters.pytorch_adapter import FrameworkAdapterPlugin
- from openfl.plugins.frameworks_adapters.pytorch_adapter import to_cpu_numpy
- 
- 
- class FrameworkAdapterPluginforMultipleOpt(FrameworkAdapterPlugin):
-     """Framework adapter plugin class for multiple optimizers."""
- 
-     def __init__(self):
-         """Initialize framework adapter."""
-         super().__init__()
- 
-     @staticmethod
-     def get_tensor_dict(model, optimizers=None):
-         """
-         Extract tensor dict from a model and a list of optimizers.
- 
-         Returns:
-         dict {weight name: numpy ndarray}
-         """
-         state = to_cpu_numpy(model.state_dict())
-         if optimizers is not None:
-             for opt in optimizers:
-                 if isinstance(opt, dict):
-                     opt_state = _get_optimizer_state(opt['optimizer'])
-                 else:
-                     opt_state = _get_optimizer_state(opt)
- 
-                 state = {**state, **opt_state}
- 
-         return state
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/workspace/PyTorch_Lightning_GAN.ipynb ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/workspace/PyTorch_Lightning_GAN.ipynb
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/workspace/PyTorch_Lightning_GAN.ipynb	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Lightning_MNIST_GAN/workspace/PyTorch_Lightning_GAN.ipynb	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,699 ****
- {
-  "cells": [
-   {
-    "cell_type": "markdown",
-    "id": "liquid-jacket",
-    "metadata": {},
-    "source": [
-     "# Federated GAN tutorial with PyTorch Lightning"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "alike-sharing",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "!pip install \"pytorch-lightning>=1.3\" \"torch==1.9.1\" \"torchvision==0.10.1\" \"torchmetrics>=0.3\" \"scikit-image\" \"matplotlib\""
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "16986f22",
-    "metadata": {},
-    "source": [
-     "# Connect to the Federation"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "4485ac79",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from openfl.interface.interactive_api.federation import Federation\n",
-     "\n",
-     "client_id = \"frontend\"\n",
-     "director_node_fqdn = \"localhost\"\n",
-     "director_port = 50050\n",
-     "\n",
-     "#Run with TLS disabled (trusted environment)\n",
-     "federation = Federation(\n",
-     "    client_id=client_id,\n",
-     "    director_node_fqdn=director_node_fqdn,\n",
-     "    director_port=director_port,\n",
-     "    tls=False,\n",
-     ")"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "e35802d5",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "shard_registry = federation.get_shard_registry()\n",
-     "shard_registry"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "67ae50de",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "federation.target_shape"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "obvious-tyler",
-    "metadata": {},
-    "source": [
-     "## Creating a FL experiment using Interactive API"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "rubber-address",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from openfl.interface.interactive_api.experiment import (\n",
-     "    DataInterface,\n",
-     "    FLExperiment,\n",
-     "    ModelInterface,\n",
-     "    TaskInterface,\n",
-     ")"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "sustainable-public",
-    "metadata": {},
-    "source": [
-     "### Register dataset"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "8d9acb53",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import copy\n",
-     "import os\n",
-     "import shutil\n",
-     "import PIL\n",
-     "from collections import OrderedDict\n",
-     "\n",
-     "import numpy as np\n",
-     "import torch\n",
-     "import torch.nn as nn\n",
-     "import torch.nn.functional as F\n",
-     "import torch.optim as optim\n",
-     "import torchvision\n",
-     "import torchvision.transforms as transforms\n",
-     "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n",
-     "from torch.utils.data import DataLoader, Dataset, random_split\n",
-     "from torchvision.datasets import MNIST"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "64f37dcf",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "mnist_transform = transforms.Compose(\n",
-     "    [\n",
-     "        transforms.ToPILImage(),\n",
-     "        transforms.Resize((28, 28)),\n",
-     "        transforms.ToTensor(),\n",
-     "        transforms.Normalize((0.1307,), (0.3081,)),\n",
-     "    ]\n",
-     ")\n",
-     "\n",
-     "\n",
-     "class MnistShardDataset(Dataset):\n",
-     "    def __init__(self, x, y, transform=None):\n",
-     "        self.x, self.y = x, y\n",
-     "        self.transform = transform\n",
-     "\n",
-     "    def __getitem__(self, index):\n",
-     "        x, y = self.x[index], self.y[index]\n",
-     "        x = self.transform(x).numpy()\n",
-     "        y = y.numpy()\n",
-     "        return x, y\n",
-     "\n",
-     "    def __len__(self):\n",
-     "        return len(self.x)\n",
-     "\n",
-     "\n",
-     "class MnistFedDataset(DataInterface):\n",
-     "    def __init__(self, **kwargs):\n",
-     "        super().__init__(**kwargs)\n",
-     "\n",
-     "    @property\n",
-     "    def shard_descriptor(self):\n",
-     "        return self._shard_descriptor\n",
-     "\n",
-     "    @shard_descriptor.setter\n",
-     "    def shard_descriptor(self, shard_descriptor):\n",
-     "        \"\"\"\n",
-     "        Describe per-collaborator procedures or sharding.\n",
-     "\n",
-     "        This method will be called during a collaborator initialization.\n",
-     "        Local shard_descriptor will be set by Envoy.\n",
-     "        \"\"\"\n",
-     "        self._shard_descriptor = shard_descriptor\n",
-     "        self.train_set = MnistShardDataset(\n",
-     "            self._shard_descriptor.get_dataset(\"train\")[:][0],\n",
-     "            self._shard_descriptor.get_dataset(\"train\")[:][1],\n",
-     "            transform=mnist_transform,\n",
-     "        )\n",
-     "        self.valid_set = MnistShardDataset(\n",
-     "            self._shard_descriptor.get_dataset(\"val\")[:][0],\n",
-     "            self._shard_descriptor.get_dataset(\"val\")[:][1],\n",
-     "            transform=mnist_transform,\n",
-     "        )\n",
-     "\n",
-     "    def __getitem__(self, index):\n",
-     "        return self.shard_descriptor[index]\n",
-     "\n",
-     "    def __len__(self):\n",
-     "        return len(self.shard_descriptor)\n",
-     "\n",
-     "    def get_train_loader(self):\n",
-     "        \"\"\"\n",
-     "        Output of this method will be provided to tasks with optimizer in contract\n",
-     "        \"\"\"\n",
-     "        if self.kwargs[\"train_bs\"]:\n",
-     "            batch_size = self.kwargs[\"train_bs\"]\n",
-     "        else:\n",
-     "            batch_size = 256\n",
-     "        return DataLoader(self.train_set, batch_size=batch_size, num_workers=4)\n",
-     "\n",
-     "    def get_valid_loader(self):\n",
-     "        \"\"\"\n",
-     "        Output of this method will be provided to tasks without optimizer in contract\n",
-     "        \"\"\"\n",
-     "        if self.kwargs[\"valid_bs\"]:\n",
-     "            batch_size = self.kwargs[\"valid_bs\"]\n",
-     "        else:\n",
-     "            batch_size = 64\n",
-     "        return DataLoader(self.valid_set, batch_size=batch_size)\n",
-     "\n",
-     "    def get_train_data_size(self):\n",
-     "        \"\"\"\n",
-     "        train data size\n",
-     "        \"\"\"\n",
-     "\n",
-     "        return len(self.train_set)\n",
-     "\n",
-     "    def get_valid_data_size(self):\n",
-     "        \"\"\"\n",
-     "        val data size\n",
-     "        \"\"\"\n",
-     "        return len(self.valid_set)\n"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "d8df35f5",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "fed_dataset = MnistFedDataset(train_bs=256, valid_bs=64)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "caring-distinction",
-    "metadata": {},
-    "source": [
-     "### Describe a model and optimizer"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "foreign-gospel",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "\"\"\"\n",
-     "Generator and discriminator model definition\n",
-     "\"\"\"\n",
-     "\n",
-     "\n",
-     "class Generator(nn.Module):\n",
-     "    def __init__(self, latent_dim, img_shape):\n",
-     "        super().__init__()\n",
-     "        self.img_shape = img_shape\n",
-     "\n",
-     "        def block(in_feat, out_feat, normalize=True):\n",
-     "            layers = [nn.Linear(in_feat, out_feat)]\n",
-     "            if normalize:\n",
-     "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
-     "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
-     "            return layers\n",
-     "\n",
-     "        self.model = nn.Sequential(\n",
-     "            *block(latent_dim, 128, normalize=False),\n",
-     "            *block(128, 256),\n",
-     "            *block(256, 512),\n",
-     "            *block(512, 1024),\n",
-     "            nn.Linear(1024, int(np.prod(img_shape))),\n",
-     "            nn.Tanh(),\n",
-     "        )\n",
-     "\n",
-     "    def forward(self, z):\n",
-     "        z = z.float()\n",
-     "        img = self.model(z)\n",
-     "        img = img.view(img.size(0), *self.img_shape)\n",
-     "        return img"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "981b810c",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "class Discriminator(nn.Module):\n",
-     "    def __init__(self, img_shape):\n",
-     "        super().__init__()\n",
-     "\n",
-     "        self.model = nn.Sequential(\n",
-     "            nn.Linear(int(np.prod(img_shape)), 512),\n",
-     "            nn.LeakyReLU(0.2, inplace=True),\n",
-     "            nn.Linear(512, 256),\n",
-     "            nn.LeakyReLU(0.2, inplace=True),\n",
-     "            nn.Linear(256, 1),\n",
-     "            nn.Sigmoid(),\n",
-     "        )\n",
-     "\n",
-     "    def forward(self, img):\n",
-     "        img_flat = img.view(img.size(0), -1)\n",
-     "        img_flat = img_flat.float()\n",
-     "        validity = self.model(img_flat)\n",
-     "\n",
-     "        return validity"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "6cc92e98",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "class GAN(LightningModule):\n",
-     "    def __init__(\n",
-     "        self,\n",
-     "        channels,\n",
-     "        width,\n",
-     "        height,\n",
-     "        train_disc_only,\n",
-     "        train_gen_only,\n",
-     "        latent_dim: int = 100,\n",
-     "        lr: float = 0.0002,\n",
-     "        b1: float = 0.5,\n",
-     "        b2: float = 0.999,\n",
-     "        batch_size: int = 256,\n",
-     "        **kwargs\n",
-     "    ):\n",
-     "        super().__init__()\n",
-     "        self.save_hyperparameters()\n",
-     "\n",
-     "        data_shape = (channels, width, height)\n",
-     "        self.generator = Generator(\n",
-     "            latent_dim=self.hparams.latent_dim, img_shape=data_shape\n",
-     "        )\n",
-     "        self.discriminator = Discriminator(img_shape=data_shape)\n",
-     "\n",
-     "        self.validation_z = torch.randn(8, self.hparams.latent_dim)\n",
-     "        self.example_input_array = torch.zeros(2, self.hparams.latent_dim)\n",
-     "        self.train_disc_only = train_disc_only\n",
-     "        self.train_gen_only = train_gen_only\n",
-     "\n",
-     "    def forward(self, z):\n",
-     "        return self.generator(z)\n",
-     "\n",
-     "    def adversarial_loss(self, y_hat, y):\n",
-     "        return F.binary_cross_entropy(y_hat, y)\n",
-     "\n",
-     "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
-     "        imgs, _ = batch\n",
-     "\n",
-     "        # sample noise\n",
-     "        z = torch.randn(imgs.shape[0], self.hparams.latent_dim)\n",
-     "        z = z.type_as(imgs)\n",
-     "\n",
-     "        if optimizer_idx == 0 and self.train_disc_only == 0:\n",
-     "            return self.train_generator(imgs, z, display_images=0)\n",
-     "\n",
-     "        elif optimizer_idx == 1 and self.train_gen_only == 0:\n",
-     "            return self.train_discriminator(imgs, z)\n",
-     "\n",
-     "    def train_generator(self, imgs, z, display_images=0):\n",
-     "        self.generated_imgs = self(z)\n",
-     "        sample_imgs = self.generated_imgs[:10]\n",
-     "        sample_imgs = np.reshape(sample_imgs.detach().cpu().numpy(), (10, 28, 28, 1))\n",
-     "            \n",
-     "        if display_images:\n",
-     "            from skimage import data, io\n",
-     "            from matplotlib import pyplot as plt\n",
-     "            for img in sample_imgs:\n",
-     "                io.imshow(img.reshape((28, 28)), cmap='gray_r')\n",
-     "                plt.axis('off')\n",
-     "                plt.show()\n",
-     "\n",
-     "        valid = torch.ones(imgs.size(0), 1)\n",
-     "        valid = valid.type_as(imgs).float()\n",
-     "\n",
-     "        g_loss = self.adversarial_loss(self.discriminator(self(z)), valid)\n",
-     "        tqdm_dict = {\"g_loss\": g_loss}\n",
-     "        output = OrderedDict(\n",
-     "            {\"loss\": g_loss, \"progress_bar\": tqdm_dict, \"log\": tqdm_dict}\n",
-     "        )\n",
-     "        self.log(name=\"Generator training loss\", value=g_loss, on_epoch=True)\n",
-     "        return output\n",
-     "\n",
-     "    def train_discriminator(self, imgs, z):\n",
-     "        valid = torch.ones(imgs.size(0), 1)\n",
-     "        valid = valid.type_as(imgs).float()\n",
-     "\n",
-     "        real_loss = self.adversarial_loss(self.discriminator(imgs), valid)\n",
-     "\n",
-     "        fake = torch.zeros(imgs.size(0), 1)\n",
-     "        fake = fake.type_as(imgs).float()\n",
-     "\n",
-     "        fake_loss = self.adversarial_loss(self.discriminator(self(z).detach()), fake)\n",
-     "\n",
-     "        d_loss = (real_loss + fake_loss) / 2\n",
-     "        tqdm_dict = {\"d_loss\": d_loss}\n",
-     "        output = OrderedDict(\n",
-     "            {\"loss\": d_loss, \"progress_bar\": tqdm_dict, \"log\": tqdm_dict}\n",
-     "        )\n",
-     "        self.log(name=\"Discriminator training loss\", value=d_loss, on_epoch=True)\n",
-     "        return output\n",
-     "\n",
-     "    def configure_optimizers(self):\n",
-     "        lr = self.hparams.lr\n",
-     "        b1 = self.hparams.b1\n",
-     "        b2 = self.hparams.b2\n",
-     "\n",
-     "        opt_g = torch.optim.Adam(self.generator.parameters(), lr=lr, betas=(b1, b2))\n",
-     "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
-     "\n",
-     "        return [opt_g, opt_d]\n",
-     "\n",
-     "    def validation_step(self, batch, batch_idx, optimizer_idx=1):\n",
-     "        imgs, _ = batch\n",
-     "\n",
-     "        valid = torch.ones(imgs.size(0), 1)\n",
-     "        valid = valid.type_as(imgs).float()\n",
-     "\n",
-     "        val_real_loss = self.adversarial_loss(self.discriminator(imgs), valid)\n",
-     "        self.log(name=\"Discriminator val loss\", value=val_real_loss, on_epoch=True)\n",
-     "        return {\"val_loss\": val_real_loss}\n",
-     "\n",
-     "    def on_epoch_end(self):\n",
-     "        z = self.validation_z.type_as(self.generator.model[0].weight)\n",
-     "\n",
-     "        sample_imgs = self(z)\n",
-     "        grid = torchvision.utils.make_grid(sample_imgs)\n",
-     "        self.logger.experiment.add_image(\"generated_images\", grid, self.current_epoch)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "5719fa50",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from pytorch_lightning.callbacks import Callback\n",
-     "\n",
-     "\n",
-     "class MetricsCallback(Callback):\n",
-     "    \"\"\"PyTorch Lightning metric callback.\"\"\"\n",
-     "\n",
-     "    def __init__(self):\n",
-     "        super().__init__()\n",
-     "        self.metrics = []\n",
-     "\n",
-     "    def on_epoch_end(self, trainer, pl_module):\n",
-     "        met = copy.deepcopy(trainer.callback_metrics)\n",
-     "        self.metrics.append(met)\n",
-     "\n",
-     "    def __call__(self):\n",
-     "        return self.get_callbacks()"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "46692b08",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "model = GAN(channels=1, width=28, height=28, train_disc_only=0, train_gen_only=0)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "greater-activation",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "optimizer = model.configure_optimizers()"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "caroline-passion",
-    "metadata": {},
-    "source": [
-     "#### Register model"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "handled-teens",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from copy import deepcopy\n",
-     "\n",
-     "# Need this plugin only if multiple optimizers are used. Not required for PyTorch Lightning with a single optimizer.\n",
-     "framework_adapter = (\n",
-     "    \"plugin_for_multiple_optimizers.FrameworkAdapterPluginforMultipleOpt\"\n",
-     ")\n",
-     "MI = ModelInterface(\n",
-     "    model=model, optimizer=optimizer, framework_plugin=framework_adapter\n",
-     ")\n",
-     "\n",
-     "initial_model = deepcopy(model)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "portuguese-groove",
-    "metadata": {},
-    "source": [
-     "### Define and register FL tasks"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "increasing-builder",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "TI = TaskInterface()\n",
-     "\n",
-     "import tqdm\n",
-     "\n",
-     "@TI.register_fl_task(\n",
-     "    model=\"model\", data_loader=\"train_loader\", device=\"device\", optimizer=\"optimizer\"\n",
-     ")\n",
-     "def train(model, train_loader, optimizer, device, some_parameter=None):\n",
-     "\n",
-     "    print(f\"\\n\\n TASK TRAIN GOT DEVICE {device}\\n\\n\")\n",
-     "\n",
-     "    AVAIL_GPUS = 1 if \"cuda\" in device else 0\n",
-     "\n",
-     "    trainer = Trainer(gpus=AVAIL_GPUS, max_epochs=1, callbacks=[MetricsCallback()])\n",
-     "    trainer.fit(model=model, train_dataloaders=train_loader)\n",
-     "    print(\"training logged metrics\", trainer.logged_metrics)\n",
-     "\n",
-     "    if \"Discriminator training loss_epoch\" in trainer.logged_metrics:\n",
-     "        train_loss = trainer.logged_metrics[\"Discriminator training loss_epoch\"]\n",
-     "    else:\n",
-     "        train_loss = trainer.logged_metrics[\"Generator training loss_epoch\"]\n",
-     "    return {\"train_loss\": train_loss}\n",
-     "\n",
-     "\n",
-     "@TI.register_fl_task(model=\"model\", data_loader=\"val_loader\", device=\"device\")\n",
-     "def validate(model, val_loader, device):\n",
-     "\n",
-     "    print(f\"\\n\\n TASK VALIDATE GOT DEVICE {device}\\n\\n\")\n",
-     "\n",
-     "    model.eval()\n",
-     "    model.to(device)\n",
-     "\n",
-     "    AVAIL_GPUS = 1 if \"cuda\" in device else 0\n",
-     "\n",
-     "    trainer = Trainer(gpus=AVAIL_GPUS, max_epochs=1, callbacks=[MetricsCallback()])\n",
-     "\n",
-     "    trainer.validate(model=model, dataloaders=val_loader)\n",
-     "    print(\"validation logged metrics\", trainer.logged_metrics)\n",
-     "\n",
-     "    val_loss = trainer.logged_metrics[\"Discriminator val loss\"]\n",
-     "\n",
-     "    return {\"val_loss\": val_loss}"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "derived-bride",
-    "metadata": {},
-    "source": [
-     "## Time to start a federated learning experiment"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "mature-renewal",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# create an experimnet in federation\n",
-     "experiment_name = \"PL_MNIST_test_experiment\"\n",
-     "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "lightweight-causing",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "fl_experiment.start(\n",
-     "    model_provider=MI,\n",
-     "    task_keeper=TI,\n",
-     "    data_loader=fed_dataset,\n",
-     "    rounds_to_train=10,\n",
-     "    opt_treatment=\"CONTINUE_GLOBAL\",\n",
-     "    device_assignment_policy=\"CUDA_PREFERRED\",\n",
-     ")"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "f1543a36",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "fl_experiment.stream_metrics()"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "f987d2c4",
-    "metadata": {},
-    "source": [
-     "## Check the images generated by the model"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "fec7a708",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "!pip install -r ../envoy/sd_requirements.txt\n",
-     "import sys\n",
-     "\n",
-     "sys.path.insert(1, \"../envoy\")\n",
-     "from mnist_shard_descriptor import MnistShardDescriptor"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "2bc77cd8",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "fed_dataset = MnistFedDataset(train_bs=256, valid_bs=64)\n",
-     "fed_dataset.shard_descriptor = MnistShardDescriptor(rank_worldsize=\"1,1\")\n",
-     "\n",
-     "last_model = fl_experiment.get_last_model()"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "5f821972",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "val_imgs, _ = next(iter(fed_dataset.get_valid_loader()))\n",
-     "\n",
-     "z = torch.randn(val_imgs.shape[0], 100)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "9549d1ab",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "last_model.train_generator(val_imgs, z, display_images=1)\n",
-     "pass"
-    ]
-   }
-  ],
-  "metadata": {
-   "kernelspec": {
-    "display_name": "Python 3 (ipykernel)",
-    "language": "python",
-    "name": "python3"
-   },
-   "language_info": {
-    "codemirror_mode": {
-     "name": "ipython",
-     "version": 3
-    },
-    "file_extension": ".py",
-    "mimetype": "text/x-python",
-    "name": "python",
-    "nbconvert_exporter": "python",
-    "pygments_lexer": "ipython3",
-    "version": "3.8.9"
-   }
-  },
-  "nbformat": 4,
-  "nbformat_minor": 5
- }
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/director/director_config.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/director/director_config.yaml
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/director/director_config.yaml	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/director/director_config.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- settings:
-   listen_ip: localhost
-   sample_shape: ['64', '128', '3']
-   target_shape: ['2']
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/director/start_director.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/director/start_director.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/director/start_director.sh	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/director/start_director.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- 
- fx director start --disable-tls -c director_config.yaml
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/director/start_director_with_tls.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/director/start_director_with_tls.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/director/start_director_with_tls.sh	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/director/start_director_with_tls.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- FQDN=$1
- fx director start -c director_config.yaml -rc cert/root_ca.crt -pk cert/"${FQDN}".key -oc cert/"${FQDN}".crt
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/envoy/envoy_config_one.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/envoy/envoy_config_one.yaml
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/envoy/envoy_config_one.yaml	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/envoy/envoy_config_one.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,10 ****
- params:
-   cuda_devices: []
- 
- optional_plugin_components: {}
- 
- shard_descriptor:
-   template: market_shard_descriptor.MarketShardDescriptor
-   params:
-     data_folder_name: Market-1501-v15.09.15
-     rank_worldsize: 1,2
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/envoy/envoy_config_two.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/envoy/envoy_config_two.yaml
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/envoy/envoy_config_two.yaml	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/envoy/envoy_config_two.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,10 ****
- params:
-   cuda_devices: []
- 
- optional_plugin_components: {}
- 
- shard_descriptor:
-   template: market_shard_descriptor.MarketShardDescriptor
-   params:
-     data_folder_name: Market-1501-v15.09.15
-     rank_worldsize: 2,2
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/envoy/market_shard_descriptor.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/envoy/market_shard_descriptor.py
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/envoy/market_shard_descriptor.py	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/envoy/market_shard_descriptor.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,136 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Market shard descriptor."""
- 
- import logging
- import re
- import zipfile
- from pathlib import Path
- from typing import List
- 
- import gdown
- from PIL import Image
- 
- from openfl.interface.interactive_api.shard_descriptor import ShardDataset
- from openfl.interface.interactive_api.shard_descriptor import ShardDescriptor
- 
- logger = logging.getLogger(__name__)
- 
- 
- class MarketShardDataset(ShardDataset):
-     """Market shard dataset."""
- 
-     def __init__(self, dataset_dir: Path, dataset_type: str, rank=1, worldsize=1):
-         """Initialize MarketShardDataset."""
-         self.dataset_dir = dataset_dir
-         self.dataset_type = dataset_type
-         self.rank = rank
-         self.worldsize = worldsize
- 
-         self.imgs_path = list(dataset_dir.glob('*.jpg'))[self.rank - 1::self.worldsize]
-         self.pattern = re.compile(r'([-\d]+)_c(\d)')
- 
-     def __len__(self):
-         """Length of shard."""
-         return len(self.imgs_path)
- 
-     def __getitem__(self, index: int):
-         """Return an item by the index."""
-         img_path = self.imgs_path[index]
-         pid, camid = map(int, self.pattern.search(img_path.name).groups())
- 
-         img = Image.open(img_path)
-         return img, (pid, camid)
- 
- 
- class MarketShardDescriptor(ShardDescriptor):
-     """
-     Market1501 Shard descriptor class.
- 
-     Reference:
-     Zheng et al. Scalable Person Re-identification: A Benchmark. ICCV 2015.
-     URL: http://www.liangzheng.org/Project/project_reid.html
- 
-     Dataset statistics:
-         identities: 1501 (+1 for background)
-         images: 12936 (train) + 3368 (query) + 15913 (gallery)
-     """
- 
-     def __init__(self, data_folder_name: str = 'Market-1501-v15.09.15',
-                  rank_worldsize: str = '1,1') -> None:
-         """Initialize MarketShardDescriptor."""
-         super().__init__()
- 
-         # Settings for sharding the dataset
-         self.rank, self.worldsize = tuple(int(num) for num in rank_worldsize.split(','))
- 
-         self.data_folder_name = data_folder_name
-         self.dataset_dir = Path.cwd() / data_folder_name
-         self.download()
- 
-         self.path_by_type = {
-             'train': self.dataset_dir / 'bounding_box_train',
-             'query': self.dataset_dir / 'query',
-             'gallery': self.dataset_dir / 'bounding_box_test'
-         }
-         self._check_before_run()
- 
-     def get_shard_dataset_types(self) -> List[str]:
-         """Get available shard dataset types."""
-         return list(self.path_by_type)
- 
-     def get_dataset(self, dataset_type='train'):
-         """Return a dataset by type."""
-         if dataset_type not in self.path_by_type:
-             raise Exception(f'Wrong dataset type: {dataset_type}.'
-                             f'Choose from the list: {", ".join(self.path_by_type)}')
-         return MarketShardDataset(
-             dataset_dir=self.path_by_type[dataset_type],
-             dataset_type=dataset_type,
-             rank=self.rank,
-             worldsize=self.worldsize
-         )
- 
-     @property
-     def sample_shape(self):
-         """Return the sample shape info."""
-         return ['64', '128', '3']
- 
-     @property
-     def target_shape(self):
-         """Return the target shape info."""
-         return ['2']
- 
-     @property
-     def dataset_description(self) -> str:
-         """Return the dataset description."""
-         return (f'Market dataset, shard number {self.rank} '
-                 f'out of {self.worldsize}')
- 
-     def download(self):
-         """Download Market1501 dataset."""
-         logger.info('Download Market1501 dataset.')
-         if self.dataset_dir.exists():
-             return None
- 
-         logger.info('Try to download.')
-         output = f'{self.data_folder_name}.zip'
- 
-         if not Path(output).exists():
-             url = 'https://drive.google.com/u/1/uc?id=0B8-rUzbwVRk0c054eEozWG9COHM'
-             gdown.download(url, output, quiet=False)
-         logger.info(f'{output} is downloaded.')
- 
-         with zipfile.ZipFile(output, 'r') as zip_ref:
-             zip_ref.extractall(Path.cwd())
- 
-         Path(output).unlink()  # remove zip
- 
-     def _check_before_run(self):
-         """Check if all files are available before going deeper."""
-         if not self.dataset_dir.exists():
-             raise RuntimeError(f'{self.dataset_dir} does not exist')
-         for dataset_path in self.path_by_type.values():
-             if not dataset_path.exists():
-                 raise RuntimeError(f'{dataset_path} does not exist')
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/envoy/requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/envoy/requirements.txt
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/envoy/requirements.txt	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/envoy/requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- gdown==3.13.0
- Pillow==8.3.2
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/envoy/start_envoy.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/envoy/start_envoy.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/envoy/start_envoy.sh	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/envoy/start_envoy.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- 
- fx envoy start -n env_one --disable-tls -dh localhost -dp 50051 -ec envoy_config_one.yaml
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/envoy/start_envoy_with_tls.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/envoy/start_envoy_with_tls.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/envoy/start_envoy_with_tls.sh	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/envoy/start_envoy_with_tls.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,7 ****
- #!/bin/bash
- set -e
- ENVOY_NAME=$1
- DIRECTOR_FQDN=$2
- ENVOY_CONFIG=$3
- 
- fx envoy start -n "$ENVOY_NAME" -dh "$DIRECTOR_FQDN" -dp 50051 -ec "$ENVOY_CONFIG" -rc cert/root_ca.crt -pk cert/"$ENVOY_NAME".key -oc cert/"$ENVOY_NAME".crt
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/workspace/losses.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/workspace/losses.py
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/workspace/losses.py	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/workspace/losses.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,98 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Compute ArcFace loss and Triplet loss."""
- 
- import math
- 
- import torch
- import torch.nn.functional as F
- from torch import nn
- 
- 
- class ArcFaceLoss(nn.Module):
-     """ArcFace loss."""
- 
-     def __init__(self, margin=0.1, scale=16, easy_margin=False):
-         """Initialize ArcFace loss."""
-         super(ArcFaceLoss, self).__init__()
-         self.m = margin
-         self.s = scale
-         self.easy_margin = easy_margin
- 
-     def forward(self, pred, target):
-         """Compute forward."""
-         # make a one-hot index
-         index = pred.data * 0.0  # size = (B, Classnum)
-         index.scatter_(1, target.data.view(-1, 1), 1)
-         index = index.bool()
- 
-         cos_m = math.cos(self.m)
-         sin_m = math.sin(self.m)
-         cos_t = pred[index]
-         sin_t = torch.sqrt(1.0 - cos_t * cos_t)
-         cos_t_add_m = cos_t * cos_m - sin_t * sin_m
- 
-         cond_v = cos_t - math.cos(math.pi - self.m)
-         cond = F.relu(cond_v)
-         keep = cos_t - math.sin(math.pi - self.m) * self.m
- 
-         cos_t_add_m = torch.where(cond.bool(), cos_t_add_m, keep)
- 
-         output = pred * 1.0  # size = (B, Classnum)
-         output[index] = cos_t_add_m
-         output = self.s * output
- 
-         return F.cross_entropy(output, target)
- 
- 
- class TripletLoss(nn.Module):
-     """
-     Triplet loss with hard positive/negative mining.
- 
-     Reference:
-     Hermans et al. In Defense of the Triplet Loss for Person Re-Identification. arXiv:1703.07737.
- 
-     Code imported from https://github.com/Cysu/open-reid/blob/master/reid/loss/triplet.py.
- 
-     Args:
-         margin (float): margin for triplet.
-         distance (str): distance for triplet.
-     """
- 
-     def __init__(self, margin=0.3, distance='cosine'):
-         """Initialize Triplet loss."""
-         super(TripletLoss, self).__init__()
- 
-         self.distance = distance
-         self.margin = margin
-         self.ranking_loss = nn.MarginRankingLoss(margin=margin)
- 
-     def forward(self, inputs, targets):
-         """
-         Compute forward.
- 
-         Args:
-             inputs: feature matrix with shape (batch_size, feat_dim)
-             targets: ground truth labels with shape (num_classes)
-         """
-         n = inputs.size(0)
- 
-         # Compute pairwise distance, replace by the official when merged
-         inputs = F.normalize(inputs, p=2, dim=1)
-         dist = - torch.mm(inputs, inputs.t())
- 
-         # For each anchor, find the hardest positive and negative
-         mask = targets.expand(n, n).eq(targets.expand(n, n).t())
-         dist_ap, dist_an = [], []
-         for i in range(n):
-             dist_ap.append(dist[i][mask[i]].max().unsqueeze(0))
-             dist_an.append(dist[i][mask[i] == 0].min().unsqueeze(0))
-         dist_ap = torch.cat(dist_ap)
-         dist_an = torch.cat(dist_an)
- 
-         # Compute ranking hinge loss
-         y = torch.ones_like(dist_an)
-         loss = self.ranking_loss(dist_an, dist_ap, y)
- 
-         return loss
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/workspace/PyTorch_Market_Re-ID.ipynb ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/workspace/PyTorch_Market_Re-ID.ipynb
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/workspace/PyTorch_Market_Re-ID.ipynb	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/workspace/PyTorch_Market_Re-ID.ipynb	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,593 ****
- {
-  "cells": [
-   {
-    "cell_type": "markdown",
-    "id": "liquid-jacket",
-    "metadata": {},
-    "source": [
-     "# Federated Market with Director example"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "db949008",
-    "metadata": {
-     "pycharm": {
-      "name": "#%%\n"
-     }
-    },
-    "outputs": [],
-    "source": [
-     "# Install dependencies if not already installed\n",
-     "!pip install -r requirements.txt"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "16986f22",
-    "metadata": {},
-    "source": [
-     "# Connect to the Federation"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "4485ac79",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Create a federation\n",
-     "from openfl.interface.interactive_api.federation import Federation\n",
-     "\n",
-     "# please use the same identificator that was used in signed certificate\n",
-     "client_id = 'frontend'\n",
-     "director_node_fqdn = 'localhost'\n",
-     "director_port = 50051\n",
-     "\n",
-     "# 1) Run with API layer - Director mTLS \n",
-     "# If the user wants to enable mTLS their must provide CA root chain, and signed key pair to the federation interface\n",
-     "# cert_chain = 'cert/root_ca.crt'\n",
-     "# api_certificate = 'cert/frontend.crt'\n",
-     "# api_private_key = 'cert/frontend.key'\n",
-     "\n",
-     "# federation = Federation(\n",
-     "#     client_id=client_id,\n",
-     "#     director_node_fqdn=director_node_fqdn,\n",
-     "#     director_port=director_port,\n",
-     "#     tls=True,\n",
-     "#     cert_chain=cert_chain,\n",
-     "#     api_cert=api_certificate,\n",
-     "#     api_private_key=api_private_key\n",
-     "# )\n",
-     "\n",
-     "# --------------------------------------------------------------------------------------------------------------------\n",
-     "\n",
-     "# 2) Run with TLS disabled (trusted environment)\n",
-     "# Federation can also determine local fqdn automatically\n",
-     "federation = Federation(\n",
-     "    client_id=client_id,\n",
-     "    director_node_fqdn=director_node_fqdn,\n",
-     "    director_port=director_port,\n",
-     "    tls=False\n",
-     ")"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "e35802d5",
-    "metadata": {
-     "pycharm": {
-      "is_executing": true
-     },
-     "scrolled": true
-    },
-    "outputs": [],
-    "source": [
-     "shard_registry = federation.get_shard_registry()\n",
-     "shard_registry"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "67ae50de",
-    "metadata": {
-     "pycharm": {
-      "is_executing": true
-     }
-    },
-    "outputs": [],
-    "source": [
-     "federation.target_shape"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "b42efc49",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# First, request a dummy_shard_desc that holds information about the federated dataset \n",
-     "dummy_shard_desc = federation.get_dummy_shard_descriptor(size=10)\n",
-     "dummy_shard_dataset = dummy_shard_desc.get_dataset('train')\n",
-     "sample, target = dummy_shard_dataset[0]\n",
-     "print(sample.shape)\n",
-     "print(target.shape)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "obvious-tyler",
-    "metadata": {},
-    "source": [
-     "## Creating a FL experiment using Interactive API"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "rubber-address",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "sustainable-public",
-    "metadata": {},
-    "source": [
-     "### Register dataset"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "64f37dcf",
-    "metadata": {
-     "scrolled": true
-    },
-    "outputs": [],
-    "source": [
-     "from copy import deepcopy\n",
-     "\n",
-     "from torch.utils.data import DataLoader, Dataset\n",
-     "from torchvision.transforms import Compose, Normalize, RandomHorizontalFlip, Resize, ToTensor\n",
-     "\n",
-     "from tools import RandomIdentitySampler\n",
-     "import transforms as T\n",
-     "\n",
-     "\n",
-     "# Now you can implement you data loaders using dummy_shard_desc\n",
-     "class ImageDataset(Dataset):\n",
-     "    \"\"\"Image Person ReID Dataset.\"\"\"\n",
-     "\n",
-     "    def __init__(self, dataset, transform=None):\n",
-     "        \"\"\"Initialize Dataset.\"\"\"\n",
-     "        self.dataset = dataset\n",
-     "        self.transform = transform\n",
-     "\n",
-     "    def __len__(self):\n",
-     "        \"\"\"Length of dataset.\"\"\"\n",
-     "        return len(self.dataset)\n",
-     "\n",
-     "    def __getitem__(self, index):\n",
-     "        \"\"\"Get item from dataset.\"\"\"\n",
-     "        img, (pid, camid) = self.dataset[index]\n",
-     "        if self.transform is not None:\n",
-     "            img = self.transform(img)\n",
-     "        return img, (pid, camid)\n",
-     "\n",
-     "\n",
-     "class MarketFLDataloader(DataInterface):\n",
-     "    \"\"\"Market Dataset.\"\"\"\n",
-     "\n",
-     "    def __init__(self, **kwargs):\n",
-     "        super().__init__(**kwargs)\n",
-     "\n",
-     "        # Prepare transforms\n",
-     "        self.transform_train = Compose([\n",
-     "            T.ResizeRandomCropping(256, 128, p=0.5),\n",
-     "            RandomHorizontalFlip(),\n",
-     "            ToTensor(),\n",
-     "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
-     "            T.RandomErasing(probability=0.5)\n",
-     "        ])\n",
-     "        self.transform_test = Compose([\n",
-     "            Resize((265, 128)),\n",
-     "            ToTensor(),\n",
-     "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
-     "        ])\n",
-     "\n",
-     "    @property\n",
-     "    def shard_descriptor(self):\n",
-     "        return self._shard_descriptor\n",
-     "\n",
-     "    @shard_descriptor.setter\n",
-     "    def shard_descriptor(self, shard_descriptor):\n",
-     "        \"\"\"\n",
-     "        Describe per-collaborator procedures or sharding.\n",
-     "\n",
-     "        This method will be called during a collaborator initialization.\n",
-     "        Local shard_descriptor will be set by Envoy.\n",
-     "        \"\"\"\n",
-     "        self._shard_descriptor = shard_descriptor\n",
-     "\n",
-     "    def get_train_loader(self, **kwargs):\n",
-     "        \"\"\"\n",
-     "        Output of this method will be provided to tasks with optimizer in contract.\n",
-     "        \"\"\"\n",
-     "        if self.kwargs['train_bs']:\n",
-     "            batch_size = self.kwargs['train_bs']\n",
-     "        else:\n",
-     "            batch_size = 64\n",
-     "\n",
-     "        self.train_ds = self.shard_descriptor.get_dataset('train')\n",
-     "        return DataLoader(\n",
-     "            # ImageDataset make transform\n",
-     "            ImageDataset(self.train_ds, transform=self.transform_train),\n",
-     "            sampler=RandomIdentitySampler(self.train_ds, num_instances=4),\n",
-     "            batch_size=batch_size,\n",
-     "            num_workers=4,\n",
-     "            pin_memory=True,\n",
-     "            drop_last=True\n",
-     "        )\n",
-     "\n",
-     "    def get_valid_loader(self, **kwargs):\n",
-     "        \"\"\"\n",
-     "        Output of this method will be provided to tasks without optimizer in contract.\n",
-     "        \"\"\"\n",
-     "        if self.kwargs['valid_bs']:\n",
-     "            batch_size = self.kwargs['valid_bs']\n",
-     "        else:\n",
-     "            batch_size = 512\n",
-     "\n",
-     "        query_sd = self.shard_descriptor.get_dataset('query')\n",
-     "        query_loader = DataLoader(\n",
-     "            ImageDataset(query_sd, transform=self.transform_test),\n",
-     "            batch_size=batch_size,\n",
-     "            num_workers=4,\n",
-     "            pin_memory=True,\n",
-     "            drop_last=False,\n",
-     "            shuffle=False\n",
-     "        )\n",
-     "\n",
-     "        self.gallery_sd = self.shard_descriptor.get_dataset('gallery')\n",
-     "        gallery_loader = DataLoader(\n",
-     "            ImageDataset(self.gallery_sd, transform=self.transform_test),\n",
-     "            batch_size=batch_size,\n",
-     "            num_workers=4,\n",
-     "            pin_memory=True,\n",
-     "            drop_last=False,\n",
-     "            shuffle=False\n",
-     "        )\n",
-     "\n",
-     "        return query_loader, gallery_loader\n",
-     "\n",
-     "    def get_train_data_size(self):\n",
-     "        \"\"\"\n",
-     "        Information for aggregation.\n",
-     "        \"\"\"\n",
-     "        return len(self.train_ds)\n",
-     "\n",
-     "    def get_valid_data_size(self):\n",
-     "        \"\"\"\n",
-     "        Information for aggregation.\n",
-     "        \"\"\"\n",
-     "        return len(self.gallery_sd)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "8cb6c73c",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "fed_dataset = MarketFLDataloader(train_bs=64, valid_bs=512)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "caring-distinction",
-    "metadata": {},
-    "source": [
-     "### Describe a model and optimizer"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "visible-victor",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import torch\n",
-     "import torch.nn as nn\n",
-     "import torch.optim as optim\n",
-     "import torchvision"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "foreign-gospel",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "\"\"\"\n",
-     "ResNet and Classifier definition\n",
-     "\"\"\"\n",
-     "\n",
-     "class ResNet50(nn.Module):\n",
-     "    \"Pretrained ResNet50.\"\n",
-     "\n",
-     "    def __init__(self, **kwargs):\n",
-     "        super().__init__()\n",
-     "        \n",
-     "        self.classifier = NormalizedClassifier()\n",
-     "\n",
-     "        resnet50 = torchvision.models.resnet50(pretrained=True)\n",
-     "        resnet50.layer4[0].conv2.stride = (1, 1)\n",
-     "        resnet50.layer4[0].downsample[0].stride = (1, 1)\n",
-     "        self.base = nn.Sequential(*list(resnet50.children())[:-2])\n",
-     "\n",
-     "        self.bn = nn.BatchNorm1d(2048)\n",
-     "        nn.init.normal_(self.bn.weight.data, 1.0, 0.02)\n",
-     "        nn.init.constant_(self.bn.bias.data, 0.0)\n",
-     "\n",
-     "    def forward(self, x):\n",
-     "        x = self.base(x)\n",
-     "        x = nn.functional.avg_pool2d(x, x.size()[2:])\n",
-     "        x = x.view(x.size(0), -1)\n",
-     "        f = self.bn(x)\n",
-     "\n",
-     "        return f\n",
-     "\n",
-     "\n",
-     "class NormalizedClassifier(nn.Module):\n",
-     "    \"\"\"Classifier.\"\"\"\n",
-     "\n",
-     "    def __init__(self):\n",
-     "        super().__init__()\n",
-     "        self.weight = nn.Parameter(torch.Tensor(1501, 2048))\n",
-     "        self.weight.data.uniform_(-1, 1).renorm_(2,0,1e-5).mul_(1e5)\n",
-     "\n",
-     "    def forward(self, x):\n",
-     "        w = self.weight\n",
-     "\n",
-     "        x = nn.functional.normalize(x, p=2, dim=1)\n",
-     "        w = nn.functional.normalize(w, p=2, dim=1)\n",
-     "\n",
-     "        return nn.functional.linear(x, w)\n",
-     "\n",
-     "\n",
-     "resnet = ResNet50()"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "greater-activation",
-    "metadata": {
-     "pycharm": {
-      "is_executing": true
-     }
-    },
-    "outputs": [],
-    "source": [
-     "parameters = list(resnet.parameters()) + list(resnet.classifier.parameters())\n",
-     "optimizer_adam = optim.Adam(parameters, lr=1e-4)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "caroline-passion",
-    "metadata": {},
-    "source": [
-     "#### Register model"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "handled-teens",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "framework_adapter = 'openfl.plugins.frameworks_adapters.pytorch_adapter.FrameworkAdapterPlugin'\n",
-     "MI = ModelInterface(model=resnet, optimizer=optimizer_adam, framework_plugin=framework_adapter)\n",
-     "# Save the initial model state\n",
-     "initial_model = deepcopy(resnet)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "portuguese-groove",
-    "metadata": {},
-    "source": [
-     "### Define and register FL tasks"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "increasing-builder",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "TI = TaskInterface()\n",
-     "\n",
-     "from logging import getLogger\n",
-     "\n",
-     "import torch\n",
-     "import tqdm\n",
-     "\n",
-     "from losses import ArcFaceLoss, TripletLoss\n",
-     "from tools import AverageMeter, evaluate, extract_feature\n",
-     "\n",
-     "logger = getLogger(__name__)\n",
-     "\n",
-     "# Task interface currently supports only standalone functions.\n",
-     "@TI.register_fl_task(model='model', data_loader='train_loader',\n",
-     "                     device='device', optimizer='optimizer')\n",
-     "def train(model, train_loader, optimizer, device):\n",
-     "    device = torch.device('cuda')\n",
-     "    \n",
-     "    criterion_cla = ArcFaceLoss(scale=16., margin=0.1)\n",
-     "    criterion_pair = TripletLoss(margin=0.3, distance='cosine')\n",
-     "\n",
-     "    batch_cla_loss = AverageMeter()\n",
-     "    batch_pair_loss = AverageMeter()\n",
-     "    corrects = AverageMeter()\n",
-     "    \n",
-     "    model.train()\n",
-     "    model.to(device)\n",
-     "    model.classifier.train()\n",
-     "    model.classifier.to(device)\n",
-     "    \n",
-     "    logger.info('==> Start training')\n",
-     "    train_loader = tqdm.tqdm(train_loader, desc='train')\n",
-     "\n",
-     "    for imgs, (pids, _) in train_loader:\n",
-     "        imgs, pids = torch.tensor(imgs).to(device), torch.tensor(pids).to(device)\n",
-     "        # Zero the parameter gradients\n",
-     "        optimizer.zero_grad()\n",
-     "        # Forward\n",
-     "        features = model(imgs)\n",
-     "        outputs = model.classifier(features)\n",
-     "        _, preds = torch.max(outputs.data, 1)\n",
-     "        # Compute loss\n",
-     "        cla_loss = criterion_cla(outputs, pids)\n",
-     "        pair_loss = criterion_pair(features, pids)\n",
-     "        loss = cla_loss + pair_loss\n",
-     "        # Backward + Optimize\n",
-     "        loss.backward()\n",
-     "        optimizer.step()\n",
-     "        # statistics\n",
-     "        corrects.update(torch.sum(preds == pids.data).float() / pids.size(0), pids.size(0))\n",
-     "        batch_cla_loss.update(cla_loss.item(), pids.size(0))\n",
-     "        batch_pair_loss.update(pair_loss.item(), pids.size(0))\n",
-     "\n",
-     "    return {'ArcFaceLoss': batch_cla_loss.avg,\n",
-     "            'TripletLoss': batch_pair_loss.avg,\n",
-     "            'Accuracy': corrects.avg.cpu()}\n",
-     "\n",
-     "\n",
-     "@TI.register_fl_task(model='model', data_loader='val_loader', device='device')\n",
-     "def validate(model, val_loader, device):\n",
-     "    queryloader, galleryloader = val_loader\n",
-     "    device = torch.device('cuda')\n",
-     "    \n",
-     "    logger.info('==> Start validating')\n",
-     "    model.eval()\n",
-     "    model.to(device)\n",
-     "    \n",
-     "    # Extract features for query set\n",
-     "    qf, q_pids, q_camids = extract_feature(model, queryloader)\n",
-     "    logger.info(f'Extracted features for query set, obtained {qf.shape} matrix')\n",
-     "    # Extract features for gallery set\n",
-     "    gf, g_pids, g_camids = extract_feature(model, galleryloader)\n",
-     "    logger.info(f'Extracted features for gallery set, obtained {gf.shape} matrix')\n",
-     "    # Compute distance matrix between query and gallery\n",
-     "    m, n = qf.size(0), gf.size(0)\n",
-     "    distmat = torch.zeros((m,n))\n",
-     "    # Cosine similarity\n",
-     "    qf = nn.functional.normalize(qf, p=2, dim=1)\n",
-     "    gf = nn.functional.normalize(gf, p=2, dim=1)\n",
-     "    for i in range(m):\n",
-     "        distmat[i] = - torch.mm(qf[i:i+1], gf.t())\n",
-     "    distmat = distmat.numpy()\n",
-     "\n",
-     "    cmc, mAP = evaluate(distmat, q_pids, g_pids, q_camids, g_camids)\n",
-     "    return {'top1': cmc[0], 'top5': cmc[4], 'top10': cmc[9], 'mAP': mAP}"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "derived-bride",
-    "metadata": {},
-    "source": [
-     "## Time to start a federated learning experiment"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "mature-renewal",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# create an experimnet in federation\n",
-     "experiment_name = 'market_test_experiment'\n",
-     "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "lightweight-causing",
-    "metadata": {
-     "pycharm": {
-      "is_executing": true
-     },
-     "scrolled": false
-    },
-    "outputs": [],
-    "source": [
-     "# If I use autoreload I got a pickling error\n",
-     "\n",
-     "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
-     "fl_experiment.start(model_provider=MI, \n",
-     "                    task_keeper=TI,\n",
-     "                    data_loader=fed_dataset,\n",
-     "                    rounds_to_train=3,\n",
-     "                    opt_treatment='RESET')"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "bfc4f89c",
-    "metadata": {
-     "pycharm": {
-      "is_executing": true,
-      "name": "#%%\n"
-     }
-    },
-    "outputs": [],
-    "source": [
-     "# If user want to stop IPython session, then reconnect and check how experiment is going \n",
-     "# fl_experiment.restore_experiment_state(MI)\n",
-     "\n",
-     "fl_experiment.stream_metrics(tensorboard_logs=False)"
-    ]
-   }
-  ],
-  "metadata": {
-   "kernelspec": {
-    "display_name": "Python 3",
-    "language": "python",
-    "name": "python3"
-   },
-   "language_info": {
-    "codemirror_mode": {
-     "name": "ipython",
-     "version": 3
-    },
-    "file_extension": ".py",
-    "mimetype": "text/x-python",
-    "name": "python",
-    "nbconvert_exporter": "python",
-    "pygments_lexer": "ipython3",
-    "version": "3.8.0"
-   }
-  },
-  "nbformat": 4,
-  "nbformat_minor": 5
- }
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/workspace/requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/workspace/requirements.txt
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/workspace/requirements.txt	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/workspace/requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- torch==1.9.0
- torchvision==0.10.0
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/workspace/tools.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/workspace/tools.py
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/workspace/tools.py	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/workspace/tools.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,190 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Tools for metric computation and Dataloader."""
- 
- import copy
- import random
- from collections import defaultdict
- from logging import getLogger
- 
- import numpy as np
- import torch
- from torch.utils.data.sampler import Sampler
- 
- logger = getLogger(__name__)
- 
- 
- class AverageMeter:
-     """
-     Computes and stores the average and current value.
- 
-     Code imported from https://github.com/pytorch/examples/blob/master/imagenet/main.py#L247-L262
-     """
- 
-     def __init__(self):
-         """Initialize Average Meter."""
-         self.reset()
- 
-     def reset(self):
-         """Reset values."""
-         self.val = 0
-         self.avg = 0
-         self.sum = 0
-         self.count = 0
- 
-     def update(self, val, n=1):
-         """Update values."""
-         self.val = val
-         self.sum += val * n
-         self.count += n
-         self.avg = self.sum / self.count
- 
- 
- def compute_ap_cmc(index, good_index, junk_index):
-     """Compute validation metrics."""
-     ap = 0
-     cmc = np.zeros(len(index))
- 
-     # remove junk_index
-     mask = np.in1d(index, junk_index, invert=True)
-     index = index[mask]
- 
-     # find good_index index
-     ngood = len(good_index)
-     mask = np.in1d(index, good_index)
-     rows_good = np.argwhere(mask)
-     rows_good = rows_good.flatten()
- 
-     cmc[rows_good[0]:] = 1.0
-     for i in range(ngood):
-         d_recall = 1.0 / ngood
-         precision = (i + 1) * 1.0 / (rows_good[i] + 1)
-         ap = ap + d_recall * precision
- 
-     return ap, cmc
- 
- 
- def evaluate(distmat, q_pids, g_pids, q_camids, g_camids):
-     """Evaluate model."""
-     num_q, num_g = distmat.shape
-     index = np.argsort(distmat, axis=1)  # from small to large
- 
-     num_no_gt = 0  # num of query imgs without groundtruth
-     num_r1 = 0
-     cmc = np.zeros(len(g_pids))
-     ap = 0
- 
-     for i in range(num_q):
-         # groundtruth index
-         query_index = np.argwhere(g_pids == q_pids[i])
-         camera_index = np.argwhere(g_camids == q_camids[i])
-         good_index = np.setdiff1d(query_index, camera_index, assume_unique=True)
-         if good_index.size == 0:
-             num_no_gt += 1
-             continue
-         # remove gallery samples that have the same pid and camid with query
-         junk_index = np.intersect1d(query_index, camera_index)
- 
-         ap_tmp, cmc_tmp = compute_ap_cmc(index[i], good_index, junk_index)
-         if cmc_tmp[0] == 1:
-             num_r1 += 1
-         cmc = cmc + cmc_tmp
-         ap += ap_tmp
- 
-     if num_no_gt > 0:
-         logger.error(f'{num_no_gt} query imgs do not have groundtruth.')
- 
-     cmc = cmc / (num_q - num_no_gt)
-     mean_ap = ap / (num_q - num_no_gt)
- 
-     return cmc, mean_ap
- 
- 
- @torch.no_grad()
- def extract_feature(model, dataloader):
-     """Extract features for validation."""
-     features, pids, camids = [], [], []
-     for imgs, (batch_pids, batch_camids) in dataloader:
-         flip_imgs = fliplr(imgs)
-         imgs, flip_imgs = imgs.cuda(), flip_imgs.cuda()
-         batch_features = model(imgs).data
-         batch_features_flip = model(flip_imgs).data
-         batch_features += batch_features_flip
- 
-         features.append(batch_features)
-         pids.append(batch_pids)
-         camids.append(batch_camids)
-     features = torch.cat(features, 0)
-     pids = torch.cat(pids, 0).numpy()
-     camids = torch.cat(camids, 0).numpy()
- 
-     return features, pids, camids
- 
- 
- def fliplr(img):
-     """Flip horizontal."""
-     inv_idx = torch.arange(img.size(3) - 1, -1, -1).long()  # N x C x H x W
-     img_flip = img.index_select(3, inv_idx)
- 
-     return img_flip
- 
- 
- class RandomIdentitySampler(Sampler):
-     """
-     Random Sampler.
- 
-     Randomly sample N identities, then for each identity,
-     randomly sample K instances, therefore batch size is N*K.
- 
-     Args:
-     - data_source (Dataset): dataset to sample from.
-     - num_instances (int): number of instances per identity.
-     """
- 
-     def __init__(self, data_source, num_instances=4):
-         """Initialize Sampler."""
-         self.data_source = data_source
-         self.num_instances = num_instances
-         self.index_dic = defaultdict(list)
-         for index, (_, (pid, _)) in enumerate(data_source):
-             self.index_dic[pid].append(index)
-         self.pids = list(self.index_dic.keys())
-         self.num_identities = len(self.pids)
- 
-         # compute number of examples in an epoch
-         self.length = 0
-         for pid in self.pids:
-             idxs = self.index_dic[pid]
-             num = len(idxs)
-             if num < self.num_instances:
-                 num = self.num_instances
-             self.length += num - num % self.num_instances
- 
-     def __iter__(self):
-         """Iterate over Sampler."""
-         list_container = []
- 
-         for pid in self.pids:
-             idxs = copy.deepcopy(self.index_dic[pid])
-             if len(idxs) < self.num_instances:
-                 idxs = np.random.choice(idxs, size=self.num_instances, replace=True)
-             random.shuffle(idxs)
-             batch_idxs = []
-             for idx in idxs:
-                 batch_idxs.append(idx)
-                 if len(batch_idxs) == self.num_instances:
-                     list_container.append(batch_idxs)
-                     batch_idxs = []
- 
-         random.shuffle(list_container)
- 
-         ret = []
-         for batch_idxs in list_container:
-             ret.extend(batch_idxs)
- 
-         return iter(ret)
- 
-     def __len__(self):
-         """Return number of examples in an epoch."""
-         return self.length
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/workspace/transforms.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/workspace/transforms.py
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/workspace/transforms.py	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_Market_Re-ID/workspace/transforms.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,103 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Image transform tools."""
- 
- import math
- import random
- 
- from PIL import Image
- 
- 
- class ResizeRandomCropping:
-     """
-     With a probability, first increase image size to (1 + 1/8), and then perform random crop.
- 
-     Args:
-         height (int): target height.
-         width (int): target width.
-         p (float): probability of performing this transformation. Default: 0.5.
-     """
- 
-     def __init__(self, height, width, p=0.5, interpolation=Image.BILINEAR):
-         """Initialize cropping."""
-         self.height = height
-         self.width = width
-         self.p = p
-         self.interpolation = interpolation
- 
-     def __call__(self, img):
-         """
-         Call of cropping.
- 
-         Args:
-             img (PIL Image): Image to be cropped.
-         Returns:
-             PIL Image: Cropped image.
-         """
-         if random.uniform(0, 1) >= self.p:
-             return img.resize((self.width, self.height), self.interpolation)
- 
-         new_width, new_height = int(round(self.width * 1.125)), int(round(self.height * 1.125))
-         resized_img = img.resize((new_width, new_height), self.interpolation)
-         x_maxrange = new_width - self.width
-         y_maxrange = new_height - self.height
-         x1 = int(round(random.uniform(0, x_maxrange)))
-         y1 = int(round(random.uniform(0, y_maxrange)))
-         cropped_img = resized_img.crop((x1, y1, x1 + self.width, y1 + self.height))
- 
-         return cropped_img
- 
- 
- class RandomErasing:
-     """
-     Randomly selects a rectangle region in an image and erases its pixels.
- 
-     'Random Erasing Data Augmentation' by Zhong et al.
-     See https://arxiv.org/pdf/1708.04896.pdf
- 
-     Args:
-          probability: The probability that the Random Erasing operation will be performed.
-          sl: Minimum proportion of erased area against input image.
-          sh: Maximum proportion of erased area against input image.
-          r1: Minimum aspect ratio of erased area.
-          mean: Erasing value.
-     """
- 
-     def __init__(self, probability=0.5, sl=0.02, sh=0.4, r1=0.3, mean=None):
-         """Initialize Erasing."""
-         if not mean:
-             mean = [0.4914, 0.4822, 0.4465]
- 
-         self.probability = probability
-         self.mean = mean
-         self.sl = sl
-         self.sh = sh
-         self.r1 = r1
- 
-     def __call__(self, img):
-         """Call of Erasing."""
-         if random.uniform(0, 1) >= self.probability:
-             return img
- 
-         for _attempt in range(100):
-             area = img.size()[1] * img.size()[2]
- 
-             target_area = random.uniform(self.sl, self.sh) * area
-             aspect_ratio = random.uniform(self.r1, 1 / self.r1)
- 
-             h = int(round(math.sqrt(target_area * aspect_ratio)))
-             w = int(round(math.sqrt(target_area / aspect_ratio)))
- 
-             if w < img.size()[2] and h < img.size()[1]:
-                 x1 = random.randint(0, img.size()[1] - h)
-                 y1 = random.randint(0, img.size()[2] - w)
-                 if img.size()[0] == 3:
-                     img[0, x1:x1 + h, y1:y1 + w] = self.mean[0]
-                     img[1, x1:x1 + h, y1:y1 + w] = self.mean[1]
-                     img[2, x1:x1 + h, y1:y1 + w] = self.mean[2]
-                 else:
-                     img[0, x1:x1 + h, y1:y1 + w] = self.mean[0]
-                 return img
- 
-         return img
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/director/director_config.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/director/director_config.yaml
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/director/director_config.yaml	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/director/director_config.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,5 ****
- settings:
-   listen_host: localhost
-   listen_port: 50050
-   sample_shape: ['256', '256', '3']
-   target_shape: ['256', '256']
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/director/start_director.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/director/start_director.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/director/start_director.sh	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/director/start_director.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- 
- fx director start --disable-tls -c director_config.yaml
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/director/start_director_with_tls.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/director/start_director_with_tls.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/director/start_director_with_tls.sh	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/director/start_director_with_tls.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- FQDN=$1
- fx director start -c director_config.yaml -rc cert/root_ca.crt -pk cert/"${FQDN}".key -oc cert/"${FQDN}".crt
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/envoy/envoy_config.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/envoy/envoy_config.yaml
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/envoy/envoy_config.yaml	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/envoy/envoy_config.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,11 ****
- params:
-   cuda_devices: [0,2]
- 
- optional_plugin_components: {}
- 
- shard_descriptor:
-   template: mvtec_shard_descriptor.MVTecShardDescriptor
-   params:
-     data_folder: MVTec_data
-     rank_worldsize: 1,1
-     obj: bottle
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/envoy/mvtec_shard_descriptor.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/envoy/mvtec_shard_descriptor.py
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/envoy/mvtec_shard_descriptor.py	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/envoy/mvtec_shard_descriptor.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,159 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """MVTec shard descriptor."""
- 
- import os
- from glob import glob
- from pathlib import Path
- 
- import numpy as np
- from imageio import imread
- from PIL import Image
- 
- from openfl.interface.interactive_api.shard_descriptor import ShardDataset
- from openfl.interface.interactive_api.shard_descriptor import ShardDescriptor
- 
- 
- class MVTecShardDataset(ShardDataset):
-     """MVTec Shard dataset class."""
- 
-     def __init__(self, images_path,
-                  mask_path, labels,
-                  rank=1,
-                  worldsize=1):
-         """Initialize MVTecShardDataset."""
-         self.rank = rank
-         self.worldsize = worldsize
-         self.images_path = images_path[self.rank - 1::self.worldsize]
-         self.mask_path = mask_path[self.rank - 1::self.worldsize]
-         self.labels = labels[self.rank - 1::self.worldsize]
- 
-     def __getitem__(self, index):
-         """Return a item by the index."""
-         img = np.asarray(imread(self.images_path[index]))
-         if img.shape[-1] != 3:
-             img = self.gray2rgb(img)
- 
-         img = self.resize(img)
-         img = np.asarray(img)
-         label = self.labels[index]
-         if self.mask_path[index]:
-             mask = np.asarray(imread(self.mask_path[index]))
-             mask = self.resize(mask)
-             mask = np.asarray(mask)
-         else:
-             mask = np.zeros(img.shape)[:, :, 0]
-         return img, mask, label
- 
-     def __len__(self):
-         """Return the len of the dataset."""
-         return len(self.images_path)
- 
-     def resize(self, image, shape=(256, 256)):
-         """Resize image."""
-         return np.array(Image.fromarray(image).resize(shape))
- 
-     def gray2rgb(self, images):
-         """Change image from gray to rgb."""
-         tile_shape = tuple(np.ones(len(images.shape), dtype=int))
-         tile_shape += (3,)
- 
-         images = np.tile(np.expand_dims(images, axis=-1), tile_shape)
-         return images
- 
- 
- class MVTecShardDescriptor(ShardDescriptor):
-     """MVTec Shard descriptor class."""
- 
-     def __init__(self, data_folder: str = 'MVTec_data',
-                  rank_worldsize: str = '1,1',
-                  obj: str = 'bottle'):
-         """Initialize MVTecShardDescriptor."""
-         super().__init__()
- 
-         self.dataset_path = Path.cwd() / data_folder
-         self.download_data()
-         self.rank, self.worldsize = tuple(int(num) for num in rank_worldsize.split(','))
-         self.obj = obj
- 
-         # Calculating data and target shapes
-         ds = self.get_dataset()
-         sample, masks, target = ds[0]
-         self._sample_shape = [str(dim) for dim in sample.shape]
-         self._target_shape = [str(dim) for dim in target.shape]
- 
-     def download_data(self):
-         """Download data."""
-         zip_file_path = self.dataset_path / 'mvtec_anomaly_detection.tar.xz'
-         if not Path(zip_file_path).exists():
-             os.makedirs(self.dataset_path, exist_ok=True)
-             print('Downloading MVTec Dataset...this might take a while')
-             os.system('wget -nc'
-                       " 'https://www.mydrive.ch/shares/38536/3830184030e49fe74747669442f0f282/download/420938113-1629952094/mvtec_anomaly_detection.tar.xz'"  # noqa
-                       f' -O {zip_file_path.relative_to(Path.cwd())}')
-             print('Downloaded MVTec dataset, untar-ring now')
-             os.system(f'tar -xvf {zip_file_path.relative_to(Path.cwd())}'
-                       f' -C {self.dataset_path.relative_to(Path.cwd())}')
-             # change to write permissions
-             self.change_permissions(self.dataset_path, 0o764)
- 
-     def change_permissions(self, folder, code):
-         """Change permissions after data is downloaded."""
-         for root, dirs, files in os.walk(folder):
-             for d in dirs:
-                 os.chmod(os.path.join(root, d), code)
-             for f in files:
-                 os.chmod(os.path.join(root, f), code)
- 
-     def get_dataset(self, dataset_type='train'):
-         """Return a shard dataset by type."""
-         # Train dataset
-         if dataset_type == 'train':
-             fpattern = os.path.join(self.dataset_path, f'{self.obj}/train/*/*.png')
-             fpaths = sorted(glob(fpattern))
-             self.images_path = list(fpaths)
-             self.labels = np.zeros(len(fpaths), dtype=np.int32)
-             # Masks
-             self.mask_path = np.full(self.labels.shape, None)
-         # Test dataset
-         elif dataset_type == 'test':
-             fpattern = os.path.join(self.dataset_path, f'{self.obj}/test/*/*.png')
-             fpaths = sorted(glob(fpattern))
-             fpaths_anom = list(
-                 filter(lambda fpath: os.path.basename(os.path.dirname(fpath)) != 'good', fpaths))
-             fpaths_good = list(
-                 filter(lambda fpath: os.path.basename(os.path.dirname(fpath)) == 'good', fpaths))
-             fpaths = fpaths_anom + fpaths_good
-             self.images_path = fpaths
-             self.labels = np.zeros(len(fpaths_anom) + len(fpaths_good), dtype=np.int32)
-             self.labels[:len(fpaths_anom)] = 1   # anomalies
-             # Masks
-             fpattern_mask = os.path.join(self.dataset_path, f'{self.obj}/ground_truth/*/*.png')
-             self.mask_path = sorted(glob(fpattern_mask)) + [None] * len(fpaths_good)
-         else:
-             raise Exception(f'Wrong dataset type: {dataset_type}.'
-                             f'Choose from the list: [train, test]')
- 
-         return MVTecShardDataset(
-             images_path=self.images_path,
-             mask_path=self.mask_path,
-             labels=self.labels,
-             rank=self.rank,
-             worldsize=self.worldsize,
-         )
- 
-     @property
-     def sample_shape(self):
-         """Return the sample shape info."""
-         return ['256', '256', '3']
- 
-     @property
-     def target_shape(self):
-         """Return the target shape info."""
-         return ['256', '256']
- 
-     @property
-     def dataset_description(self) -> str:
-         """Return the shard dataset description."""
-         return (f'MVTec dataset, shard number {self.rank}'
-                 f' out of {self.worldsize}')
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/envoy/sd_requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/envoy/sd_requirements.txt
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/envoy/sd_requirements.txt	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/envoy/sd_requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- numpy
- pillow
- imageio
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/envoy/start_envoy.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/envoy/start_envoy.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/envoy/start_envoy.sh	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/envoy/start_envoy.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- 
- fx envoy start -n env_one --disable-tls --envoy-config-path envoy_config.yaml -dh localhost -dp 50050
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/envoy/start_envoy_with_tls.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/envoy/start_envoy_with_tls.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/envoy/start_envoy_with_tls.sh	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/envoy/start_envoy_with_tls.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,6 ****
- #!/bin/bash
- set -e
- ENVOY_NAME=$1
- DIRECTOR_FQDN=$2
- 
- fx envoy start -n "$ENVOY_NAME" --envoy-config-path envoy_config.yaml -dh"$DIRECTOR_FQDN" -dp 50050 -rc cert/root_ca.crt -pk cert/"$ENVOY_NAME".key -oc cert/"$ENVOY_NAME".crt
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/README.md ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/README.md
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/README.md	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/README.md	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,64 ****
- # Anomaly Detection with PatchSVDD for MVTec Dataset
- 
- ![MVTec AD objects](https://www.mvtec.com/fileadmin/Redaktion/mvtec.com/company/research/datasets/dataset_overview_large.png "MVTec AD objects")
- 
- ### 1. About dataset
- 
- MVTec AD is a dataset for benchmarking anomaly detection methods with a focus on industrial
- inspection. It contains over 5000 high-resolution images divided into fifteen different object and
- texture categories. Each class contains 60 to 390 normal train images (defect free) and 40 to 167
- test images (with various kinds of defects as well as images without defects). More info
- at [MVTec dataset](https://www.mvtec.com/company/research/datasets/mvtec-ad). For each object, the
- data is divided into 3 folders - 'train' (containing defect free training images), 'test'(
- containing test images, both good and bad), 'ground_truth' (containing the masks of defected
- images).
- 
- ### 2. About model
- 
- Two neural networks are used: an encoder and a classifier. The encoder is composed of convolutional
- layers only. The classifier is a two layered MLP model having 128 hidden units per layer, and the
- input to the classifier is a subtraction of the features of the two patches. The activation
- function for both networks is a LeakyReLU with a α = 0.1. The encoder has a hierarchical structure.
- The receptive field of the encoder is K = 64, and that of the embedded smaller encoder is K = 32.
- Patch SVDD divides the images into patches with a size K and a stride S. The values for the strides
- are S = 16 and S = 4 for the encoders with K = 64 and K = 32, respectively.
- 
- ### 3. Links
- 
- * [Original paper](https://arxiv.org/abs/2006.16067)
- * [Original Github code](https://github.com/nuclearboy95/Anomaly-Detection-PatchSVDD-PyTorch/tree/934d6238e5e0ad511e2a0e7fc4f4899010e7d892)
- * [MVTec ad dataset download link](https://www.mydrive.ch/shares/38536/3830184030e49fe74747669442f0f282/download/420938113-1629952094/mvtec_anomaly_detection.tar.xz)
- 
- ### 4. How to run this tutorial (without TLS and locally as a simulation):
- 
- Go to example folder:
- cd <openfl_folder>/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD
- 
- 1. Run director:
- 
- ```sh
- cd director
- bash start_director.sh
- ```
- 
- 2. Run envoy:
- 
- ```sh
- cd envoy
- bash start_envoy.sh env_one envoy_config.yaml
- ```
- 
- Optional: start second envoy:
- 
- - Copy `envoy` to another place and run from there:
- 
- ```sh
- bash start_envoy.sh env_two envoy_config_two.yaml
- ```
- 
- 3. Run `PatchSVDD_with_Director.ipynb` jupyter notebook:
- 
- ```sh
- cd workspace
- jupyter lab PatchSVDD_with_Director.ipynb
- ```
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/workspace/data_transf.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/workspace/data_transf.py
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/workspace/data_transf.py	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/workspace/data_transf.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,48 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Data transform functions."""
- 
- import numpy as np
- from sklearn.metrics import balanced_accuracy_score
- from sklearn.metrics import precision_recall_curve
- from sklearn.metrics import roc_auc_score
- 
- 
- def bilinears(images, shape) -> np.ndarray:
-     """Generate binlinears."""
-     import cv2
-     n = images.shape[0]
-     new_shape = (n,) + shape
-     ret = np.zeros(new_shape, dtype=images.dtype)
-     for i in range(n):
-         ret[i] = cv2.resize(images[i], dsize=shape[::-1], interpolation=cv2.INTER_LINEAR)
-     return ret
- 
- 
- def bal_acc_score(obj, predictions, labels):
-     """Calculate balanced accuracy score."""
-     precision, recall, thresholds = precision_recall_curve(labels.flatten(), predictions.flatten())
-     f1_score = (2 * precision * recall) / (precision + recall)
-     threshold = thresholds[np.argmax(f1_score)]
-     prediction_result = predictions > threshold
-     ba_score = balanced_accuracy_score(labels, prediction_result)
-     return ba_score
- 
- 
- def detection_auroc(obj, anomaly_scores, labels):
-     """Calculate detection auroc."""
-     # 1: anomaly 0: normal
-     auroc = roc_auc_score(labels, anomaly_scores)
-     return auroc
- 
- 
- def segmentation_auroc(obj, anomaly_maps, masks):
-     """Calculate segmentation auroc."""
-     gt = masks
-     gt = gt.astype(np.int32)
-     gt[gt == 255] = 1  # 1: anomaly
- 
-     anomaly_maps = bilinears(anomaly_maps, (256, 256))
-     auroc = roc_auc_score(gt.flatten(), anomaly_maps.flatten())
-     return auroc
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/workspace/inspection.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/workspace/inspection.py
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/workspace/inspection.py	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/workspace/inspection.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,139 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Inspection of images and patches."""
- 
- import os
- import shutil
- 
- import ngtpy
- import numpy as np
- from data_transf import bal_acc_score
- from data_transf import detection_auroc
- from data_transf import segmentation_auroc
- from sklearn.neighbors import KDTree
- from utils import distribute_scores
- 
- 
- def search_nn(test_emb, train_emb_flat, nn=1, method='kdt'):
-     """Seach nearest neighbors."""
-     if method == 'ngt':
-         return search_nn_ngt(test_emb, train_emb_flat, nn=nn)
- 
-     kdt = KDTree(train_emb_flat)
- 
-     ntest, i, j, d = test_emb.shape
-     closest_inds = np.empty((ntest, i, j, nn), dtype=np.int32)
-     l2_maps = np.empty((ntest, i, j, nn), dtype=np.float32)
- 
-     for n_ in range(ntest):
-         for i_ in range(i):
-             dists, inds = kdt.query(test_emb[n_, i_, :, :], return_distance=True, k=nn)
-             closest_inds[n_, i_, :, :] = inds[:, :]
-             l2_maps[n_, i_, :, :] = dists[:, :]
- 
-     return l2_maps, closest_inds
- 
- 
- def search_nn_ngt(test_emb, train_emb_flat, nn=1):
-     """Search nearest neighbors."""
-     ntest, i, j, d = test_emb.shape
-     closest_inds = np.empty((ntest, i, j, nn), dtype=np.int32)
-     l2_maps = np.empty((ntest, i, j, nn), dtype=np.float32)
- 
-     dpath = f'/tmp/{os.getpid()}'
-     ngtpy.create(dpath, d)
-     index = ngtpy.Index(dpath)
-     index.batch_insert(train_emb_flat)
- 
-     for n_ in range(ntest):
-         for i_ in range(i):
-             for j_ in range(j):
-                 query = test_emb[n_, i_, j_, :]
-                 results = index.search(query, nn)
-                 inds = [result[0] for result in results]
- 
-                 closest_inds[n_, i_, j_, :] = inds
-                 vecs = np.asarray([index.get_object(inds[nn_]) for nn_ in range(nn)])
-                 dists = np.linalg.norm(query - vecs, axis=-1)
-                 l2_maps[n_, i_, j_, :] = dists
-     shutil.rmtree(dpath)
- 
-     return l2_maps, closest_inds
- 
- 
- def assess_anomaly_maps(obj, anomaly_maps, masks, labels):
-     """Assess anomaly maps."""
-     auroc_seg = segmentation_auroc(obj, anomaly_maps, masks)
- 
-     anomaly_scores = anomaly_maps.max(axis=-1).max(axis=-1)
-     auroc_det = detection_auroc(obj, anomaly_scores, labels)
-     ba_score = bal_acc_score(obj, anomaly_scores, labels)
-     return auroc_det, auroc_seg, ba_score
- 
- 
- def eval_embeddings_nn_multik(obj, embs64, embs32, masks, labels, nn=1):
-     """Evaluate embeddings."""
-     emb_tr, emb_te = embs64
-     maps_64 = measure_emb_nn(emb_te, emb_tr, method='kdt', nn=nn)
-     maps_64 = distribute_scores(maps_64, (256, 256), k=64, s=16)
-     det_64, seg_64, ba_64 = assess_anomaly_maps(obj, maps_64, masks, labels)
- 
-     emb_tr, emb_te = embs32
-     maps_32 = measure_emb_nn(emb_te, emb_tr, method='ngt', nn=nn)
-     maps_32 = distribute_scores(maps_32, (256, 256), k=32, s=4)
-     det_32, seg_32, ba_32 = assess_anomaly_maps(obj, maps_32, masks, labels)
- 
-     maps_sum = maps_64 + maps_32
-     det_sum, seg_sum, ba_sum = assess_anomaly_maps(obj, maps_sum, masks, labels)
- 
-     maps_mult = maps_64 * maps_32
-     det_mult, seg_mult, ba_mult = assess_anomaly_maps(obj, maps_mult, masks, labels)
- 
-     return {
-         'det_64': det_64,
-         'seg_64': seg_64,
-         'bal_acc_64': ba_64,
- 
-         'det_32': det_32,
-         'seg_32': seg_32,
-         'bal_acc_32': ba_32,
- 
-         'det_sum': det_sum,
-         'seg_sum': seg_sum,
-         'bal_acc_sum': ba_sum,
- 
-         'det_mult': det_mult,
-         'seg_mult': seg_mult,
-         'bal_acc_mult': ba_mult,
- 
-         'maps_64': maps_64,
-         'maps_32': maps_32,
-         'maps_sum': maps_sum,
-         'maps_mult': maps_mult,
-     }
- 
- 
- def eval_embeddings_nn_maps(obj, embs64, embs32, masks, labels, nn=1):
-     """Evaluate embeddings."""
-     emb_tr, emb_te = embs64
-     maps_64 = measure_emb_nn(emb_te, emb_tr, method='kdt', nn=nn)
-     maps_64 = distribute_scores(maps_64, (256, 256), k=64, s=16)
- 
-     emb_tr, emb_te = embs32
-     maps_32 = measure_emb_nn(emb_te, emb_tr, method='ngt', nn=nn)
-     maps_32 = distribute_scores(maps_32, (256, 256), k=32, s=4)
- 
-     maps_mult = maps_64 * maps_32
-     return maps_mult
- 
- 
- def measure_emb_nn(emb_te, emb_tr, method='kdt', nn=1):
-     """Measure embeddings."""
-     d = emb_tr.shape[-1]
-     train_emb_all = emb_tr.reshape(-1, d)
- 
-     l2_maps, _ = search_nn(emb_te, train_emb_all, method=method, nn=nn)
-     anomaly_maps = np.mean(l2_maps, axis=-1)
- 
-     return anomaly_maps
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/workspace/PatchSVDD_with_Director.ipynb ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/workspace/PatchSVDD_with_Director.ipynb
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/workspace/PatchSVDD_with_Director.ipynb	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/workspace/PatchSVDD_with_Director.ipynb	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,1120 ****
- {
-  "cells": [
-   {
-    "cell_type": "markdown",
-    "id": "liquid-jacket",
-    "metadata": {},
-    "source": [
-     "# Federated PatchSVDD algorithm with Director example"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "83e6aae2",
-    "metadata": {},
-    "source": [
-     "# PatchSVDD algorithm\n",
-     "Anomaly detection involves making a binary decision as to whether an input image contains an anomaly, and anomaly segmentation aims to locate the anomaly on the pixel level. The deep learning variant of Support vector data description (SVDD: a long-standing algorithm used for anomaly detection) is used to the patch-based method using self-supervised learning. This extension enables anomaly segmentation and improves detection performances which are measured in AUROC on MVTec AD dataset.\n",
-     "\n",
-     "![alt text](https://media.arxiv-vanity.com/render-output/5520416/x4.png \"Patch Level SVDD for Anomaly Detection\")\n",
-     "\n",
-     "* Original paper: https://arxiv.org/abs/2006.16067\n",
-     "* Original Github code: https://github.com/nuclearboy95/Anomaly-Detection-PatchSVDD-PyTorch/tree/934d6238e5e0ad511e2a0e7fc4f4899010e7d892\n",
-     "* MVTec ad dataset download link: https://www.mydrive.ch/shares/38536/3830184030e49fe74747669442f0f282/download/420938113-1629952094/mvtec_anomaly_detection.tar.xz"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "alike-sharing",
-    "metadata": {
-     "scrolled": true
-    },
-    "outputs": [],
-    "source": [
-     "# Install dependencies if not already installed\n",
-     "!pip install torchvision==0.8.1 matplotlib numpy scikit-image scikit-learn torch tqdm Pillow imageio opencv-python ngt"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "16986f22",
-    "metadata": {},
-    "source": [
-     "# Connect to the Federation"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "4485ac79",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Create a federation\n",
-     "from openfl.interface.interactive_api.federation import Federation\n",
-     "\n",
-     "# 1) Run with API layer - Director mTLS \n",
-     "# If the user wants to enable mTLS their must provide CA root chain, and signed key pair to the federation interface\n",
-     "# cert_chain = 'cert/root_ca.crt'\n",
-     "# API_certificate = 'cert/frontend.crt'\n",
-     "# API_private_key = 'cert/frontend.key'\n",
-     "\n",
-     "# federation = Federation(client_id='frontend', director_node_fqdn='localhost', director_port='50051',\n",
-     "#                        cert_chain=cert_chain, api_cert=API_certificate, api_private_key=API_private_key)\n",
-     "\n",
-     "# --------------------------------------------------------------------------------------------------------------------\n",
-     "\n",
-     "# 2) Run with TLS disabled (trusted environment)\n",
-     "# Federation can also determine local fqdn automatically\n",
-     "federation = Federation(client_id='frontend', director_node_fqdn='localhost', director_port='50050', tls=False)\n"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "e35802d5",
-    "metadata": {
-     "scrolled": true
-    },
-    "outputs": [],
-    "source": [
-     "shard_registry = federation.get_shard_registry()\n",
-     "shard_registry"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "67ae50de",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "federation.target_shape"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "obvious-tyler",
-    "metadata": {},
-    "source": [
-     "## Creating a FL experiment using Interactive API"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "rubber-address",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "sustainable-public",
-    "metadata": {},
-    "source": [
-     "### Register dataset"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "dd2407cf",
-    "metadata": {
-     "scrolled": true
-    },
-    "outputs": [],
-    "source": [
-     "#Arguments\n",
-     "args = {\n",
-     "'obj' : 'bottle',\n",
-     "'lambda_value': '1e-3',\n",
-     "'D' : 64,\n",
-     "'lr' : '1e-4',\n",
-     "}"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "8669bc63",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import argparse\n",
-     "import torch\n",
-     "from functools import reduce\n",
-     "from torch.utils.data import DataLoader,Dataset\n",
-     "import torch.nn as nn\n",
-     "import torch.nn.functional as F\n",
-     "import math\n",
-     "import numpy as np\n",
-     "from PIL import Image\n",
-     "from imageio import imread\n",
-     "from glob import glob\n",
-     "from sklearn.metrics import roc_auc_score\n",
-     "import os, shutil\n",
-     "import _pickle as p\n",
-     "from contextlib import contextmanager\n",
-     "import PIL\n",
-     "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
-     "from torchvision import transforms as tsf\n",
-     "from utils import to_device, task, DictionaryConcatDataset, crop_chw, cnn_output_size, crop_image_chw\n",
-     "from functools import reduce"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "64f37dcf",
-    "metadata": {
-     "scrolled": true
-    },
-    "outputs": [],
-    "source": [
-     "def generate_coords(H, W, K):\n",
-     "    h = np.random.randint(0, H - K + 1)\n",
-     "    w = np.random.randint(0, W - K + 1)\n",
-     "    return h, w\n",
-     "\n",
-     "\n",
-     "def generate_coords_position(H, W, K):\n",
-     "    with task('P1'):\n",
-     "        p1 = generate_coords(H, W, K)\n",
-     "        h1, w1 = p1\n",
-     "\n",
-     "    pos = np.random.randint(8)\n",
-     "\n",
-     "    with task('P2'):\n",
-     "        J = K // 4\n",
-     "\n",
-     "        K3_4 = 3 * K // 4\n",
-     "        h_dir, w_dir = pos_to_diff[pos]\n",
-     "        h_del, w_del = np.random.randint(J, size=2)\n",
-     "\n",
-     "        h_diff = h_dir * (h_del + K3_4)\n",
-     "        w_diff = w_dir * (w_del + K3_4)\n",
-     "\n",
-     "        h2 = h1 + h_diff\n",
-     "        w2 = w1 + w_diff\n",
-     "\n",
-     "        h2 = np.clip(h2, 0, H - K)\n",
-     "        w2 = np.clip(w2, 0, W - K)\n",
-     "\n",
-     "        p2 = (h2, w2)\n",
-     "\n",
-     "    return p1, p2, pos\n",
-     "\n",
-     "\n",
-     "def generate_coords_svdd(H, W, K):\n",
-     "    with task('P1'):\n",
-     "        p1 = generate_coords(H, W, K)\n",
-     "        h1, w1 = p1\n",
-     "\n",
-     "    with task('P2'):\n",
-     "        J = K // 32\n",
-     "\n",
-     "        h_jit, w_jit = 0, 0\n",
-     "\n",
-     "        while h_jit == 0 and w_jit == 0:\n",
-     "            h_jit = np.random.randint(-J, J + 1)\n",
-     "            w_jit = np.random.randint(-J, J + 1)\n",
-     "\n",
-     "        h2 = h1 + h_jit\n",
-     "        w2 = w1 + w_jit\n",
-     "\n",
-     "        h2 = np.clip(h2, 0, H - K)\n",
-     "        w2 = np.clip(w2, 0, W - K)\n",
-     "\n",
-     "        p2 = (h2, w2)\n",
-     "\n",
-     "    return p1, p2\n",
-     "\n",
-     "\n",
-     "pos_to_diff = {\n",
-     "    0: (-1, -1),\n",
-     "    1: (-1, 0),\n",
-     "    2: (-1, 1),\n",
-     "    3: (0, -1),\n",
-     "    4: (0, 1),\n",
-     "    5: (1, -1),\n",
-     "    6: (1, 0),\n",
-     "    7: (1, 1)\n",
-     "}\n"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "242e3109",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "class SVDD_Dataset(Dataset):\n",
-     "    def __init__(self, memmap, K=64, repeat=1):\n",
-     "        super().__init__()\n",
-     "        self.arr = np.asarray(memmap)\n",
-     "        self.K = K\n",
-     "        self.repeat = repeat\n",
-     "        \n",
-     "\n",
-     "    def __len__(self):\n",
-     "        N = self.arr.shape[0]\n",
-     "        return N * self.repeat\n",
-     "\n",
-     "    def __getitem__(self, idx):\n",
-     "        N = self.arr.shape[0]\n",
-     "        K = self.K\n",
-     "        n = idx % N\n",
-     "\n",
-     "        p1, p2 = generate_coords_svdd(256, 256, K)\n",
-     "\n",
-     "        image = self.arr[n]\n",
-     "\n",
-     "        patch1 = crop_image_chw(image, p1, K)\n",
-     "        patch2 = crop_image_chw(image, p2, K)\n",
-     "\n",
-     "        return patch1, patch2"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "cea3ee13",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "class PositionDataset(Dataset):\n",
-     "    def __init__(self, x, K=64, repeat=1):\n",
-     "        super(PositionDataset, self).__init__()\n",
-     "        self.x = np.asarray(x)\n",
-     "        self.K = K\n",
-     "        self.repeat = repeat\n",
-     "\n",
-     "    def __len__(self):\n",
-     "        N = self.x.shape[0]\n",
-     "        return N * self.repeat\n",
-     "\n",
-     "    def __getitem__(self, idx):\n",
-     "        N = self.x.shape[0]\n",
-     "        K = self.K\n",
-     "        n = idx % N\n",
-     "\n",
-     "        image = self.x[n]\n",
-     "        p1, p2, pos = generate_coords_position(256, 256, K)\n",
-     "\n",
-     "        patch1 = crop_image_chw(image, p1, K).copy()\n",
-     "        patch2 = crop_image_chw(image, p2, K).copy()\n",
-     "\n",
-     "        # perturb RGB\n",
-     "        rgbshift1 = np.random.normal(scale=0.02, size=(3, 1, 1))\n",
-     "        rgbshift2 = np.random.normal(scale=0.02, size=(3, 1, 1))\n",
-     "\n",
-     "        patch1 += rgbshift1\n",
-     "        patch2 += rgbshift2\n",
-     "\n",
-     "        # additive noise\n",
-     "        noise1 = np.random.normal(scale=0.02, size=(3, K, K))\n",
-     "        noise2 = np.random.normal(scale=0.02, size=(3, K, K))\n",
-     "\n",
-     "        patch1 += noise1\n",
-     "        patch2 += noise2\n",
-     "\n",
-     "        return patch1, patch2, pos\n"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "6efc53ee",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "class PatchDataset_NCHW(Dataset):\n",
-     "    def __init__(self, memmap, tfs=None, K=32, S=1):\n",
-     "        super().__init__()\n",
-     "        self.arr = memmap\n",
-     "        self.tfs = tfs\n",
-     "        self.S = S\n",
-     "        self.K = K\n",
-     "        self.N = self.arr.shape[0]\n",
-     "    \n",
-     "    def __len__(self):\n",
-     "        return self.N * self.row_num * self.col_num\n",
-     "\n",
-     "    @property\n",
-     "    def row_num(self):\n",
-     "        N, C, H, W = self.arr.shape\n",
-     "        K = self.K\n",
-     "        S = self.S\n",
-     "        I = cnn_output_size(H, k=K, s=S)\n",
-     "        return I\n",
-     "\n",
-     "    @property\n",
-     "    def col_num(self):\n",
-     "        N, C, H, W = self.arr.shape\n",
-     "        K = self.K\n",
-     "        S = self.S\n",
-     "        J = cnn_output_size(W, k=K, s=S)\n",
-     "        return J\n",
-     "\n",
-     "    def __getitem__(self, idx):\n",
-     "        N = self.N\n",
-     "        n, i, j = np.unravel_index(idx, (N, self.row_num, self.col_num))\n",
-     "        K = self.K\n",
-     "        S = self.S\n",
-     "        image = self.arr[n]\n",
-     "        patch = crop_chw(image, i, j, K, S)\n",
-     "\n",
-     "        if self.tfs:\n",
-     "            patch = self.tfs(patch)\n",
-     "\n",
-     "        return patch, n, i, j\n"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "fd781c21",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "\"\"\"\n",
-     "ShardDataset class\n",
-     "\"\"\"\n",
-     "class MVTecShardDataset(Dataset):\n",
-     "    \n",
-     "    def __init__(self, dataset):\n",
-     "        self._dataset = dataset\n",
-     "        \n",
-     "    def __getitem__(self, index):\n",
-     "        img, mask, label = self._dataset[index]\n",
-     "        return img, mask, label\n",
-     "    \n",
-     "    def __len__(self):\n",
-     "        return len(self._dataset)\n",
-     "    \n",
-     "class MVTecSD(DataInterface):\n",
-     "\n",
-     "    def __init__(self, **kwargs):\n",
-     "        super().__init__(**kwargs)\n",
-     "    \n",
-     "    @property\n",
-     "    def shard_descriptor(self):\n",
-     "        return self._shard_descriptor\n",
-     "        \n",
-     "    @shard_descriptor.setter\n",
-     "    def shard_descriptor(self, shard_descriptor):\n",
-     "        \"\"\"\n",
-     "        Describe per-collaborator procedures or sharding.\n",
-     "\n",
-     "        This method will be called during a collaborator initialization.\n",
-     "        Local shard_descriptor  will be set by Envoy.\n",
-     "        \"\"\"\n",
-     "        self._shard_descriptor = shard_descriptor\n",
-     "        \n",
-     "        self.train_set = MVTecShardDataset(shard_descriptor.get_dataset('train'))\n",
-     "\n",
-     "        self.test_set = MVTecShardDataset(shard_descriptor.get_dataset('test'))    \n",
-     "    \n",
-     "    def get_train_loader(self, **kwargs):\n",
-     "        \"\"\"\n",
-     "        Output of this method will be provided to tasks with optimizer in contract\n",
-     "        \"\"\"\n",
-     "        train_x = np.stack([image for image, mask, label in self.train_set]).astype(np.float32)\n",
-     "        mean = train_x.astype(np.float32).mean(axis=0)\n",
-     "        train_x = (train_x.astype(np.float32) - mean) / 255\n",
-     "        train_x = np.transpose(train_x, [0, 3, 1, 2])\n",
-     "    \n",
-     "        if self.kwargs['train_bs']:\n",
-     "            batch_size = self.kwargs['train_bs']\n",
-     "        else:\n",
-     "            batch_size = 64\n",
-     "            \n",
-     "        loader = DataLoader(self.get_train_dataset_dict(train_x), batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
-     "        return loader\n",
-     "\n",
-     "    def get_valid_loader(self, **kwargs):\n",
-     "        \"\"\"\n",
-     "        Output of this method will be provided to tasks without optimizer in contract\n",
-     "        \"\"\"\n",
-     "        # We need both train and test data for obtaining embeddings\n",
-     "        train_x = np.stack([image for image, mask, label in self.train_set]).astype(np.float32)\n",
-     "        mean = train_x.astype(np.float32).mean(axis=0)\n",
-     "        train_x = (train_x.astype(np.float32) - mean) / 255\n",
-     "        train_x = np.transpose(train_x, [0, 3, 1, 2])\n",
-     "        \n",
-     "        #getting val loader\n",
-     "        test_x = np.stack([image for image, mask, label in self.test_set]).astype(np.float32)\n",
-     "        mean = test_x.astype(np.float32).mean(axis=0)\n",
-     "        test_x = (test_x.astype(np.float32) - mean) / 255\n",
-     "        test_x = np.transpose(test_x, [0, 3, 1, 2])\n",
-     "        \n",
-     "        masks = np.stack([mask for image, mask, label in self.test_set]).astype(np.int32)\n",
-     "        masks[masks <= 128] = 0\n",
-     "        masks[masks > 128] = 255\n",
-     "        labels = np.stack([label for image, mask, label in self.test_set]).astype(np.int32)\n",
-     "\n",
-     "        return (train_x, test_x, masks, labels, mean)\n",
-     "\n",
-     "\n",
-     "    def get_train_data_size(self):\n",
-     "        \"\"\"\n",
-     "        Information for aggregation\n",
-     "        \"\"\"\n",
-     "        return len(self.train_set)\n",
-     "        \n",
-     "\n",
-     "    def get_valid_data_size(self):\n",
-     "        \"\"\"\n",
-     "        Information for aggregation\n",
-     "        \"\"\"\n",
-     "        return len(self.test_set)\n",
-     "    \n",
-     "    def get_train_dataset_dict(self,inp_x):\n",
-     "        rep = 100\n",
-     "        datasets = dict()\n",
-     "        datasets[f'pos_64'] = PositionDataset(inp_x, K=64, repeat=rep)\n",
-     "        datasets[f'pos_32'] = PositionDataset(inp_x, K=32, repeat=rep)\n",
-     "\n",
-     "        datasets[f'svdd_64'] = SVDD_Dataset(inp_x, K=64, repeat=rep)\n",
-     "        datasets[f'svdd_32'] = SVDD_Dataset(inp_x, K=32, repeat=rep)\n",
-     "        dataset = DictionaryConcatDataset(datasets)\n",
-     "        return dataset\n"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "d8df35f5",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "fed_dataset = MVTecSD(train_bs=64, val_bs=64)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "8f786b8b",
-    "metadata": {},
-    "source": [
-     "### Describe a model and optimizer"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "visible-victor",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import torch.optim as optim\n",
-     "import torch.nn as nn\n",
-     "import torch\n",
-     "import torch.nn.functional as F\n",
-     "import math\n",
-     "from utils import makedirpath"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "138e1493",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "class Encoder(nn.Module):\n",
-     "    def __init__(self, K, D=64, bias=True):\n",
-     "        super().__init__()\n",
-     "\n",
-     "        self.conv1 = nn.Conv2d(3, 64, 5, 2, 0, bias=bias)\n",
-     "        self.conv2 = nn.Conv2d(64, 64, 5, 2, 0, bias=bias)\n",
-     "        self.conv3 = nn.Conv2d(64, 128, 5, 2, 0, bias=bias)\n",
-     "        self.conv4 = nn.Conv2d(128, D, 5, 1, 0, bias=bias)\n",
-     "\n",
-     "        self.K = K\n",
-     "        self.D = D\n",
-     "        self.bias = bias\n",
-     "\n",
-     "    def forward(self, x):\n",
-     "        h = self.conv1(x)\n",
-     "        h = F.leaky_relu(h, 0.1)\n",
-     "\n",
-     "        h = self.conv2(h)\n",
-     "        h = F.leaky_relu(h, 0.1)\n",
-     "\n",
-     "        h = self.conv3(h)\n",
-     "\n",
-     "        if self.K == 64:\n",
-     "            h = F.leaky_relu(h, 0.1)\n",
-     "            h = self.conv4(h)\n",
-     "\n",
-     "        h = torch.tanh(h)\n",
-     "\n",
-     "        return h\n",
-     "\n",
-     "def forward_hier(x, emb_small, K):\n",
-     "    K_2 = K // 2\n",
-     "    n = x.size(0)\n",
-     "    x1 = x[..., :K_2, :K_2]\n",
-     "    x2 = x[..., :K_2, K_2:]\n",
-     "    x3 = x[..., K_2:, :K_2]\n",
-     "    x4 = x[..., K_2:, K_2:]\n",
-     "    xx = torch.cat([x1, x2, x3, x4], dim=0)\n",
-     "    hh = emb_small(xx)\n",
-     "\n",
-     "    h1 = hh[:n]\n",
-     "    h2 = hh[n: 2 * n]\n",
-     "    h3 = hh[2 * n: 3 * n]\n",
-     "    h4 = hh[3 * n:]\n",
-     "\n",
-     "    h12 = torch.cat([h1, h2], dim=3)\n",
-     "    h34 = torch.cat([h3, h4], dim=3)\n",
-     "    h = torch.cat([h12, h34], dim=2)\n",
-     "    return h\n"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "113f5a73",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "class EncoderDeep(nn.Module):\n",
-     "    def __init__(self, K, D=64, bias=True):\n",
-     "        super().__init__()\n",
-     "\n",
-     "        self.conv1 = nn.Conv2d(3, 32, 3, 2, 0, bias=bias)\n",
-     "        self.conv2 = nn.Conv2d(32, 64, 3, 1, 0, bias=bias)\n",
-     "        self.conv3 = nn.Conv2d(64, 128, 3, 1, 0, bias=bias)\n",
-     "        self.conv4 = nn.Conv2d(128, 128, 3, 1, 0, bias=bias)\n",
-     "        self.conv5 = nn.Conv2d(128, 64, 3, 1, 0, bias=bias)\n",
-     "        self.conv6 = nn.Conv2d(64, 32, 3, 1, 0, bias=bias)\n",
-     "        self.conv7 = nn.Conv2d(32, 32, 3, 1, 0, bias=bias)\n",
-     "        self.conv8 = nn.Conv2d(32, D, 3, 1, 0, bias=bias)\n",
-     "\n",
-     "        self.K = K\n",
-     "        self.D = D\n",
-     "\n",
-     "    def forward(self, x):\n",
-     "        h = self.conv1(x)\n",
-     "        h = F.leaky_relu(h, 0.1)\n",
-     "\n",
-     "        h = self.conv2(h)\n",
-     "        h = F.leaky_relu(h, 0.1)\n",
-     "\n",
-     "        h = self.conv3(h)\n",
-     "        h = F.leaky_relu(h, 0.1)\n",
-     "\n",
-     "        h = self.conv4(h)\n",
-     "        h = F.leaky_relu(h, 0.1)\n",
-     "\n",
-     "        h = self.conv5(h)\n",
-     "        h = F.leaky_relu(h, 0.1)\n",
-     "\n",
-     "        h = self.conv6(h)\n",
-     "        h = F.leaky_relu(h, 0.1)\n",
-     "\n",
-     "        h = self.conv7(h)\n",
-     "        h = F.leaky_relu(h, 0.1)\n",
-     "\n",
-     "        h = self.conv8(h)\n",
-     "        h = torch.tanh(h)\n",
-     "\n",
-     "        return h\n"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "70ccf01d",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "class EncoderHier(nn.Module):\n",
-     "    def __init__(self, K, D=64, bias=True):\n",
-     "        super().__init__()\n",
-     "\n",
-     "        if K > 64:\n",
-     "            self.enc = EncoderHier(K // 2, D, bias=bias)\n",
-     "\n",
-     "        elif K == 64:\n",
-     "            self.enc = EncoderDeep(K // 2, D, bias=bias)\n",
-     "\n",
-     "        else:\n",
-     "            raise ValueError()\n",
-     "\n",
-     "        self.conv1 = nn.Conv2d(D, 128, 2, 1, 0, bias=bias)\n",
-     "        self.conv2 = nn.Conv2d(128, D, 1, 1, 0, bias=bias)\n",
-     "\n",
-     "        self.K = K\n",
-     "        self.D = D\n",
-     "\n",
-     "    def forward(self, x):\n",
-     "        h = forward_hier(x, self.enc, K=self.K)\n",
-     "\n",
-     "        h = self.conv1(h)\n",
-     "        h = F.leaky_relu(h, 0.1)\n",
-     "\n",
-     "        h = self.conv2(h)\n",
-     "        h = torch.tanh(h)\n",
-     "\n",
-     "        return h\n"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "6e7688de",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "xent = nn.CrossEntropyLoss()\n",
-     "\n",
-     "class NormalizedLinear(nn.Module):\n",
-     "    __constants__ = ['bias', 'in_features', 'out_features']\n",
-     "\n",
-     "    def __init__(self, in_features, out_features, bias=True):\n",
-     "        super(NormalizedLinear, self).__init__()\n",
-     "        self.in_features = in_features\n",
-     "        self.out_features = out_features\n",
-     "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
-     "        if bias:\n",
-     "            self.bias = nn.Parameter(torch.Tensor(out_features))\n",
-     "        else:\n",
-     "            self.register_parameter('bias', None)\n",
-     "        self.reset_parameters()\n",
-     "\n",
-     "    def reset_parameters(self):\n",
-     "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
-     "        if self.bias is not None:\n",
-     "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
-     "            bound = 1 / math.sqrt(fan_in)\n",
-     "            nn.init.uniform_(self.bias, -bound, bound)\n",
-     "\n",
-     "    def forward(self, x):\n",
-     "        with torch.no_grad():\n",
-     "            w = self.weight / self.weight.data.norm(keepdim=True, dim=0)\n",
-     "        return F.linear(x, w, self.bias)\n",
-     "\n",
-     "    def extra_repr(self):\n",
-     "        return 'in_features={}, out_features={}, bias={}'.format(\n",
-     "            self.in_features, self.out_features, self.bias is not None\n",
-     "        )\n"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "foreign-gospel",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "class PositionClassifier(nn.Module):\n",
-     "    def __init__(self, K, D, class_num=8):\n",
-     "        super().__init__()\n",
-     "        self.D = D\n",
-     "\n",
-     "        self.fc1 = nn.Linear(D, 128)\n",
-     "        self.act1 = nn.LeakyReLU(0.1)\n",
-     "\n",
-     "        self.fc2 = nn.Linear(128, 128)\n",
-     "        self.act2 = nn.LeakyReLU(0.1)\n",
-     "\n",
-     "        self.fc3 = NormalizedLinear(128, class_num)\n",
-     "        self.fc3.requires_grad_(False)\n",
-     "\n",
-     "        self.K = K\n",
-     "\n",
-     "    def forward(self, h1, h2):\n",
-     "        h1 = h1.view(-1, self.D)\n",
-     "        h2 = h2.view(-1, self.D)\n",
-     "\n",
-     "        h = h1 - h2\n",
-     "\n",
-     "        h = self.fc1(h)\n",
-     "        h = self.act1(h)\n",
-     "\n",
-     "        h = self.fc2(h)\n",
-     "        h = self.act2(h)\n",
-     "\n",
-     "        h = self.fc3(h)\n",
-     "        return h\n"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "db853fe0",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "\"\"\"\n",
-     "Model definition (ensembled)\n",
-     "\"\"\"\n",
-     "class MyEnsembledModel(nn.Module):\n",
-     "    def __init__(self, enc, cls_64, cls_32):\n",
-     "        super().__init__()\n",
-     "        self._enc = enc\n",
-     "        self._cls_64 = cls_64\n",
-     "        self._cls_32 = cls_32\n",
-     "        \n",
-     "    def forward(self):\n",
-     "        pass\n",
-     "\n",
-     "\n",
-     "enc = EncoderHier(64, args['D'])\n",
-     "cls_64 = PositionClassifier(64, args['D'])\n",
-     "cls_32 = PositionClassifier(32, args['D'])\n",
-     "\n",
-     "model = MyEnsembledModel(enc, cls_64, cls_32)\n",
-     "\n",
-     "params_to_update = []\n",
-     "for p in model.parameters():\n",
-     "    if p.requires_grad:\n",
-     "        params_to_update.append(p)\n",
-     "optimizer_adam = torch.optim.Adam(params=params_to_update , lr=float(args['lr']))\n"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "caroline-passion",
-    "metadata": {},
-    "source": [
-     "#### Register model"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "handled-teens",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from copy import deepcopy\n",
-     "\n",
-     "framework_adapter = 'openfl.plugins.frameworks_adapters.pytorch_adapter.FrameworkAdapterPlugin'\n",
-     "MI = ModelInterface(model=model, optimizer=optimizer_adam, framework_plugin=framework_adapter)\n",
-     "\n",
-     "# Save the initial model state\n",
-     "initial_model = deepcopy(model)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "portuguese-groove",
-    "metadata": {},
-    "source": [
-     "### Define and register FL tasks"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "increasing-builder",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "TI = TaskInterface()\n",
-     "import torch\n",
-     "import tqdm\n",
-     "from utils import cnn_output_size\n",
-     "from inspection import eval_embeddings_nn_multik\n",
-     "\n",
-     "# The Interactive API supports registering functions definied in main module or imported.\n",
-     "def function_defined_in_notebook(some_parameter):\n",
-     "    print(f'Also I accept a parameter and it is {some_parameter}')\n",
-     "\n",
-     "# Task interface currently supports only standalone functions.\n",
-     "@TI.add_kwargs(**{'some_parameter': 42})\n",
-     "@TI.register_fl_task(model='model', data_loader='train_loader', \\\n",
-     "                     device='device', optimizer='optimizer')     \n",
-     "\n",
-     "def train(model, train_loader, optimizer, device, some_parameter=None):\n",
-     "    print(f'\\n\\n TASK TRAIN GOT DEVICE {device}\\n\\n')\n",
-     "    \n",
-     "    function_defined_in_notebook(some_parameter)\n",
-     "    \n",
-     "    train_loader = tqdm.tqdm(train_loader, desc=\"train\")\n",
-     "\n",
-     "    model.train()\n",
-     "    model.to(device)\n",
-     "    losses = []\n",
-     "\n",
-     "    for d in train_loader:\n",
-     "        d = to_device(d, device, non_blocking=True)\n",
-     "        optimizer.zero_grad()\n",
-     "        loss_pos_64 = PositionClassifier_infer(model._cls_64, model._enc, d['pos_64'])\n",
-     "        loss_pos_32 = PositionClassifier_infer(model._cls_32, model._enc.enc, d['pos_32'])\n",
-     "        loss_svdd_64 = SVDD_Dataset_infer(model._enc, d['svdd_64'])\n",
-     "        loss_svdd_32 = SVDD_Dataset_infer(model._enc.enc, d['svdd_32'])\n",
-     "\n",
-     "        loss = loss_pos_64 + loss_pos_32 + float(args['lambda_value']) * (loss_svdd_64 + loss_svdd_32)\n",
-     "        loss.backward()\n",
-     "        optimizer.step()\n",
-     "        losses.append(loss.detach().cpu().numpy())\n",
-     "    return {'train_loss': np.mean(losses),}\n",
-     "    \n",
-     "\n",
-     "@TI.register_fl_task(model='model', data_loader='val_loader', device='device')     \n",
-     "def validate(model, val_loader, device):\n",
-     "    print(f'\\n\\n TASK VALIDATE GOT DEVICE {device}\\n\\n')\n",
-     "    \n",
-     "    model._enc.eval()\n",
-     "    model._enc.to(device)\n",
-     "    \n",
-     "    x_tr, x_te, masks, labels, mean = val_loader\n",
-     "\n",
-     "    embs64_tr = infer_(x_tr, model._enc, K=64, S=16, device=device)\n",
-     "    embs64_te = infer_(x_te, model._enc, K=64, S=16, device=device)\n",
-     "    embs32_tr = infer_(x_tr, model._enc.enc, K=32, S=4, device=device)\n",
-     "    embs32_te = infer_(x_te, model._enc.enc, K=32, S=4, device=device)\n",
-     "\n",
-     "    embs64 = embs64_tr, embs64_te\n",
-     "    embs32 = embs32_tr, embs32_te\n",
-     "\n",
-     "    results = eval_embeddings_nn_multik(args['obj'], embs64, embs32, masks, labels)\n",
-     "    \n",
-     "    maps = results['maps_mult']\n",
-     "    obj = args['obj']\n",
-     "\n",
-     "    print(\"| K64 | Det: {:.3f} Seg:{:.3f} BA: {:.3f}\".format(results['det_64'],results['seg_64'],results['bal_acc_64']))\n",
-     "    print(\"| K32 | Det: {:.3f} Seg:{:.3f} BA: {:.3f}\".format(results['det_32'],results['seg_32'],results['bal_acc_32']))\n",
-     "    print(\"| sum | Det: {:.3f} Seg:{:.3f} BA: {:.3f}\".format(results['det_sum'],results['seg_sum'],results['bal_acc_sum']))\n",
-     "    print(\"| mult | Det: {:.3f} Seg:{:.3f} BA: {:.3f}\".format(results['det_mult'],results['seg_mult'],results['bal_acc_mult']))\n",
-     "\n",
-     "    return {'detection_score_sum': results['det_sum'], 'segmentation_score_sum': results['seg_sum'], 'balanced_accuracy_score_sum': results['bal_acc_sum'], 'detection_score_mult': results['det_mult'], 'segmentation_score_mult': results['seg_mult'], 'balanced_accuracy_score_mult': results['bal_acc_mult']}\n",
-     "\n",
-     "    "
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "17d53d96",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Infer functions\n",
-     "def PositionClassifier_infer(c, enc, batch):\n",
-     "    x1s, x2s, ys = batch\n",
-     "    h1 = enc(x1s)\n",
-     "    h2 = enc(x2s)\n",
-     "    logits = c(h1, h2)\n",
-     "    loss = xent(logits, ys)\n",
-     "    return loss\n",
-     "\n",
-     "def SVDD_Dataset_infer(enc, batch):\n",
-     "    x1s, x2s, = batch\n",
-     "    h1s = enc(x1s)\n",
-     "    h2s = enc(x2s)\n",
-     "    diff = h1s - h2s\n",
-     "    l2 = diff.norm(dim=1)\n",
-     "    loss = l2.mean()\n",
-     "    return loss\n",
-     "\n",
-     "def infer_(x, enc, K, S, device):\n",
-     "    dataset = PatchDataset_NCHW(x, K=K, S=S)\n",
-     "    loader = DataLoader(dataset, batch_size=64, shuffle=False, pin_memory=True)\n",
-     "    embs = np.empty((dataset.N, dataset.row_num, dataset.col_num, args['D']), dtype=np.float32)  # [-1, I, J, D]\n",
-     "    enc = enc.eval()\n",
-     "    with torch.no_grad():\n",
-     "        for xs, ns, iis, js in loader:\n",
-     "            xs = xs.to(device)\n",
-     "            embedding = enc(xs)\n",
-     "            embedding = embedding.detach().cpu().numpy()\n",
-     "\n",
-     "            for embed, n, i, j in zip(embedding, ns, iis, js):\n",
-     "                embs[n, i, j] = np.squeeze(embed)\n",
-     "    return embs"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "derived-bride",
-    "metadata": {},
-    "source": [
-     "## Time to start a federated learning experiment"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "mature-renewal",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# create an experimnet in federation\n",
-     "experiment_name = 'MVTec_test_experiment'\n",
-     "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "lightweight-causing",
-    "metadata": {
-     "scrolled": true
-    },
-    "outputs": [],
-    "source": [
-     "# If I use autoreload I got a pickling error\n",
-     "\n",
-     "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
-     "fl_experiment.start(model_provider=MI, \n",
-     "                    task_keeper=TI,\n",
-     "                    data_loader=fed_dataset,\n",
-     "                    rounds_to_train=10,\n",
-     "                    opt_treatment='CONTINUE_GLOBAL',\n",
-     "                    device_assignment_policy='CUDA_PREFERRED')\n"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "f1543a36",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# If user wants to stop IPython session, then reconnect and check how experiment is going \n",
-     "# fl_experiment.restore_experiment_state(MI)\n",
-     "\n",
-     "fl_experiment.stream_metrics()"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "8c30b301",
-    "metadata": {},
-    "source": [
-     "## Now we validate the best model and print anomaly maps!"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "12186086",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "!pip install -r ../envoy/sd_requirements.txt\n",
-     "import sys\n",
-     "sys.path.insert(1, '../envoy')\n",
-     "from mvtec_shard_descriptor import MVTecShardDescriptor\n",
-     "from inspection import measure_emb_nn, eval_embeddings_nn_maps\n",
-     "import matplotlib.pyplot as plt\n",
-     "from PIL import Image\n",
-     "from skimage.segmentation import mark_boundaries\n",
-     "from utils import makedirpath, distribute_scores\n",
-     "import pickle"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "439049e1",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "def obtain_maps(model, val_loader, device):\n",
-     "    print(f'\\n\\n OBTAIN MAPS GOT DEVICE {device}\\n\\n')\n",
-     "    \n",
-     "    model._enc.eval()\n",
-     "    model._enc.to(device)\n",
-     "    \n",
-     "    x_tr, x_te, masks, labels, mean = val_loader\n",
-     "\n",
-     "    embs64_tr = infer_(x_tr, model._enc, K=64, S=16, device=device)\n",
-     "    embs64_te = infer_(x_te, model._enc, K=64, S=16, device=device)\n",
-     "    embs32_tr = infer_(x_tr, model._enc.enc, K=32, S=4, device=device)\n",
-     "    embs32_te = infer_(x_te, model._enc.enc, K=32, S=4, device=device)\n",
-     "\n",
-     "    embs64 = embs64_tr, embs64_te\n",
-     "    embs32 = embs32_tr, embs32_te\n",
-     "\n",
-     "    maps = eval_embeddings_nn_maps(args['obj'], embs64, embs32, masks, labels)    \n",
-     "    print_anomaly_maps(args['obj'], maps, x_te, masks, mean)\n",
-     "    \n",
-     "\n",
-     "def infer_(x, enc, K, S, device):\n",
-     "    dataset = PatchDataset_NCHW(x, K=K, S=S)\n",
-     "    loader = DataLoader(dataset, batch_size=64, shuffle=False, pin_memory=True)\n",
-     "    embs = np.empty((dataset.N, dataset.row_num, dataset.col_num, args['D']), dtype=np.float32)  # [-1, I, J, D]\n",
-     "    enc = enc.eval()\n",
-     "    with torch.no_grad():\n",
-     "        for xs, ns, iis, js in loader:\n",
-     "            xs = xs.to(device)\n",
-     "            embedding = enc(xs)\n",
-     "            embedding = embedding.detach().cpu().numpy()\n",
-     "\n",
-     "            for embed, n, i, j in zip(embedding, ns, iis, js):\n",
-     "                embs[n, i, j] = np.squeeze(embed)\n",
-     "    return embs\n",
-     "\n",
-     "def print_anomaly_maps(obj, maps, images, masks, mean):\n",
-     "    \"\"\"Print generated anomaly maps.\"\"\"\n",
-     "    mshape = maps.shape[0]\n",
-     "    images = np.transpose(images, [0, 3, 2, 1])\n",
-     "    images = (images.astype(np.float32) * 255 + mean)\n",
-     "\n",
-     "    for n in range(10):\n",
-     "        fig, axes = plt.subplots(ncols=2)\n",
-     "        fig.set_size_inches(6, 3)\n",
-     "\n",
-     "        shape = (128, 128)\n",
-     "        image = np.array(Image.fromarray((images[n] * 255).astype(np.uint8)).resize(shape[::-1]))\n",
-     "        mask = np.array(Image.fromarray(masks[n]).resize(shape[::-1]))\n",
-     "        image = mark_boundaries(image, mask, color=(1, 0, 0), mode='thick')\n",
-     "\n",
-     "        axes[0].imshow(image)\n",
-     "        axes[0].set_axis_off()\n",
-     "\n",
-     "        axes[1].imshow(maps[n], vmax=maps[n].max(), cmap='Reds')\n",
-     "        axes[1].set_axis_off()\n",
-     "\n",
-     "        plt.tight_layout()\n",
-     "        plt.show()\n",
-     "        plt.close()"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "52ba543f",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "fed_dataset = MVTecSD(train_bs=64, val_bs=64)\n",
-     "fed_dataset.shard_descriptor = MVTecShardDescriptor(obj=args['obj'], data_folder='MVTec_data',rank_worldsize='1,1')\n",
-     "\n",
-     "last_model = fl_experiment.get_last_model()\n",
-     "obtain_maps(last_model, fed_dataset.get_valid_loader(), 'cuda')"
-    ]
-   }
-  ],
-  "metadata": {
-   "kernelspec": {
-    "display_name": "Python 3 (ipykernel)",
-    "language": "python",
-    "name": "python3"
-   },
-   "language_info": {
-    "codemirror_mode": {
-     "name": "ipython",
-     "version": 3
-    },
-    "file_extension": ".py",
-    "mimetype": "text/x-python",
-    "name": "python",
-    "nbconvert_exporter": "python",
-    "pygments_lexer": "ipython3",
-    "version": "3.8.5"
-   }
-  },
-  "nbformat": 4,
-  "nbformat_minor": 5
- }
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/workspace/utils.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/workspace/utils.py
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/workspace/utils.py	2022-11-18 11:06:29.739187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_MVTec_PatchSVDD/workspace/utils.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,133 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Utilities."""
- 
- import os
- from contextlib import contextmanager
- 
- import _pickle as p
- import numpy as np
- import torch
- from torch.utils.data import Dataset
- 
- 
- def to_device(obj, device, non_blocking=False):
-     """Copy to device."""
-     if isinstance(obj, torch.Tensor):
-         return obj.to(device, non_blocking=non_blocking)
- 
-     if isinstance(obj, dict):
-         return {k: to_device(v, device, non_blocking=non_blocking)
-                 for k, v in obj.items()}
- 
-     if isinstance(obj, list):
-         return [to_device(v, device, non_blocking=non_blocking)
-                 for v in obj]
- 
-     if isinstance(obj, tuple):
-         return tuple([to_device(v, device, non_blocking=non_blocking)
-                      for v in obj])
- 
- 
- @contextmanager
- def task(_):
-     """Yield."""
-     yield
- 
- 
- class DictionaryConcatDataset(Dataset):
-     """Concate dictionaries."""
- 
-     def __init__(self, d_of_datasets):
-         """Initialize."""
-         self.d_of_datasets = d_of_datasets
-         lengths = [len(d) for d in d_of_datasets.values()]
-         self._length = min(lengths)
-         self.keys = self.d_of_datasets.keys()
-         assert min(lengths) == max(lengths), 'Length of the datasets should be the same'
- 
-     def __getitem__(self, idx):
-         """Get item."""
-         return {
-             key: self.d_of_datasets[key][idx]
-             for key in self.keys
-         }
- 
-     def __len__(self):
-         """Get length."""
-         return self._length
- 
- 
- def crop_chw(image, i, j, k, s=1):
-     """Crop func."""
-     if s == 1:
-         h, w = i, j
-     else:
-         h = s * i
-         w = s * j
-     return image[:, h: h + k, w: w + k]
- 
- 
- def cnn_output_size(h, k, s=1, p=0) -> int:
-     """Output size.
- 
-     :param int H: input_size
-     :param int K: filter_size
-     :param int S: stride
-     :param int P: padding
-     :return:.
- 
-     """
-     return 1 + (h - k + 2 * p) // s
- 
- 
- def crop_image_chw(image, coord, k):
-     """Crop func."""
-     h, w = coord
-     return image[:, h: h + k, w: w + k]
- 
- 
- def load_binary(fpath, encoding='ASCII'):
-     """Load binaries."""
-     with open(fpath, 'rb') as f:
-         return p.load(f, encoding=encoding)
- 
- 
- def save_binary(d, fpath):
-     """Save binary."""
-     with open(fpath, 'wb') as f:
-         p.dump(d, f)
- 
- 
- def makedirpath(fpath: str):
-     """Make path."""
-     dpath = os.path.dirname(fpath)
-     if dpath:
-         os.makedirs(dpath, exist_ok=True)
- 
- 
- def distribute_scores(score_masks, output_shape, k: int, s: int) -> np.ndarray:
-     """Distribute scores."""
-     n_all = score_masks.shape[0]
-     results = [distribute_score(score_masks[n], output_shape, k, s) for n in range(n_all)]
-     return np.asarray(results)
- 
- 
- def distribute_score(score_mask, output_shape, k: int, s: int) -> np.ndarray:
-     """Distribute scores."""
-     h, w = output_shape
-     mask = np.zeros([h, w], dtype=np.float32)
-     cnt = np.zeros([h, w], dtype=np.int32)
- 
-     i, j = score_mask.shape[:2]
-     for i_ in range(i):
-         for j_ in range(j):
-             h_, w_ = i_ * s, j_ * s
- 
-             mask[h_: h_ + k, w_: w_ + k] += score_mask[i_, j_]
-             cnt[h_: h_ + k, w_: w_ + k] += 1
- 
-     cnt[cnt == 0] = 1
- 
-     return mask / cnt
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/director/director_config.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/director/director_config.yaml
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/director/director_config.yaml	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/director/director_config.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,5 ****
- settings:
-   listen_host: localhost
-   listen_port: 50051
-   sample_shape: ['64', '64', '3']
-   target_shape: ['64', '64']
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/director/start_director.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/director/start_director.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/director/start_director.sh	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/director/start_director.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- 
- fx director start --disable-tls -c director_config.yaml
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/director/start_director_with_tls.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/director/start_director_with_tls.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/director/start_director_with_tls.sh	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/director/start_director_with_tls.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- FQDN=$1
- fx director start -c director_config.yaml -rc cert/root_ca.crt -pk cert/"${FQDN}".key -oc cert/"${FQDN}".crt
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/envoy/envoy_config.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/envoy/envoy_config.yaml
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/envoy/envoy_config.yaml	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/envoy/envoy_config.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,10 ****
- params:
-   cuda_devices: []
- 
- optional_plugin_components: {}
- 
- shard_descriptor:
-   template: tinyimagenet_shard_descriptor.TinyImageNetShardDescriptor
-   params:
-     data_folder: tinyimagenet_data
-     rank_worldsize: 1,1
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/envoy/requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/envoy/requirements.txt
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/envoy/requirements.txt	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/envoy/requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1 ****
- Pillow==8.3.2
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/envoy/start_envoy.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/envoy/start_envoy.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/envoy/start_envoy.sh	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/envoy/start_envoy.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- 
- fx envoy start -n env_one --disable-tls --envoy-config-path envoy_config.yaml -dh localhost -dp 50051
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/envoy/start_envoy_with_tls.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/envoy/start_envoy_with_tls.sh
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/envoy/start_envoy_with_tls.sh	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/envoy/start_envoy_with_tls.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,6 ****
- #!/bin/bash
- set -e
- ENVOY_NAME=$1
- DIRECTOR_FQDN=$2
- 
- fx envoy start -n "$ENVOY_NAME" --envoy-config-path envoy_config.yaml -dh "$DIRECTOR_FQDN" -dp 50051 -rc cert/root_ca.crt -pk cert/"$ENVOY_NAME".key -oc cert/"$ENVOY_NAME".crt
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/envoy/tinyimagenet_shard_descriptor.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/envoy/tinyimagenet_shard_descriptor.py
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/envoy/tinyimagenet_shard_descriptor.py	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/envoy/tinyimagenet_shard_descriptor.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,118 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """TinyImageNet Shard Descriptor."""
- 
- import glob
- import logging
- import os
- import shutil
- from pathlib import Path
- from typing import Tuple
- 
- from PIL import Image
- 
- from openfl.interface.interactive_api.shard_descriptor import ShardDataset
- from openfl.interface.interactive_api.shard_descriptor import ShardDescriptor
- 
- logger = logging.getLogger(__name__)
- 
- 
- class TinyImageNetDataset(ShardDataset):
-     """TinyImageNet shard dataset class."""
- 
-     NUM_IMAGES_PER_CLASS = 500
- 
-     def __init__(self, data_folder: Path, data_type='train', rank=1, worldsize=1):
-         """Initialize TinyImageNetDataset."""
-         self.data_type = data_type
-         self._common_data_folder = data_folder
-         self._data_folder = os.path.join(data_folder, data_type)
-         self.labels = {}  # fname - label number mapping
-         self.image_paths = sorted(
-             glob.iglob(
-                 os.path.join(self._data_folder, '**', '*.JPEG'),
-                 recursive=True
-             )
-         )[rank - 1::worldsize]
-         with open(os.path.join(self._common_data_folder, 'wnids.txt'), 'r') as fp:
-             self.label_texts = sorted([text.strip() for text in fp.readlines()])
-         self.label_text_to_number = {text: i for i, text in enumerate(self.label_texts)}
-         self.fill_labels()
- 
-     def __len__(self) -> int:
-         """Return the len of the shard dataset."""
-         return len(self.image_paths)
- 
-     def __getitem__(self, index: int) -> Tuple['Image', int]:
-         """Return an item by the index."""
-         file_path = self.image_paths[index]
-         label = self.labels[os.path.basename(file_path)]
-         return self.read_image(file_path), label
- 
-     def read_image(self, path: Path) -> Image:
-         """Read the image."""
-         img = Image.open(path)
-         return img
- 
-     def fill_labels(self) -> None:
-         """Fill labels."""
-         if self.data_type == 'train':
-             for label_text, i in self.label_text_to_number.items():
-                 for cnt in range(self.NUM_IMAGES_PER_CLASS):
-                     self.labels[f'{label_text}_{cnt}.JPEG'] = i
-         elif self.data_type == 'val':
-             with open(os.path.join(self._data_folder, 'val_annotations.txt'), 'r') as fp:
-                 for line in fp.readlines():
-                     terms = line.split('\t')
-                     file_name, label_text = terms[0], terms[1]
-                     self.labels[file_name] = self.label_text_to_number[label_text]
- 
- 
- class TinyImageNetShardDescriptor(ShardDescriptor):
-     """Shard descriptor class."""
- 
-     def __init__(
-             self,
-             data_folder: str = 'data',
-             rank_worldsize: str = '1,1',
-             **kwargs
-     ):
-         """Initialize TinyImageNetShardDescriptor."""
-         self.common_data_folder = Path.cwd() / data_folder
-         self.data_folder = Path.cwd() / data_folder / 'tiny-imagenet-200'
-         self.download_data()
-         self.rank, self.worldsize = tuple(int(num) for num in rank_worldsize.split(','))
- 
-     def download_data(self):
-         """Download prepared shard dataset."""
-         zip_file_path = self.common_data_folder / 'tiny-imagenet-200.zip'
-         os.makedirs(self.common_data_folder, exist_ok=True)
-         os.system(f'wget --no-clobber http://cs231n.stanford.edu/tiny-imagenet-200.zip'
-                   f' -O {zip_file_path}')
-         shutil.unpack_archive(str(zip_file_path), str(self.common_data_folder))
- 
-     def get_dataset(self, dataset_type):
-         """Return a shard dataset by type."""
-         return TinyImageNetDataset(
-             data_folder=self.data_folder,
-             data_type=dataset_type,
-             rank=self.rank,
-             worldsize=self.worldsize
-         )
- 
-     @property
-     def sample_shape(self):
-         """Return the sample shape info."""
-         return ['64', '64', '3']
- 
-     @property
-     def target_shape(self):
-         """Return the target shape info."""
-         return ['64', '64']
- 
-     @property
-     def dataset_description(self) -> str:
-         """Return the shard dataset description."""
-         return (f'TinyImageNetDataset dataset, shard number {self.rank}'
-                 f' out of {self.worldsize}')
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/workspace/non-federated_case.ipynb ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/workspace/non-federated_case.ipynb
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/workspace/non-federated_case.ipynb	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/workspace/non-federated_case.ipynb	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,305 ****
- {
-  "cells": [
-   {
-    "cell_type": "markdown",
-    "source": [
-     "## Vanilla PyTorch training on TinyImageNet dataset"
-    ],
-    "metadata": {}
-   },
-   {
-    "cell_type": "markdown",
-    "source": [
-     "This notebook is intended to show that fixing random seeds leads to the same result in both federated and non-federated cases."
-    ],
-    "metadata": {}
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "source": [
-     "!pip install -r requirements.txt"
-    ],
-    "outputs": [],
-    "metadata": {}
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "source": [
-     "from pathlib import Path\n",
-     "import os\n",
-     "import shutil\n",
-     "from torch.utils.data import Dataset\n",
-     "from torch.utils.data import DataLoader\n",
-     "from torch import nn\n",
-     "from torch import optim\n",
-     "import torch.nn.functional as F\n",
-     "import torch\n",
-     "import torchvision.transforms as T\n",
-     "import torchvision\n",
-     "import glob\n",
-     "import tqdm\n",
-     "from PIL import Image\n",
-     "import numpy as np"
-    ],
-    "outputs": [],
-    "metadata": {}
-   },
-   {
-    "cell_type": "markdown",
-    "source": [
-     "## Download data"
-    ],
-    "metadata": {}
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "source": [
-     "common_data_folder = Path.cwd() / 'data'\n",
-     "zip_file_path = common_data_folder / 'tiny-imagenet-200.zip'\n",
-     "os.makedirs(common_data_folder, exist_ok=True)\n",
-     "os.system(f'wget --no-clobber http://cs231n.stanford.edu/tiny-imagenet-200.zip'\n",
-     "          f' -O {zip_file_path}')\n",
-     "shutil.unpack_archive(str(zip_file_path), str(common_data_folder))"
-    ],
-    "outputs": [],
-    "metadata": {}
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "source": [
-     "class TinyImageNetDataset(Dataset):\n",
-     "    \"\"\"TinyImageNet shard dataset class.\"\"\"\n",
-     "\n",
-     "    NUM_IMAGES_PER_CLASS = 500\n",
-     "\n",
-     "    def __init__(self, data_folder: Path, data_type='train', transform=None):\n",
-     "        \"\"\"Initialize TinyImageNetDataset.\"\"\"\n",
-     "        self.data_type = data_type\n",
-     "        self._common_data_folder = data_folder\n",
-     "        self._data_folder = os.path.join(data_folder, data_type)\n",
-     "        self.labels = {}  # fname - label number mapping\n",
-     "        self.image_paths = sorted(\n",
-     "            glob.iglob(\n",
-     "                os.path.join(self._data_folder, '**', '*.JPEG'),\n",
-     "                recursive=True\n",
-     "            )\n",
-     "        )\n",
-     "        with open(os.path.join(self._common_data_folder, 'wnids.txt'), 'r') as fp:\n",
-     "            self.label_texts = sorted([text.strip() for text in fp.readlines()])\n",
-     "        self.label_text_to_number = {text: i for i, text in enumerate(self.label_texts)}\n",
-     "        self.fill_labels()\n",
-     "        self.transform = transform\n",
-     "\n",
-     "    def __len__(self) -> int:\n",
-     "        \"\"\"Return the len of the shard dataset.\"\"\"\n",
-     "        return len(self.image_paths)\n",
-     "\n",
-     "    def __getitem__(self, index: int):\n",
-     "        \"\"\"Return an item by the index.\"\"\"\n",
-     "        file_path = self.image_paths[index]\n",
-     "        sample = self.read_image(file_path)\n",
-     "        if self.transform:\n",
-     "            sample = self.transform(sample)\n",
-     "        label = self.labels[os.path.basename(file_path)]\n",
-     "        return sample, label\n",
-     "\n",
-     "    def read_image(self, path: Path):\n",
-     "        \"\"\"Read the image.\"\"\"\n",
-     "        img = Image.open(path)\n",
-     "        return img\n",
-     "\n",
-     "    def fill_labels(self) -> None:\n",
-     "        \"\"\"Fill labels.\"\"\"\n",
-     "        if self.data_type == 'train':\n",
-     "            for label_text, i in self.label_text_to_number.items():\n",
-     "                for cnt in range(self.NUM_IMAGES_PER_CLASS):\n",
-     "                    self.labels[f'{label_text}_{cnt}.JPEG'] = i\n",
-     "        elif self.data_type == 'val':\n",
-     "            with open(os.path.join(self._data_folder, 'val_annotations.txt'), 'r') as fp:\n",
-     "                for line in fp.readlines():\n",
-     "                    terms = line.split('\\t')\n",
-     "                    file_name, label_text = terms[0], terms[1]\n",
-     "                    self.labels[file_name] = self.label_text_to_number[label_text]"
-    ],
-    "outputs": [],
-    "metadata": {}
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "source": [
-     "normalize = T.Normalize(\n",
-     "    mean=[0.485, 0.456, 0.406],\n",
-     "    std=[0.229, 0.224, 0.225]\n",
-     ")\n",
-     "\n",
-     "augmentation = T.RandomApply(\n",
-     "    [T.RandomHorizontalFlip(),\n",
-     "     T.RandomRotation(10),\n",
-     "     T.RandomResizedCrop(64)], \n",
-     "    p=.8\n",
-     ")\n",
-     "\n",
-     "training_transform = T.Compose(\n",
-     "    [T.Lambda(lambda x: x.convert(\"RGB\")),\n",
-     "     T.ToTensor(),\n",
-     "     augmentation,\n",
-     "     normalize]\n",
-     ")\n",
-     "\n",
-     "valid_transform = T.Compose(\n",
-     "    [T.Lambda(lambda x: x.convert(\"RGB\")),\n",
-     "     T.ToTensor(),\n",
-     "     normalize]\n",
-     ")"
-    ],
-    "outputs": [],
-    "metadata": {}
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "dense-commerce",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "def get_train_loader():\n",
-     "    generator=torch.Generator()\n",
-     "    generator.manual_seed(0)\n",
-     "    train_set = TinyImageNetDataset(common_data_folder / 'tiny-imagenet-200', transform=training_transform)\n",
-     "    return DataLoader(train_set, batch_size=64, shuffle=True, generator=generator)\n",
-     "\n",
-     "def get_valid_loader():\n",
-     "    valid_set = TinyImageNetDataset(common_data_folder / 'tiny-imagenet-200', data_type='val', transform=valid_transform)\n",
-     "    return DataLoader(valid_set, batch_size=64)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "source": [
-     "## Describe the model and optimizer"
-    ],
-    "metadata": {}
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "source": [
-     "class Net(nn.Module):\n",
-     "    def __init__(self):\n",
-     "        torch.manual_seed(0)\n",
-     "        super(Net, self).__init__()\n",
-     "        self.model = torchvision.models.mobilenet_v2(pretrained=True)\n",
-     "        self.model.requires_grad_(False)\n",
-     "        self.model.classifier[1] = torch.nn.Linear(in_features=1280, \\\n",
-     "                        out_features=200, bias=True)\n",
-     "\n",
-     "    def forward(self, x):\n",
-     "        x = self.model.forward(x)\n",
-     "        return x\n",
-     "\n",
-     "model = Net()"
-    ],
-    "outputs": [],
-    "metadata": {}
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "source": [
-     "optimizer = optim.Adam([x for x in model.parameters() if x.requires_grad], lr=1e-4)"
-    ],
-    "outputs": [],
-    "metadata": {}
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "source": [
-     "loss_fn = F.cross_entropy"
-    ],
-    "outputs": [],
-    "metadata": {}
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "source": [
-     "def train():\n",
-     "    torch.manual_seed(0)\n",
-     "    device='cpu'\n",
-     "    \n",
-     "    data_loader = tqdm.tqdm(get_train_loader(), desc=\"train\")\n",
-     "    model.train()\n",
-     "    model.to(device)\n",
-     "\n",
-     "    losses = []\n",
-     "\n",
-     "    for data, target in data_loader:\n",
-     "        data, target = torch.tensor(data).to(device), torch.tensor(\n",
-     "            target).to(device)\n",
-     "        optimizer.zero_grad()\n",
-     "        output = model(data)\n",
-     "        loss = loss_fn(output, target)\n",
-     "        loss.backward()\n",
-     "        optimizer.step()\n",
-     "        losses.append(loss.detach().cpu().numpy())\n",
-     "        \n",
-     "    return {'train_loss': np.mean(losses),}\n",
-     "\n",
-     "def validate():\n",
-     "    torch.manual_seed(0)\n",
-     "    device = torch.device('cpu')\n",
-     "    model.eval()\n",
-     "    model.to(device)\n",
-     "    \n",
-     "    data_loader = tqdm.tqdm(get_valid_loader(), desc=\"validate\")\n",
-     "    val_score = 0\n",
-     "    total_samples = 0\n",
-     "\n",
-     "    with torch.no_grad():\n",
-     "        for data, target in data_loader:\n",
-     "            samples = target.shape[0]\n",
-     "            total_samples += samples\n",
-     "            data, target = torch.tensor(data).to(device), \\\n",
-     "                torch.tensor(target).to(device, dtype=torch.int64)\n",
-     "            output = model(data)\n",
-     "            pred = output.argmax(dim=1,keepdim=True)\n",
-     "            val_score += pred.eq(target).sum().cpu().numpy()\n",
-     "            \n",
-     "    return {'acc': val_score / total_samples,}"
-    ],
-    "outputs": [],
-    "metadata": {}
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "source": [
-     "for i in range(5):\n",
-     "    if i == 0:\n",
-     "        name, value = next(iter(validate().items()))\n",
-     "        print(f'{name}: {value:f}')\n",
-     "    \n",
-     "    name, value = next(iter(train().items()))\n",
-     "    print(f'{name}: {value:f}')\n",
-     "    \n",
-     "    name, value = next(iter(validate().items()))\n",
-     "    print(f'{name}: {value:f}')"
-    ],
-    "outputs": [],
-    "metadata": {}
-   }
-  ],
-  "metadata": {
-   "language_info": {
-    "name": "python"
-   }
-  },
-  "nbformat": 4,
-  "nbformat_minor": 5
- }
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/workspace/pytorch_tinyimagenet.ipynb ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/workspace/pytorch_tinyimagenet.ipynb
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/workspace/pytorch_tinyimagenet.ipynb	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/workspace/pytorch_tinyimagenet.ipynb	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,483 ****
- {
-  "cells": [
-   {
-    "cell_type": "markdown",
-    "id": "26fdd9ed",
-    "metadata": {},
-    "source": [
-     "# Federated PyTorch TinyImageNet Tutorial"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "895288d0",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "!pip install -r requirements.txt"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "billion-drunk",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import os\n",
-     "import glob\n",
-     "\n",
-     "from PIL import Image\n",
-     "\n",
-     "import numpy as np\n",
-     "import torch\n",
-     "import torch.nn as nn\n",
-     "import torch.nn.functional as F\n",
-     "import torch.optim as optim\n",
-     "from openfl.interface.interactive_api.federation import Federation\n",
-     "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment\n",
-     "from copy import deepcopy\n",
-     "import torchvision\n",
-     "from torchvision import transforms as T\n",
-     "from torch.utils.data import Dataset\n",
-     "from torch.utils.data import DataLoader\n",
-     "import tqdm\n",
-     "\n",
-     "torch.manual_seed(0)\n",
-     "np.random.seed(0)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "246f9c98",
-    "metadata": {},
-    "source": [
-     "## Connect to the Federation"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "d657e463",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Create a federation\n",
-     "\n",
-     "# please use the same identificator that was used in signed certificate\n",
-     "client_id = 'api'\n",
-     "cert_dir = 'cert'\n",
-     "director_node_fqdn = 'localhost'\n",
-     "# 1) Run with API layer - Director mTLS \n",
-     "# If the user wants to enable mTLS their must provide CA root chain, and signed key pair to the federation interface\n",
-     "# cert_chain = f'{cert_dir}/root_ca.crt'\n",
-     "# api_certificate = f'{cert_dir}/{client_id}.crt'\n",
-     "# api_private_key = f'{cert_dir}/{client_id}.key'\n",
-     "\n",
-     "# federation = Federation(client_id=client_id, director_node_fqdn=director_node_fqdn, director_port='50051',\n",
-     "#                        cert_chain=cert_chain, api_cert=api_certificate, api_private_key=api_private_key)\n",
-     "\n",
-     "# --------------------------------------------------------------------------------------------------------------------\n",
-     "\n",
-     "# 2) Run with TLS disabled (trusted environment)\n",
-     "# Federation can also determine local fqdn automatically\n",
-     "federation = Federation(client_id=client_id, director_node_fqdn=director_node_fqdn, director_port='50051', tls=False)\n"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "1abebd90",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "federation.target_shape"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "47dcfab3",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "shard_registry = federation.get_shard_registry()\n",
-     "shard_registry"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "a2a6c237",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# First, request a dummy_shard_desc that holds information about the federated dataset \n",
-     "dummy_shard_desc = federation.get_dummy_shard_descriptor(size=10)\n",
-     "dummy_shard_dataset = dummy_shard_desc.get_dataset('train')\n",
-     "sample, target = dummy_shard_dataset[0]\n",
-     "print(sample.shape)\n",
-     "print(target.shape)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "cc0dbdbd",
-    "metadata": {},
-    "source": [
-     "## Creating a FL experiment using Interactive API"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "b0979470",
-    "metadata": {},
-    "source": [
-     "### Register dataset"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "7dda1680",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "normalize = T.Normalize(\n",
-     "    mean=[0.485, 0.456, 0.406],\n",
-     "    std=[0.229, 0.224, 0.225]\n",
-     ")\n",
-     "\n",
-     "augmentation = T.RandomApply(\n",
-     "    [T.RandomHorizontalFlip(),\n",
-     "     T.RandomRotation(10),\n",
-     "     T.RandomResizedCrop(64)], \n",
-     "    p=.8\n",
-     ")\n",
-     "\n",
-     "training_transform = T.Compose(\n",
-     "    [T.Lambda(lambda x: x.convert(\"RGB\")),\n",
-     "     T.ToTensor(),\n",
-     "     augmentation,\n",
-     "     normalize]\n",
-     ")\n",
-     "\n",
-     "valid_transform = T.Compose(\n",
-     "    [T.Lambda(lambda x: x.convert(\"RGB\")),\n",
-     "     T.ToTensor(),\n",
-     "     normalize]\n",
-     ")\n"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "0314d5bf",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "class TransformedDataset(Dataset):\n",
-     "    \"\"\"Image Person ReID Dataset.\"\"\"\n",
-     "\n",
-     "    def __init__(self, dataset, transform=None, target_transform=None):\n",
-     "        \"\"\"Initialize Dataset.\"\"\"\n",
-     "        self.dataset = dataset\n",
-     "        self.transform = transform\n",
-     "        self.target_transform = target_transform\n",
-     "\n",
-     "    def __len__(self):\n",
-     "        \"\"\"Length of dataset.\"\"\"\n",
-     "        return len(self.dataset)\n",
-     "\n",
-     "    def __getitem__(self, index):\n",
-     "        img, label = self.dataset[index]\n",
-     "        label = self.target_transform(label) if self.target_transform else label\n",
-     "        img = self.transform(img) if self.transform else img\n",
-     "        return img, label\n"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "01369e3b",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "class TinyImageNetDataset(DataInterface):\n",
-     "    def __init__(self, **kwargs):\n",
-     "        self.kwargs = kwargs\n",
-     "    \n",
-     "    @property\n",
-     "    def shard_descriptor(self):\n",
-     "        return self._shard_descriptor\n",
-     "        \n",
-     "    @shard_descriptor.setter\n",
-     "    def shard_descriptor(self, shard_descriptor):\n",
-     "        \"\"\"\n",
-     "        Describe per-collaborator procedures or sharding.\n",
-     "\n",
-     "        This method will be called during a collaborator initialization.\n",
-     "        Local shard_descriptor  will be set by Envoy.\n",
-     "        \"\"\"\n",
-     "        self._shard_descriptor = shard_descriptor\n",
-     "        \n",
-     "        self.train_set = TransformedDataset(\n",
-     "            self._shard_descriptor.get_dataset('train'),\n",
-     "            transform=training_transform\n",
-     "        )\n",
-     "        self.valid_set = TransformedDataset(\n",
-     "            self._shard_descriptor.get_dataset('val'),\n",
-     "            transform=valid_transform\n",
-     "        )\n",
-     "        \n",
-     "    def get_train_loader(self, **kwargs):\n",
-     "        \"\"\"\n",
-     "        Output of this method will be provided to tasks with optimizer in contract\n",
-     "        \"\"\"\n",
-     "        generator=torch.Generator()\n",
-     "        generator.manual_seed(0)\n",
-     "        return DataLoader(\n",
-     "            self.train_set, batch_size=self.kwargs['train_bs'], shuffle=True, generator=generator\n",
-     "            )\n",
-     "\n",
-     "    def get_valid_loader(self, **kwargs):\n",
-     "        \"\"\"\n",
-     "        Output of this method will be provided to tasks without optimizer in contract\n",
-     "        \"\"\"\n",
-     "        return DataLoader(self.valid_set, batch_size=self.kwargs['valid_bs'])\n",
-     "\n",
-     "    def get_train_data_size(self):\n",
-     "        \"\"\"\n",
-     "        Information for aggregation\n",
-     "        \"\"\"\n",
-     "        return len(self.train_set)\n",
-     "\n",
-     "    def get_valid_data_size(self):\n",
-     "        \"\"\"\n",
-     "        Information for aggregation\n",
-     "        \"\"\"\n",
-     "        return len(self.valid_set)\n",
-     "    "
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "4a6cedef",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "fed_dataset = TinyImageNetDataset(train_bs=64, valid_bs=64)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "74cac654",
-    "metadata": {},
-    "source": [
-     "### Describe the model and optimizer"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "43e25fe3",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "\"\"\"\n",
-     "MobileNetV2 model\n",
-     "\"\"\"\n",
-     "\n",
-     "class Net(nn.Module):\n",
-     "    def __init__(self):\n",
-     "        torch.manual_seed(0)\n",
-     "        super(Net, self).__init__()\n",
-     "        self.model = torchvision.models.mobilenet_v2(pretrained=True)\n",
-     "        self.model.requires_grad_(False)\n",
-     "        self.model.classifier[1] = torch.nn.Linear(in_features=1280, \\\n",
-     "                        out_features=200, bias=True)\n",
-     "\n",
-     "    def forward(self, x):\n",
-     "        x = self.model.forward(x)\n",
-     "        return x\n",
-     "\n",
-     "model_net = Net()"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "79021778",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "params_to_update = []\n",
-     "for param in model_net.parameters():\n",
-     "    if param.requires_grad == True:\n",
-     "        params_to_update.append(param)\n",
-     "        \n",
-     "optimizer_adam = optim.Adam(params_to_update, lr=1e-4)\n",
-     "\n",
-     "def cross_entropy(output, target):\n",
-     "    \"\"\"Binary cross-entropy metric\n",
-     "    \"\"\"\n",
-     "    return F.cross_entropy(input=output,target=target)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "f097cdc5",
-    "metadata": {},
-    "source": [
-     "### Register model"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "06a8cca8",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "framework_adapter = 'openfl.plugins.frameworks_adapters.pytorch_adapter.FrameworkAdapterPlugin'\n",
-     "model_interface = ModelInterface(model=model_net, optimizer=optimizer_adam, framework_plugin=framework_adapter)\n",
-     "\n",
-     "# Save the initial model state\n",
-     "initial_model = deepcopy(model_net)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "849c165b",
-    "metadata": {},
-    "source": [
-     "## Define and register FL tasks"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "b9649385",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "task_interface = TaskInterface()\n",
-     "\n",
-     "\n",
-     "# The Interactive API supports registering functions definied in main module or imported.\n",
-     "def function_defined_in_notebook(some_parameter):\n",
-     "    print(f'Also I accept a parameter and it is {some_parameter}')\n",
-     "\n",
-     "# Task interface currently supports only standalone functions.\n",
-     "@task_interface.add_kwargs(**{'some_parameter': 42})\n",
-     "@task_interface.register_fl_task(model='net_model', data_loader='train_loader', \\\n",
-     "                     device='device', optimizer='optimizer')     \n",
-     "def train(net_model, train_loader, optimizer, device, loss_fn=cross_entropy, some_parameter=None):\n",
-     "    torch.manual_seed(0)\n",
-     "    device='cpu'\n",
-     "    function_defined_in_notebook(some_parameter)\n",
-     "    \n",
-     "    train_loader = tqdm.tqdm(train_loader, desc=\"train\")\n",
-     "    net_model.train()\n",
-     "    net_model.to(device)\n",
-     "\n",
-     "    losses = []\n",
-     "\n",
-     "    for data, target in train_loader:\n",
-     "        data, target = torch.tensor(data).to(device), torch.tensor(\n",
-     "            target).to(device)\n",
-     "        optimizer.zero_grad()\n",
-     "        output = net_model(data)\n",
-     "        loss = loss_fn(output=output, target=target)\n",
-     "        loss.backward()\n",
-     "        optimizer.step()\n",
-     "        losses.append(loss.detach().cpu().numpy())\n",
-     "        \n",
-     "    return {'train_loss': np.mean(losses),}\n",
-     "\n",
-     "\n",
-     "@task_interface.register_fl_task(model='net_model', data_loader='val_loader', device='device')     \n",
-     "def validate(net_model, val_loader, device):\n",
-     "    torch.manual_seed(0)\n",
-     "    device = torch.device('cpu')\n",
-     "    net_model.eval()\n",
-     "    net_model.to(device)\n",
-     "    \n",
-     "    val_loader = tqdm.tqdm(val_loader, desc=\"validate\")\n",
-     "    val_score = 0\n",
-     "    total_samples = 0\n",
-     "\n",
-     "    with torch.no_grad():\n",
-     "        for data, target in val_loader:\n",
-     "            samples = target.shape[0]\n",
-     "            total_samples += samples\n",
-     "            data, target = torch.tensor(data).to(device), \\\n",
-     "                torch.tensor(target).to(device, dtype=torch.int64)\n",
-     "            output = net_model(data)\n",
-     "            pred = output.argmax(dim=1,keepdim=True)\n",
-     "            val_score += pred.eq(target).sum().cpu().numpy()\n",
-     "            \n",
-     "    return {'acc': val_score / total_samples,}"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "8f0ebf2d",
-    "metadata": {},
-    "source": [
-     "## Time to start a federated learning experiment"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "d41b7896",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# create an experimnet in federation\n",
-     "experiment_name = 'tinyimagenet_test_experiment'\n",
-     "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "41b44de9",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
-     "fl_experiment.start(\n",
-     "    model_provider=model_interface, \n",
-     "    task_keeper=task_interface,\n",
-     "    data_loader=fed_dataset,\n",
-     "    rounds_to_train=5,\n",
-     "    opt_treatment='CONTINUE_GLOBAL'\n",
-     ")"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "83edd88f",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# If user want to stop IPython session, then reconnect and check how experiment is going\n",
-     "# fl_experiment.restore_experiment_state(model_interface)\n",
-     "\n",
-     "fl_experiment.stream_metrics(tensorboard_logs=False)"
-    ]
-   }
-  ],
-  "metadata": {
-   "language_info": {
-    "name": "python"
-   }
-  },
-  "nbformat": 4,
-  "nbformat_minor": 5
- }
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/workspace/requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/workspace/requirements.txt
*** ./openfl/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/workspace/requirements.txt	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/PyTorch_TinyImageNet/workspace/requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- torch==1.7.0
- torchvision==0.8.1
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/director/director_config.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/director/director_config.yaml
*** ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/director/director_config.yaml	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/director/director_config.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,5 ****
- settings:
-   listen_host: localhost
-   listen_port: 50051
-   sample_shape: ['784']
-   target_shape: ['1']
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/director/start_director.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/director/start_director.sh
*** ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/director/start_director.sh	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/director/start_director.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- 
- fx director start --disable-tls -c director_config.yaml
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/director/start_director_with_tls.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/director/start_director_with_tls.sh
*** ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/director/start_director_with_tls.sh	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/director/start_director_with_tls.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- FQDN=$1
- fx director start -c director_config.yaml -rc cert/root_ca.crt -pk cert/"${FQDN}".key -oc cert/"${FQDN}".crt
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/envoy_config_one.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/envoy_config_one.yaml
*** ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/envoy_config_one.yaml	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/envoy_config_one.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,9 ****
- params:
-   cuda_devices: []
- 
- optional_plugin_components: {}
- 
- shard_descriptor:
-   template: mnist_shard_descriptor.MnistShardDescriptor
-   params:
-     rank_worldsize: 1, 2
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/envoy_config_two.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/envoy_config_two.yaml
*** ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/envoy_config_two.yaml	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/envoy_config_two.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,9 ****
- params:
-   cuda_devices: []
- 
- optional_plugin_components: {}
- 
- shard_descriptor:
-   template: mnist_shard_descriptor.MnistShardDescriptor
-   params:
-     rank_worldsize: 2, 2
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/mnist_shard_descriptor.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/mnist_shard_descriptor.py
*** ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/mnist_shard_descriptor.py	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/mnist_shard_descriptor.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,102 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Mnist Shard Descriptor."""
- 
- import logging
- import os
- from typing import List
- 
- import numpy as np
- import requests
- 
- from openfl.interface.interactive_api.shard_descriptor import ShardDataset
- from openfl.interface.interactive_api.shard_descriptor import ShardDescriptor
- 
- logger = logging.getLogger(__name__)
- 
- 
- class MnistShardDataset(ShardDataset):
-     """Mnist Shard dataset class."""
- 
-     def __init__(self, x, y, data_type, rank=1, worldsize=1):
-         """Initialize TinyImageNetDataset."""
-         self.data_type = data_type
-         self.rank = rank
-         self.worldsize = worldsize
-         self.x = x[self.rank - 1::self.worldsize]
-         self.y = y[self.rank - 1::self.worldsize]
- 
-     def __getitem__(self, index: int):
-         """Return an item by the index."""
-         return self.x[index], self.y[index]
- 
-     def __len__(self):
-         """Return the len of the dataset."""
-         return len(self.x)
- 
- 
- class MnistShardDescriptor(ShardDescriptor):
-     """Mnist Shard descriptor class."""
- 
-     def __init__(
-             self,
-             rank_worldsize: str = '1, 1',
-             **kwargs
-     ):
-         """Initialize MnistShardDescriptor."""
-         self.rank, self.worldsize = tuple(int(num) for num in rank_worldsize.split(','))
-         (x_train, y_train), (x_test, y_test) = self.download_data()
-         self.data_by_type = {
-             'train': (x_train, y_train),
-             'val': (x_test, y_test)
-         }
- 
-     def get_shard_dataset_types(self) -> List[str]:
-         """Get available shard dataset types."""
-         return list(self.data_by_type)
- 
-     def get_dataset(self, dataset_type='train'):
-         """Return a shard dataset by type."""
-         if dataset_type not in self.data_by_type:
-             raise Exception(f'Wrong dataset type: {dataset_type}')
-         return MnistShardDataset(
-             *self.data_by_type[dataset_type],
-             data_type=dataset_type,
-             rank=self.rank,
-             worldsize=self.worldsize
-         )
- 
-     @property
-     def sample_shape(self):
-         """Return the sample shape info."""
-         return ['784']
- 
-     @property
-     def target_shape(self):
-         """Return the target shape info."""
-         return ['1']
- 
-     @property
-     def dataset_description(self) -> str:
-         """Return the dataset description."""
-         return (f'Mnist dataset, shard number {self.rank}'
-                 f' out of {self.worldsize}')
- 
-     def download_data(self):
-         """Download prepared dataset."""
-         local_file_path = 'mnist.npz'
-         mnist_url = 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz'
-         response = requests.get(mnist_url)
-         with open(local_file_path, 'wb') as f:
-             f.write(response.content)
- 
-         with np.load(local_file_path) as f:
-             x_train, y_train = f['x_train'], f['y_train']
-             x_test, y_test = f['x_test'], f['y_test']
-             x_train = np.reshape(x_train, (-1, 784))
-             x_test = np.reshape(x_test, (-1, 784))
- 
-         os.remove(local_file_path)  # remove mnist.npz
-         print('Mnist data was loaded!')
-         return (x_train, y_train), (x_test, y_test)
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/start_envoy.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/start_envoy.sh
*** ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/start_envoy.sh	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/start_envoy.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,6 ****
- #!/bin/bash
- set -e
- ENVOY_NAME=$1
- ENVOY_CONF=$2
- 
- fx envoy start -n "$ENVOY_NAME" --disable-tls --envoy-config-path "$ENVOY_CONF" -dh localhost -dp 50051
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/start_envoy_with_tls.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/start_envoy_with_tls.sh
*** ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/start_envoy_with_tls.sh	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/envoy/start_envoy_with_tls.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,7 ****
- #!/bin/bash
- set -e
- ENVOY_NAME=$1
- ENVOY_CONF=$2
- DIRECTOR_FQDN=$3
- 
- fx envoy start -n "$ENVOY_NAME" --envoy-config-path "$ENVOY_CONF" -dh "$DIRECTOR_FQDN" -dp 50051 -rc cert/root_ca.crt -pk cert/"$ENVOY_NAME".key -oc cert/"$ENVOY_NAME".crt
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/README.md ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/README.md
*** ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/README.md	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/README.md	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,44 ****
- # MNIST Classification Tutorial
- 
- ![mnist digits](http://i.ytimg.com/vi/0QI3xgXuB-Q/hqdefault.jpg "MNIST Digits")
- 
- ### 1. About dataset
- 
- It is a dataset of 60,000 small square 28×28 pixel grayscale images of handwritten single digits
- between 0 and 9. More info at [wiki](https://en.wikipedia.org/wiki/MNIST_database).
- 
- ### 2. About model
- 
- We use simple fully-connected neural network defined at
- [layers.py](./workspace/layers.py) file.
- 
- ### 3. How to run this tutorial (without TLC and locally as a simulation):
- 
- 1. Run director:
- 
- ```sh
- cd director_folder
- ./start_director.sh
- ```
- 
- 2. Run envoy:
- 
- ```sh
- cd envoy_folder
- ./start_envoy.sh env_one envoy_config_one.yaml
- ```
- 
- Optional: start second envoy:
- 
- - Copy `envoy_folder` to another place and run from there:
- 
- ```sh
- ./start_envoy.sh env_two envoy_config_two.yaml
- ```
- 
- 3. Run `Mnist_Classification_FL.ipybnb` jupyter notebook:
- 
- ```sh
- cd workspace
- jupyter lab Mnist_Classification_FL.ipybnb
- ```
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/workspace/layers.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/workspace/layers.py
*** ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/workspace/layers.py	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/workspace/layers.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,27 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Useful keras functions."""
- from tensorflow import keras
- from tensorflow.keras import layers
- 
- 
- def create_model():
-     """Create keras model."""
-     inputs = keras.Input(shape=(784,), name='digits')
-     x1 = layers.Dense(64, activation='relu')(inputs)
-     x2 = layers.Dense(64, activation='relu')(x1)
-     outputs = layers.Dense(10, name='predictions')(x2)
-     model = keras.Model(inputs=inputs, outputs=outputs)
-     return model
- 
- # Instantiate an optimizer.
- # Instantiate a loss function.
- 
- 
- optimizer = keras.optimizers.SGD(learning_rate=1e-3)
- loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)
- 
- # Prepare the metrics.
- train_acc_metric = keras.metrics.SparseCategoricalAccuracy()
- val_acc_metric = keras.metrics.SparseCategoricalAccuracy()
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/workspace/Tensorflow_MNIST.ipynb ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/workspace/Tensorflow_MNIST.ipynb
*** ./openfl/openfl-tutorials/interactive_api/Tensorflow_MNIST/workspace/Tensorflow_MNIST.ipynb	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_MNIST/workspace/Tensorflow_MNIST.ipynb	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,388 ****
- {
-  "cells": [
-   {
-    "cell_type": "markdown",
-    "id": "26fdd9ed",
-    "metadata": {},
-    "source": [
-     "# Federated Tensorflow Mnist Tutorial"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "d0570122",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Install dependencies if not already installed\n",
-     "!pip install tensorflow==2.3.1"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "246f9c98",
-    "metadata": {},
-    "source": [
-     "## Connect to the Federation"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "d657e463",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Create a federation\n",
-     "from openfl.interface.interactive_api.federation import Federation\n",
-     "\n",
-     "# please use the same identificator that was used in signed certificate\n",
-     "client_id = 'api'\n",
-     "cert_dir = 'cert'\n",
-     "director_node_fqdn = 'localhost'\n",
-     "director_port=50051\n",
-     "# 1) Run with API layer - Director mTLS \n",
-     "# If the user wants to enable mTLS their must provide CA root chain, and signed key pair to the federation interface\n",
-     "# cert_chain = f'{cert_dir}/root_ca.crt'\n",
-     "# api_certificate = f'{cert_dir}/{client_id}.crt'\n",
-     "# api_private_key = f'{cert_dir}/{client_id}.key'\n",
-     "\n",
-     "# federation = Federation(\n",
-     "#     client_id=client_id,\n",
-     "#     director_node_fqdn=director_node_fqdn,\n",
-     "#     director_port=director_port,\n",
-     "#     cert_chain=cert_chain,\n",
-     "#     api_cert=api_certificate,\n",
-     "#     api_private_key=api_private_key\n",
-     "# )\n",
-     "\n",
-     "# --------------------------------------------------------------------------------------------------------------------\n",
-     "\n",
-     "# 2) Run with TLS disabled (trusted environment)\n",
-     "# Federation can also determine local fqdn automatically\n",
-     "federation = Federation(\n",
-     "    client_id=client_id,\n",
-     "    director_node_fqdn=director_node_fqdn,\n",
-     "    director_port=director_port, \n",
-     "    tls=False\n",
-     ")\n"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "47dcfab3",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "shard_registry = federation.get_shard_registry()\n",
-     "shard_registry"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "a2a6c237",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# First, request a dummy_shard_desc that holds information about the federated dataset \n",
-     "dummy_shard_desc = federation.get_dummy_shard_descriptor(size=10)\n",
-     "dummy_shard_dataset = dummy_shard_desc.get_dataset('train')\n",
-     "sample, target = dummy_shard_dataset[0]\n",
-     "f\"Sample shape: {sample.shape}, target shape: {target.shape}\""
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "cc0dbdbd",
-    "metadata": {},
-    "source": [
-     "## Describing FL experimen"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "fc88700a",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "3b468ae1",
-    "metadata": {},
-    "source": [
-     "### Register model"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "06545bbb",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from layers import create_model, optimizer\n",
-     "framework_adapter = 'openfl.plugins.frameworks_adapters.keras_adapter.FrameworkAdapterPlugin'\n",
-     "model = create_model()\n",
-     "MI = ModelInterface(model=model, optimizer=optimizer, framework_plugin=framework_adapter)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "b0979470",
-    "metadata": {},
-    "source": [
-     "### Register dataset"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "d8c9eb50",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import numpy as np\n",
-     "from tensorflow.keras.utils import Sequence\n",
-     "\n",
-     "class DataGenerator(Sequence):\n",
-     "\n",
-     "    def __init__(self, shard_descriptor, batch_size):\n",
-     "        self.shard_descriptor = shard_descriptor\n",
-     "        self.batch_size = batch_size\n",
-     "        self.indices = np.arange(len(shard_descriptor))\n",
-     "        self.on_epoch_end()\n",
-     "\n",
-     "    def __len__(self):\n",
-     "        return len(self.indices) // self.batch_size\n",
-     "\n",
-     "    def __getitem__(self, index):\n",
-     "        index = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
-     "        batch = [self.indices[k] for k in index]\n",
-     "\n",
-     "        X, y = self.shard_descriptor[batch]\n",
-     "        return X, y\n",
-     "\n",
-     "    def on_epoch_end(self):\n",
-     "        np.random.shuffle(self.indices)\n",
-     "\n",
-     "\n",
-     "class MnistFedDataset(DataInterface):\n",
-     "\n",
-     "    def __init__(self, **kwargs):\n",
-     "        super().__init__(**kwargs)\n",
-     "\n",
-     "    @property\n",
-     "    def shard_descriptor(self):\n",
-     "        return self._shard_descriptor\n",
-     "\n",
-     "    @shard_descriptor.setter\n",
-     "    def shard_descriptor(self, shard_descriptor):\n",
-     "        \"\"\"\n",
-     "        Describe per-collaborator procedures or sharding.\n",
-     "\n",
-     "        This method will be called during a collaborator initialization.\n",
-     "        Local shard_descriptor will be set by Envoy.\n",
-     "        \"\"\"\n",
-     "        self._shard_descriptor = shard_descriptor\n",
-     "        \n",
-     "        self.train_set = shard_descriptor.get_dataset('train')\n",
-     "        self.valid_set = shard_descriptor.get_dataset('val')\n",
-     "\n",
-     "    def __getitem__(self, index):\n",
-     "        return self.shard_descriptor[index]\n",
-     "\n",
-     "    def __len__(self):\n",
-     "        return len(self.shard_descriptor)\n",
-     "\n",
-     "    def get_train_loader(self):\n",
-     "        \"\"\"\n",
-     "        Output of this method will be provided to tasks with optimizer in contract\n",
-     "        \"\"\"\n",
-     "        if self.kwargs['train_bs']:\n",
-     "            batch_size = self.kwargs['train_bs']\n",
-     "        else:\n",
-     "            batch_size = 32\n",
-     "        return DataGenerator(self.train_set, batch_size=batch_size)\n",
-     "\n",
-     "    def get_valid_loader(self):\n",
-     "        \"\"\"\n",
-     "        Output of this method will be provided to tasks without optimizer in contract\n",
-     "        \"\"\"\n",
-     "        if self.kwargs['valid_bs']:\n",
-     "            batch_size = self.kwargs['valid_bs']\n",
-     "        else:\n",
-     "            batch_size = 32\n",
-     "        \n",
-     "        return DataGenerator(self.valid_set, batch_size=batch_size)\n",
-     "\n",
-     "    def get_train_data_size(self):\n",
-     "        \"\"\"\n",
-     "        Information for aggregation\n",
-     "        \"\"\"\n",
-     "        \n",
-     "        return len(self.train_set)\n",
-     "\n",
-     "    def get_valid_data_size(self):\n",
-     "        \"\"\"\n",
-     "        Information for aggregation\n",
-     "        \"\"\"\n",
-     "        return len(self.valid_set)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "b0dfb459",
-    "metadata": {},
-    "source": [
-     "### Create Mnist federated dataset"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "4af5c4c2",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "fed_dataset = MnistFedDataset(train_bs=64, valid_bs=512)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "849c165b",
-    "metadata": {},
-    "source": [
-     "## Define and register FL tasks"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "b9649385",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "TI = TaskInterface()\n",
-     "\n",
-     "import time\n",
-     "import tensorflow as tf\n",
-     "from layers import train_acc_metric, val_acc_metric, loss_fn\n",
-     "\n",
-     "# from openfl.component.aggregation_functions import AdagradAdaptiveAggregation    # Uncomment this lines to use \n",
-     "# agg_fn = AdagradAdaptiveAggregation(model_interface=MI, learning_rate=0.4)       # Adaptive Federated Optimization\n",
-     "# @TI.set_aggregation_function(agg_fn)                                             # alghorithm!\n",
-     "#                                                                                  # See details in the:\n",
-     "#                                                                                  # https://arxiv.org/abs/2003.00295\n",
-     "\n",
-     "@TI.register_fl_task(model='model', data_loader='train_dataset', \\\n",
-     "                     device='device', optimizer='optimizer')     \n",
-     "def train(model, train_dataset, optimizer, device, loss_fn=loss_fn, warmup=False):\n",
-     "    start_time = time.time()\n",
-     "\n",
-     "    # Iterate over the batches of the dataset.\n",
-     "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
-     "        with tf.GradientTape() as tape:\n",
-     "            logits = model(x_batch_train, training=True)\n",
-     "            loss_value = loss_fn(y_batch_train, logits)\n",
-     "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
-     "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
-     "\n",
-     "        # Update training metric.\n",
-     "        train_acc_metric.update_state(y_batch_train, logits)\n",
-     "\n",
-     "        # Log every 200 batches.\n",
-     "        if step % 200 == 0:\n",
-     "            print(\n",
-     "                \"Training loss (for one batch) at step %d: %.4f\"\n",
-     "                % (step, float(loss_value))\n",
-     "            )\n",
-     "            print(\"Seen so far: %d samples\" % ((step + 1) * 64))\n",
-     "        if warmup:\n",
-     "            break\n",
-     "\n",
-     "    # Display metrics at the end of each epoch.\n",
-     "    train_acc = train_acc_metric.result()\n",
-     "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
-     "\n",
-     "    # Reset training metrics at the end of each epoch\n",
-     "    train_acc_metric.reset_states()\n",
-     "\n",
-     "        \n",
-     "    return {'train_acc': train_acc,}\n",
-     "\n",
-     "\n",
-     "@TI.register_fl_task(model='model', data_loader='val_dataset', device='device')     \n",
-     "def validate(model, val_dataset, device):\n",
-     "    # Run a validation loop at the end of each epoch.\n",
-     "    for x_batch_val, y_batch_val in val_dataset:\n",
-     "        val_logits = model(x_batch_val, training=False)\n",
-     "        # Update val metrics\n",
-     "        val_acc_metric.update_state(y_batch_val, val_logits)\n",
-     "    val_acc = val_acc_metric.result()\n",
-     "    val_acc_metric.reset_states()\n",
-     "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
-     "            \n",
-     "    return {'validation_accuracy': val_acc,}"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "8f0ebf2d",
-    "metadata": {},
-    "source": [
-     "## Time to start a federated learning experiment"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "d41b7896",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# create an experimnet in federation\n",
-     "experiment_name = 'mnist_experiment'\n",
-     "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "41b44de9",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
-     "fl_experiment.start(model_provider=MI, \n",
-     "                   task_keeper=TI,\n",
-     "                   data_loader=fed_dataset,\n",
-     "                   rounds_to_train=5,\n",
-     "                   opt_treatment='CONTINUE_GLOBAL')"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "01fa7cea",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "fl_experiment.stream_metrics()"
-    ]
-   }
-  ],
-  "metadata": {
-   "language_info": {
-    "name": "python"
-   }
-  },
-  "nbformat": 4,
-  "nbformat_minor": 5
- }
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/director/director_config.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/director/director_config.yaml
*** ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/director/director_config.yaml	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/director/director_config.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- settings:
-   listen_ip: localhost
-   sample_shape: ['3', '96']
-   target_shape: ['10719']
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/director/start_director.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/director/start_director.sh
*** ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/director/start_director.sh	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/director/start_director.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- 
- fx director start --disable-tls -c director_config.yaml
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/director/start_director_with_tls.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/director/start_director_with_tls.sh
*** ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/director/start_director_with_tls.sh	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/director/start_director_with_tls.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- FQDN=$1
- fx director start -c director_config.yaml -rc cert/root_ca.crt -pk cert/"${FQDN}".key -oc cert/"${FQDN}".crt
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/envoy_config_one.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/envoy_config_one.yaml
*** ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/envoy_config_one.yaml	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/envoy_config_one.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,11 ****
- # https://www.gutenberg.org/files/36668/36668-h/36668-h.htm
- params:
-   cuda_devices: []
- 
- optional_plugin_components: {}
- 
- shard_descriptor:
-   template: shard_descriptor.NextWordShardDescriptor
-   params:
-     title: Polish Fairy Tales
-     author: A. J. Gliński
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/envoy_config_three.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/envoy_config_three.yaml
*** ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/envoy_config_three.yaml	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/envoy_config_three.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,11 ****
- # https://www.gutenberg.org/files/4357/4357-h/4357-h.htm
- params:
-   cuda_devices: []
- 
- optional_plugin_components: {}
- 
- shard_descriptor:
-   template: shard_descriptor.NextWordShardDescriptor
-   params:
-     title: American Fairy Tales
-     author: L. FRANK BAUM
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/envoy_config_two.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/envoy_config_two.yaml
*** ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/envoy_config_two.yaml	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/envoy_config_two.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,11 ****
- # https://www.gutenberg.org/cache/epub/7439/pg7439-images.html
- params:
-   cuda_devices: []
- 
- optional_plugin_components: {}
- 
- shard_descriptor:
-   template: shard_descriptor.NextWordShardDescriptor
-   params:
-     title: English Fairy Tales
-     author: Joseph Jacobs
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/sd_requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/sd_requirements.txt
*** ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/sd_requirements.txt	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/sd_requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- gdown==3.13.0
- numpy==1.19.5
- pandas==1.3.3
- pyarrow==5.0.0
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/shard_descriptor.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/shard_descriptor.py
*** ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/shard_descriptor.py	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/shard_descriptor.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,142 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Shard descriptor for text."""
- 
- import re
- import urllib.request
- import zipfile
- from pathlib import Path
- 
- import gdown
- import numpy as np
- import pandas as pd
- 
- from openfl.interface.interactive_api.shard_descriptor import ShardDataset
- from openfl.interface.interactive_api.shard_descriptor import ShardDescriptor
- 
- 
- class NextWordShardDataset(ShardDataset):
-     """Shard Dataset for text."""
- 
-     def __init__(self, X, y):
-         """Initialize NextWordShardDataset."""
-         self.X = X
-         self.y = y
- 
-     def __len__(self):
-         """Count number of sequences."""
-         return len(self.X)
- 
-     def __getitem__(self, index: int):
-         """Return an item by the index."""
-         return self.X[index], self.y[index]
- 
- 
- class NextWordShardDescriptor(ShardDescriptor):
-     """Data is any text."""
- 
-     def __init__(self, title: str = '', author: str = '') -> None:
-         """Initialize NextWordShardDescriptor."""
-         super().__init__()
- 
-         self.title = title
-         self.author = author
- 
-         dataset_dir = self.download_data(title)
-         data = self.load_data(dataset_dir)  # list of words
-         self.X, self.y = self.get_sequences(data)
- 
-     def get_dataset(self, dataset_type='train', train_val_split=0.8):
-         """Return a dataset by type."""
-         train_size = round(len(self.X) * train_val_split)
-         if dataset_type == 'train':
-             X = self.X[:train_size]
-             y = self.y[:train_size]
-         elif dataset_type == 'val':
-             X = self.X[train_size:]
-             y = self.y[train_size:]
-         else:
-             raise Exception(f'Wrong dataset type: {dataset_type}.'
-                             f'Choose from the list: [train, val]')
-         return NextWordShardDataset(X, y)
- 
-     @property
-     def sample_shape(self):
-         """Return the sample shape info."""
-         length, n_gram, vector_size = self.X.shape
-         return [str(n_gram), str(vector_size)]  # three vectors
- 
-     @property
-     def target_shape(self):
-         """Return the target shape info."""
-         length, vocab_size = self.y.shape
-         return [str(vocab_size)]  # row at one-hot matrix with n = vocab_size
- 
-     @property
-     def dataset_description(self) -> str:
-         """Return the dataset description."""
-         return f'Dataset from {self.title} by {self.author}'
- 
-     @staticmethod
-     def load_data(path):
-         """Load text file, return list of words."""
-         file = open(path, 'r', encoding='utf8').read()
-         data = re.findall(r'[a-z]+', file.lower())
-         return data
- 
-     @staticmethod
-     def get_sequences(data):
-         """Transform words to sequences, for X transform to vectors as well."""
-         # spacy en_core_web_sm vocab_size = 10719, vector_size = 96
-         x_seq = []
-         y_seq = []
- 
-         # created with make_vocab.py from
-         # https://gist.github.com/katerina-merkulova/e351b11c67832034b49652835b14adb0
-         NextWordShardDescriptor.download_vectors()
-         vectors = pd.read_feather('keyed_vectors.feather')
-         vectors.set_index('index', inplace=True)
- 
-         for i in range(len(data) - 3):
-             x = data[i:i + 3]  # make 3-grams
-             y = data[i + 3]
-             cur_x = [vectors.vector[word] for word in x if word in vectors.index]
-             if len(cur_x) == 3 and y in vectors.index:
-                 x_seq.append(cur_x)
-                 y_seq.append(vectors.index.get_loc(y))
- 
-         x_seq = np.array(x_seq)
-         y_seq = np.array(y_seq)
-         y = np.zeros((y_seq.size, 10719))
-         y[np.arange(y_seq.size), y_seq] = 1
-         return x_seq, y
- 
-     @staticmethod
-     def download_data(title):
-         """Download text by title form Github Gist."""
-         url = ('https://gist.githubusercontent.com/katerina-merkulova/e351b11c67832034b49652835b'
-                '14adb0/raw/5b6667c3a2e1266f3d9125510069d23d8f24dc73/' + title.replace(' ', '_')
-                + '.txt')
-         filepath = Path.cwd() / f'{title}.txt'
-         if not filepath.exists():
-             response = urllib.request.urlopen(url)
-             content = response.read().decode('utf-8')
-             with open(filepath, 'w', encoding='utf-8') as file:
-                 file.write(content)
-         return filepath
- 
-     @staticmethod
-     def download_vectors():
-         """Download vectors."""
-         if Path('keyed_vectors.feather').exists():
-             return None
- 
-         output = 'keyed_vectors.zip'
-         if not Path(output).exists():
-             url = 'https://drive.google.com/uc?id=1QfidtkJ9qxzNLs1pgXoY_hqnBjsDI_2i'
-             gdown.download(url, output, quiet=False)
- 
-         with zipfile.ZipFile(output, 'r') as zip_ref:
-             zip_ref.extractall(Path.cwd())
- 
-         Path(output).unlink()  # remove zip
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/start_envoy.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/start_envoy.sh
*** ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/start_envoy.sh	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/start_envoy.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- 
- fx envoy start -n env_one --disable-tls -dh localhost -dp 50051 -ec envoy_config_one.yaml
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/start_envoy_with_tls.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/start_envoy_with_tls.sh
*** ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/start_envoy_with_tls.sh	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/envoy/start_envoy_with_tls.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,6 ****
- #!/bin/bash
- set -e
- ENVOY_NAME=$1
- DIRECTOR_FQDN=$2
- 
- fx envoy start -n "$ENVOY_NAME" --envoy-config-path envoy_config.yaml -d "$DIRECTOR_FQDN":50051 -rc cert/root_ca.crt -pk cert/"$ENVOY_NAME".key -oc cert/"$ENVOY_NAME".crt
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/README.md ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/README.md
*** ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/README.md	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/README.md	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,45 ****
- # Next Word Prediction Tutorial on Keras
- 
- ### 0. GPU supporting
- 
- Currently GPU (with CUDA 11) is not supported by Tensorflow properly, so we disable CUDA in the
- tutorial. Otherwise, you can use these charms in first
- answer (https://stackoverflow.com/questions/41991101/importerror-libcudnn-when-running-a-tensorflow-program)
- to fix your environment and enjoy GPU. Don't forget to
- change `os.environ['CUDA_VISIBLE_DEVICES'] = '-1'` to a positive value.
- 
- As an option you can set CUDA variable for each envoy before starting
- it: `export CUDA_VISIBLE_DEVICES=0`
- 
- ### 1. Data
- 
- Different envoys could have different texts, there were used 3 books of fairy tales:
- 
- - Polish Fairy Tales by A. J. Gliński https://www.gutenberg.org/files/36668/36668-h/36668-h.htm
- - English Fairy Tales by Joseph Jacobs https://www.gutenberg.org/cache/epub/7439/pg7439-images.html
- - American Fairy Tales by L. FRANK BAUM https://www.gutenberg.org/files/4357/4357-h/4357-h.htm
- 
- ### 2. Keras Model
- 
- At this point OpenFL maintains Sequential API and Functional API. Keras Submodel is not supported.
- https://github.com/intel/openfl/issues/185
- 
- ## To run experiment:
- 
- 1. Create a folder for each envoy (they can be subfolders of `envoy` for simulation purposes or
-    folders on different machines in a real-life setting), in our case we should create three
-    folders.
- 2. Put a relevant `envoy_config` in each of the three folders and copy other files from `envoy`
-    there as well.
- 3. Modify the `start_envoy` accordingly:
-     1. change `env_one` to `env_two`, `env_three` (or any unique envoy names you like)
-     2. `envoy_config_one.yaml` to  `envoy_config_two.yaml` and `envoy_config_three.yaml`.
- 4. Install requirements for each envoy: `pip install -r sd_requirements.txt`
- 5. Run the director: execute `start_director.sh` in `director`.
- 6. Run the envoys: execute `start_envoy.sh` in each envoy folder.
- 7. Run the notebook using JupyterLab in `workspace`.
- 
- ```sh
- cd workspace 
- jupyter lab
- ```
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/workspace/requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/workspace/requirements.txt
*** ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/workspace/requirements.txt	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/workspace/requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- tensorflow==2.7.0
- numpy==1.19.5
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/workspace/Tensorflow_Word_Prediction.ipynb ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/workspace/Tensorflow_Word_Prediction.ipynb
*** ./openfl/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/workspace/Tensorflow_Word_Prediction.ipynb	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-tutorials/interactive_api/Tensorflow_Word_Prediction/workspace/Tensorflow_Word_Prediction.ipynb	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,481 ****
- {
-  "cells": [
-   {
-    "cell_type": "markdown",
-    "id": "2390f64a",
-    "metadata": {},
-    "source": [
-     "# Federated Next Word Prediction with Director example"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "e3f166dd",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# install requirements\n",
-     "!pip install -r requirements.txt"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "52a6f355",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import numpy as np\n",
-     "\n",
-     "import os\n",
-     "# disable GPUs due to Tensoflow not supporting CUDA 11\n",
-     "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "1a8e22c1",
-    "metadata": {},
-    "source": [
-     "# Connect to the Federation"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "5c479dad",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Create a federation\n",
-     "from openfl.interface.interactive_api.federation import Federation\n",
-     "\n",
-     "# please use the same identificator that was used in signed certificate\n",
-     "cliend_id = 'frontend'\n",
-     "\n",
-     "# 1) Run with API layer - Director mTLS\n",
-     "# If the user wants to enable mTLS their must provide CA root chain, and signed key pair to the federation interface\n",
-     "# cert_chain = 'cert/root_ca.crt'\n",
-     "# API_certificate = 'cert/frontend.crt'\n",
-     "# API_private_key = 'cert/frontend.key'\n",
-     "\n",
-     "# federation = Federation(client_id='frontend', director_node_fqdn='localhost', director_port='50051', disable_tls=False,\n",
-     "#                        cert_chain=cert_chain, api_cert=API_certificate, api_private_key=API_private_key)\n",
-     "\n",
-     "# --------------------------------------------------------------------------------------------------------------------\n",
-     "\n",
-     "# 2) Run with TLS disabled (trusted environment)\n",
-     "# Federation can also determine local fqdn automatically\n",
-     "federation = Federation(client_id='frontend', director_node_fqdn='localhost', director_port='50051', tls=False)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "466edd2c",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "shard_registry = federation.get_shard_registry()\n",
-     "shard_registry"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "381a2e96",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "federation.target_shape"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "d72d9aef",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# First, request a dummy_shard_desc that holds information about the federated dataset \n",
-     "dummy_shard_desc = federation.get_dummy_shard_descriptor(size=10)\n",
-     "sample, target = dummy_shard_desc.get_dataset(dataset_type='')[0]"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "obvious-tyler",
-    "metadata": {},
-    "source": [
-     "## Creating a FL experiment using Interactive API"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "9001b56e",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "sustainable-public",
-    "metadata": {},
-    "source": [
-     "### Register dataset"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "41ba9a55",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from tensorflow.keras.utils import Sequence\n",
-     "\n",
-     "class DataGenerator(Sequence):\n",
-     "\n",
-     "    def __init__(self, dataset, batch_size):\n",
-     "        self.dataset = dataset\n",
-     "        self.batch_size = batch_size\n",
-     "        self.on_epoch_end()\n",
-     "\n",
-     "    def __len__(self):\n",
-     "        return len(self.dataset) // self.batch_size\n",
-     "\n",
-     "    def __getitem__(self, index):\n",
-     "        return self.dataset[index * self.batch_size:(index + 1) * self.batch_size]\n",
-     "\n",
-     "# Now you can implement you data loaders using dummy_shard_desc\n",
-     "class NextWordSD(DataInterface):\n",
-     "\n",
-     "    def __init__(self, train_val_split=0.8, **kwargs):\n",
-     "        super().__init__(**kwargs)\n",
-     "        self.train_val_split = train_val_split\n",
-     "\n",
-     "    @property\n",
-     "    def shard_descriptor(self):\n",
-     "        return self._shard_descriptor\n",
-     "\n",
-     "    @shard_descriptor.setter\n",
-     "    def shard_descriptor(self, shard_descriptor):\n",
-     "        \"\"\"\n",
-     "        Describe per-collaborator procedures or sharding.\n",
-     "\n",
-     "        This method will be called during a collaborator initialization.\n",
-     "        Local shard_descriptor will be set by Envoy.\n",
-     "        \"\"\"\n",
-     "        self._shard_descriptor = shard_descriptor\n",
-     "\n",
-     "    def __getitem__(self, index):\n",
-     "        return self.shard_descriptor[index]\n",
-     "\n",
-     "    def __len__(self):\n",
-     "        return len(self.shard_descriptor)\n",
-     "\n",
-     "    def get_train_loader(self):\n",
-     "        \"\"\"\n",
-     "        Output of this method will be provided to tasks with optimizer in contract\n",
-     "        \"\"\"\n",
-     "        if self.kwargs['train_bs']:\n",
-     "            batch_size = self.kwargs['train_bs']\n",
-     "        else:\n",
-     "            batch_size = 64\n",
-     "\n",
-     "        self.train_dataset = self.shard_descriptor.get_dataset('train', self.train_val_split)\n",
-     "        return DataGenerator(self.train_dataset, batch_size=batch_size)\n",
-     "\n",
-     "    def get_valid_loader(self):\n",
-     "        \"\"\"\n",
-     "        Output of this method will be provided to tasks without optimizer in contract\n",
-     "        \"\"\"\n",
-     "        if self.kwargs['valid_bs']:\n",
-     "            batch_size = self.kwargs['valid_bs']\n",
-     "        else:\n",
-     "            batch_size = 512\n",
-     "\n",
-     "        self.val_dataset = self.shard_descriptor.get_dataset('val', self.train_val_split)\n",
-     "        return DataGenerator(self.val_dataset, batch_size=batch_size)\n",
-     "\n",
-     "    def get_train_data_size(self):\n",
-     "        \"\"\"\n",
-     "        Information for aggregation\n",
-     "        \"\"\"\n",
-     "        return len(self.train_dataset)\n",
-     "\n",
-     "    def get_valid_data_size(self):\n",
-     "        \"\"\"\n",
-     "        Information for aggregation\n",
-     "        \"\"\"\n",
-     "        return len(self.val_dataset)\n"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "caring-distinction",
-    "metadata": {},
-    "source": [
-     "### Describe a model and optimizer\n",
-     "#### Sequential API"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "3524931d",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import tensorflow as tf\n",
-     "from tensorflow.keras.layers import LSTM, Dense\n",
-     "from tensorflow.keras.optimizers import Adam\n",
-     "from tensorflow.keras.metrics import TopKCategoricalAccuracy\n",
-     "from tensorflow.keras.losses import CategoricalCrossentropy\n",
-     "from tensorflow.keras.models import Sequential\n",
-     "\n",
-     "model = Sequential()\n",
-     "model.add(LSTM(1000, return_sequences=True))\n",
-     "model.add(LSTM(1000))\n",
-     "model.add(Dense(1000, activation='tanh'))\n",
-     "model.add(Dense(10719, activation='softmax'))\n",
-     "\n",
-     "optimizer = Adam(learning_rate=0.001)\n",
-     "loss_fn = CategoricalCrossentropy()\n",
-     "train_acc_metric = TopKCategoricalAccuracy(k=10)\n",
-     "val_acc_metric = TopKCategoricalAccuracy(k=10)\n",
-     "\n",
-     "batch_size = 64\n",
-     "model.build(input_shape=[batch_size, 3, 96])"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "9b26d13e",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "fed_dataset = NextWordSD(train_bs=64, valid_bs=512)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "portuguese-groove",
-    "metadata": {},
-    "source": [
-     "### Define and register FL tasks"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "7e326d8f",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "TI = TaskInterface()\n",
-     "\n",
-     "# https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit\n",
-     "@TI.register_fl_task(model='model', data_loader='train_loader', device='device', optimizer='optimizer')\n",
-     "def train(model, train_loader, device, optimizer):\n",
-     "\n",
-     "    # Iterate over the batches of the dataset.\n",
-     "    for step, (x_batch_train, y_batch_train) in enumerate(train_loader):\n",
-     "\n",
-     "        y = tf.convert_to_tensor(y_batch_train)\n",
-     "        with tf.GradientTape() as tape:\n",
-     "            y_pred = model(x_batch_train, training=True)  # Forward pass\n",
-     "            # Compute the loss value\n",
-     "            # (the loss function is configured in `compile()`)\n",
-     "            loss = loss_fn(y, y_pred)\n",
-     "\n",
-     "        # Compute gradients\n",
-     "        trainable_vars = model.trainable_variables\n",
-     "        gradients = tape.gradient(loss, trainable_vars)\n",
-     "\n",
-     "        # Update weights\n",
-     "        optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
-     "\n",
-     "        # Update metrics\n",
-     "        train_acc_metric.update_state(y, y_pred)\n",
-     "    \n",
-     "    # Reset training metrics at the end of each epoch\n",
-     "    train_acc = train_acc_metric.result()\n",
-     "    train_acc_metric.reset_states()\n",
-     "    return {'train_acc': train_acc, 'loss': loss}\n",
-     "\n",
-     "\n",
-     "@TI.register_fl_task(model='model', data_loader='val_loader', device='device')\n",
-     "def validate(model, val_loader, device=''):\n",
-     "    for x_batch_val, y_batch_val in val_loader:\n",
-     "        y = tf.convert_to_tensor(y_batch_val)\n",
-     "        # Compute predictions\n",
-     "        y_pred = model(x_batch_val, training=False)\n",
-     "        # Update the metrics.\n",
-     "        val_acc_metric.update_state(y, y_pred)\n",
-     "    val_acc = val_acc_metric.result()\n",
-     "    val_acc_metric.reset_states()\n",
-     "    return {'validation_accuracy': val_acc}\n"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "caroline-passion",
-    "metadata": {},
-    "source": [
-     "#### Register model"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "145676d1",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from copy import deepcopy\n",
-     "\n",
-     "framework_adapter = 'openfl.plugins.frameworks_adapters.keras_adapter.FrameworkAdapterPlugin'\n",
-     "MI = ModelInterface(model=model, optimizer=optimizer, framework_plugin=framework_adapter)\n",
-     "# Save the initial model state\n",
-     "initial_model = deepcopy(model)"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "derived-bride",
-    "metadata": {},
-    "source": [
-     "## Time to start a federated learning experiment"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "df9d0e68",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# create an experimnet in federation\n",
-     "experiment_name = 'word_prediction_test_experiment'\n",
-     "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "1fdb59e1",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# If I use autoreload I got a pickling error\n",
-     "\n",
-     "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
-     "fl_experiment.start(model_provider=MI, \n",
-     "                    task_keeper=TI,\n",
-     "                    data_loader=fed_dataset,\n",
-     "                    rounds_to_train=20,\n",
-     "                    opt_treatment='RESET')"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "92510227",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# If user want to stop IPython session, then reconnect and check how experiment is going \n",
-     "# fl_experiment.restore_experiment_state(MI)\n",
-     "\n",
-     "fl_experiment.stream_metrics()"
-    ]
-   },
-   {
-    "cell_type": "markdown",
-    "id": "e9e0c0a8",
-    "metadata": {
-     "pycharm": {
-      "name": "#%% md\n"
-     }
-    },
-    "source": [
-     "## Testing the best model"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "0b55ddee",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "!pip install -r ../envoy/sd_requirements.txt"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "b23a6ec6",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "import sys\n",
-     "sys.path.insert(1, '../envoy')"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "6bbdfedc",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "from shard_descriptor import NextWordShardDescriptor\n",
-     "\n",
-     "# https://www.gutenberg.org/files/2892/2892-h/2892-h.htm\n",
-     "fed_dataset = NextWordSD(train_bs=64, valid_bs=512, train_val_split=0)\n",
-     "fed_dataset.shard_descriptor = NextWordShardDescriptor(title='Irish Fairy Tales', author='James Stephens')"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "821b69a7",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "best_model = fl_experiment.get_best_model()\n",
-     "\n",
-     "# We remove data from director\n",
-     "fl_experiment.remove_experiment_data()\n",
-     "\n",
-     "# Validating initial model\n",
-     "validate(initial_model, fed_dataset.get_valid_loader())"
-    ]
-   },
-   {
-    "cell_type": "code",
-    "execution_count": null,
-    "id": "5c75b1f5",
-    "metadata": {},
-    "outputs": [],
-    "source": [
-     "# Validating trained model\n",
-     "validate(best_model, fed_dataset.get_valid_loader())"
-    ]
-   }
-  ],
-  "metadata": {
-   "language_info": {
-    "name": "python"
-   }
-  },
-  "nbformat": 4,
-  "nbformat_minor": 5
- }
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/default/director.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/default/director.yaml
*** ./openfl/openfl-workspace/default/director.yaml	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/default/director.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,14 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- # Director's config.
- # Parameters:
- #   1. sample_shape - sample shape interface unified across the Federation
- #   2. target_shape - target shape interface unified across the Federation
- 
- settings:
-   sample_shape: []
-   target_shape: []
-   listen_host: localhost  # listen FQDN or ip
-   listen_port: 50051  # listen port
-   envoy_health_check_period: 60  # in seconds
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/default/envoy_config.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/default/envoy_config.yaml
*** ./openfl/openfl-workspace/default/envoy_config.yaml	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/default/envoy_config.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,33 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- # SETUP ENVOY PARAMETERS
- 
- # cuda_devices - field allows you to put indeces of cuda devices you want to allow using
- #     in Federated experiments
- 
- # SETUP SHARD DESCRIPTOR
- # To start envoy implement LocalShardDescriptor class in shard_descriptor module.
- # Alternatively, point to an implemented Shard Descriptor in 'template' field.
- 
- # Put in 'params' group any argument needed to initialize choosen Shard Descriptor.
- # Parameters are optional. For clarity, this example config contains three parameters:
- # 1. data_path - string with data location on disk
- # 2. sample_shape - shape of sample's numpy representaion that will by return from __getitem__ 
- # 3. target_shape - shape of target's numpy representaion that will by return from __getitem__ 
- 
- 
- params:
-   cuda_devices: []
- 
- optional_plugin_components:
-   cuda_device_monitor:
-     template: openfl.plugins.processing_units_monitor.pynvml_monitor.PynvmlCUDADeviceMonitor
-     settings: []
- 
- shard_descriptor:
-   template: shard_descriptor.LocalShardDescriptor
-   params:
-     data_path: data
-     sample_shape: []
-     target_shape: []
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/default/plan/cols.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/default/plan/cols.yaml
*** ./openfl/openfl-workspace/default/plan/cols.yaml	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/default/plan/cols.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,5 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- collaborators:
-   
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/default/plan/data.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/default/plan/data.yaml
*** ./openfl/openfl-workspace/default/plan/data.yaml	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/default/plan/data.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,6 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- # collaborator_name,data_directory_path
- one,1
-   
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/default/plan/plan.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/default/plan/plan.yaml
*** ./openfl/openfl-workspace/default/plan/plan.yaml	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/default/plan/plan.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,36 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- aggregator :
-   defaults : plan/defaults/aggregator.yaml
-   template : openfl.component.Aggregator
-   settings :
-     init_state_path : save/init.pbuf
-     best_state_path : save/best.pbuf
-     last_state_path : save/last.pbuf
-     rounds_to_train : 10
- 
- collaborator :
-   defaults : plan/defaults/collaborator.yaml
-   template : openfl.component.Collaborator
-   settings :
-     delta_updates    : false
-     opt_treatment    : RESET
- 
- data_loader :
-   defaults : plan/defaults/data_loader.yaml
- 
- task_runner :
-   defaults : plan/defaults/task_runner.yaml
- 
- network :
-   defaults : plan/defaults/network.yaml
- 
- assigner :
-   defaults : plan/defaults/assigner.yaml
- 
- tasks :
-   defaults : plan/defaults/tasks_fast_estimator.yaml
- 
- compression_pipeline :
-   defaults : plan/defaults/compression_pipeline.yaml
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/default/shard_descriptor.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/default/shard_descriptor.py
*** ./openfl/openfl-workspace/default/shard_descriptor.py	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/default/shard_descriptor.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,22 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """
- Shard Descriptor template.
- 
- It is recommended to perform tensor manipulations using numpy.
- """
- 
- from openfl.interface.interactive_api.shard_descriptor import ShardDescriptor
- 
- 
- class LocalShardDescriptor(ShardDescriptor):
-     """Shard descriptor subclass."""
- 
-     def __init__(self, data_path: str, sample_shape: tuple, target_shape: tuple) -> None:
-         """
-         Initialize local Shard Descriptor.
- 
-         Parameters are arbitrary, set up the ShardDescriptor-related part
-         of the envoy_config.yaml as you need.
-         """
-         super().__init__()
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/fe_tf_adversarial_cifar/plan/cols.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_tf_adversarial_cifar/plan/cols.yaml
*** ./openfl/openfl-workspace/fe_tf_adversarial_cifar/plan/cols.yaml	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_tf_adversarial_cifar/plan/cols.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,5 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- collaborators:
-   
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/fe_tf_adversarial_cifar/plan/data.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_tf_adversarial_cifar/plan/data.yaml
*** ./openfl/openfl-workspace/fe_tf_adversarial_cifar/plan/data.yaml	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_tf_adversarial_cifar/plan/data.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,6 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- # collaborator_name,data_directory_path
- one,1
-   
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/fe_tf_adversarial_cifar/plan/defaults ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_tf_adversarial_cifar/plan/defaults
*** ./openfl/openfl-workspace/fe_tf_adversarial_cifar/plan/defaults	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_tf_adversarial_cifar/plan/defaults	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- ../../workspace/plan/defaults
- 
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/fe_tf_adversarial_cifar/plan/plan.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_tf_adversarial_cifar/plan/plan.yaml
*** ./openfl/openfl-workspace/fe_tf_adversarial_cifar/plan/plan.yaml	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_tf_adversarial_cifar/plan/plan.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,42 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- aggregator :
-   defaults : plan/defaults/aggregator.yaml
-   template : openfl.component.Aggregator
-   settings :
-     init_state_path : save/keras_lenet_init.pbuf
-     best_state_path : save/keras_lenet_best.pbuf
-     last_state_path : save/keras_lenet_last.pbuf
-     rounds_to_train : 10
- 
- collaborator :
-   defaults : plan/defaults/collaborator.yaml
-   template : openfl.component.Collaborator
-   settings :
-     delta_updates    : false
-     opt_treatment    : RESET
- 
- data_loader :
-   defaults : plan/defaults/data_loader.yaml
-   template : src.fecifar_inmemory.FastEstimatorCifarInMemory
-   settings :
-     collaborator_count : 2
-     data_group_name    : cifar
-     batch_size         : 32
- 
- task_runner :
-   defaults : plan/defaults/task_runner.yaml
-   template : src.fe_fgsm.FastEstimatorFGSM
- 
- network :
-   defaults : plan/defaults/network.yaml
- 
- assigner :
-   defaults : plan/defaults/assigner.yaml
- 
- tasks :
-   defaults : plan/defaults/tasks_fast_estimator.yaml
- 
- compression_pipeline :
-   defaults : plan/defaults/compression_pipeline.yaml
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/fe_tf_adversarial_cifar/requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_tf_adversarial_cifar/requirements.txt
*** ./openfl/openfl-workspace/fe_tf_adversarial_cifar/requirements.txt	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_tf_adversarial_cifar/requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- torch==1.6
- tensorflow==2.7.0
- fastestimator==1.1.1
- albumentations==0.5.2
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/fe_tf_adversarial_cifar/src/fecifar_inmemory.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_tf_adversarial_cifar/src/fecifar_inmemory.py
*** ./openfl/openfl-workspace/fe_tf_adversarial_cifar/src/fecifar_inmemory.py	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_tf_adversarial_cifar/src/fecifar_inmemory.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,94 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- 
- import fastestimator as fe
- from fastestimator.dataset.data import cifar10
- from fastestimator.op.numpyop.univariate import Normalize
- 
- from openfl.federated import FastEstimatorDataLoader
- 
- 
- class FastEstimatorCifarInMemory(FastEstimatorDataLoader):
-     """TensorFlow Data Loader for MNIST Dataset."""
- 
-     def __init__(self, data_path, batch_size, **kwargs):
-         """
-         Initialize.
- 
-         Args:
-             data_path: File path for the dataset
-             batch_size (int): The batch size for the data loader
-             **kwargs: Additional arguments, passed to super init and
-              load_mnist_shard
-         """
-         # TODO: We should be downloading the dataset shard into a directory
-         # TODO: There needs to be a method to ask how many collaborators and
-         #  what index/rank is this collaborator.
-         # Then we have a way to automatically shard based on rank and size
-         # of collaborator list.
- 
-         train_data, eval_data = cifar10.load_data()
-         test_data = eval_data.split(0.5)
- 
-         collaborator_count = kwargs['collaborator_count']
- 
-         train_data, eval_data, test_data = self.split_data(
-             train_data,
-             eval_data,
-             test_data,
-             int(data_path),
-             collaborator_count
-         )
- 
-         print(f'train_data = {train_data}')
-         print(f'eval_data = {eval_data}')
-         print(f'test_data = {test_data}')
- 
-         print(f'batch_size = {batch_size}')
- 
-         super().__init__(fe.Pipeline(
-             train_data=train_data,
-             eval_data=eval_data,
-             test_data=test_data,
-             batch_size=batch_size,
-             ops=[
-                 Normalize(inputs='x', outputs='x',
-                           mean=(0.4914, 0.4822, 0.4465),
-                           std=(0.2471, 0.2435, 0.2616))
-             ]), **kwargs)
- 
-     def split_data(self, train, eva, test, rank, collaborator_count):
-         """Split data into N parts, where N is the collaborator count."""
-         if collaborator_count == 1:
-             return train, eva, test
- 
-         fraction = [1.0 / float(collaborator_count)]
-         fraction *= (collaborator_count - 1)
- 
-         # Expand the split list into individual parameters
-         train_split = train.split(*fraction)
-         eva_split = eva.split(*fraction)
-         test_split = test.split(*fraction)
- 
-         train = [train]
-         eva = [eva]
-         test = [test]
- 
-         if type(train_split) is not list:
-             train.append(train_split)
-             eva.append(eva_split)
-             test.append(test_split)
-         else:
-             # Combine all partitions into a single list
-             train = [train] + train_split
-             eva = [eva] + eva_split
-             test = [test] + test_split
- 
-         # Extract the right shard
-         train = train[rank - 1]
-         eva = eva[rank - 1]
-         test = test[rank - 1]
- 
-         return train, eva, test
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/fe_tf_adversarial_cifar/src/fe_fgsm.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_tf_adversarial_cifar/src/fe_fgsm.py
*** ./openfl/openfl-workspace/fe_tf_adversarial_cifar/src/fe_fgsm.py	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_tf_adversarial_cifar/src/fe_fgsm.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,118 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- 
- import fastestimator as fe
- import tensorflow as tf
- from fastestimator.architecture.tensorflow import LeNet
- from fastestimator.op.tensorop import Average
- from fastestimator.op.tensorop.gradient import FGSM
- from fastestimator.op.tensorop.gradient import Watch
- from fastestimator.op.tensorop.loss import CrossEntropy
- from fastestimator.op.tensorop.model import ModelOp
- from fastestimator.op.tensorop.model import UpdateOp
- from fastestimator.trace.metric import Accuracy
- 
- from openfl.federated import FastEstimatorTaskRunner
- from openfl.federated import TaskRunner
- 
- 
- class FastEstimatorFGSM(FastEstimatorTaskRunner):
-     """An FGSM example based on the LeNet model."""
- 
-     def __init__(self, **kwargs):
-         """
-         Initialize.
- 
-         Args:
-             **kwargs: Additional parameters to pass to the function
-         """
-         TaskRunner.__init__(self, **kwargs)
-         # Now the data pipeline will be initialized and the rest of the
-         # network/estimator can be built
-         self.model = self.build_model()
-         self.network = self.build_network()
-         estimator = self.build_estimator()
-         super().__init__(estimator, **kwargs)
- 
-         self.initialize_tensorkeys_for_functions()
- 
-         self.logger.info(self.model.__repr__())
- 
-         if self.data_loader is not None:
-             self.logger.info(f'Train Set Size : {self.get_train_data_size()}')
-             self.logger.info(f'Valid Set Size : {self.get_valid_data_size()}')
- 
-     def build_model(self):
-         """
-         Define the FastEstimator model architecture.
- 
-         Args:
-             None
- 
-         Returns:
-             model: Union[tf.keras.sequential, nn.module]
- 
-         """
-         def get_model():
-             tf.keras.backend.clear_session()  # to avoid layer names mismatching
-             return LeNet(input_shape=(32, 32, 3))
-         model = fe.build(model_fn=get_model,
-                          optimizer_fn='adam', model_name='adv_model')
-         return model
- 
-     def build_network(self):
-         """
-         Define the FastEstimator network flow.
- 
-         Args:
-             None
- 
-         Returns:
-             network: KerasNetwork object
-         """
-         epsilon = 0.04
- 
-         network = fe.Network(ops=[
-             Watch(inputs='x'),
-             ModelOp(model=self.model, inputs='x', outputs='y_pred'),
-             CrossEntropy(inputs=('y_pred', 'y'), outputs='base_ce'),
-             FGSM(data='x', loss='base_ce', outputs='x_adverse', epsilon=epsilon),
-             ModelOp(model=self.model, inputs='x_adverse', outputs='y_pred_adv'),
-             CrossEntropy(inputs=('y_pred_adv', 'y'), outputs='adv_ce'),
-             Average(inputs=('base_ce', 'adv_ce'), outputs='avg_ce'),
-             UpdateOp(model=self.model, loss_name='avg_ce')
-         ])
- 
-         return network
- 
-     def build_estimator(self):
-         """
-         Define the estimator to run the experiment.
- 
-         This will persist throughout the lifetime of the TaskRunner.
- 
-         Args:
-             None
- 
-         Returns:
-             estimator: Estimator object
-         """
-         max_train_steps_per_epoch = None
-         max_eval_steps_per_epoch = None
- 
-         traces = [
-             Accuracy(true_key='y', pred_key='y_pred', output_name='clean_accuracy'),
-             Accuracy(true_key='y', pred_key='y_pred_adv', output_name='adversarial_accuracy'),
-         ]
-         estimator = fe.Estimator(pipeline=self.data_loader.pipeline,
-                                  network=self.network,
-                                  epochs=2,
-                                  traces=traces,
-                                  max_train_steps_per_epoch=max_train_steps_per_epoch,
-                                  max_eval_steps_per_epoch=max_eval_steps_per_epoch,
-                                  monitor_names=['base_ce', 'adv_ce'],
-                                  log_steps=1000)
- 
-         return estimator
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/fe_tf_adversarial_cifar/src/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_tf_adversarial_cifar/src/__init__.py
*** ./openfl/openfl-workspace/fe_tf_adversarial_cifar/src/__init__.py	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_tf_adversarial_cifar/src/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """You may copy this file as the starting point of your own model."""
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/fe_tf_adversarial_cifar/.workspace ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_tf_adversarial_cifar/.workspace
*** ./openfl/openfl-workspace/fe_tf_adversarial_cifar/.workspace	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_tf_adversarial_cifar/.workspace	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- current_plan_name: default
- 
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/fe_torch_adversarial_cifar/plan/cols.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_torch_adversarial_cifar/plan/cols.yaml
*** ./openfl/openfl-workspace/fe_torch_adversarial_cifar/plan/cols.yaml	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_torch_adversarial_cifar/plan/cols.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,5 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- collaborators:
-   
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/fe_torch_adversarial_cifar/plan/data.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_torch_adversarial_cifar/plan/data.yaml
*** ./openfl/openfl-workspace/fe_torch_adversarial_cifar/plan/data.yaml	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_torch_adversarial_cifar/plan/data.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,6 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- # collaborator_name,data_directory_path
- one,1
-   
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/fe_torch_adversarial_cifar/plan/plan.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_torch_adversarial_cifar/plan/plan.yaml
*** ./openfl/openfl-workspace/fe_torch_adversarial_cifar/plan/plan.yaml	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_torch_adversarial_cifar/plan/plan.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,42 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- aggregator :
-   defaults : plan/defaults/aggregator.yaml
-   template : openfl.component.Aggregator
-   settings :
-     init_state_path : save/keras_lenet_init.pbuf
-     best_state_path : save/keras_lenet_best.pbuf
-     last_state_path : save/keras_lenet_last.pbuf
-     rounds_to_train : 10
- 
- collaborator :
-   defaults : plan/defaults/collaborator.yaml
-   template : openfl.component.Collaborator
-   settings :
-     delta_updates    : false
-     opt_treatment    : RESET
- 
- data_loader :
-   defaults : plan/defaults/data_loader.yaml
-   template : src.fecifar_inmemory.FastEstimatorCifarInMemory
-   settings :
-     collaborator_count : 2
-     data_group_name    : cifar
-     batch_size         : 32
- 
- task_runner :
-   defaults : plan/defaults/task_runner.yaml
-   template : src.fe_fgsm.FastEstimatorFGSM
- 
- network :
-   defaults : plan/defaults/network.yaml
- 
- assigner :
-   defaults : plan/defaults/assigner.yaml
- 
- tasks :
-   defaults : plan/defaults/tasks_fast_estimator.yaml
- 
- compression_pipeline :
-   defaults : plan/defaults/compression_pipeline.yaml
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/fe_torch_adversarial_cifar/requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_torch_adversarial_cifar/requirements.txt
*** ./openfl/openfl-workspace/fe_torch_adversarial_cifar/requirements.txt	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_torch_adversarial_cifar/requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- torch==1.6
- tensorflow==2.7.0
- fastestimator==1.1.1
- albumentations==0.5.2
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/fe_torch_adversarial_cifar/src/fecifar_inmemory.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_torch_adversarial_cifar/src/fecifar_inmemory.py
*** ./openfl/openfl-workspace/fe_torch_adversarial_cifar/src/fecifar_inmemory.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_torch_adversarial_cifar/src/fecifar_inmemory.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,92 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- 
- import fastestimator as fe
- from fastestimator.dataset.data import cifar10
- from fastestimator.op.numpyop.univariate import ChannelTranspose
- from fastestimator.op.numpyop.univariate import Normalize
- 
- from openfl.federated import FastEstimatorDataLoader
- 
- 
- class FastEstimatorCifarInMemory(FastEstimatorDataLoader):
-     """TensorFlow Data Loader for MNIST Dataset."""
- 
-     def __init__(self, data_path, batch_size, collaborator_count, **kwargs):
-         """
-         Initialize.
- 
-         Args:
-             data_path: File path for the dataset
-             batch_size (int): The batch size for the data loader
-             **kwargs: Additional arguments, passed to super init and load_mnist_shard
-         """
-         # TODO: We should be downloading the dataset shard into a directory
-         # TODO: There needs to be a method to ask how many collaborators and
-         #  what index/rank is this collaborator.
-         # Then we have a way to automatically shard based on rank and size of
-         # collaborator list.
- 
-         train_data, eval_data = cifar10.load_data()
-         test_data = eval_data.split(0.5)
- 
-         train_data, eval_data, test_data = self.split_data(
-             train_data,
-             eval_data,
-             test_data,
-             int(data_path),
-             collaborator_count
-         )
-         super().__init__(fe.Pipeline(
-             train_data=train_data,
-             eval_data=eval_data,
-             test_data=test_data,
-             batch_size=batch_size,
-             ops=[
-                 Normalize(inputs='x', outputs='x',
-                           mean=(0.4914, 0.4822, 0.4465),
-                           std=(0.2471, 0.2435, 0.2616)),
-                 ChannelTranspose(inputs='x', outputs='x')
-             ]), **kwargs)
- 
-         print(f'train_data = {train_data}')
-         print(f'eval_data = {eval_data}')
-         print(f'test_data = {test_data}')
- 
-         print(f'batch_size = {batch_size}')
- 
-     def split_data(self, train, eva, test, rank, collaborator_count):
-         """Split data into N parts, where N is the collaborator count."""
-         if collaborator_count == 1:
-             return train, eva, test
- 
-         fraction = [1.0 / float(collaborator_count)]
-         fraction *= (collaborator_count - 1)
- 
-         # Expand the split list into individual parameters
-         train_split = train.split(*fraction)
-         eva_split = eva.split(*fraction)
-         test_split = test.split(*fraction)
- 
-         train = [train]
-         eva = [eva]
-         test = [test]
- 
-         if type(train_split) is not list:
-             train.append(train_split)
-             eva.append(eva_split)
-             test.append(test_split)
-         else:
-             # Combine all partitions into a single list
-             train = [train] + train_split
-             eva = [eva] + eva_split
-             test = [test] + test_split
- 
-         # Extract the right shard
-         train = train[rank - 1]
-         eva = eva[rank - 1]
-         test = test[rank - 1]
- 
-         return train, eva, test
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/fe_torch_adversarial_cifar/src/fe_fgsm.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_torch_adversarial_cifar/src/fe_fgsm.py
*** ./openfl/openfl-workspace/fe_torch_adversarial_cifar/src/fe_fgsm.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_torch_adversarial_cifar/src/fe_fgsm.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,114 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- 
- import fastestimator as fe
- from fastestimator.architecture.pytorch import LeNet
- from fastestimator.op.tensorop import Average
- from fastestimator.op.tensorop.gradient import FGSM
- from fastestimator.op.tensorop.gradient import Watch
- from fastestimator.op.tensorop.loss import CrossEntropy
- from fastestimator.op.tensorop.model import ModelOp
- from fastestimator.op.tensorop.model import UpdateOp
- from fastestimator.trace.metric import Accuracy
- 
- from openfl.federated import FastEstimatorTaskRunner
- from openfl.federated import TaskRunner
- 
- 
- class FastEstimatorFGSM(FastEstimatorTaskRunner):
-     """An FGSM example based on the LeNet model."""
- 
-     def __init__(self, **kwargs):
-         """
-         Initialize.
- 
-         Args:
-             **kwargs: Additional parameters to pass to the function
-         """
-         TaskRunner.__init__(self, **kwargs)
-         # Now the data pipeline will be initialized and the rest of the
-         # network/estimator can be built
-         self.model = self.build_model()
-         self.network = self.build_network()
-         estimator = self.build_estimator()
-         super().__init__(estimator, **kwargs)
- 
-         self.initialize_tensorkeys_for_functions()
- 
-         self.logger.info(self.model.__repr__())
- 
-         if self.data_loader is not None:
-             self.logger.info(f'Train Set Size : {self.get_train_data_size()}')
-             self.logger.info(f'Valid Set Size : {self.get_valid_data_size()}')
- 
-     def build_model(self):
-         """
-         Define the FastEstimator model architecture.
- 
-         Args:
-             None
- 
-         Returns:
-             model: Union[tf.keras.sequential, nn.module]
- 
-         """
-         model = fe.build(model_fn=lambda: LeNet(input_shape=(3, 32, 32)),
-                          optimizer_fn='adam', model_name='adv_model')
-         return model
- 
-     def build_network(self):
-         """
-         Define the FastEstimator network flow.
- 
-         Args:
-             None
- 
-         Returns:
-             network: KerasNetwork object
-         """
-         epsilon = 0.04
- 
-         network = fe.Network(ops=[
-             Watch(inputs='x'),
-             ModelOp(model=self.model, inputs='x', outputs='y_pred'),
-             CrossEntropy(inputs=('y_pred', 'y'), outputs='base_ce'),
-             FGSM(data='x', loss='base_ce', outputs='x_adverse', epsilon=epsilon),
-             ModelOp(model=self.model, inputs='x_adverse', outputs='y_pred_adv'),
-             CrossEntropy(inputs=('y_pred_adv', 'y'), outputs='adv_ce'),
-             Average(inputs=('base_ce', 'adv_ce'), outputs='avg_ce'),
-             UpdateOp(model=self.model, loss_name='avg_ce')
-         ])
- 
-         return network
- 
-     def build_estimator(self):
-         """
-         Define the estimator to run the experiment.
- 
-         This will persist throughout the lifetime of the TaskRunner.
- 
-         Args:
-             None
- 
-         Returns:
-             estimator: Estimator object
-         """
-         max_train_steps_per_epoch = None
-         max_eval_steps_per_epoch = None
- 
-         traces = [
-             Accuracy(true_key='y', pred_key='y_pred', output_name='clean_accuracy'),
-             Accuracy(true_key='y', pred_key='y_pred_adv', output_name='adversarial_accuracy'),
-         ]
-         estimator = fe.Estimator(pipeline=self.data_loader.pipeline,
-                                  network=self.network,
-                                  epochs=2,
-                                  traces=traces,
-                                  max_train_steps_per_epoch=max_train_steps_per_epoch,
-                                  max_eval_steps_per_epoch=max_eval_steps_per_epoch,
-                                  monitor_names=['base_ce', 'adv_ce'],
-                                  log_steps=1000)
- 
-         return estimator
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/fe_torch_adversarial_cifar/src/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_torch_adversarial_cifar/src/__init__.py
*** ./openfl/openfl-workspace/fe_torch_adversarial_cifar/src/__init__.py	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_torch_adversarial_cifar/src/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """You may copy this file as the starting point of your own model."""
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/fe_torch_adversarial_cifar/.workspace ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_torch_adversarial_cifar/.workspace
*** ./openfl/openfl-workspace/fe_torch_adversarial_cifar/.workspace	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/fe_torch_adversarial_cifar/.workspace	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- current_plan_name: default
- 
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/__init__.py
*** ./openfl/openfl-workspace/__init__.py	2022-11-18 11:06:29.743187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """openfl-workspace package."""
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_cnn_mnist/plan/cols.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_mnist/plan/cols.yaml
*** ./openfl/openfl-workspace/keras_cnn_mnist/plan/cols.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_mnist/plan/cols.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,5 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- collaborators:
-   
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_cnn_mnist/plan/data.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_mnist/plan/data.yaml
*** ./openfl/openfl-workspace/keras_cnn_mnist/plan/data.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_mnist/plan/data.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,7 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- # collaborator_name,data_directory_path
- one,1
- 
-   
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_cnn_mnist/plan/defaults ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_mnist/plan/defaults
*** ./openfl/openfl-workspace/keras_cnn_mnist/plan/defaults	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_mnist/plan/defaults	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- ../../workspace/plan/defaults
- 
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_cnn_mnist/plan/plan.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_mnist/plan/plan.yaml
*** ./openfl/openfl-workspace/keras_cnn_mnist/plan/plan.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_mnist/plan/plan.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,42 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- aggregator :
-   defaults : plan/defaults/aggregator.yaml
-   template : openfl.component.Aggregator
-   settings :
-     init_state_path : save/keras_cnn_mnist_init.pbuf
-     best_state_path : save/keras_cnn_mnist_best.pbuf
-     last_state_path : save/keras_cnn_mnist_last.pbuf
-     rounds_to_train : 10
- 
- collaborator :
-   defaults : plan/defaults/collaborator.yaml
-   template : openfl.component.Collaborator
-   settings :
-     delta_updates    : false
-     opt_treatment    : RESET
- 
- data_loader :
-   defaults : plan/defaults/data_loader.yaml
-   template : src.tfmnist_inmemory.TensorFlowMNISTInMemory
-   settings :
-     collaborator_count : 2
-     data_group_name    : mnist
-     batch_size         : 256
- 
- task_runner :
-   defaults : plan/defaults/task_runner.yaml
-   template : src.keras_cnn.KerasCNN
- 
- network :
-   defaults : plan/defaults/network.yaml
- 
- assigner :
-   defaults : plan/defaults/assigner.yaml
- 
- tasks :
-   defaults : plan/defaults/tasks_keras.yaml
- 
- compression_pipeline :
-   defaults : plan/defaults/compression_pipeline.yaml
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_cnn_mnist/requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_mnist/requirements.txt
*** ./openfl/openfl-workspace/keras_cnn_mnist/requirements.txt	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_mnist/requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1 ****
- tensorflow==2.7.0
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_cnn_mnist/src/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_mnist/src/__init__.py
*** ./openfl/openfl-workspace/keras_cnn_mnist/src/__init__.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_mnist/src/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """You may copy this file as the starting point of your own model."""
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_cnn_mnist/src/keras_cnn.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_mnist/src/keras_cnn.py
*** ./openfl/openfl-workspace/keras_cnn_mnist/src/keras_cnn.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_mnist/src/keras_cnn.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,86 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- 
- import tensorflow.keras as ke
- from tensorflow.keras import Sequential
- from tensorflow.keras.layers import Conv2D
- from tensorflow.keras.layers import Dense
- from tensorflow.keras.layers import Flatten
- 
- from openfl.federated import KerasTaskRunner
- 
- 
- class KerasCNN(KerasTaskRunner):
-     """A basic convolutional neural network model."""
- 
-     def __init__(self, **kwargs):
-         """
-         Initialize.
- 
-         Args:
-             **kwargs: Additional parameters to pass to the function
-         """
-         super().__init__(**kwargs)
- 
-         self.model = self.build_model(self.feature_shape, self.data_loader.num_classes, **kwargs)
- 
-         self.initialize_tensorkeys_for_functions()
- 
-         self.model.summary(print_fn=self.logger.info)
- 
-         if self.data_loader is not None:
-             self.logger.info(f'Train Set Size : {self.get_train_data_size()}')
-             self.logger.info(f'Valid Set Size : {self.get_valid_data_size()}')
- 
-     def build_model(self,
-                     input_shape,
-                     num_classes,
-                     conv_kernel_size=(4, 4),
-                     conv_strides=(2, 2),
-                     conv1_channels_out=16,
-                     conv2_channels_out=32,
-                     final_dense_inputsize=100,
-                     **kwargs):
-         """
-         Define the model architecture.
- 
-         Args:
-             input_shape (numpy.ndarray): The shape of the data
-             num_classes (int): The number of classes of the dataset
- 
-         Returns:
-             tensorflow.python.keras.engine.sequential.Sequential: The model defined in Keras
- 
-         """
-         model = Sequential()
- 
-         model.add(Conv2D(conv1_channels_out,
-                          kernel_size=conv_kernel_size,
-                          strides=conv_strides,
-                          activation='relu',
-                          input_shape=input_shape))
- 
-         model.add(Conv2D(conv2_channels_out,
-                          kernel_size=conv_kernel_size,
-                          strides=conv_strides,
-                          activation='relu'))
- 
-         model.add(Flatten())
- 
-         model.add(Dense(final_dense_inputsize, activation='relu'))
- 
-         model.add(Dense(num_classes, activation='softmax'))
- 
-         model.compile(loss=ke.losses.categorical_crossentropy,
-                       optimizer=ke.optimizers.Adam(),
-                       metrics=['accuracy'])
- 
-         # initialize the optimizer variables
-         opt_vars = model.optimizer.variables()
- 
-         for v in opt_vars:
-             v.initializer.run(session=self.sess)
- 
-         return model
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_cnn_mnist/src/mnist_utils.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_mnist/src/mnist_utils.py
*** ./openfl/openfl-workspace/keras_cnn_mnist/src/mnist_utils.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_mnist/src/mnist_utils.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,118 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- 
- from logging import getLogger
- 
- import numpy as np
- from tensorflow.python.keras.utils.data_utils import get_file
- 
- logger = getLogger(__name__)
- 
- 
- def one_hot(labels, classes):
-     """
-     One Hot encode a vector.
- 
-     Args:
-         labels (list):  List of labels to onehot encode
-         classes (int): Total number of categorical classes
- 
-     Returns:
-         np.array: Matrix of one-hot encoded labels
-     """
-     return np.eye(classes)[labels]
- 
- 
- def _load_raw_datashards(shard_num, collaborator_count):
-     """
-     Load the raw data by shard.
- 
-     Returns tuples of the dataset shard divided into training and validation.
- 
-     Args:
-         shard_num (int): The shard number to use
-         collaborator_count (int): The number of collaborators in the federation
- 
-     Returns:
-         2 tuples: (image, label) of the training, validation dataset
-     """
-     origin_folder = 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/'
-     path = get_file('mnist.npz',
-                     origin=origin_folder + 'mnist.npz',
-                     file_hash='731c5ac602752760c8e48fbffcf8c3b850d9dc2a2aedcf2cc48468fc17b673d1')
- 
-     with np.load(path) as f:
-         # get all of mnist
-         X_train_tot = f['x_train']
-         y_train_tot = f['y_train']
- 
-         X_valid_tot = f['x_test']
-         y_valid_tot = f['y_test']
- 
-     # create the shards
-     shard_num = int(shard_num)
-     X_train = X_train_tot[shard_num::collaborator_count]
-     y_train = y_train_tot[shard_num::collaborator_count]
- 
-     X_valid = X_valid_tot[shard_num::collaborator_count]
-     y_valid = y_valid_tot[shard_num::collaborator_count]
- 
-     return (X_train, y_train), (X_valid, y_valid)
- 
- 
- def load_mnist_shard(shard_num, collaborator_count, categorical=True,
-                      channels_last=True, **kwargs):
-     """
-     Load the MNIST dataset.
- 
-     Args:
-         shard_num (int): The shard to use from the dataset
-         collaborator_count (int): The number of collaborators in the federation
-         categorical (bool): True = convert the labels to one-hot encoded
-          vectors (Default = True)
-         channels_last (bool): True = The input images have the channels
-          last (Default = True)
-         **kwargs: Additional parameters to pass to the function
- 
-     Returns:
-         list: The input shape
-         int: The number of classes
-         numpy.ndarray: The training data
-         numpy.ndarray: The training labels
-         numpy.ndarray: The validation data
-         numpy.ndarray: The validation labels
-     """
-     img_rows, img_cols = 28, 28
-     num_classes = 10
- 
-     (X_train, y_train), (X_valid, y_valid) = _load_raw_datashards(
-         shard_num, collaborator_count
-     )
- 
-     if channels_last:
-         X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)
-         X_valid = X_valid.reshape(X_valid.shape[0], img_rows, img_cols, 1)
-         input_shape = (img_rows, img_cols, 1)
-     else:
-         X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)
-         X_valid = X_valid.reshape(X_valid.shape[0], 1, img_rows, img_cols)
-         input_shape = (1, img_rows, img_cols)
- 
-     X_train = X_train.astype('float32')
-     X_valid = X_valid.astype('float32')
-     X_train /= 255
-     X_valid /= 255
- 
-     logger.info(f'MNIST > X_train Shape : {X_train.shape}')
-     logger.info(f'MNIST > y_train Shape : {y_train.shape}')
-     logger.info(f'MNIST > Train Samples : {X_train.shape[0]}')
-     logger.info(f'MNIST > Valid Samples : {X_valid.shape[0]}')
- 
-     if categorical:
-         # convert class vectors to binary class matrices
-         y_train = one_hot(y_train, num_classes)
-         y_valid = one_hot(y_valid, num_classes)
- 
-     return input_shape, num_classes, X_train, y_train, X_valid, y_valid
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_cnn_mnist/src/tfmnist_inmemory.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_mnist/src/tfmnist_inmemory.py
*** ./openfl/openfl-workspace/keras_cnn_mnist/src/tfmnist_inmemory.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_mnist/src/tfmnist_inmemory.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,39 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- 
- from openfl.federated import TensorFlowDataLoader
- from .mnist_utils import load_mnist_shard
- 
- 
- class TensorFlowMNISTInMemory(TensorFlowDataLoader):
-     """TensorFlow Data Loader for MNIST Dataset."""
- 
-     def __init__(self, data_path, batch_size, **kwargs):
-         """
-         Initialize.
- 
-         Args:
-             data_path: File path for the dataset
-             batch_size (int): The batch size for the data loader
-             **kwargs: Additional arguments, passed to super init and load_mnist_shard
-         """
-         super().__init__(batch_size, **kwargs)
- 
-         # TODO: We should be downloading the dataset shard into a directory
-         # TODO: There needs to be a method to ask how many collaborators and
-         #  what index/rank is this collaborator.
-         # Then we have a way to automatically shard based on rank and size of
-         # collaborator list.
- 
-         _, num_classes, X_train, y_train, X_valid, y_valid = load_mnist_shard(
-             shard_num=int(data_path), **kwargs
-         )
- 
-         self.X_train = X_train
-         self.y_train = y_train
-         self.X_valid = X_valid
-         self.y_valid = y_valid
- 
-         self.num_classes = num_classes
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_cnn_mnist/.workspace ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_mnist/.workspace
*** ./openfl/openfl-workspace/keras_cnn_mnist/.workspace	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_mnist/.workspace	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- current_plan_name: default
- 
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_cnn_with_compression/plan/cols.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_with_compression/plan/cols.yaml
*** ./openfl/openfl-workspace/keras_cnn_with_compression/plan/cols.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_with_compression/plan/cols.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,5 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- collaborators:
-   
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_cnn_with_compression/plan/data.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_with_compression/plan/data.yaml
*** ./openfl/openfl-workspace/keras_cnn_with_compression/plan/data.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_with_compression/plan/data.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,7 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- # collaborator_name,data_directory_path
- one,1
- 
-   
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_cnn_with_compression/plan/defaults ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_with_compression/plan/defaults
*** ./openfl/openfl-workspace/keras_cnn_with_compression/plan/defaults	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_with_compression/plan/defaults	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- ../../workspace/plan/defaults
- 
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_cnn_with_compression/plan/plan.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_with_compression/plan/plan.yaml
*** ./openfl/openfl-workspace/keras_cnn_with_compression/plan/plan.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_with_compression/plan/plan.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,47 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- aggregator :
-   defaults : plan/defaults/aggregator.yaml
-   template : openfl.component.Aggregator
-   settings :
-     init_state_path : save/keras_cnn_mnist_init.pbuf
-     best_state_path : save/keras_cnn_mnist_best.pbuf
-     last_state_path : save/keras_cnn_mnist_last.pbuf
-     db_store_rounds: 2
-     rounds_to_train : 10
- 
- collaborator :
-   defaults : plan/defaults/collaborator.yaml
-   template : openfl.component.Collaborator
-   settings :
-     db_store_rounds: 2
-     delta_updates    : true
-     opt_treatment    : RESET
- 
- data_loader :
-   defaults : plan/defaults/data_loader.yaml
-   template : src.tfmnist_inmemory.TensorFlowMNISTInMemory
-   settings :
-     collaborator_count : 2
-     data_group_name    : mnist
-     batch_size         : 256
- 
- task_runner :
-   defaults : plan/defaults/task_runner.yaml
-   template : src.keras_cnn.KerasCNN
- 
- network :
-   defaults : plan/defaults/network.yaml
- 
- assigner :
-   defaults : plan/defaults/assigner.yaml
- 
- tasks :
-   defaults : plan/defaults/tasks_keras.yaml
- 
- compression_pipeline :
-   defaults : plan/defaults/compression_pipeline.yaml
-   template : openfl.pipelines.KCPipeline
-   settings :
-     n_clusters : 6
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_cnn_with_compression/requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_with_compression/requirements.txt
*** ./openfl/openfl-workspace/keras_cnn_with_compression/requirements.txt	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_with_compression/requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1 ****
- tensorflow==2.7.0
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_cnn_with_compression/src/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_with_compression/src/__init__.py
*** ./openfl/openfl-workspace/keras_cnn_with_compression/src/__init__.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_with_compression/src/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """You may copy this file as the starting point of your own model."""
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_cnn_with_compression/src/keras_cnn.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_with_compression/src/keras_cnn.py
*** ./openfl/openfl-workspace/keras_cnn_with_compression/src/keras_cnn.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_with_compression/src/keras_cnn.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,86 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- 
- import tensorflow.keras as ke
- from tensorflow.keras import Sequential
- from tensorflow.keras.layers import Conv2D
- from tensorflow.keras.layers import Dense
- from tensorflow.keras.layers import Flatten
- 
- from openfl.federated import KerasTaskRunner
- 
- 
- class KerasCNN(KerasTaskRunner):
-     """A basic convolutional neural network model."""
- 
-     def __init__(self, **kwargs):
-         """
-         Initialize.
- 
-         Args:
-             **kwargs: Additional parameters to pass to the function
-         """
-         super().__init__(**kwargs)
- 
-         self.model = self.build_model(self.feature_shape, self.data_loader.num_classes, **kwargs)
- 
-         self.initialize_tensorkeys_for_functions()
- 
-         self.model.summary(print_fn=self.logger.info)
- 
-         if self.data_loader is not None:
-             self.logger.info(f'Train Set Size : {self.get_train_data_size()}')
-             self.logger.info(f'Valid Set Size : {self.get_valid_data_size()}')
- 
-     def build_model(self,
-                     input_shape,
-                     num_classes,
-                     conv_kernel_size=(4, 4),
-                     conv_strides=(2, 2),
-                     conv1_channels_out=16,
-                     conv2_channels_out=32,
-                     final_dense_inputsize=100,
-                     **kwargs):
-         """
-         Define the model architecture.
- 
-         Args:
-             input_shape (numpy.ndarray): The shape of the data
-             num_classes (int): The number of classes of the dataset
- 
-         Returns:
-             tensorflow.python.keras.engine.sequential.Sequential: The model defined in Keras
- 
-         """
-         model = Sequential()
- 
-         model.add(Conv2D(conv1_channels_out,
-                          kernel_size=conv_kernel_size,
-                          strides=conv_strides,
-                          activation='relu',
-                          input_shape=input_shape))
- 
-         model.add(Conv2D(conv2_channels_out,
-                          kernel_size=conv_kernel_size,
-                          strides=conv_strides,
-                          activation='relu'))
- 
-         model.add(Flatten())
- 
-         model.add(Dense(final_dense_inputsize, activation='relu'))
- 
-         model.add(Dense(num_classes, activation='softmax'))
- 
-         model.compile(loss=ke.losses.categorical_crossentropy,
-                       optimizer=ke.optimizers.Adam(),
-                       metrics=['accuracy'])
- 
-         # initialize the optimizer variables
-         opt_vars = model.optimizer.variables()
- 
-         for v in opt_vars:
-             v.initializer.run(session=self.sess)
- 
-         return model
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_cnn_with_compression/src/mnist_utils.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_with_compression/src/mnist_utils.py
*** ./openfl/openfl-workspace/keras_cnn_with_compression/src/mnist_utils.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_with_compression/src/mnist_utils.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,118 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- 
- from logging import getLogger
- 
- import numpy as np
- from tensorflow.python.keras.utils.data_utils import get_file
- 
- logger = getLogger(__name__)
- 
- 
- def one_hot(labels, classes):
-     """
-     One Hot encode a vector.
- 
-     Args:
-         labels (list):  List of labels to onehot encode
-         classes (int): Total number of categorical classes
- 
-     Returns:
-         np.array: Matrix of one-hot encoded labels
-     """
-     return np.eye(classes)[labels]
- 
- 
- def _load_raw_datashards(shard_num, collaborator_count):
-     """
-     Load the raw data by shard.
- 
-     Returns tuples of the dataset shard divided into training and validation.
- 
-     Args:
-         shard_num (int): The shard number to use
-         collaborator_count (int): The number of collaborators in the federation
- 
-     Returns:
-         2 tuples: (image, label) of the training, validation dataset
-     """
-     origin_folder = 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/'
-     path = get_file('mnist.npz',
-                     origin=origin_folder + 'mnist.npz',
-                     file_hash='731c5ac602752760c8e48fbffcf8c3b850d9dc2a2aedcf2cc48468fc17b673d1')
- 
-     with np.load(path) as f:
-         # get all of mnist
-         X_train_tot = f['x_train']
-         y_train_tot = f['y_train']
- 
-         X_valid_tot = f['x_test']
-         y_valid_tot = f['y_test']
- 
-     # create the shards
-     shard_num = int(shard_num)
-     X_train = X_train_tot[shard_num::collaborator_count]
-     y_train = y_train_tot[shard_num::collaborator_count]
- 
-     X_valid = X_valid_tot[shard_num::collaborator_count]
-     y_valid = y_valid_tot[shard_num::collaborator_count]
- 
-     return (X_train, y_train), (X_valid, y_valid)
- 
- 
- def load_mnist_shard(shard_num, collaborator_count, categorical=True,
-                      channels_last=True, **kwargs):
-     """
-     Load the MNIST dataset.
- 
-     Args:
-         shard_num (int): The shard to use from the dataset
-         collaborator_count (int): The number of collaborators in the federation
-         categorical (bool): True = convert the labels to one-hot encoded
-          vectors (Default = True)
-         channels_last (bool): True = The input images have the channels
-          last (Default = True)
-         **kwargs: Additional parameters to pass to the function
- 
-     Returns:
-         list: The input shape
-         int: The number of classes
-         numpy.ndarray: The training data
-         numpy.ndarray: The training labels
-         numpy.ndarray: The validation data
-         numpy.ndarray: The validation labels
-     """
-     img_rows, img_cols = 28, 28
-     num_classes = 10
- 
-     (X_train, y_train), (X_valid, y_valid) = _load_raw_datashards(
-         shard_num, collaborator_count
-     )
- 
-     if channels_last:
-         X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)
-         X_valid = X_valid.reshape(X_valid.shape[0], img_rows, img_cols, 1)
-         input_shape = (img_rows, img_cols, 1)
-     else:
-         X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)
-         X_valid = X_valid.reshape(X_valid.shape[0], 1, img_rows, img_cols)
-         input_shape = (1, img_rows, img_cols)
- 
-     X_train = X_train.astype('float32')
-     X_valid = X_valid.astype('float32')
-     X_train /= 255
-     X_valid /= 255
- 
-     logger.info(f'MNIST > X_train Shape : {X_train.shape}')
-     logger.info(f'MNIST > y_train Shape : {y_train.shape}')
-     logger.info(f'MNIST > Train Samples : {X_train.shape[0]}')
-     logger.info(f'MNIST > Valid Samples : {X_valid.shape[0]}')
- 
-     if categorical:
-         # convert class vectors to binary class matrices
-         y_train = one_hot(y_train, num_classes)
-         y_valid = one_hot(y_valid, num_classes)
- 
-     return input_shape, num_classes, X_train, y_train, X_valid, y_valid
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_cnn_with_compression/src/tfmnist_inmemory.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_with_compression/src/tfmnist_inmemory.py
*** ./openfl/openfl-workspace/keras_cnn_with_compression/src/tfmnist_inmemory.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_with_compression/src/tfmnist_inmemory.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,39 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- 
- from openfl.federated import TensorFlowDataLoader
- from .mnist_utils import load_mnist_shard
- 
- 
- class TensorFlowMNISTInMemory(TensorFlowDataLoader):
-     """TensorFlow Data Loader for MNIST Dataset."""
- 
-     def __init__(self, data_path, batch_size, **kwargs):
-         """
-         Initialize.
- 
-         Args:
-             data_path: File path for the dataset
-             batch_size (int): The batch size for the data loader
-             **kwargs: Additional arguments, passed to super init and load_mnist_shard
-         """
-         super().__init__(batch_size, **kwargs)
- 
-         # TODO: We should be downloading the dataset shard into a directory
-         # TODO: There needs to be a method to ask how many collaborators and
-         #  what index/rank is this collaborator.
-         # Then we have a way to automatically shard based on rank and size of
-         # collaborator list.
- 
-         _, num_classes, X_train, y_train, X_valid, y_valid = load_mnist_shard(
-             shard_num=int(data_path), **kwargs
-         )
- 
-         self.X_train = X_train
-         self.y_train = y_train
-         self.X_valid = X_valid
-         self.y_valid = y_valid
- 
-         self.num_classes = num_classes
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_cnn_with_compression/.workspace ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_with_compression/.workspace
*** ./openfl/openfl-workspace/keras_cnn_with_compression/.workspace	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_cnn_with_compression/.workspace	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- current_plan_name: default
- 
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_nlp/plan/cols.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp/plan/cols.yaml
*** ./openfl/openfl-workspace/keras_nlp/plan/cols.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp/plan/cols.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,5 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- collaborators:
-   
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_nlp/plan/data.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp/plan/data.yaml
*** ./openfl/openfl-workspace/keras_nlp/plan/data.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp/plan/data.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,7 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- # collaborator_name,data_directory_path
- one,1
- 
-   
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_nlp/plan/plan.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp/plan/plan.yaml
*** ./openfl/openfl-workspace/keras_nlp/plan/plan.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp/plan/plan.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,47 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- aggregator :
-   defaults : plan/defaults/aggregator.yaml
-   template : openfl.component.Aggregator
-   settings :
-     init_state_path : save/keras_nlp_init.pbuf
-     best_state_path : save/keras_nlp_best.pbuf
-     last_state_path : save/keras_nlp_last.pbuf
-     rounds_to_train : 10
- 
- collaborator :
-   defaults : plan/defaults/collaborator.yaml
-   template : openfl.component.Collaborator
-   settings :
-     epochs_per_round : 10
-     polling_interval : 4
-     delta_updates    : false
-     opt_treatment    : RESET
- 
- data_loader :
-   defaults : plan/defaults/data_loader.yaml
-   template : src.nlp_dataloader.NLPDataLoader
-   settings :
-     collaborator_count : 2
-     batch_size         : 64
-     split_ratio: 0.2
-     num_samples: 10000
- 
- task_runner :
-   defaults : plan/defaults/task_runner.yaml
-   template : src.nlp_taskrunner.KerasNLP
-   settings :
-     latent_dim : 256
- 
- network :
-   defaults : plan/defaults/network.yaml
- 
- assigner :
-   defaults : plan/defaults/assigner.yaml
- 
- tasks :
-   defaults : plan/defaults/tasks_keras.yaml
- 
- compression_pipeline :
-   defaults : plan/defaults/compression_pipeline.yaml
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_nlp/requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp/requirements.txt
*** ./openfl/openfl-workspace/keras_nlp/requirements.txt	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp/requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1 ****
- tensorflow==2.7.0
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_nlp/src/dataloader_utils.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp/src/dataloader_utils.py
*** ./openfl/openfl-workspace/keras_nlp/src/dataloader_utils.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp/src/dataloader_utils.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,221 ****
- """Copyright (C) 2020-2021 Intel Corporation
-    SPDX-License-Identifier: Apache-2.0
- 
- Licensed subject to the terms of the separately executed evaluation
- license agreement between Intel Corporation and you.
- """
- from logging import getLogger
- from os import getcwd
- from os import path
- from os import remove
- from zipfile import ZipFile
- 
- import numpy as np
- import requests
- 
- logger = getLogger(__name__)
- 
- 
- def download_data_():
-     """Download data.
- 
-     Returns:
-       string: relative path to data file
-     """
-     pkg = 'fra-eng.zip'   # Language file: change this to change the language
-     data_dir = 'data'
-     url = 'http://www.manythings.org/anki/' + pkg
-     filename = pkg.split('-')[0] + '.txt'
- 
-     workspace_dir = getcwd()
-     default_path = path.join(workspace_dir, data_dir)
-     pkgpath = path.join(default_path, pkg)       # path to downloaded zipfile
-     filepath = path.join(default_path, filename)  # path to extracted file
- 
-     if path.isfile(filepath):
-         return path.join(data_dir, filename)
-     try:
-         response = requests.get(url, headers={'User-Agent': 'openfl'})
-         if response.status_code == 200:
-             with open(pkgpath, 'wb') as f:
-                 f.write(response.content)
-         else:
-             print(f'Error while downloading {pkg} from {url}: Aborting!')
-             exit()
-     except Exception:
-         print(f'Error while downloading {pkg} from {url}: Aborting!')
-         exit()
- 
-     try:
-         with ZipFile(pkgpath, 'r') as z:
-             z.extract(filename, default_path)
-     except Exception:
-         print(f'Error while extracting {pkgpath}: Aborting!')
-         exit()
- 
-     if path.isfile(filepath):
-         remove(pkgpath)
-         return path.join(data_dir, filename)
-     else:
-         return ''
- 
- 
- def import_raw_data_(data_path='', num_samples=0):
-     """Import data.
- 
-     Returns:
-       dict: variable details
-       numpy.ndarray: encoder input data
-       numpy.ndarray: decoder input data
-       numpy.ndarray: decoder labels
-     """
-     # Vectorize the data.
-     input_texts = []
-     target_texts = []
-     input_characters = set()
-     target_characters = set()
-     with open(data_path, 'r', encoding='utf-8') as f:
-         lines = f.read().split('\n')
-     for line in lines[: min(num_samples, len(lines) - 1)]:
-         input_text, target_text, _ = line.split('\t')
-         # We use 'tab' as the 'start sequence' character
-         # for the targets, and '\n' as 'end sequence' character.
-         target_text = '\t' + target_text + '\n'
-         input_texts.append(input_text)
-         target_texts.append(target_text)
-         for char in input_text:
-             if char not in input_characters:
-                 input_characters.add(char)
-         for char in target_text:
-             if char not in target_characters:
-                 target_characters.add(char)
- 
-     input_characters = sorted(input_characters)
-     target_characters = sorted(target_characters)
-     num_encoder_tokens = len(input_characters)
-     num_decoder_tokens = len(target_characters)
-     max_encoder_seq_length = max([len(txt) for txt in input_texts])
-     max_decoder_seq_length = max([len(txt) for txt in target_texts])
- 
-     details = {'num_samples': len(input_texts),
-                'num_encoder_tokens': num_encoder_tokens,
-                'num_decoder_tokens': num_decoder_tokens,
-                'max_encoder_seq_length': max_encoder_seq_length,
-                'max_decoder_seq_length': max_decoder_seq_length}
- 
-     input_token_index = {char: i for i, char in enumerate(input_characters)}
-     target_token_index = {char: i for i, char in enumerate(target_characters)}
- 
-     encoder_input_data = np.zeros(
-         (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype='float32')
- 
-     decoder_input_data = np.zeros(
-         (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')
- 
-     decoder_target_data = np.zeros(
-         (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')
- 
-     for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):
-         for t, char in enumerate(input_text):
-             encoder_input_data[i, t, input_token_index[char]] = 1.0
-         encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.0
-         for t, char in enumerate(target_text):
-             # decoder_target_data is ahead of decoder_input_data by one timestep
-             decoder_input_data[i, t, target_token_index[char]] = 1.0
-             if t > 0:
-                 # decoder_target_data will be ahead by one timestep
-                 # and will not include the start character.
-                 decoder_target_data[i, t - 1, target_token_index[char]] = 1.0
-         decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.0
-         decoder_target_data[i, t:, target_token_index[' ']] = 1.0
- 
-     logger.info(f'[DL]-import_raw_data: Number of samples = {len(input_texts)}')
-     logger.info(f'[DL]-import_raw_data: Number of unique input tokens = {num_encoder_tokens}')
-     logger.info(f'[DL]-import_raw_data: '
-                 f'Number of unique decoder tokens = {num_decoder_tokens}')
- 
-     logger.info(f'[DL]-import_raw_data: '
-                 f'Max sequence length for inputs = {max_encoder_seq_length}')
- 
-     logger.info(f'[DL]-import_raw_data: '
-                 f'Max sequence length for outputs = {max_decoder_seq_length}')
- 
-     logger.info(f'[DL]-import_raw_data: encoder_input_data = {encoder_input_data.shape}')
-     logger.info(f'[DL]-import_raw_data: decoder_input_data = {decoder_input_data.shape}')
-     logger.info(f'[DL]-import_raw_data: decoder_target_data = {decoder_target_data.shape}')
- 
-     return details, encoder_input_data, decoder_input_data, decoder_target_data
- 
- 
- def get_datasets_(encoder_input_data, decoder_input_data,
-                   decoder_target_data, num_samples, split_ratio):
-     """Create train/val.
- 
-     Returns:
-       dict: Results, containing the train-valid split of the dataset (split_ratio = 0.2)
-     """
-     import random
- 
-     random.seed(42)
-     train_indexes = random.sample(range(num_samples), int(num_samples * (1 - split_ratio)))
-     valid_indexes = np.delete(range(num_samples), train_indexes)
- 
-     # Dataset creation (2 inputs <encoder,decoder>, 1 output <decoder_target>)
-     encoder_train_input = encoder_input_data[train_indexes, :, :]
-     decoder_train_input = decoder_input_data[train_indexes, :, :]
-     decoder_train_labels = decoder_target_data[train_indexes, :, :]
- 
-     encoder_valid_input = encoder_input_data[valid_indexes, :, :]
-     decoder_valid_input = decoder_input_data[valid_indexes, :, :]
-     decoder_valid_labels = decoder_target_data[valid_indexes, :, :]
- 
-     results = {'encoder_train_input': encoder_train_input,
-                'decoder_train_input': decoder_train_input,
-                'decoder_train_labels': decoder_train_labels,
-                'encoder_valid_input': encoder_valid_input,
-                'decoder_valid_input': decoder_valid_input,
-                'decoder_valid_labels': decoder_valid_labels}
- 
-     logger.info(f'[DL]get_datasets: encoder_train_input = {encoder_train_input.shape}')
-     logger.info(f'[DL]get_datasets: decoder_train_labels= {decoder_train_labels.shape}')
- 
-     return results
- 
- 
- def load_shard(collaborator_count, shard_num, data_path, num_samples, split_ratio):
-     """Load data-shards.
- 
-     Returns:
-       Tuple: ( numpy.ndarray: X_train_encoder,
-                numpy.ndarray: X_train_decoder,
-                numpy.ndarray: y_train)
-       Tuple: ( numpy.ndarray: X_valid_encoder,
-                numpy.ndarray: X_valid_decoder,
-                numpy.ndarray: y_valid)
-       Dict: details, from DataLoader_utils.get_datasets
-     """
-     details, encoder_input_data, decoder_input_data, decoder_target_data = import_raw_data_(
-         data_path,
-         num_samples
-     )
- 
-     train_val_dataset = get_datasets_(encoder_input_data, decoder_input_data,
-                                       decoder_target_data, num_samples, split_ratio)
-     # Get the data shards
-     shard_num = int(shard_num)
-     X_train_encoder = train_val_dataset['encoder_train_input'][shard_num::collaborator_count]
-     X_train_decoder = train_val_dataset['decoder_train_input'][shard_num::collaborator_count]
-     y_train = train_val_dataset['decoder_train_labels'][shard_num::collaborator_count]
- 
-     X_valid_encoder = train_val_dataset['encoder_valid_input'][shard_num::collaborator_count]
-     X_valid_decoder = train_val_dataset['decoder_valid_input'][shard_num::collaborator_count]
-     y_valid = train_val_dataset['decoder_valid_labels'][shard_num::collaborator_count]
- 
-     logger.info(f'[DL]load_shard: X_train_encoder = {X_train_encoder.shape}')
-     logger.info(f'[DL]load_shard: y_train = {y_train.shape}')
- 
-     return (
-         (X_train_encoder, X_train_decoder, y_train),
-         (X_valid_encoder, X_valid_decoder, y_valid),
-         details
-     )
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_nlp/src/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp/src/__init__.py
*** ./openfl/openfl-workspace/keras_nlp/src/__init__.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp/src/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """openfl nlp keras template."""
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_nlp/src/nlp_dataloader.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp/src/nlp_dataloader.py
*** ./openfl/openfl-workspace/keras_nlp/src/nlp_dataloader.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp/src/nlp_dataloader.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,133 ****
- """Copyright (C) 2020-2021 Intel Corporation
-    SPDX-License-Identifier: Apache-2.0
- 
- Licensed subject to the terms of the separately executed evaluation
- license agreement between Intel Corporation and you.
- """
- from logging import getLogger
- 
- import numpy as np
- import src.dataloader_utils as dlu
- 
- from openfl.federated import KerasDataLoader
- 
- logger = getLogger(__name__)
- 
- 
- class NLPDataLoader(KerasDataLoader):
-     """NLP Dataloader template."""
- 
-     def __init__(self, collaborator_count, split_ratio,
-                  num_samples, data_path, batch_size, **kwargs):
-         """Instantiate the data object.
- 
-         Args:
-             data_path: The file path to the data Returns:
-             batch_size: The batch size of the data loader tuple: shape of an example feature array
-             **kwargs: Additional arguments, passed to super init and load_mnist_shard
- 
-         Returns:
-            none
-         """
-         self.shard_num = data_path
-         self.data_path = dlu.download_data_()
- 
-         self.batch_size = batch_size
- 
-         train, valid, details = dlu.load_shard(collaborator_count, self.shard_num,
-                                                self.data_path, num_samples, split_ratio)
- 
-         self.num_samples = details['num_samples']
-         self.num_encoder_tokens = details['num_encoder_tokens']
-         self.num_decoder_tokens = details['num_decoder_tokens']
-         self.max_encoder_seq_length = details['max_encoder_seq_length']
-         self.max_decoder_seq_length = details['max_decoder_seq_length']
- 
-         self.X_train = [train[0], train[1]]
-         self.y_train = train[2]
-         self.X_valid = [valid[0], valid[1]]
-         self.y_valid = valid[2]
- 
-     def get_feature_shape(self):
-         """Get the shape of an example feature array."""
-         return self.X_train[0].shape
- 
-     def get_train_loader(self, batch_size=None):
-         """
-         Get training data loader.
- 
-         Returns
-         -------
-         loader object
-         """
-         return self._get_batch_generator(X1=self.X_train[0], X2=self.X_train[1],
-                                          y=self.y_train, batch_size=batch_size)
- 
-     def get_valid_loader(self, batch_size=None):
-         """
-         Get validation data loader.
- 
-         Returns:
-             loader object
-         """
-         return self._get_batch_generator(X1=self.X_valid[0], X2=self.X_valid[1],
-                                          y=self.y_valid, batch_size=batch_size)
- 
-     def get_train_data_size(self):
-         """
-         Get total number of training samples.
- 
-         Returns:
-             int: number of training samples
-         """
-         return self.X_train[0].shape[0]
- 
-     def get_valid_data_size(self):
-         """
-         Get total number of validation samples.
- 
-         Returns:
-             int: number of validation samples
-         """
-         return self.X_valid[0].shape[0]
- 
-     @staticmethod
-     def _batch_generator(X1, X2, y, idxs, batch_size, num_batches):
-         """
-         Generate batch of data.
- 
-         Args:
-             X: input data
-             y: label data
-             idxs: The index of the dataset
-             batch_size: The batch size for the data loader
-             num_batches: The number of batches
-         Yields:
-             tuple: input data, label data
-         """
-         for i in range(num_batches):
-             a = i * batch_size
-             b = a + batch_size
-             yield [X1[idxs[a:b]], X2[idxs[a:b]]], y[idxs[a:b]]
- 
-     def _get_batch_generator(self, X1, X2, y, batch_size):
-         """
-         Return the dataset generator.
- 
-         Args:
-             X1: input data  (encoder)
-             X2: input data  (decoder)
-             y: label data
-             batch_size: The batch size for the data loader
-         """
-         if batch_size is None:
-             batch_size = self.batch_size
-         # shuffle data indices
-         idxs = np.random.permutation(np.arange(X1.shape[0]))
-         # compute the number of batches
-         num_batches = int(np.ceil(X1.shape[0] / batch_size))
-         # build the generator and return it
-         # TODO: due to _batch_generator(X1, ...) has first param X1, all params here will be moved,
-         #       X1 -> X2, X2 -> y, y -> idxs, idxs -> batch_size, batch_size -> num_batches,
-         #       and num_batches -> should be unexpected in this function
-         return self._batch_generator(X1, X2, y, idxs, batch_size, num_batches)
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_nlp/src/nlp_taskrunner.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp/src/nlp_taskrunner.py
*** ./openfl/openfl-workspace/keras_nlp/src/nlp_taskrunner.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp/src/nlp_taskrunner.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,73 ****
- """Copyright (C) 2020-2021 Intel Corporation
-    SPDX-License-Identifier: Apache-2.0
- 
- Licensed subject to the terms of the separately executed evaluation
- license agreement between Intel Corporation and you.
- """
- from tensorflow import keras
- 
- from openfl.federated import KerasTaskRunner
- 
- 
- def build_model(latent_dim, num_encoder_tokens, num_decoder_tokens, **kwargs):
-     """
-     Define the model architecture.
- 
-     Args:
-         input_shape (numpy.ndarray): The shape of the data
-         num_classes (int): The number of classes of the dataset
-     Returns:
-         tensorflow.python.keras.engine.sequential.Sequential: The model defined in Keras
-     """
-     encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))
-     encoder = keras.layers.LSTM(latent_dim, return_state=True)
-     encoder_outputs, state_h, state_c = encoder(encoder_inputs)
- 
-     # We discard `encoder_outputs` and only keep the states.
-     encoder_states = [state_h, state_c]
- 
-     # Set up the decoder, using `encoder_states` as initial state.
-     decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))
- 
-     # We set up our decoder to return full output sequences,
-     # and to return internal states as well. We don't use the
-     # return states in the training model, but we will use them in inference.
-     decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)
-     decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)
-     decoder_dense = keras.layers.Dense(num_decoder_tokens, activation='softmax')
-     decoder_outputs = decoder_dense(decoder_outputs)
- 
-     # Define the model that will turn
-     # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`
-     model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)
- 
-     model.compile(
-         optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy']
-     )
- 
-     return model
- 
- 
- class KerasNLP(KerasTaskRunner):
-     """A basic convolutional neural network model."""
- 
-     def __init__(self, latent_dim, **kwargs):
-         """
-         Init taskrunner.
- 
-         Args:
-             **kwargs: Additional parameters to pass to the function
-         """
-         super().__init__(**kwargs)
- 
-         self.model = build_model(latent_dim,
-                                  self.data_loader.num_encoder_tokens,
-                                  self.data_loader.num_decoder_tokens,
-                                  **kwargs)
- 
-         self.initialize_tensorkeys_for_functions()
- 
-         self.model.summary(print_fn=self.logger.info)
- 
-         if self.data_loader is not None:
-             self.logger.info(f'Train Set Size : {self.get_train_data_size()}')
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_nlp/.workspace ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp/.workspace
*** ./openfl/openfl-workspace/keras_nlp/.workspace	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp/.workspace	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- current_plan_name: default
- 
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_nlp_gramine_ready/plan/cols.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp_gramine_ready/plan/cols.yaml
*** ./openfl/openfl-workspace/keras_nlp_gramine_ready/plan/cols.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp_gramine_ready/plan/cols.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,5 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- collaborators:
-   
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_nlp_gramine_ready/plan/data.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp_gramine_ready/plan/data.yaml
*** ./openfl/openfl-workspace/keras_nlp_gramine_ready/plan/data.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp_gramine_ready/plan/data.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,7 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- # collaborator_name,data_directory_path
- one,1
- 
-   
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_nlp_gramine_ready/plan/plan.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp_gramine_ready/plan/plan.yaml
*** ./openfl/openfl-workspace/keras_nlp_gramine_ready/plan/plan.yaml	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp_gramine_ready/plan/plan.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,47 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- aggregator :
-   defaults : plan/defaults/aggregator.yaml
-   template : openfl.component.Aggregator
-   settings :
-     init_state_path : save/keras_nlp_init.pbuf
-     best_state_path : save/keras_nlp_best.pbuf
-     last_state_path : save/keras_nlp_last.pbuf
-     rounds_to_train : 10
- 
- collaborator :
-   defaults : plan/defaults/collaborator.yaml
-   template : openfl.component.Collaborator
-   settings :
-     epochs_per_round : 10
-     polling_interval : 4
-     delta_updates    : false
-     opt_treatment    : RESET
- 
- data_loader :
-   defaults : plan/defaults/data_loader.yaml
-   template : src.nlp_dataloader.NLPDataLoader
-   settings :
-     collaborator_count : 2
-     batch_size         : 64
-     split_ratio: 0.2
-     num_samples: 10000
- 
- task_runner :
-   defaults : plan/defaults/task_runner.yaml
-   template : src.nlp_taskrunner.KerasNLP
-   settings :
-     latent_dim : 256
- 
- network :
-   defaults : plan/defaults/network.yaml
- 
- assigner :
-   defaults : plan/defaults/assigner.yaml
- 
- tasks :
-   defaults : plan/defaults/tasks_keras.yaml
- 
- compression_pipeline :
-   defaults : plan/defaults/compression_pipeline.yaml
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_nlp_gramine_ready/requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp_gramine_ready/requirements.txt
*** ./openfl/openfl-workspace/keras_nlp_gramine_ready/requirements.txt	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp_gramine_ready/requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1 ****
- tensorflow-cpu==2.7.0
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_nlp_gramine_ready/src/dataloader_utils.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp_gramine_ready/src/dataloader_utils.py
*** ./openfl/openfl-workspace/keras_nlp_gramine_ready/src/dataloader_utils.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp_gramine_ready/src/dataloader_utils.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,221 ****
- """Copyright (C) 2020-2021 Intel Corporation
-    SPDX-License-Identifier: Apache-2.0
- 
- Licensed subject to the terms of the separately executed evaluation
- license agreement between Intel Corporation and you.
- """
- from logging import getLogger
- from os import getcwd
- from os import path
- from os import remove
- from zipfile import ZipFile
- 
- import numpy as np
- import requests
- 
- logger = getLogger(__name__)
- 
- 
- def download_data_():
-     """Download data.
- 
-     Returns:
-       string: relative path to data file
-     """
-     pkg = 'fra-eng.zip'   # Language file: change this to change the language
-     data_dir = 'data'
-     url = 'http://www.manythings.org/anki/' + pkg
-     filename = pkg.split('-')[0] + '.txt'
- 
-     workspace_dir = getcwd()
-     default_path = path.join(workspace_dir, data_dir)
-     pkgpath = path.join(default_path, pkg)       # path to downloaded zipfile
-     filepath = path.join(default_path, filename)  # path to extracted file
- 
-     if path.isfile(filepath):
-         return path.join(data_dir, filename)
-     try:
-         response = requests.get(url, headers={'User-Agent': 'openfl'})
-         if response.status_code == 200:
-             with open(pkgpath, 'wb') as f:
-                 f.write(response.content)
-         else:
-             print(f'Error while downloading {pkg} from {url}: Aborting!')
-             exit()
-     except Exception:
-         print(f'Error while downloading {pkg} from {url}: Aborting!')
-         exit()
- 
-     try:
-         with ZipFile(pkgpath, 'r') as z:
-             z.extract(filename, default_path)
-     except Exception:
-         print(f'Error while extracting {pkgpath}: Aborting!')
-         exit()
- 
-     if path.isfile(filepath):
-         remove(pkgpath)
-         return path.join(data_dir, filename)
-     else:
-         return ''
- 
- 
- def import_raw_data_(data_path='', num_samples=0):
-     """Import data.
- 
-     Returns:
-       dict: variable details
-       numpy.ndarray: encoder input data
-       numpy.ndarray: decoder input data
-       numpy.ndarray: decoder labels
-     """
-     # Vectorize the data.
-     input_texts = []
-     target_texts = []
-     input_characters = set()
-     target_characters = set()
-     with open(data_path, 'r', encoding='utf-8') as f:
-         lines = f.read().split('\n')
-     for line in lines[: min(num_samples, len(lines) - 1)]:
-         input_text, target_text, _ = line.split('\t')
-         # We use 'tab' as the 'start sequence' character
-         # for the targets, and '\n' as 'end sequence' character.
-         target_text = '\t' + target_text + '\n'
-         input_texts.append(input_text)
-         target_texts.append(target_text)
-         for char in input_text:
-             if char not in input_characters:
-                 input_characters.add(char)
-         for char in target_text:
-             if char not in target_characters:
-                 target_characters.add(char)
- 
-     input_characters = sorted(input_characters)
-     target_characters = sorted(target_characters)
-     num_encoder_tokens = len(input_characters)
-     num_decoder_tokens = len(target_characters)
-     max_encoder_seq_length = max([len(txt) for txt in input_texts])
-     max_decoder_seq_length = max([len(txt) for txt in target_texts])
- 
-     details = {'num_samples': len(input_texts),
-                'num_encoder_tokens': num_encoder_tokens,
-                'num_decoder_tokens': num_decoder_tokens,
-                'max_encoder_seq_length': max_encoder_seq_length,
-                'max_decoder_seq_length': max_decoder_seq_length}
- 
-     input_token_index = {char: i for i, char in enumerate(input_characters)}
-     target_token_index = {char: i for i, char in enumerate(target_characters)}
- 
-     encoder_input_data = np.zeros(
-         (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype='float32')
- 
-     decoder_input_data = np.zeros(
-         (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')
- 
-     decoder_target_data = np.zeros(
-         (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')
- 
-     for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):
-         for t, char in enumerate(input_text):
-             encoder_input_data[i, t, input_token_index[char]] = 1.0
-         encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.0
-         for t, char in enumerate(target_text):
-             # decoder_target_data is ahead of decoder_input_data by one timestep
-             decoder_input_data[i, t, target_token_index[char]] = 1.0
-             if t > 0:
-                 # decoder_target_data will be ahead by one timestep
-                 # and will not include the start character.
-                 decoder_target_data[i, t - 1, target_token_index[char]] = 1.0
-         decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.0
-         decoder_target_data[i, t:, target_token_index[' ']] = 1.0
- 
-     logger.info(f'[DL]-import_raw_data: Number of samples = {len(input_texts)}')
-     logger.info(f'[DL]-import_raw_data: Number of unique input tokens = {num_encoder_tokens}')
-     logger.info(f'[DL]-import_raw_data: '
-                 f'Number of unique decoder tokens = {num_decoder_tokens}')
- 
-     logger.info(f'[DL]-import_raw_data: '
-                 f'Max sequence length for inputs = {max_encoder_seq_length}')
- 
-     logger.info(f'[DL]-import_raw_data: '
-                 f'Max sequence length for outputs = {max_decoder_seq_length}')
- 
-     logger.info(f'[DL]-import_raw_data: encoder_input_data = {encoder_input_data.shape}')
-     logger.info(f'[DL]-import_raw_data: decoder_input_data = {decoder_input_data.shape}')
-     logger.info(f'[DL]-import_raw_data: decoder_target_data = {decoder_target_data.shape}')
- 
-     return details, encoder_input_data, decoder_input_data, decoder_target_data
- 
- 
- def get_datasets_(encoder_input_data, decoder_input_data,
-                   decoder_target_data, num_samples, split_ratio):
-     """Create train/val.
- 
-     Returns:
-       dict: Results, containing the train-valid split of the dataset (split_ratio = 0.2)
-     """
-     import random
- 
-     random.seed(42)
-     train_indexes = random.sample(range(num_samples), int(num_samples * (1 - split_ratio)))
-     valid_indexes = np.delete(range(num_samples), train_indexes)
- 
-     # Dataset creation (2 inputs <encoder,decoder>, 1 output <decoder_target>)
-     encoder_train_input = encoder_input_data[train_indexes, :, :]
-     decoder_train_input = decoder_input_data[train_indexes, :, :]
-     decoder_train_labels = decoder_target_data[train_indexes, :, :]
- 
-     encoder_valid_input = encoder_input_data[valid_indexes, :, :]
-     decoder_valid_input = decoder_input_data[valid_indexes, :, :]
-     decoder_valid_labels = decoder_target_data[valid_indexes, :, :]
- 
-     results = {'encoder_train_input': encoder_train_input,
-                'decoder_train_input': decoder_train_input,
-                'decoder_train_labels': decoder_train_labels,
-                'encoder_valid_input': encoder_valid_input,
-                'decoder_valid_input': decoder_valid_input,
-                'decoder_valid_labels': decoder_valid_labels}
- 
-     logger.info(f'[DL]get_datasets: encoder_train_input = {encoder_train_input.shape}')
-     logger.info(f'[DL]get_datasets: decoder_train_labels= {decoder_train_labels.shape}')
- 
-     return results
- 
- 
- def load_shard(collaborator_count, shard_num, data_path, num_samples, split_ratio):
-     """Load data-shards.
- 
-     Returns:
-       Tuple: ( numpy.ndarray: X_train_encoder,
-                numpy.ndarray: X_train_decoder,
-                numpy.ndarray: y_train)
-       Tuple: ( numpy.ndarray: X_valid_encoder,
-                numpy.ndarray: X_valid_decoder,
-                numpy.ndarray: y_valid)
-       Dict: details, from DataLoader_utils.get_datasets
-     """
-     details, encoder_input_data, decoder_input_data, decoder_target_data = import_raw_data_(
-         data_path,
-         num_samples
-     )
- 
-     train_val_dataset = get_datasets_(encoder_input_data, decoder_input_data,
-                                       decoder_target_data, num_samples, split_ratio)
-     # Get the data shards
-     shard_num = int(shard_num)
-     X_train_encoder = train_val_dataset['encoder_train_input'][shard_num::collaborator_count]
-     X_train_decoder = train_val_dataset['decoder_train_input'][shard_num::collaborator_count]
-     y_train = train_val_dataset['decoder_train_labels'][shard_num::collaborator_count]
- 
-     X_valid_encoder = train_val_dataset['encoder_valid_input'][shard_num::collaborator_count]
-     X_valid_decoder = train_val_dataset['decoder_valid_input'][shard_num::collaborator_count]
-     y_valid = train_val_dataset['decoder_valid_labels'][shard_num::collaborator_count]
- 
-     logger.info(f'[DL]load_shard: X_train_encoder = {X_train_encoder.shape}')
-     logger.info(f'[DL]load_shard: y_train = {y_train.shape}')
- 
-     return (
-         (X_train_encoder, X_train_decoder, y_train),
-         (X_valid_encoder, X_valid_decoder, y_valid),
-         details
-     )
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_nlp_gramine_ready/src/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp_gramine_ready/src/__init__.py
*** ./openfl/openfl-workspace/keras_nlp_gramine_ready/src/__init__.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp_gramine_ready/src/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """openfl nlp keras template."""
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_nlp_gramine_ready/src/nlp_dataloader.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp_gramine_ready/src/nlp_dataloader.py
*** ./openfl/openfl-workspace/keras_nlp_gramine_ready/src/nlp_dataloader.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp_gramine_ready/src/nlp_dataloader.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,133 ****
- """Copyright (C) 2020-2021 Intel Corporation
-    SPDX-License-Identifier: Apache-2.0
- 
- Licensed subject to the terms of the separately executed evaluation
- license agreement between Intel Corporation and you.
- """
- from logging import getLogger
- 
- import numpy as np
- import src.dataloader_utils as dlu
- 
- from openfl.federated import KerasDataLoader
- 
- logger = getLogger(__name__)
- 
- 
- class NLPDataLoader(KerasDataLoader):
-     """NLP Dataloader template."""
- 
-     def __init__(self, collaborator_count, split_ratio,
-                  num_samples, data_path, batch_size, **kwargs):
-         """Instantiate the data object.
- 
-         Args:
-             data_path: The file path to the data Returns:
-             batch_size: The batch size of the data loader tuple: shape of an example feature array
-             **kwargs: Additional arguments, passed to super init and load_mnist_shard
- 
-         Returns:
-            none
-         """
-         self.shard_num = data_path
-         self.data_path = dlu.download_data_()
- 
-         self.batch_size = batch_size
- 
-         train, valid, details = dlu.load_shard(collaborator_count, self.shard_num,
-                                                self.data_path, num_samples, split_ratio)
- 
-         self.num_samples = details['num_samples']
-         self.num_encoder_tokens = details['num_encoder_tokens']
-         self.num_decoder_tokens = details['num_decoder_tokens']
-         self.max_encoder_seq_length = details['max_encoder_seq_length']
-         self.max_decoder_seq_length = details['max_decoder_seq_length']
- 
-         self.X_train = [train[0], train[1]]
-         self.y_train = train[2]
-         self.X_valid = [valid[0], valid[1]]
-         self.y_valid = valid[2]
- 
-     def get_feature_shape(self):
-         """Get the shape of an example feature array."""
-         return self.X_train[0].shape
- 
-     def get_train_loader(self, batch_size=None):
-         """
-         Get training data loader.
- 
-         Returns
-         -------
-         loader object
-         """
-         return self._get_batch_generator(X1=self.X_train[0], X2=self.X_train[1],
-                                          y=self.y_train, batch_size=batch_size)
- 
-     def get_valid_loader(self, batch_size=None):
-         """
-         Get validation data loader.
- 
-         Returns:
-             loader object
-         """
-         return self._get_batch_generator(X1=self.X_valid[0], X2=self.X_valid[1],
-                                          y=self.y_valid, batch_size=batch_size)
- 
-     def get_train_data_size(self):
-         """
-         Get total number of training samples.
- 
-         Returns:
-             int: number of training samples
-         """
-         return self.X_train[0].shape[0]
- 
-     def get_valid_data_size(self):
-         """
-         Get total number of validation samples.
- 
-         Returns:
-             int: number of validation samples
-         """
-         return self.X_valid[0].shape[0]
- 
-     @staticmethod
-     def _batch_generator(X1, X2, y, idxs, batch_size, num_batches):
-         """
-         Generate batch of data.
- 
-         Args:
-             X: input data
-             y: label data
-             idxs: The index of the dataset
-             batch_size: The batch size for the data loader
-             num_batches: The number of batches
-         Yields:
-             tuple: input data, label data
-         """
-         for i in range(num_batches):
-             a = i * batch_size
-             b = a + batch_size
-             yield [X1[idxs[a:b]], X2[idxs[a:b]]], y[idxs[a:b]]
- 
-     def _get_batch_generator(self, X1, X2, y, batch_size):
-         """
-         Return the dataset generator.
- 
-         Args:
-             X1: input data  (encoder)
-             X2: input data  (decoder)
-             y: label data
-             batch_size: The batch size for the data loader
-         """
-         if batch_size is None:
-             batch_size = self.batch_size
-         # shuffle data indices
-         idxs = np.random.permutation(np.arange(X1.shape[0]))
-         # compute the number of batches
-         num_batches = int(np.ceil(X1.shape[0] / batch_size))
-         # build the generator and return it
-         # TODO: due to _batch_generator(X1, ...) has first param X1, all params here will be moved,
-         #       X1 -> X2, X2 -> y, y -> idxs, idxs -> batch_size, batch_size -> num_batches,
-         #       and num_batches -> should be unexpected in this function
-         return self._batch_generator(X1, X2, y, idxs, batch_size, num_batches)
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_nlp_gramine_ready/src/nlp_taskrunner.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp_gramine_ready/src/nlp_taskrunner.py
*** ./openfl/openfl-workspace/keras_nlp_gramine_ready/src/nlp_taskrunner.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp_gramine_ready/src/nlp_taskrunner.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,73 ****
- """Copyright (C) 2020-2021 Intel Corporation
-    SPDX-License-Identifier: Apache-2.0
- 
- Licensed subject to the terms of the separately executed evaluation
- license agreement between Intel Corporation and you.
- """
- from tensorflow import keras
- 
- from openfl.federated import KerasTaskRunner
- 
- 
- def build_model(latent_dim, num_encoder_tokens, num_decoder_tokens, **kwargs):
-     """
-     Define the model architecture.
- 
-     Args:
-         input_shape (numpy.ndarray): The shape of the data
-         num_classes (int): The number of classes of the dataset
-     Returns:
-         tensorflow.python.keras.engine.sequential.Sequential: The model defined in Keras
-     """
-     encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))
-     encoder = keras.layers.LSTM(latent_dim, return_state=True)
-     encoder_outputs, state_h, state_c = encoder(encoder_inputs)
- 
-     # We discard `encoder_outputs` and only keep the states.
-     encoder_states = [state_h, state_c]
- 
-     # Set up the decoder, using `encoder_states` as initial state.
-     decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))
- 
-     # We set up our decoder to return full output sequences,
-     # and to return internal states as well. We don't use the
-     # return states in the training model, but we will use them in inference.
-     decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)
-     decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)
-     decoder_dense = keras.layers.Dense(num_decoder_tokens, activation='softmax')
-     decoder_outputs = decoder_dense(decoder_outputs)
- 
-     # Define the model that will turn
-     # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`
-     model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)
- 
-     model.compile(
-         optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy']
-     )
- 
-     return model
- 
- 
- class KerasNLP(KerasTaskRunner):
-     """A basic convolutional neural network model."""
- 
-     def __init__(self, latent_dim, **kwargs):
-         """
-         Init taskrunner.
- 
-         Args:
-             **kwargs: Additional parameters to pass to the function
-         """
-         super().__init__(**kwargs)
- 
-         self.model = build_model(latent_dim,
-                                  self.data_loader.num_encoder_tokens,
-                                  self.data_loader.num_decoder_tokens,
-                                  **kwargs)
- 
-         self.initialize_tensorkeys_for_functions()
- 
-         self.model.summary(print_fn=self.logger.info)
- 
-         if self.data_loader is not None:
-             self.logger.info(f'Train Set Size : {self.get_train_data_size()}')
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/keras_nlp_gramine_ready/.workspace ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp_gramine_ready/.workspace
*** ./openfl/openfl-workspace/keras_nlp_gramine_ready/.workspace	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/keras_nlp_gramine_ready/.workspace	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- current_plan_name: default
- 
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_2dunet/plan/cols.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_2dunet/plan/cols.yaml
*** ./openfl/openfl-workspace/tf_2dunet/plan/cols.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_2dunet/plan/cols.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- collaborators:
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_2dunet/plan/data.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_2dunet/plan/data.yaml
*** ./openfl/openfl-workspace/tf_2dunet/plan/data.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_2dunet/plan/data.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,8 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- # all keys under 'collaborators' corresponds to a specific colaborator name the corresponding dictionary has data_name, data_path pairs.
- # Note that in the mnist case we do not store the data locally, and the data_path is used to pass an integer that helps the data object
- # construct the shard of the mnist dataset to be use for this collaborator.
- one,/raid/datasets/MICCAI_BraTS_2019_Data_Training/HGG/0
- two,/raid/datasets/MICCAI_BraTS_2019_Data_Training/HGG/1
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_2dunet/plan/defaults ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_2dunet/plan/defaults
*** ./openfl/openfl-workspace/tf_2dunet/plan/defaults	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_2dunet/plan/defaults	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- ../../workspace/plan/defaults
- 
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_2dunet/plan/plan.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_2dunet/plan/plan.yaml
*** ./openfl/openfl-workspace/tf_2dunet/plan/plan.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_2dunet/plan/plan.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,44 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- aggregator :
-   defaults : plan/defaults/aggregator.yaml
-   template : openfl.component.Aggregator
-   settings :
-     init_state_path : save/tf_2dunet_brats_init.pbuf
-     last_state_path : save/tf_2dunet_brats_latest.pbuf
-     best_state_path : save/tf_2dunet_brats_best.pbuf
-     rounds_to_train : 10
-     db_store_rounds : 2
- 
- collaborator :
-   defaults : plan/defaults/collaborator.yaml
-   template : openfl.component.Collaborator
-   settings :
-     delta_updates    : true
-     opt_treatment    : RESET
- 
- data_loader :
-   defaults : plan/defaults/data_loader.yaml
-   template : src.tfbrats_inmemory.TensorFlowBratsInMemory
-   settings :
-     batch_size: 64
-     percent_train: 0.8
-     collaborator_count : 2
-     data_group_name    : brats
- 
- task_runner :
-   defaults : plan/defaults/task_runner.yaml
-   template : src.tf_2dunet.TensorFlow2DUNet
- 
- network :
-   defaults : plan/defaults/network.yaml
- 
- assigner :
-   defaults : plan/defaults/assigner.yaml
- 
- tasks :
-   defaults : plan/defaults/tasks_tensorflow.yaml
- 
- compression_pipeline :
-   defaults : plan/defaults/compression_pipeline.yaml
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_2dunet/README.md ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_2dunet/README.md
*** ./openfl/openfl-workspace/tf_2dunet/README.md	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_2dunet/README.md	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,44 ****
- Running steps:
- 1) Download and extract data to any folder (`$DATA_PATH`). The output of `tree $DATA_PATH -L 2`:
- ```
- .
- ├── MICCAI_BraTS_2019_Data_Training
- │   ├── HGG
- │   ├── LGG
- │   ├── name_mapping.csv
- │   └── survival_data.csv
- ```
- To use a `tree` command, you have to install it first: `sudo apt-get install tree`
- 
- 2) Choose a subfolder (`$SUBFOLDER`) corresponding to scan subset: 
-     - `HGG`: glioblastoma scans
-     - `LGG`: lower grade glioma scans
-  
- Let's pick `HGG`: `export SUBFOLDER=HGG`. The learning rate has been already tuned for this task, so you don't have to change it. If you pick `LGG`, all the next steps will be the same.
- 
- 3) In order for each collaborator to use separate slice of data, we split main folder into `n` subfolders:
- ```bash
- cd $DATA_PATH/$SUBFOLDER
- i=0; 
- for f in *; 
- do 
-     d=dir_$(printf $((i%n)));  # change n to number of data slices (number of collaborators in federation)
-     mkdir -p $d; 
-     mv "$f" $d; 
-     let i++; 
- done
- ```
- Output of `tree $DATA_PATH/$SUBFOLDER -L 1` in case when `n = 2`:
- ```
- .
- ├── 0
- └── 1
- ```
- If BraTS20 has the same structure, we can split it in the same way.
- Each slice contains subdirectories containing `*.nii.gz` files. According to `load_from_NIfTI` function [docstring](https://github.com/intel/openfl/blob/2e6680fedcd4d99363c94792c4a9cc272e4eebc0/openfl-workspace/tf_2dunet/src/brats_utils.py#L68), `NIfTI files for whole brains are assumed to be contained in subdirectories of the parent directory`. So we can use these slice folders as collaborator data paths.
- 
- 4) We are ready to train! Try executing the [Hello Federation](https://openfl.readthedocs.io/en/latest/running_the_federation.baremetal.html#hello-federation-your-first-federated-learning-training) steps. Make sure you have `openfl` installed in your Python virtual environment. All you have to do is to specify collaborator data paths to slice folders. We have combined all 'Hello Federation' steps in a single bash script, so it is easier to test:
- ```bash
- bash tests/github/test_hello_federation.sh tf_2dunet fed_work12345alpha81671 one123dragons beta34unicorns localhost --col1-data-path $DATA_PATH/MICCAI_BraTS_2019_Data_Training/$SUBFOLDER/0 --col2-data-path $DATA_PATH/MICCAI_BraTS_2019_Data_Training/$SUBFOLDER/1 --rounds-to-train 5
- ```
- The result of the execution of the command above is 5 completed training rounds. 
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_2dunet/requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_2dunet/requirements.txt
*** ./openfl/openfl-workspace/tf_2dunet/requirements.txt	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_2dunet/requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- nibabel
- tensorflow==2.7.0
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_2dunet/src/brats_utils.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_2dunet/src/brats_utils.py
*** ./openfl/openfl-workspace/tf_2dunet/src/brats_utils.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_2dunet/src/brats_utils.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,137 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """You may copy this file as the starting point of your own model."""
- 
- import logging
- import os
- 
- import numpy as np
- 
- from .nii_reader import nii_reader
- 
- logger = logging.getLogger(__name__)
- 
- 
- def train_val_split(features, labels, percent_train, shuffle):
-     """Train/validation splot of the BraTS dataset.
- 
-     Splits incoming feature and labels into training and validation. The value
-     of shuffle determines whether shuffling occurs before the split is performed.
- 
-     Args:
-         features: The input images
-         labels: The ground truth labels
-         percent_train (float): The percentage of the dataset that is training.
-         shuffle (bool): True = shuffle the dataset before the split
- 
-     Returns:
-         train_features: The input images for the training dataset
-         train_labels: The ground truth labels for the training dataset
-         val_features: The input images for the validation dataset
-         val_labels: The ground truth labels for the validation dataset
-     """
- 
-     def split(lst, idx):
-         """Split a Python list into 2 lists.
- 
-         Args:
-             lst: The Python list to split
-             idx: The index where to split the list into 2 parts
- 
-         Returns:
-             Two lists
- 
-         """
-         if idx < 0 or idx > len(lst):
-             raise ValueError('split was out of expected range.')
-         return lst[:idx], lst[idx:]
- 
-     nb_features = len(features)
-     nb_labels = len(labels)
-     if nb_features != nb_labels:
-         raise RuntimeError('Number of features and labels do not match.')
-     if shuffle:
-         new_order = np.random.permutation(np.arange(nb_features))
-         features = features[new_order]
-         labels = labels[new_order]
-     split_idx = int(percent_train * nb_features)
-     train_features, val_features = split(lst=features, idx=split_idx)
-     train_labels, val_labels = split(lst=labels, idx=split_idx)
-     return train_features, train_labels, val_features, val_labels
- 
- 
- def load_from_nifti(parent_dir,
-                     percent_train,
-                     shuffle,
-                     channels_last=True,
-                     task='whole_tumor',
-                     **kwargs):
-     """Load the BraTS dataset from the NiFTI file format.
- 
-     Loads data from the parent directory (NIfTI files for whole brains are
-     assumed to be contained in subdirectories of the parent directory).
-     Performs a split of the data into training and validation, and the value
-     of shuffle determined whether shuffling is performed before this split
-     occurs - both split and shuffle are done in a way to
-     keep whole brains intact. The kwargs are passed to nii_reader.
- 
-     Args:
-         parent_dir: The parent directory for the BraTS data
-         percent_train (float): The percentage of the data to make the training dataset
-         shuffle (bool): True means shuffle the dataset order before the split
-         channels_last (bool): Input tensor uses channels as last dimension (Default is True)
-         task: Prediction task (Default is 'whole_tumor' prediction)
-         **kwargs: Variable arguments to pass to the function
- 
-     Returns:
-         train_features: The input images for the training dataset
-         train_labels: The ground truth labels for the training dataset
-         val_features: The input images for the validation dataset
-         val_labels: The ground truth labels for the validation dataset
- 
-     """
-     path = os.path.join(parent_dir)
-     subdirs = os.listdir(path)
-     subdirs.sort()
-     if not subdirs:
-         raise SystemError(f'''{parent_dir} does not contain subdirectories.
- Please make sure you have BraTS dataset downloaded
- and located in data directory for this collaborator.
-         ''')
-     subdir_paths = [os.path.join(path, subdir) for subdir in subdirs]
- 
-     imgs_all = []
-     msks_all = []
-     for brain_path in subdir_paths:
-         these_imgs, these_msks = nii_reader(
-             brain_path=brain_path,
-             task=task,
-             channels_last=channels_last,
-             **kwargs
-         )
-         # the needed files where not present if a tuple of None is returned
-         if these_imgs is None:
-             logger.debug(f'Brain subdirectory: {brain_path} did not contain the needed files.')
-         else:
-             imgs_all.append(these_imgs)
-             msks_all.append(these_msks)
- 
-     # converting to arrays to allow for numpy indexing used during split
-     imgs_all = np.array(imgs_all)
-     msks_all = np.array(msks_all)
- 
-     # note here that each is a list of 155 slices per brain, and so the
-     # split keeps brains intact
-     imgs_all_train, msks_all_train, imgs_all_val, msks_all_val = train_val_split(
-         features=imgs_all,
-         labels=msks_all,
-         percent_train=percent_train,
-         shuffle=shuffle
-     )
-     # now concatenate the lists
-     imgs_train = np.concatenate(imgs_all_train, axis=0)
-     msks_train = np.concatenate(msks_all_train, axis=0)
-     imgs_val = np.concatenate(imgs_all_val, axis=0)
-     msks_val = np.concatenate(msks_all_val, axis=0)
- 
-     return imgs_train, msks_train, imgs_val, msks_val
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_2dunet/src/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_2dunet/src/__init__.py
*** ./openfl/openfl-workspace/tf_2dunet/src/__init__.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_2dunet/src/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """You may copy this file as the starting point of your own model."""
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_2dunet/src/nii_reader.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_2dunet/src/nii_reader.py
*** ./openfl/openfl-workspace/tf_2dunet/src/nii_reader.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_2dunet/src/nii_reader.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,289 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- 
- import os
- 
- import nibabel as nib
- import numpy as np
- import numpy.ma as ma
- 
- 
- def parse_segments(seg, msk_modes):
-     """Parse the label segments.
- 
-     Each channel corresponds to a different region of the tumor, decouple and stack these
- 
-     mode_to_key_value = {"necrotic": 1, "edema": 2, "GD": 4}
- 
-     Args:
-         seg: The segmentation labels
-         msk_modes: Label mode to parse for the model
- 
-     Returns:
-         The processed mask labels
- 
-     """
-     msks_parsed = []
-     for slice_ in range(seg.shape[-1]):
-         # which mask values indicicate which label mode
-         mode_to_key_value = {'necrotic': 1, 'edema': 2, 'GD': 4}
-         curr = seg[:, :, slice_]
-         this_msk_parts = []
-         for mode in msk_modes:
-             this_msk_parts.append(
-                 ma.masked_not_equal(curr, mode_to_key_value[mode]).filled(
-                     fill_value=0
-                 )
-             )
-         msks_parsed.append(np.dstack(this_msk_parts))
- 
-     # Replace all tumorous areas with 1 (previously marked as 1, 2 or 4)
-     mask = np.asarray(msks_parsed)
-     mask[mask > 0] = 1
- 
-     return mask
- 
- 
- def normalize_stack(imgs):
-     """Z-score normalization of the input images.
- 
-     Args:
-         imgs: The input images
- 
-     Returns:
-         The processed (normalized) input images
- 
-     """
-     imgs = (imgs - np.mean(imgs)) / (np.std(imgs))
-     return imgs
- 
- 
- def resize_data(dataset, new_size=128, rotate=3):
-     """Resize 2D images within data by cropping equally from their boundaries.
- 
-     Args:
-         dataset (np.array): Data containing 2D images whose dimensions are
-         along the 1st and 2nd axes.
-         new_size (int): Dimensions of square image to which resizing will
-         occur. Assumed to be an even distance away from both dimensions of
-         the images within dataset. (default 128) rotate (int): Number of
-         counter clockwise 90 degree rotations to perform.
- 
-     Returns:
-         (np.array): resized data
- 
-     Raises:
-         ValueError: If (dataset.shape[1] - new_size) and
-          (dataset.shape[2] - new_size) are not both even integers.
- 
-     """
-     # Determine whether dataset and new_size are compatible with existing logic
-     if (dataset.shape[1] - new_size) % 2 != 0 and (dataset.shape[2] - new_size) % 2 != 0:
-         raise ValueError(f'dataset shape: {dataset.shape} and new_size: {new_size} '
-                          f'are not compatible with existing logic')
- 
-     start_index = int((dataset.shape[1] - new_size) / 2)
-     end_index = dataset.shape[1] - start_index
- 
-     if rotate != 0:
-         resized = np.rot90(dataset[:, start_index:end_index, start_index:end_index],
-                            rotate, axes=(1, 2))
-     else:
-         resized = dataset[:, start_index:end_index, start_index:end_index]
- 
-     return resized
- 
- 
- # adapted from https://github.com/NervanaSystems/topologies
- def _update_channels(imgs, msks, img_channels_to_keep,
-                      msk_channels_to_keep, channels_last):
-     """Filter the channels of images and move placement of channels in shape if desired.
- 
-     Args:
-         imgs (np.array): A stack of images with channels (channels could be
-         anywhere in number from one to four. Images are indexed along first
-         axis, with channels along fourth (last) axis. msks (np.array): A stack
-         of binary masks with channels (channels could be anywhere in number
-         from one to four. Images are indexed along first axis, with channels
-         along fourth (last) axis. img_channels_to_keep (flat np.ndarray): the
-         channels to keep in the image (remove others) msk_channels_to_keep
-         (flat np.ndarray): the channels to sum in the mask (resulting in
-         a single channel array)
-         channels_last (bool): Return channels in last axis? otherwise just
-          after first
- 
-     Returns:
-         images, masks with selected channels
-     """
-     new_imgs = imgs[:, :, :, img_channels_to_keep]
-     # the mask channels that are kept are summed over to leave one channel
-     # note the indices producing non-zero entries on these masks are mutually exclusive
-     # so that the result continues to be an array with only ones and zeros
-     msk_summands = [
-         msks[:, :, :, channel:channel + 1] for channel in msk_channels_to_keep
-     ]
-     new_msks = np.sum(msk_summands, axis=0)
- 
-     if not channels_last:
-         new_order = [0, 3, 1, 2]
-         return np.transpose(new_imgs, new_order), np.transpose(new_msks, new_order)
-     else:
-         return new_imgs, new_msks
- 
- 
- def list_files(root, extension, parts):
-     """Construct files from root, parts."""
-     files = [root + part + extension for part in parts]
-     return files
- 
- 
- def nii_reader(brain_path, task, channels_last=True,
-                numpy_type='float64', normalization='by_mode', **kwargs):
-     """Fetch a whole brain 3D image from disc.
- 
-     Assumes data_dir contains only subdirectories, each containing exactly one
-     of each of the following files: "<subdir>_<type>.nii.gz", where <subdir> is
-     the name of the subdirectory and <type> is one of ["t1", "t2","flair","t1ce"],
-     as well as a segmentation label file "<subdir>_<suffix>", where suffix is:
-     'seg_binary.nii.gz', 'seg_binarized.nii.gz', or 'SegBinarized.nii.gz'.
-     These files provide all modes and segmenation label for a single patient
-     brain scan consisting of 155 axial slice images. The reader returns the whole
-     brain (all 155 slices).
-     Note: Much of the logic here is included in order to allow for the reader
-     to have the same functionality (shared code) regardless of normalization
-     method. This allows us to validate all functionality except the normalization,
-     against data on disc that was previously processed by normalizing all scanning
-     modalities together. Post validation as desired, the code can be simplified.
- 
-     Args:
-         brain_path (str): path to files containing image features and label
-         set for a single brain.
-         task (string): Describes the classification task, which determines
-         the way in which the scanning modes and label information is filtered
-         and combined.
-         channels_last (bool): Determines whether reader should output channels
-         in the position of the last axis.Otherwise channels are placed just
-         after first axis.
-         numpy_type (string): The numpy datatype for final casting before return.
-         normalization (string): Determines whether the feature scanning modes
-         are not normalized (None), normalized by scanning mode ('by_mode'),
-         or normalized across all modes ('modes_together').
-         **kwargs: unused
- 
-     Returns:
-         np.array: whole 3D brain associated to a subdirectory given by the index
- 
-     Raises:
-         ValueError: If label_type is not in
-                     ['whole_tumor', 'enhanced_tumor', 'active_core', 'other']
-         ValueError: If the path determined by idx and indexed_data_paths points
-                     to a file with incomplete data
- 
-     """
-     files = os.listdir(brain_path)
-     # link task to appropriate image and mask channels of interest
-     img_modes = ['t1', 't2', 'flair', 't1ce']
-     msk_modes = ['necrotic', 'edema', 'GD']
-     task_to_img_modes = {
-         'whole_tumor': ['flair'],
-         'enhanced_tumor': ['t1'],
-         'active_core': ['t2'],
-         'other': ['t1', 't2', 'flair', 't1ce'],
-     }
-     task_to_msk_modes = {
-         'whole_tumor': ['necrotic', 'edema', 'GD'],
-         'enhanced_tumor': ['GD'],
-         'active_core': ['edema', 'GD'],
-         'other': ['necrotic', 'edema', 'GD'],
-     }
-     msk_names = ['seg_binary', 'seg_binarized', 'SegBinarized', 'seg']
- 
-     # validate that task is an allowed key
-     if task not in task_to_img_modes.keys():
-         raise ValueError(f'{task} is not a valid task')
- 
-     # validate that the tasks used in task_to_img_modes and
-     # task_to_msk_modes are the same
-     if set(task_to_img_modes.keys()) != set(task_to_msk_modes.keys()):
-         raise RuntimeError('Hard coded keys to task_to_img_modes'
-                            'and task_to_mask_modes are not the same and should be.')
- 
-     # check that all appropriate files are present
-     file_root = brain_path.split('/')[-1] + '_'
-     extension = '.nii.gz'
- 
-     # record files needed
-     # needed mask files are currntly independent of task
-     need_files_oneof = list_files(file_root, extension, msk_names)
-     if normalization != 'modes_together':
-         need_files_all = list_files(file_root, extension, task_to_img_modes[task])
-     else:
-         need_files_all = list_files(file_root, extension, img_modes)
- 
-     correct_files = np.all([
-         (reqd in files)
-         for reqd in need_files_all
-     ]) and np.sum([
-         (reqd in files)
-         for reqd in need_files_oneof
-     ]) == 1
- 
-     if not correct_files:
-         return None, None
- 
-     # get image (features)
-     imgs_per_mode = []
-     for file in need_files_all:
-         path = os.path.join(brain_path, file)
-         full_brain = np.array(nib.load(path).dataobj)
-         imgs_per_mode.append(resize_data(np.transpose(full_brain, [-1, 0, 1])))
- 
-     # normalize each model then stack, stack after normalizing all modes together,
-     # or stack without normalizing at all
-     if normalization == 'by_mode':
-         imgs = np.stack([normalize_stack(imgs) for imgs in imgs_per_mode], axis=-1)
-     elif normalization == 'modes_together':
-         imgs = normalize_stack(np.stack(imgs_per_mode, axis=-1))
-     elif normalization is None:
-         imgs = np.stack(imgs_per_mode, axis=-1)
-     else:
-         raise ValueError(f'{normalization} is not a supported normalization.')
- 
-     # get mask (labels)
-     for file in need_files_oneof:
-         if file in files:
-             path = os.path.join(brain_path, file)
-             full_brain_msk = np.array(nib.load(path).dataobj)
-             msks = resize_data(parse_segments(full_brain_msk, msk_modes))
-             break
- 
-     # determine which channels are wanted in our images in the case where we kept
-     # extra scanning modes in order to normalize across all but only use a subset
-     msk_mode_to_channel = {
-         mode: channel_num for (channel_num, mode) in enumerate(msk_modes)
-     }
-     msk_channels_to_keep = np.array(
-         [msk_mode_to_channel[mode] for mode in task_to_msk_modes[task]])
-     # if we normalization is by_mode or None,
-     # we have already restricted the image channels
-     if normalization in ['by_mode', None]:
-         img_channels_to_keep = np.arange(imgs.shape[-1])
-     elif normalization == 'modes_together':
-         img_mode_to_channel = {
-             mode: channel_num for (channel_num, mode) in enumerate(img_modes)
-         }
-         img_channels_to_keep = np.array(
-             [img_mode_to_channel[mode] for mode in task_to_img_modes[task]]
-         )
-     else:
-         raise ValueError(f'{normalization} is not a supported normalization.')
- 
-     img = imgs
-     msk = msks
- 
-     img, msk = _update_channels(
-         img, msk, img_channels_to_keep, msk_channels_to_keep, channels_last)
- 
-     return img.astype(numpy_type), msk.astype(numpy_type)
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_2dunet/src/tf_2dunet.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_2dunet/src/tf_2dunet.py
*** ./openfl/openfl-workspace/tf_2dunet/src/tf_2dunet.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_2dunet/src/tf_2dunet.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,250 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- 
- import tensorflow.compat.v1 as tf
- 
- from openfl.federated import TensorFlowTaskRunner
- 
- tf.disable_v2_behavior()
- 
- 
- class TensorFlow2DUNet(TensorFlowTaskRunner):
-     """Initialize.
- 
-     Args:
-         **kwargs: Additional parameters to pass to the function
- 
-     """
- 
-     def __init__(self, **kwargs):
-         """Initialize.
- 
-         Args:
-             **kwargs: Additional parameters to pass to the function
- 
-         """
-         super().__init__(**kwargs)
- 
-         self.create_model(**kwargs)
-         self.initialize_tensorkeys_for_functions()
- 
-     def create_model(self,
-                      training_smoothing=32.0,
-                      validation_smoothing=1.0,
-                      **kwargs):
-         """Create the TensorFlow 2D U-Net model.
- 
-         Args:
-             training_smoothing (float): (Default=32.0)
-             validation_smoothing (float): (Default=1.0)
-             **kwargs: Additional parameters to pass to the function
- 
-         """
-         config = tf.ConfigProto()
-         config.gpu_options.allow_growth = True
-         config.intra_op_parallelism_threads = 112
-         config.inter_op_parallelism_threads = 1
-         self.sess = tf.Session(config=config)
- 
-         self.X = tf.placeholder(tf.float32, self.input_shape)
-         self.y = tf.placeholder(tf.float32, self.input_shape)
-         self.output = define_model(self.X, use_upsampling=True, **kwargs)
- 
-         self.loss = dice_coef_loss(self.y, self.output, smooth=training_smoothing)
-         self.loss_name = dice_coef_loss.__name__
-         self.validation_metric = dice_coef(
-             self.y, self.output, smooth=validation_smoothing)
-         self.validation_metric_name = dice_coef.__name__
- 
-         self.global_step = tf.train.get_or_create_global_step()
- 
-         self.tvars = tf.trainable_variables()
- 
-         self.optimizer = tf.train.RMSPropOptimizer(1e-2)
- 
-         self.gvs = self.optimizer.compute_gradients(self.loss, self.tvars)
-         self.train_step = self.optimizer.apply_gradients(self.gvs,
-                                                          global_step=self.global_step)
- 
-         self.opt_vars = self.optimizer.variables()
- 
-         # FIXME: Do we really need to share the opt_vars?
-         # Two opt_vars for one tvar: gradient and square sum for RMSprop.
-         self.fl_vars = self.tvars + self.opt_vars
- 
-         self.initialize_globals()
- 
- 
- def dice_coef(y_true, y_pred, smooth=1.0, **kwargs):
-     """Dice coefficient.
- 
-     Calculate the Dice Coefficient
- 
-     Args:
-         y_true: Ground truth annotation array
-         y_pred: Prediction array from model
-         smooth (float): Laplace smoothing factor (Default=1.0)
-         **kwargs: Additional parameters to pass to the function
- 
-     Returns:
-         float: Dice cofficient metric
- 
-     """
-     intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])
-     coef = (
-         (tf.constant(2.) * intersection + tf.constant(smooth))
-         / (tf.reduce_sum(y_true, axis=[1, 2, 3])
-            + tf.reduce_sum(y_pred, axis=[1, 2, 3]) + tf.constant(smooth))
-     )
-     return tf.reduce_mean(coef)
- 
- 
- def dice_coef_loss(y_true, y_pred, smooth=1.0, **kwargs):
-     """Dice coefficient loss.
- 
-     Calculate the -log(Dice Coefficient) loss
- 
-     Args:
-         y_true: Ground truth annotation array
-         y_pred: Prediction array from model
-         smooth (float): Laplace smoothing factor (Default=1.0)
-         **kwargs: Additional parameters to pass to the function
- 
-     Returns:
-         float: -log(Dice cofficient) metric
- 
-     """
-     intersection = tf.reduce_sum(y_true * y_pred, axis=(1, 2, 3))
- 
-     term1 = -tf.log(tf.constant(2.0) * intersection + smooth)
-     term2 = tf.log(tf.reduce_sum(y_true, axis=(1, 2, 3))
-                    + tf.reduce_sum(y_pred, axis=(1, 2, 3)) + smooth)
- 
-     term1 = tf.reduce_mean(term1)
-     term2 = tf.reduce_mean(term2)
- 
-     loss = term1 + term2
- 
-     return loss
- 
- 
- CHANNEL_LAST = True
- if CHANNEL_LAST:
-     concat_axis = -1
-     data_format = 'channels_last'
- else:
-     concat_axis = 1
-     data_format = 'channels_first'
- 
- tf.keras.backend.set_image_data_format(data_format)
- 
- 
- def define_model(input_tensor,
-                  use_upsampling=False,
-                  n_cl_out=1,
-                  dropout=0.2,
-                  print_summary=True,
-                  activation_function='relu',
-                  seed=0xFEEDFACE,
-                  depth=5,
-                  dropout_at=None,
-                  initial_filters=32,
-                  batch_norm=True,
-                  **kwargs):
-     """Define the TensorFlow model.
- 
-     Args:
-         input_tensor: input shape ot the model
-         use_upsampling (bool): True = use bilinear interpolation;
-                                False = use transposed convolution (Default=False)
-         n_cl_out (int): Number of channels in input layer (Default=1)
-         dropout (float): Dropout percentage (Default=0.2)
-         print_summary (bool): True = print the model summary (Default = True)
-         activation_function: The activation function to use after convolutional
-          layers (Default='relu')
-         seed: random seed (Default=0xFEEDFACE)
-         depth (int): Number of max pooling layers in encoder (Default=5)
-         dropout_at: Layers to perform dropout after (Default=[2,3])
-         initial_filters (int): Number of filters in first convolutional
-          layer (Default=32)
-         batch_norm (bool): True = use batch normalization (Default=True)
-         **kwargs: Additional parameters to pass to the function
- 
-     """
-     if dropout_at is None:
-         dropout_at = [2, 3]
-     # Set keras learning phase to train
-     tf.keras.backend.set_learning_phase(True)
- 
-     # Don't initialize variables on the fly
-     tf.keras.backend.manual_variable_initialization(False)
- 
-     inputs = tf.keras.layers.Input(tensor=input_tensor, name='Images')
- 
-     if activation_function == 'relu':
-         activation = tf.nn.relu
-     elif activation_function == 'leakyrelu':
-         activation = tf.nn.leaky_relu
- 
-     params = {
-         'activation': activation,
-         'data_format': data_format,
-         'kernel_initializer': tf.keras.initializers.he_uniform(seed=seed),
-         'kernel_size': (3, 3),
-         'padding': 'same',
-     }
- 
-     convb_layers = {}
- 
-     net = inputs
-     filters = initial_filters
-     for i in range(depth):
-         name = f'conv{i + 1}a'
-         net = tf.keras.layers.Conv2D(name=name, filters=filters, **params)(net)
-         if i in dropout_at:
-             net = tf.keras.layers.Dropout(dropout)(net)
-         name = f'conv{i + 1}b'
-         net = tf.keras.layers.Conv2D(name=name, filters=filters, **params)(net)
-         if batch_norm:
-             net = tf.keras.layers.BatchNormalization()(net)
-         convb_layers[name] = net
-         # only pool if not last level
-         if i != depth - 1:
-             name = f'pool{i + 1}'
-             net = tf.keras.layers.MaxPooling2D(name=name, pool_size=(2, 2))(net)
-             filters *= 2
- 
-     # do the up levels
-     filters //= 2
-     for i in range(depth - 1):
-         if use_upsampling:
-             up = tf.keras.layers.UpSampling2D(
-                 name=f'up{depth + i + 1}', size=(2, 2))(net)
-         else:
-             up = tf.keras.layers.Conv2DTranspose(
-                 name='transConv6', filters=filters, data_format=data_format,
-                 kernel_size=(2, 2), strides=(2, 2), padding='same')(net)
-         net = tf.keras.layers.concatenate(
-             [up, convb_layers[f'conv{depth - i - 1}b']],
-             axis=concat_axis
-         )
-         net = tf.keras.layers.Conv2D(
-             name=f'conv{depth + i + 1}a',
-             filters=filters, **params)(net)
-         net = tf.keras.layers.Conv2D(
-             name=f'conv{depth + i + 1}b',
-             filters=filters, **params)(net)
-         filters //= 2
- 
-     net = tf.keras.layers.Conv2D(name='Mask', filters=n_cl_out,
-                                  kernel_size=(1, 1), data_format=data_format,
-                                  activation='sigmoid')(net)
- 
-     model = tf.keras.models.Model(inputs=[inputs], outputs=[net])
- 
-     if print_summary:
-         print(model.summary())
- 
-     return net
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_2dunet/src/tfbrats_inmemory.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_2dunet/src/tfbrats_inmemory.py
*** ./openfl/openfl-workspace/tf_2dunet/src/tfbrats_inmemory.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_2dunet/src/tfbrats_inmemory.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,36 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- 
- from openfl.federated import TensorFlowDataLoader
- from .brats_utils import load_from_nifti
- 
- 
- class TensorFlowBratsInMemory(TensorFlowDataLoader):
-     """TensorFlow Data Loader for the BraTS dataset."""
- 
-     def __init__(self, data_path, batch_size, percent_train=0.8, pre_split_shuffle=True, **kwargs):
-         """Initialize.
- 
-         Args:
-             data_path: The file path for the BraTS dataset
-             batch_size (int): The batch size to use
-             percent_train (float): The percentage of the data to use for training (Default=0.8)
-             pre_split_shuffle (bool): True= shuffle the dataset before
-             performing the train/validate split (Default=True)
-             **kwargs: Additional arguments, passed to super init and load_from_nifti
- 
-         Returns:
-             Data loader with BraTS data
-         """
-         super().__init__(batch_size, **kwargs)
- 
-         X_train, y_train, X_valid, y_valid = load_from_nifti(parent_dir=data_path,
-                                                              percent_train=percent_train,
-                                                              shuffle=pre_split_shuffle,
-                                                              **kwargs)
-         self.X_train = X_train
-         self.y_train = y_train
-         self.X_valid = X_valid
-         self.y_valid = y_valid
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_2dunet/.workspace ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_2dunet/.workspace
*** ./openfl/openfl-workspace/tf_2dunet/.workspace	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_2dunet/.workspace	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- current_plan_name: default
- 
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_3dunet_brats/plan/cols.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/plan/cols.yaml
*** ./openfl/openfl-workspace/tf_3dunet_brats/plan/cols.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/plan/cols.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,5 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- collaborators:
-    - one
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_3dunet_brats/plan/data.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/plan/data.yaml
*** ./openfl/openfl-workspace/tf_3dunet_brats/plan/data.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/plan/data.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,16 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- # all keys under 'collaborators' corresponds to a specific colaborator name the corresponding dictionary has data_name, data_path pairs.
- # Note that in the mnist case we do not store the data locally, and the data_path is used to pass an integer that helps the data object
- # construct the shard of the mnist dataset to be use for this collaborator.
- #
- # collaborator_name,data_directory_path
- 
- # You'll need to shard as necessary
- # Symbolically link the ./data directory to whereever you have BraTS stored.
- # e.g. ln -s ~/data/MICCAI_BraTS2020_TrainingData ./data/one
- 
- one,~/MICCAI_BraTS2020_TrainingData/split_0
- two,~/MICCAI_BraTS2020_TrainingData/split_1
- 
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_3dunet_brats/plan/defaults/aggregator.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/plan/defaults/aggregator.yaml
*** ./openfl/openfl-workspace/tf_3dunet_brats/plan/defaults/aggregator.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/plan/defaults/aggregator.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- template : openfl.component.Aggregator
- settings :
-     db_store_rounds   : 1
-     
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_3dunet_brats/plan/defaults/assigner.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/plan/defaults/assigner.yaml
*** ./openfl/openfl-workspace/tf_3dunet_brats/plan/defaults/assigner.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/plan/defaults/assigner.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,9 ****
- template : openfl.component.RandomGroupedAssigner
- settings :
-   task_groups  :
-     - name       : train_and_validate
-       percentage : 1.0
-       tasks      :
-         - aggregated_model_validation
-         - train
-         - locally_tuned_model_validation
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_3dunet_brats/plan/defaults/collaborator.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/plan/defaults/collaborator.yaml
*** ./openfl/openfl-workspace/tf_3dunet_brats/plan/defaults/collaborator.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/plan/defaults/collaborator.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,5 ****
- template : openfl.component.Collaborator
- settings :
-     opt_treatment     : 'CONTINUE_LOCAL'
-     delta_updates     : True
-     db_store_rounds   : 1
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_3dunet_brats/plan/defaults/compression_pipeline.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/plan/defaults/compression_pipeline.yaml
*** ./openfl/openfl-workspace/tf_3dunet_brats/plan/defaults/compression_pipeline.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/plan/defaults/compression_pipeline.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1 ****
- template: openfl.pipelines.NoCompressionPipeline
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_3dunet_brats/plan/defaults/data_loader.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/plan/defaults/data_loader.yaml
*** ./openfl/openfl-workspace/tf_3dunet_brats/plan/defaults/data_loader.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/plan/defaults/data_loader.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1 ****
- template: openfl.federated.DataLoader
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_3dunet_brats/plan/defaults/defaults ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/plan/defaults/defaults
*** ./openfl/openfl-workspace/tf_3dunet_brats/plan/defaults/defaults	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/plan/defaults/defaults	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- ../../workspace/plan/defaults
- 
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_3dunet_brats/plan/defaults/network.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/plan/defaults/network.yaml
*** ./openfl/openfl-workspace/tf_3dunet_brats/plan/defaults/network.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/plan/defaults/network.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,9 ****
- template: openfl.federation.Network
- settings:
-     agg_addr                   : auto
-     agg_port                   : auto
-     hash_salt                  : auto
-     disable_tls                : False
-     client_reconnect_interval  : 5
-     disable_client_auth        : False
-     cert_folder                : cert
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_3dunet_brats/plan/defaults/task_runner.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/plan/defaults/task_runner.yaml
*** ./openfl/openfl-workspace/tf_3dunet_brats/plan/defaults/task_runner.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/plan/defaults/task_runner.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1 ****
- template: openfl.federated.task_runner.CoreTaskRunner
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_3dunet_brats/plan/defaults/tasks_fast_estimator.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/plan/defaults/tasks_fast_estimator.yaml
*** ./openfl/openfl-workspace/tf_3dunet_brats/plan/defaults/tasks_fast_estimator.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/plan/defaults/tasks_fast_estimator.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,22 ****
- aggregated_model_validation:
-   function : validate
-   kwargs   :
-     batch_size : 32
-     apply      : global
-     metrics    :
-       - accuracy
-    
- locally_tuned_model_validation:
-   function : validate
-   kwargs   :
-     batch_size : 32
-     apply      : local
-     metrics    :
-       - accuracy
- train:
-   function : train
-   kwargs   :
-     batch_size : 32
-     epochs     : 1
-     metrics    :
-     - loss
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_3dunet_brats/plan/defaults/tasks_keras.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/plan/defaults/tasks_keras.yaml
*** ./openfl/openfl-workspace/tf_3dunet_brats/plan/defaults/tasks_keras.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/plan/defaults/tasks_keras.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,23 ****
- aggregated_model_validation:
-   function : validate
-   kwargs   :
-     batch_size : 32
-     apply      : global
-     metrics    :
-       - accuracy
- 
- locally_tuned_model_validation:
-   function : validate
-   kwargs   :
-     batch_size : 32
-     apply      : local
-     metrics    :
-       - accuracy
- 
- train:
-   function : train
-   kwargs   :
-     batch_size : 32
-     epochs     : 1
-     metrics    :
-     - loss
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_3dunet_brats/plan/defaults/tasks_tensorflow.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/plan/defaults/tasks_tensorflow.yaml
*** ./openfl/openfl-workspace/tf_3dunet_brats/plan/defaults/tasks_tensorflow.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/plan/defaults/tasks_tensorflow.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,23 ****
- aggregated_model_validation:
-   function : validate
-   kwargs   :
-     batch_size : 32
-     apply      : global
-     metrics    :
-       - acc
- 
- locally_tuned_model_validation:
-   function : validate
-   kwargs   :
-     batch_size : 32
-     apply      : local
-     metrics    :
-       - acc
- 
- train:
-   function : train_batches
-   kwargs   :
-     batch_size  : 32
-     num_batches : 1
-     metrics     :
-     - loss
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_3dunet_brats/plan/defaults/tasks_torch.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/plan/defaults/tasks_torch.yaml
*** ./openfl/openfl-workspace/tf_3dunet_brats/plan/defaults/tasks_torch.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/plan/defaults/tasks_torch.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,19 ****
- aggregated_model_validation:
-   function : validate
-   kwargs   :
-     apply   : global
-     metrics :
-       - acc
-   
- locally_tuned_model_validation:
-   function  : validate
-   kwargs    :
-     apply: local
-     metrics :
-       - acc
-   
- train:
-   function : train_batches
-   kwargs   :
-     metrics     :
-     - loss
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_3dunet_brats/plan/plan.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/plan/plan.yaml
*** ./openfl/openfl-workspace/tf_3dunet_brats/plan/plan.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/plan/plan.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,83 ****
- aggregator:
-   defaults: plan/defaults/aggregator.yaml
-   settings:
-     best_state_path: save/tf_3dunet_brats_best.pbuf
-     init_state_path: save/tf_3dunet_brats_init.pbuf
-     last_state_path: save/tf_3dunet_brats_latest.pbuf
-     db_store_rounds: 2
-     rounds_to_train: 10
-   template: openfl.component.Aggregator
- assigner:
-   defaults: plan/defaults/assigner.yaml
-   settings:
-     task_groups:
-     - name: train_and_validate
-       percentage: 1.0
-       tasks:
-       - aggregated_model_validation
-       - train
-       - locally_tuned_model_validation
-   template: openfl.component.RandomGroupedAssigner
- collaborator:
-   defaults: plan/defaults/collaborator.yaml
-   settings:
-     db_store_rounds: 2
-     delta_updates: true
-     opt_treatment: RESET
-   template: openfl.component.Collaborator
- data_loader:
-   defaults: plan/defaults/data_loader.yaml
-   settings:
-     batch_size: 4
-     crop_dim: 64
-     num_classes: 1
-     number_input_channels: 1
-     percent_train: 0.8
-   template: src.tf_brats_dataloader.TensorFlowBratsDataLoader
- network:
-   defaults: plan/defaults/network.yaml
-   settings:
-     agg_addr: DESKTOP-AOKV1IJ.localdomain
-     agg_port: auto
-     cert_folder: cert
-     client_reconnect_interval: 5
-     disable_client_auth: false
-     disable_tls: false
-     hash_salt: auto
-   template: openfl.federation.Network
- task_runner:
-   defaults: plan/defaults/task_runner.yaml
-   settings:
-     batch_norm: true
-     batch_size: 4
-     depth: 4
-     initial_filters: 16
-     use_upsampling: false
-   template: src.tf_3dunet_model.TensorFlow3dUNet
- tasks:
-   aggregated_model_validation:
-     function: validate
-     kwargs:
-       apply: global
-       batch_size: 4
-       metrics:
-       - dice_coef
-       - soft_dice_coef
-   defaults: plan/defaults/tasks_tensorflow.yaml
-   locally_tuned_model_validation:
-     function: validate
-     kwargs:
-       apply: local
-       batch_size: 4
-       metrics:
-       - dice_coef
-       - soft_dice_coef
-   settings: {}
-   train:
-     function: train
-     kwargs:
-       batch_size: 4
-       epochs: 1
-       metrics:
-       - loss
-       num_batches: 1
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_3dunet_brats/README.md ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/README.md
*** ./openfl/openfl-workspace/tf_3dunet_brats/README.md	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/README.md	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,166 ****
- # TensorFlow 3D U-Net for the BraTS dataset
- 
- This is a full example for training the Brain Tumor Segmentation 2020 ([BraTS2020](https://www.med.upenn.edu/cbica/brats2020/data.html)) with OpenFL. 
- 
- *Note: This is **not** the 3D U-Net model that was used in the paper and not the sharding used. Nevertheless, it should make a good template for how to train using OpenFL.*
- 
- The files `src\dataloader.py` and `src\define_model.py` are where we define the TensorFlow [dataset loader](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) and the 3D U-Net model. In `src\dataloader.py` we demonstrate how to use an out-of-memory data loader that pulls batches of data from files as needed.
- 
- ## Steps to run
- 
- 1. Download the [BraTS 2020 dataset](https://www.med.upenn.edu/cbica/brats2020/registration.html). It should be the one labeled **BraTS'20 Training Data: Segmentation Task**. 
- 
- 2. Extract the `MICCAI_BraTS2020_TrainingData.zip` zip file to any folder. Let's call that folder `${DATA_PATH}`. The file structure of `${DATA_PATH}` should look like this: 
- 
- ```bash
- user@localhost ~$ tree ${DATA_PATH} -L 2
- ${DATA_PATH}/MICCAI_BraTS2020_TrainingData
- ├── BraTS20_Training_001
- │   ├── BraTS20_Training_001_flair.nii.gz    <── The MRI FLAIR channel (best one for prediction)
- │   ├── BraTS20_Training_001_seg.nii.gz      <── The ground truth label
- │   ├── BraTS20_Training_001_t1.nii.gz       <── The T1-weighted MRI channel
- │   ├── BraTS20_Training_001_t1ce.nii.gz     <── The T1-Contrast Enhanced-weighted MRI channel
- │   └── BraTS20_Training_001_t2.nii.gz       <── The T2-weighted MRI channel
- ├── BraTS20_Training_002
- │   ├── BraTS20_Training_002_flair.nii.gz
- │   ├── BraTS20_Training_002_seg.nii.gz
- │   ├── BraTS20_Training_002_t1.nii.gz
- │   ├── BraTS20_Training_002_t1ce.nii.gz
- │   └── BraTS20_Training_002_t2.nii.gz
- ├── ...
- ├── BraTS20_Training_369
- │   ├── BraTS20_Training_369_flair.nii.gz
- │   ├── BraTS20_Training_369_seg.nii.gz
- │   ├── BraTS20_Training_369_t1.nii.gz
- │   ├── BraTS20_Training_369_t1ce.nii.gz
- │   └── BraTS20_Training_369_t2.nii.gz
- ├── name_mapping.csv
- └── survival_info.csv
- ```
- If `tree` is not installed, then run `sudo apt-get install tree` to install it (Ubuntu).
- 
- 3. In order for each collaborator to use separate slice of data, we split main folder into subfolders, one for each collaborator. **NOTE:** In the real world each collaborator will have it's own data and this split already exists. We're splitting here to simulate a federation with different participants.
- 
- #### `split_directory.sh`
- ```bash 
- #!/bin/bash
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- # Split the BraTS data directory into NUM_COLLABORATORS 
- 
- SOURCE=${1}  # The directory where the BraTS dataset is located (e.g. ~/data/MICCAI_BraTS2020_TrainingData)
- DESTINATION=${2}   # The destination directory for the randomized, split training data folders
- NUM_COLLABORATORS=${3:-2}  # The number of collaborator splits for the subdirectories
- 
- help() {
-     echo
-     echo "======================================================================="
-     echo "~$ split_directory.sh BRATS_DATA_SOURCE_DIRECTORY DESTINATION_DIRECTORY"
-     echo "======================================================================="
-     echo
-     echo "BRATS_DATA_SOURCE_DIRECTORY: The directory where the BraTS dataset is located (e.g. ~/data/MICCAI_BraTS2020_TrainingData)"
-     echo "DESTINATION DIRECTORY: The destination directory for the randomized, split training data folders (e.g. ~/brats_data_split)"
-     echo "NUM_COLLABORATORS: The number of collaborator splits for the subdirectories (default: 2)"
-     echo "-h, --help            display this help and exit"
-     echo
-     echo
- }
- 
- if [ "$#" -lt 2 ] || ! [ -d ${1} ]; then
-     help
-     exit 1
- fi
- 
- get_seeded_random()
- {
-   seed="$1"
-   openssl enc -aes-256-ctr -pass pass:"$seed" -nosalt \
-     </dev/zero 2>/dev/null
- }
- 
- # Remove the destination directory if it exists
- if [ -d ${DESTINATION} ] 
- then
-     echo "Removing existing directory." 
-     rm -r ${DESTINATION}
- fi
- 
- printf "Shard into ${NUM_COLLABORATORS} directories under ${DESTINATION}."
- echo ' '
- spin='-\|/'
- 
- n=0
- i=0
- # Find the subdirectories under the SOURCE directory and randomly shuffle them (seed is the same)
- for f in `find ${SOURCE} -mindepth 1 -maxdepth 2 -type d | shuf --random-source=<(get_seeded_random 816)`; do
- 
-   ((n++))
- 
-   # The folder to put the folder
-   idx=$((n % ${NUM_COLLABORATORS}))
- 
-   i=$(( (i+1) %4 ))
-   printf "\r${spin:$i:1} ${f}"
- 
-   d=${DESTINATION}/split_${idx}/
- 
-   # Make the directory (if it doesn't exist) and copy the folder to it.
-   mkdir -p ${d}
-   cp -r ${f} ${d}
- 
- done
- 
- echo ' '
- echo ' '
- ```
- 
- `~$ bash split_directory.sh ${DATA_PATH} ${NEW_PATH} ${NUMBER OF COLLABORATORS}`
- 
- where `${NEW_PATH}` is where you want to copy the original data (and split it randomly into subdirectories). The default is 2 collaborators (so 2 splits).
- 
- The new directories for the data are:
- ```
- ${NEW_PATH}
- ├── split_0
- │   ├── BraTS20_Training_001
- │   ├── BraTS20_Training_002
- │   ├── BraTS20_Training_003
- │   ├── ...
- └── split_1
-     ├── BraTS20_Training_009
-     ├── BraTS20_Training_014
-     ├── BraTS20_Training_015
-     ├── ...
- ```
- 
- 4. Now update the `plan/data.yaml` file to reflect the new data directories:
- 
- ```
- $ cat plan/data.yaml
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- # all keys under 'collaborators' corresponds to a specific colaborator name the corresponding dictionary has data_name, data_path pairs.
- # Note that in the mnist case we do not store the data locally, and the data_path is used to pass an integer that helps the data object
- # construct the shard of the mnist dataset to be use for this collaborator.
- #
- # collaborator_name,data_directory_path
- 
- # You'll need to shard as necessary
- # Symbolically link the ./data directory to whereever you have BraTS stored.
- # e.g. ln -s ~/data/MICCAI_BraTS2020_TrainingData ./data/one
- 
- one,${NEW_PATH}/split_0
- two,${NEW_PATH}/split_1
- 
- ```
- 
- where you replace `${NEW_PATH}` by the new directory path
- 
- 5. We are ready to train! Try executing the [Hello Federation](https://openfl.readthedocs.io/en/latest/running_the_federation.baremetal.html#hello-federation-your-first-federated-learning-training) steps. Make sure you have `openfl` installed in your Python virtual environment. All you have to do is to specify collaborator data paths to slice folders. We have combined all 'Hello Federation' steps in a single bash script, so it is easier to test:
- 
- ```bash
- bash tests/github/test_hello_federation.sh tf_3dunet_brats fed_work12345alpha81671 one123dragons beta34unicorns localhost --col1-data-path $NEW_PATH/split_0 --col2-data-path $NEW_PATH/$SUBFOLDER/split_1 --rounds-to-train 5
- ```
- The result of the execution of the command above is 5 completed training rounds. 
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_3dunet_brats/requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/requirements.txt
*** ./openfl/openfl-workspace/tf_3dunet_brats/requirements.txt	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- tensorflow>=2
- nibabel
- numpy
- 
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_3dunet_brats/split_directory.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/split_directory.sh
*** ./openfl/openfl-workspace/tf_3dunet_brats/split_directory.sh	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/split_directory.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,70 ****
- #!/bin/bash
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- # Split the BraTS data directory into NUM_COLLABORATORS 
- 
- SOURCE=${1}  # The directory where the BraTS dataset is located (e.g. ~/data/MICCAI_BraTS2020_TrainingData)
- DESTINATION=${2}   # The destination directory for the randomized, split training data folders
- NUM_COLLABORATORS=${3:-2}  # The number of collaborator splits for the subdirectories
- 
- help() {
-     echo
-     echo "======================================================================="
-     echo "~$ split_directory.sh BRATS_DATA_SOURCE_DIRECTORY DESTINATION_DIRECTORY"
-     echo "======================================================================="
-     echo
-     echo "BRATS_DATA_SOURCE_DIRECTORY: The directory where the BraTS dataset is located (e.g. ~/data/MICCAI_BraTS2020_TrainingData)"
-     echo "DESTINATION DIRECTORY: The destination directory for the randomized, split training data folders (e.g. ~/brats_data_split)"
-     echo "NUM_COLLABORATORS: The number of collaborator splits for the subdirectories (default: 2)"
-     echo "-h, --help            display this help and exit"
-     echo
-     echo
- }
- 
- if [ "$#" -lt 2 ] || ! [ -d ${1} ]; then
-     help
-     exit 1
- fi
- 
- get_seeded_random()
- {
-   seed="$1"
-   openssl enc -aes-256-ctr -pass pass:"$seed" -nosalt \
-     </dev/zero 2>/dev/null
- }
- 
- # Remove the destination directory if it exists
- if [ -d ${DESTINATION} ] 
- then
-     echo "Removing existing directory." 
-     rm -r ${DESTINATION}
- fi
- 
- printf "Shard into ${NUM_COLLABORATORS} directories under ${DESTINATION}."
- echo ' '
- spin='-\|/'
- 
- n=0
- i=0
- # Find the subdirectories under the SOURCE directory and randomly shuffle them (seed is the same)
- for f in `find ${SOURCE} -mindepth 1 -maxdepth 2 -type d | shuf --random-source=<(get_seeded_random 816)`; do
- 
-   ((n++))
- 
-   # The folder to put the folder
-   idx=$((n % ${NUM_COLLABORATORS}))
- 
-   i=$(( (i+1) %4 ))
-   printf "\r${spin:$i:1} ${f}"
- 
-   d=${DESTINATION}/split_${idx}/
- 
-   # Make the directory (if it doesn't exist) and copy the folder to it.
-   mkdir -p ${d}
-   cp -r ${f} ${d}
- 
- done
- 
- echo ' '
- echo ' '
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_3dunet_brats/src/dataloader.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/src/dataloader.py
*** ./openfl/openfl-workspace/tf_3dunet_brats/src/dataloader.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/src/dataloader.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,294 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- 
- import os
- 
- import nibabel as nib
- import numpy as np
- import tensorflow as tf
- 
- 
- class DatasetGenerator:
-     """Generate a TensorFlow data loader from the BraTS .nii.gz files."""
- 
-     def __init__(self, crop_dim,
-                  data_path,
-                  batch_size=4,
-                  number_input_channels=1,
-                  num_classes=1,
-                  train_test_split=0.80,
-                  validate_test_split=0.5,
-                  random_seed=816,
-                  shard=0):
-         """Initialize the class."""
-         self.data_path = os.path.abspath(os.path.expanduser(data_path))
-         self.batch_size = batch_size
-         self.crop_dim = [crop_dim, crop_dim, crop_dim, number_input_channels]
-         self.num_input_channels = number_input_channels
-         self.num_classes = num_classes
-         self.random_seed = random_seed
- 
-         self.train_test_split = train_test_split
-         self.validate_test_split = validate_test_split
-         self.shard = shard
- 
-         self.create_file_list()
- 
-         if self.num_files > 0:
- 
-             self.ds_train, self.ds_val, self.ds_test = self.get_dataset()
- 
-         else:
- 
-             self.ds_train = None
-             self.ds_val = None
-             self.ds_test = None
-             raise ValueError(f'ERROR: No BraTS datafiles found under directory {self.data_path}')
- 
-     def create_file_list(self):
-         """
-         Get list of the files from the BraTS raw data.
- 
-         Split into training and testing sets.
-         """
-         searchpath = os.path.join(self.data_path, '*/*_seg.nii.gz')
-         filenames = tf.io.gfile.glob(searchpath)
- 
-         # Create a dictionary of tuples with image filename and label filename
- 
-         self.num_files = len(filenames)
-         self.filenames = {}
-         for idx, filename in enumerate(filenames):
-             self.filenames[idx] = [filename.replace('_seg.nii.gz', '_flair.nii.gz'), filename]
- 
-     def z_normalize_img(self, img):
-         """
-         Normalize the image.
- 
-         The mean value for each image is 0 and the standard deviation is 1.
-         """
-         # TODO: Correct this for multiple MRI channels
-         return (img - np.mean(img)) / np.std(img)
- 
-     def crop(self, img, msk, randomize):
-         """Randomly crop the image and mask."""
-         slices = []
- 
-         # Do we randomize?
-         is_random = randomize and np.random.rand() > 0.5
- 
-         for idx in range(len(img.shape) - 1):  # Go through each dimension
- 
-             croplen = self.crop_dim[idx]
-             imglen = img.shape[idx]
- 
-             start = (imglen - croplen) // 2
- 
-             ratio_crop = 0.20  # Crop up this this % of pixels for offset
-             # Number of pixels to offset crop in this dimension
-             offset = int(np.floor(start * ratio_crop))
- 
-             if offset > 0:
-                 if is_random:
-                     start += np.random.choice(range(-offset, offset))
-                     if ((start + croplen) > imglen):  # Don't fall off the image
-                         start = (imglen - croplen) // 2
-             else:
-                 start = 0
- 
-             slices.append(slice(start, start + croplen))
- 
-         return img[tuple(slices)], msk[tuple(slices)]
- 
-     def augment_data(self, img, msk):
-         """
-         Augmentation the input images.
- 
-         Flip image and mask. Rotate image and mask.
-         """
-         # Determine if axes are equal and can be rotated
-         # If the axes aren't equal then we can't rotate them.
-         equal_dim_axis = []
-         for idx in range(0, len(self.crop_dim)):
-             for jdx in range(idx + 1, len(self.crop_dim)):
-                 if self.crop_dim[idx] == self.crop_dim[jdx]:
-                     equal_dim_axis.append([idx, jdx])  # Valid rotation axes
-         dim_to_rotate = equal_dim_axis
- 
-         if np.random.rand() > 0.5:
-             # Random 0,1 (axes to flip)
-             ax = np.random.choice(np.arange(len(self.crop_dim) - 1))
-             img = np.flip(img, ax)
-             msk = np.flip(msk, ax)
- 
-         elif (len(dim_to_rotate) > 0) and (np.random.rand() > 0.5):
-             rot = np.random.choice([1, 2, 3])  # 90, 180, or 270 degrees
- 
-             # This will choose the axes to rotate
-             # Axes must be equal in size
-             random_axis = dim_to_rotate[np.random.choice(len(dim_to_rotate))]
- 
-             img = np.rot90(img, rot, axes=random_axis)  # Rotate axes 0 and 1
-             msk = np.rot90(msk, rot, axes=random_axis)  # Rotate axes 0 and 1
- 
-         return img, msk
- 
-     def read_nifti_file(self, idx, randomize=False):
-         """Read Nifti file."""
-         idx = idx.numpy()
-         imgfile = self.filenames[idx][0]
-         mskfile = self.filenames[idx][1]
- 
-         img_temp = np.array(nib.load(imgfile).dataobj)
-         img_temp = np.rot90(img_temp)
- 
-         img = np.zeros(list(img_temp.shape) + [self.num_input_channels])
-         # Normalize
-         img_temp = self.z_normalize_img(img_temp)
- 
-         img[..., 0] = img_temp
- 
-         for channel in range(1, self.num_input_channels):
- 
-             if channel == 1:
-                 imgfile = self.filenames[idx][1].replace('_flair', '_t1')
-             elif channel == 2:
-                 imgfile = self.filenames[idx][1].replace('_flair', '_t1ce')
-             elif channel == 3:
-                 imgfile = self.filenames[idx][1].replace('_flair', '_t2')
- 
-             img_temp = np.array(nib.load(imgfile).dataobj)
- 
-             img_temp = np.rot90(img_temp)
- 
-             # Normalize
-             img_temp = self.z_normalize_img(img_temp)
- 
-             img[..., channel] = img_temp
- 
-         msk = np.rot90(np.array(nib.load(mskfile).dataobj))
-         msk = np.expand_dims(msk, -1)
- 
-         # labels: {
-         #      0: background,
-         #      1: edema,
-         #      2: non-enhancing tumor,
-         #      3: enhancing tumour}
- 
-         # Combine all masks but background
-         if self.num_classes == 1:
-             msk[msk > 0] = 1.0
-         else:
-             msk_temp = np.zeros(list(msk.shape) + [self.num_classes])
-             for channel in range(self.num_classes):
-                 msk_temp[msk == channel, channel] = 1.0
-             msk = msk_temp
- 
-         # Crop
-         img, msk = self.crop(img, msk, randomize)
- 
-         # Randomly rotate
-         if randomize:
-             img, msk = self.augment_data(img, msk)
- 
-         return img, msk
- 
-     def get_input_shape(self):
-         """Get the shape of the input."""
-         return self.crop_dim
- 
-     def plot_images(self, ds, slice_num=90):
-         """Plot images from dataset."""
-         import matplotlib.pyplot as plt
- 
-         plt.figure(figsize=(20, 20))
- 
-         num_cols = 2
- 
-         msk_channel = 0
-         img_channel = 0
- 
-         for img, msk in ds.take(1):
-             bs = img.shape[0]
- 
-             for idx in range(bs):
-                 plt.subplot(bs, num_cols, idx * num_cols + 1)
-                 plt.imshow(img[idx, :, :, slice_num, img_channel], cmap='bone')
-                 plt.title('MRI', fontsize=18)
-                 plt.subplot(bs, num_cols, idx * num_cols + 2)
-                 plt.imshow(msk[idx, :, :, slice_num, msk_channel], cmap='bone')
-                 plt.title('Tumor', fontsize=18)
- 
-         plt.show()
- 
-         print(f'Mean pixel value of image = {np.mean(img[0, :, :, :, 0])}')
- 
-     def display_train_images(self, slice_num=90):
-         """Plot some training images."""
-         self.plot_images(self.ds_train, slice_num)
- 
-     def display_validation_images(self, slice_num=90):
-         """Plot some validation images."""
-         self.plot_images(self.ds_val, slice_num)
- 
-     def display_test_images(self, slice_num=90):
-         """Plot some test images."""
-         self.plot_images(self.ds_test, slice_num)
- 
-     def get_train(self):
-         """Return train dataset."""
-         return self.ds_train
- 
-     def get_test(self):
-         """Return test dataset."""
-         return self.ds_test
- 
-     def get_validate(self):
-         """Return validation dataset."""
-         return self.ds_val
- 
-     def get_dataset(self):
-         """Create a TensorFlow data loader."""
-         self.num_train = int(self.num_files * self.train_test_split)
-         numvaltest = self.num_files - self.num_train
- 
-         ds = tf.data.Dataset.range(self.num_files).shuffle(
-             self.num_files, self.random_seed)  # Shuffle the dataset
- 
-         # Horovod Sharding
-         # Here we are not actually dividing the dataset into shards
-         # but instead just reshuffling the training dataset for every
-         # shard. Then in the training loop we just go through the training
-         # dataset but the number of steps is divided by the number of shards.
-         ds_train = ds.take(self.num_train).shuffle(
-             self.num_train, self.shard)  # Reshuffle based on shard
-         ds_val_test = ds.skip(self.num_train)
-         self.num_val = int(numvaltest * self.validate_test_split)
-         self.num_test = self.num_train - self.num_val
-         ds_val = ds_val_test.take(self.num_val)
-         ds_test = ds_val_test.skip(self.num_val)
- 
-         ds_train = ds_train.map(lambda x: tf.py_function(self.read_nifti_file,
-                                                          [x, True], [tf.float32, tf.float32]),
-                                 num_parallel_calls=tf.data.experimental.AUTOTUNE)
-         ds_val = ds_val.map(lambda x: tf.py_function(self.read_nifti_file,
-                                                      [x, False], [tf.float32, tf.float32]),
-                             num_parallel_calls=tf.data.experimental.AUTOTUNE)
-         ds_test = ds_test.map(lambda x: tf.py_function(self.read_nifti_file,
-                                                        [x, False], [tf.float32, tf.float32]),
-                               num_parallel_calls=tf.data.experimental.AUTOTUNE)
- 
-         ds_train = ds_train.batch(self.batch_size, drop_remainder=True)
-         ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)
- 
-         batch_size_val = max(1, self.batch_size // 2)    # Could be any batch size you'd like
-         ds_val = ds_val.batch(batch_size_val, drop_remainder=True)
-         ds_val = ds_val.prefetch(tf.data.experimental.AUTOTUNE)
- 
-         batch_size_test = max(1, self.batch_size // 2)   # Could be any batch size you'd like
-         ds_test = ds_test.batch(batch_size_test, drop_remainder=True)
-         ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)
- 
-         return ds_train, ds_val, ds_test
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_3dunet_brats/src/define_model.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/src/define_model.py
*** ./openfl/openfl-workspace/tf_3dunet_brats/src/define_model.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/src/define_model.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,158 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- 
- import tensorflow as tf
- 
- 
- def dice_coef(target, prediction, axis=(1, 2, 3), smooth=0.0001):
-     """
-     Sorenson Dice.
- 
-     Returns
-     -------
-     dice coefficient (float)
-     """
-     prediction = tf.round(prediction)  # Round to 0 or 1
- 
-     intersection = tf.reduce_sum(target * prediction, axis=axis)
-     union = tf.reduce_sum(target + prediction, axis=axis)
-     numerator = tf.constant(2.) * intersection + smooth
-     denominator = union + smooth
-     coef = numerator / denominator
- 
-     return tf.reduce_mean(coef)
- 
- 
- def soft_dice_coef(target, prediction, axis=(1, 2, 3), smooth=0.0001):
-     """
-     Soft Sorenson Dice.
- 
-     Does not round the predictions to either 0 or 1.
- 
-     Returns
-     -------
-     soft dice coefficient (float)
-     """
-     intersection = tf.reduce_sum(target * prediction, axis=axis)
-     union = tf.reduce_sum(target + prediction, axis=axis)
-     numerator = tf.constant(2.) * intersection + smooth
-     denominator = union + smooth
-     coef = numerator / denominator
- 
-     return tf.reduce_mean(coef)
- 
- 
- def dice_loss(target, prediction, axis=(1, 2, 3), smooth=0.0001):
-     """
-     Sorenson (Soft) Dice loss.
- 
-     Using -log(Dice) as the loss since it is better behaved.
-     Also, the log allows avoidance of the division which
-     can help prevent underflow when the numbers are very small.
- 
-     Returns
-     -------
-     dice loss (float)
-     """
-     intersection = tf.reduce_sum(prediction * target, axis=axis)
-     p = tf.reduce_sum(prediction, axis=axis)
-     t = tf.reduce_sum(target, axis=axis)
-     numerator = tf.reduce_mean(intersection + smooth)
-     denominator = tf.reduce_mean(t + p + smooth)
-     dice_loss = -tf.math.log(2. * numerator) + tf.math.log(denominator)
- 
-     return dice_loss
- 
- 
- def build_model(input_shape,
-                 n_cl_out=1,
-                 use_upsampling=False,
-                 dropout=0.2,
-                 print_summary=True,
-                 seed=816,
-                 depth=5,
-                 dropout_at=(2, 3),
-                 initial_filters=16,
-                 batch_norm=True,
-                 **kwargs):
-     """Build the TensorFlow model.
- 
-     Args:
-         input_tensor: input shape ot the model
-         use_upsampling (bool): True = use bilinear interpolation;
-                             False = use transposed convolution (Default=False)
-         n_cl_out (int): Number of channels in output layer (Default=1)
-         dropout (float): Dropout percentage (Default=0.2)
-         print_summary (bool): True = print the model summary (Default = True)
-         seed: random seed (Default=816)
-         depth (int): Number of max pooling layers in encoder (Default=5)
-         dropout_at: Layers to perform dropout after (Default=[2,3])
-         initial_filters (int): Number of filters in first convolutional
-         layer (Default=16)
-         batch_norm (bool): True = use batch normalization (Default=True)
-         **kwargs: Additional parameters to pass to the function
-     """
-     if (input_shape[0] % (2**depth)) > 0:
-         raise ValueError(f'Crop dimension must be a multiple of 2^(depth of U-Net) = {2**depth}')
- 
-     inputs = tf.keras.layers.Input(input_shape, name='brats_mr_image')
- 
-     activation = tf.keras.activations.relu
- 
-     params = {'kernel_size': (3, 3, 3), 'activation': activation,
-               'padding': 'same',
-               'kernel_initializer': tf.keras.initializers.he_uniform(seed=seed)}
- 
-     convb_layers = {}
- 
-     net = inputs
-     filters = initial_filters
-     for i in range(depth):
-         name = f'conv{i + 1}a'
-         net = tf.keras.layers.Conv3D(name=name, filters=filters, **params)(net)
-         if i in dropout_at:
-             net = tf.keras.layers.Dropout(dropout)(net)
-         name = f'conv{i + 1}b'
-         net = tf.keras.layers.Conv3D(name=name, filters=filters, **params)(net)
-         if batch_norm:
-             net = tf.keras.layers.BatchNormalization()(net)
-         convb_layers[name] = net
-         # only pool if not last level
-         if i != depth - 1:
-             name = f'pool{i + 1}'
-             net = tf.keras.layers.MaxPooling3D(name=name, pool_size=(2, 2, 2))(net)
-             filters *= 2
- 
-     # do the up levels
-     filters //= 2
-     for i in range(depth - 1):
-         if use_upsampling:
-             up = tf.keras.layers.UpSampling3D(
-                 name=f'up{depth + i + 1}', size=(2, 2, 2))(net)
-         else:
-             up = tf.keras.layers.Conv3DTranspose(name=f'transConv{depth + i + 1}',
-                                                  filters=filters,
-                                                  kernel_size=(2, 2, 2),
-                                                  strides=(2, 2, 2),
-                                                  padding='same')(net)
-         net = tf.keras.layers.concatenate(
-             [up, convb_layers[f'conv{depth - i - 1}b']],
-             axis=-1
-         )
-         net = tf.keras.layers.Conv3D(
-             name=f'conv{depth + i + 1}a',
-             filters=filters, **params)(net)
-         net = tf.keras.layers.Conv3D(
-             name=f'conv{depth + i + 1}b',
-             filters=filters, **params)(net)
-         filters //= 2
- 
-     net = tf.keras.layers.Conv3D(name='prediction', filters=n_cl_out,
-                                  kernel_size=(1, 1, 1),
-                                  activation='sigmoid')(net)
- 
-     model = tf.keras.models.Model(inputs=[inputs], outputs=[net])
- 
-     return model
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_3dunet_brats/src/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/src/__init__.py
*** ./openfl/openfl-workspace/tf_3dunet_brats/src/__init__.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/src/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """You may copy this file as the starting point of your own model."""
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_3dunet_brats/src/tf_3dunet_model.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/src/tf_3dunet_model.py
*** ./openfl/openfl-workspace/tf_3dunet_brats/src/tf_3dunet_model.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/src/tf_3dunet_model.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,215 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- 
- import tensorflow as tf
- 
- from openfl.federated import KerasTaskRunner
- from .define_model import build_model
- from .define_model import dice_coef
- from .define_model import dice_loss
- from .define_model import soft_dice_coef
- 
- 
- class TensorFlow3dUNet(KerasTaskRunner):
-     """Initialize.
- 
-     Args:
-         **kwargs: Additional parameters to pass to the function
- 
-     """
- 
-     def __init__(self, initial_filters=16,
-                  depth=5,
-                  batch_norm=True,
-                  use_upsampling=False,
-                  **kwargs):
-         """Initialize.
- 
-         Args:
-             **kwargs: Additional parameters to pass to the function
- 
-         """
-         super().__init__(**kwargs)
- 
-         self.model = self.create_model(
-             input_shape=self.feature_shape,
-             n_cl_out=self.data_loader.num_classes,
-             initial_filters=initial_filters,
-             use_upsampling=use_upsampling,
-             depth=depth,
-             batch_norm=batch_norm,
-             **kwargs
-         )
-         self.initialize_tensorkeys_for_functions()
- 
-         self.model.summary(print_fn=self.logger.info, line_length=120)
- 
-     def create_model(self,
-                      input_shape,
-                      n_cl_out=1,
-                      use_upsampling=False,
-                      dropout=0.2,
-                      print_summary=True,
-                      seed=816,
-                      depth=5,
-                      dropout_at=(2, 3),
-                      initial_filters=16,
-                      batch_norm=True,
-                      **kwargs):
-         """Create the TensorFlow 3D U-Net CNN model.
- 
-         Args:
-             input_shape (list): input shape of the data
-             n_cl_out (int): Number of output classes in label (Default=1)
-             **kwargs: Additional parameters to pass to the function
- 
-         """
-         #
-         # Define Model
-         #
-         model = build_model(input_shape,
-                             n_cl_out=n_cl_out,
-                             use_upsampling=use_upsampling,
-                             dropout=dropout,
-                             print_summary=print_summary,
-                             seed=seed,
-                             depth=depth,
-                             dropout_at=dropout_at,
-                             initial_filters=initial_filters,
-                             batch_norm=batch_norm)
- 
-         self.optimizer = tf.keras.optimizers.Adam()
- 
-         model.compile(
-             loss=dice_loss,
-             optimizer=self.optimizer,
-             metrics=[dice_coef, soft_dice_coef],
-         )
- 
-         self.tvars = model.layers
-         print(f'layer names: {[var.name for var in self.tvars]}')
- 
-         self.opt_vars = self.optimizer.variables()
-         print(f'optimizer vars: {self.opt_vars}')
- 
-         # Two opt_vars for one tvar: gradient and square sum for RMSprop.
-         self.fl_vars = self.tvars + self.opt_vars
- 
-         return model
- 
- 
- if __name__ == '__main__':
- 
-     from tf_brats_dataloader import DatasetGenerator
-     import os
- 
-     import argparse
- 
-     parser = argparse.ArgumentParser(
-         description='Train 3D U-Net model', add_help=True,
-         formatter_class=argparse.ArgumentDefaultsHelpFormatter)
- 
-     parser.add_argument('--data_path',
-                         default='~/data/MICCAI_BraTS2020_TrainingData/',
-                         # Or wherever you unzipped the BraTS datset,
-                         help='Root directory for BraTS 2020 dataset')
-     parser.add_argument('--epochs',
-                         type=int,
-                         default=5,
-                         help='Number of epochs')
-     parser.add_argument('--crop_dim',
-                         type=int,
-                         default=64,
-                         help='Crop all dimensions to this (height, width, depth)')
-     parser.add_argument('--batch_size',
-                         type=int,
-                         default=4,
-                         help='Training batch size')
-     parser.add_argument('--train_test_split',
-                         type=float,
-                         default=0.80,
-                         help='Train/test split (0-1)')
-     parser.add_argument('--validate_test_split',
-                         type=float,
-                         default=0.50,
-                         help='Validation/test split (0-1)')
-     parser.add_argument('--number_input_channels',
-                         type=int,
-                         default=1,
-                         help='Number of input channels')
-     parser.add_argument('--num_classes',
-                         type=int,
-                         default=1,
-                         help='Number of output classes/channels')
-     parser.add_argument('--random_seed',
-                         default=816,
-                         help='Random seed for determinism')
-     parser.add_argument('--print_model',
-                         action='store_true',
-                         default=True,
-                         help='Print the summary of the model layers')
-     parser.add_argument('--filters',
-                         type=int,
-                         default=16,
-                         help='Number of filters in the first convolutional layer')
-     parser.add_argument('--use_upsampling',
-                         action='store_true',
-                         default=False,
-                         help='Use upsampling instead of transposed convolution')
-     parser.add_argument('--use_batchnorm',
-                         action='store_true',
-                         default=True,
-                         help='Use batch normalization')
-     parser.add_argument('--saved_model_name',
-                         default='saved_model_3DUnet',
-                         help='Save model to this path')
- 
-     args = parser.parse_args()
- 
-     print(args)
- 
-     brats_data = DatasetGenerator(args.crop_dim,
-                                   data_path=os.path.abspath(os.path.expanduser(args.data_path)),
-                                   batch_size=args.batch_size,
-                                   train_test_split=args.train_test_split,
-                                   validate_test_split=args.validate_test_split,
-                                   number_input_channels=args.number_input_channels,
-                                   num_classes=args.num_classes,
-                                   random_seed=args.random_seed
-                                   )
- 
-     model = build_model([args.crop_dim, args.crop_dim, args.crop_dim, args.number_input_channels],
-                         use_upsampling=args.use_upsampling,
-                         n_cl_out=args.num_classes,
-                         dropout=0.2,
-                         print_summary=args.print_model,
-                         seed=args.random_seed,
-                         depth=5,
-                         dropout_at=[2, 3],
-                         initial_filters=args.filters,
-                         batch_norm=args.use_batchnorm
-                         )
- 
-     model.compile(loss=dice_loss,
-                   optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),
-                   metrics=[dice_coef, soft_dice_coef]
-                   )
- 
-     checkpoint = tf.keras.callbacks.ModelCheckpoint(args.saved_model_name,
-                                                     verbose=1,
-                                                     save_best_only=True)
- 
-     # TensorBoard
-     import datetime
-     logs_dir = os.path.join('tensorboard_logs',
-                             datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))
-     tb_logs = tf.keras.callbacks.TensorBoard(log_dir=logs_dir)
- 
-     callbacks = [checkpoint, tb_logs]
- 
-     history = model.fit(brats_data.ds_train,
-                         validation_data=brats_data.ds_val,
-                         epochs=args.epochs,
-                         callbacks=callbacks)
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_3dunet_brats/src/tf_brats_dataloader.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/src/tf_brats_dataloader.py
*** ./openfl/openfl-workspace/tf_3dunet_brats/src/tf_brats_dataloader.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/src/tf_brats_dataloader.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,99 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- 
- 
- import os
- 
- from openfl.federated import TensorFlowDataLoader
- from .dataloader import DatasetGenerator
- 
- 
- class TensorFlowBratsDataLoader(TensorFlowDataLoader):
-     """TensorFlow Data Loader for the BraTS dataset."""
- 
-     def __init__(self, data_path, batch_size=4,
-                  crop_dim=64, percent_train=0.8,
-                  pre_split_shuffle=True,
-                  number_input_channels=1,
-                  num_classes=1,
-                  **kwargs):
-         """Initialize.
- 
-         Args:
-             data_path: The file path for the BraTS dataset
-             batch_size (int): The batch size to use
-             crop_dim (int): Crop the original image to this size on each dimension
-             percent_train (float): The percentage of the data to use for training (Default=0.8)
-             pre_split_shuffle (bool): True= shuffle the dataset before
-             performing the train/validate split (Default=True)
-             **kwargs: Additional arguments, passed to super init
- 
-         Returns:
-             Data loader with BraTS data
-         """
-         super().__init__(batch_size, **kwargs)
- 
-         self.data_path = os.path.abspath(os.path.expanduser(data_path))
-         self.batch_size = batch_size
-         self.crop_dim = [crop_dim, crop_dim, crop_dim, number_input_channels]
-         self.num_input_channels = number_input_channels
-         self.num_classes = num_classes
- 
-         self.train_test_split = percent_train
- 
-         self.brats_data = DatasetGenerator(crop_dim,
-                                            data_path=data_path,
-                                            number_input_channels=number_input_channels,
-                                            batch_size=batch_size,
-                                            train_test_split=percent_train,
-                                            validate_test_split=0.5,
-                                            num_classes=num_classes,
-                                            random_seed=816)
- 
-     def get_feature_shape(self):
-         """
-         Get the shape of an example feature array.
- 
-         Returns:
-             tuple: shape of an example feature array
-         """
-         return tuple(self.brats_data.get_input_shape())
- 
-     def get_train_loader(self, batch_size=None, num_batches=None):
-         """
-         Get training data loader.
- 
-         Returns
-         -------
-         loader object
-         """
-         return self.brats_data.ds_train
- 
-     def get_valid_loader(self, batch_size=None):
-         """
-         Get validation data loader.
- 
-         Returns:
-             loader object
-         """
-         return self.brats_data.ds_val
- 
-     def get_train_data_size(self):
-         """
-         Get total number of training samples.
- 
-         Returns:
-             int: number of training samples
-         """
-         return self.brats_data.num_train
- 
-     def get_valid_data_size(self):
-         """
-         Get total number of validation samples.
- 
-         Returns:
-             int: number of validation samples
-         """
-         return self.brats_data.num_val
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_3dunet_brats/.workspace ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/.workspace
*** ./openfl/openfl-workspace/tf_3dunet_brats/.workspace	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_3dunet_brats/.workspace	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- current_plan_name: default
- 
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_cnn_histology/plan/cols.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_cnn_histology/plan/cols.yaml
*** ./openfl/openfl-workspace/tf_cnn_histology/plan/cols.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_cnn_histology/plan/cols.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- collaborators:
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_cnn_histology/plan/data.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_cnn_histology/plan/data.yaml
*** ./openfl/openfl-workspace/tf_cnn_histology/plan/data.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_cnn_histology/plan/data.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,11 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- # all keys under 'collaborators' corresponds to a specific colaborator name the corresponding dictionary has data_name, data_path pairs.
- # Note that in the mnist case we do not store the data locally, and the data_path is used to pass an integer that helps the data object
- # construct the shard of the mnist dataset to be use for this collaborator.
- #
- # collaborator_name,data_directory_path
- 
- one,1
- two,2
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_cnn_histology/plan/defaults ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_cnn_histology/plan/defaults
*** ./openfl/openfl-workspace/tf_cnn_histology/plan/defaults	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_cnn_histology/plan/defaults	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- ../../workspace/plan/defaults
- 
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_cnn_histology/plan/plan.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_cnn_histology/plan/plan.yaml
*** ./openfl/openfl-workspace/tf_cnn_histology/plan/plan.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_cnn_histology/plan/plan.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,64 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- aggregator :
-   defaults : plan/defaults/aggregator.yaml
-   template : openfl.component.Aggregator
-   settings :
-     init_state_path  : save/tf_cnn_histology_init.pbuf
-     last_state_path  : save/tf_cnn_histology_latest.pbuf
-     best_state_path  : save/tf_cnn_histology_best.pbuf
-     db_store_rounds: 2
-     rounds_to_train : 10
- 
- collaborator :
-   defaults : plan/defaults/collaborator.yaml
-   template : openfl.component.Collaborator
-   settings :
-     delta_updates    : true
-     db_store_rounds: 2
-     opt_treatment    : RESET
- 
- data_loader :
-   defaults : plan/defaults/data_loader.yaml
-   template : src.tfhistology_inmemory.TensorFlowHistologyInMemory
-   settings :
-     batch_size: 64
-     percent_train: 0.8
-     collaborator_count : 2
-     data_group_name    : histology
- 
- task_runner :
-   defaults : plan/defaults/task_runner.yaml
-   template : src.tf_cnn.TensorFlowCNN
- 
- network :
-   defaults : plan/defaults/network.yaml
- 
- assigner :
-   defaults : plan/defaults/assigner.yaml
- 
- tasks:
-   defaults: plan/defaults/tasks_tensorflow.yaml
-   aggregated_model_validation:
-     function: validate
-     kwargs:
-       apply: global
-       batch_size: 32
-       metrics:
-       - sparse_categorical_accuracy
-   locally_tuned_model_validation:
-     function: validate
-     kwargs:
-       apply: local
-       batch_size: 32
-       metrics:
-       - sparse_categorical_accuracy
-   settings: {}
-   train:
-     function: train
-     kwargs:
-       batch_size: 32
-       epochs: 1
-       metrics:
-       - loss
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_cnn_histology/requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_cnn_histology/requirements.txt
*** ./openfl/openfl-workspace/tf_cnn_histology/requirements.txt	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_cnn_histology/requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- pillow
- tensorflow==2.7.0
- tensorflow-datasets
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_cnn_histology/src/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_cnn_histology/src/__init__.py
*** ./openfl/openfl-workspace/tf_cnn_histology/src/__init__.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_cnn_histology/src/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """You may copy this file as the starting point of your own model."""
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_cnn_histology/src/tf_cnn.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_cnn_histology/src/tf_cnn.py
*** ./openfl/openfl-workspace/tf_cnn_histology/src/tf_cnn.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_cnn_histology/src/tf_cnn.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,108 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- 
- import tensorflow as tf
- 
- from openfl.federated import KerasTaskRunner
- 
- 
- class TensorFlowCNN(KerasTaskRunner):
-     """Initialize.
- 
-     Args:
-         **kwargs: Additional parameters to pass to the function
- 
-     """
- 
-     def __init__(self, **kwargs):
-         """Initialize.
- 
-         Args:
-             **kwargs: Additional parameters to pass to the function
- 
-         """
-         super().__init__(**kwargs)
- 
-         self.model = self.create_model(
-             self.feature_shape,
-             self.data_loader.num_classes,
-             **kwargs
-         )
-         self.initialize_tensorkeys_for_functions()
- 
-     def create_model(self,
-                      input_shape,
-                      num_classes,
-                      training_smoothing=32.0,
-                      validation_smoothing=1.0,
-                      **kwargs):
-         """Create the TensorFlow CNN Histology model.
- 
-         Args:
-             training_smoothing (float): (Default=32.0)
-             validation_smoothing (float): (Default=1.0)
-             **kwargs: Additional parameters to pass to the function
- 
-         """
-         print(tf.config.threading.get_intra_op_parallelism_threads())
-         print(tf.config.threading.get_inter_op_parallelism_threads())
-         # ## Define Model
-         #
-         # Convolutional neural network model
- 
-         inputs = tf.keras.layers.Input(shape=input_shape)
-         conv = tf.keras.layers.Conv2D(
-             filters=16, kernel_size=(3, 3), padding='same', activation='relu')(inputs)
-         conv = tf.keras.layers.Conv2D(
-             filters=32, kernel_size=(3, 3), padding='same', activation='relu')(conv)
-         maxpool = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv)
- 
-         conv = tf.keras.layers.Conv2D(
-             filters=64, kernel_size=(3, 3), padding='same', activation='relu')(maxpool)
-         conv = tf.keras.layers.Conv2D(
-             filters=128, kernel_size=(3, 3), padding='same', activation='relu')(conv)
-         concat = tf.keras.layers.concatenate([maxpool, conv])
-         maxpool = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(concat)
- 
-         conv = tf.keras.layers.Conv2D(
-             filters=256, kernel_size=(3, 3), padding='same', activation='relu')(maxpool)
-         conv = tf.keras.layers.Conv2D(
-             filters=512, kernel_size=(3, 3), padding='same', activation='relu')(conv)
-         concat = tf.keras.layers.concatenate([maxpool, conv])
-         maxpool = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(concat)
- 
-         conv = tf.keras.layers.Conv2D(
-             filters=256, kernel_size=(3, 3), padding='same', activation='relu')(maxpool)
-         conv = tf.keras.layers.Conv2D(
-             filters=512, kernel_size=(3, 3), padding='same', activation='relu')(conv)
-         concat = tf.keras.layers.concatenate([maxpool, conv])
-         maxpool = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(concat)
- 
-         flat = tf.keras.layers.Flatten()(maxpool)
-         dense = tf.keras.layers.Dense(128)(flat)
-         drop = tf.keras.layers.Dropout(0.5)(dense)
- 
-         predict = tf.keras.layers.Dense(num_classes)(drop)
- 
-         model = tf.keras.models.Model(inputs=[inputs], outputs=[predict])
- 
-         self.optimizer = tf.keras.optimizers.Adam()
- 
-         model.compile(
-             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
-             optimizer=self.optimizer,
-             metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],
-         )
- 
-         self.tvars = model.layers
-         print(f'layer names: {[var.name for var in self.tvars]}')
- 
-         self.opt_vars = self.optimizer.variables()
-         print(f'optimizer vars: {self.opt_vars}')
- 
-         # Two opt_vars for one tvar: gradient and square sum for RMSprop.
-         self.fl_vars = self.tvars + self.opt_vars
- 
-         return model
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_cnn_histology/src/tfds_utils.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_cnn_histology/src/tfds_utils.py
*** ./openfl/openfl-workspace/tf_cnn_histology/src/tfds_utils.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_cnn_histology/src/tfds_utils.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,126 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- 
- from logging import getLogger
- 
- import numpy as np
- import tensorflow_datasets as tfds
- 
- logger = getLogger(__name__)
- 
- 
- def one_hot(labels, classes):
-     """
-     One Hot encode a vector.
- 
-     Args:
-         labels (list):  List of labels to onehot encode
-         classes (int): Total number of categorical classes
- 
-     Returns:
-         np.array: Matrix of one-hot encoded labels
-     """
-     return np.eye(classes)[labels]
- 
- 
- def _load_raw_datashards(shard_num, collaborator_count):
-     """
-     Load the raw data by shard.
- 
-     Returns tuples of the dataset shard divided into training and validation.
- 
-     Args:
-         shard_num (int): The shard number to use
-         collaborator_count (int): The number of collaborators in the federation
- 
-     Returns:
-         2 tuples: (image, label) of the training, validation dataset
-     """
-     (ds), metadata = tfds.load('colorectal_histology', data_dir='.',
-                                shuffle_files=False, split='train', batch_size=-1,
-                                with_info=True, as_supervised=True)
- 
-     image, label = tfds.as_numpy(ds)
- 
-     np.random.seed(42)
-     shuf = np.random.permutation(len(image))
-     image = image[shuf]
-     label = label[shuf]
- 
-     split = int(len(image) * 0.8)
- 
-     X_train_tot = image[:split]
-     y_train_tot = label[:split]
- 
-     X_valid_tot = image[split:]
-     y_valid_tot = label[split:]
- 
-     shard_num = int(shard_num)
- 
-     # create the shards
-     X_train = X_train_tot[shard_num::collaborator_count]
-     y_train = y_train_tot[shard_num::collaborator_count]
- 
-     X_valid = X_valid_tot[shard_num::collaborator_count]
-     y_valid = y_valid_tot[shard_num::collaborator_count]
- 
-     return (X_train, y_train), (X_valid, y_valid)
- 
- 
- def load_histology_shard(shard_num, collaborator_count, categorical=True,
-                          channels_last=True, **kwargs):
-     """
-     Load the colorectal histology dataset.
- 
-     Args:
-         shard_num (int): The shard to use from the dataset
-         collaborator_count (int): The number of collaborators in the federation
-         categorical (bool): True = convert the labels to one-hot encoded
-          vectors (Default = True)
-         channels_last (bool): True = The input images have the channels last
-          (Default = True)
-         **kwargs: Additional parameters to pass to the function
- 
-     Returns:
-         list: The input shape
-         int: The number of classes
-         numpy.ndarray: The training data
-         numpy.ndarray: The training labels
-         numpy.ndarray: The validation data
-         numpy.ndarray: The validation labels
-     """
-     num_classes = 8
-     img_rows = 150
-     img_cols = 150
-     channels = 3
- 
-     (X_train, y_train), (X_valid, y_valid) = _load_raw_datashards(
-         shard_num, collaborator_count)
- 
-     if channels_last:
-         X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, channels)
-         X_valid = X_valid.reshape(X_valid.shape[0], img_rows, img_cols, channels)
-         input_shape = (img_rows, img_cols, channels)
-     else:
-         X_train = X_train.reshape(X_train.shape[0], channels, img_rows, img_cols)
-         X_valid = X_valid.reshape(X_valid.shape[0], channels, img_rows, img_cols)
-         input_shape = (channels, img_rows, img_cols)
- 
-     X_train = X_train.astype('float32')
-     X_valid = X_valid.astype('float32')
-     X_train /= 255
-     X_valid /= 255
- 
-     logger.info(f'Histology > X_train Shape : {X_train.shape}')
-     logger.info(f'Histology > y_train Shape : {y_train.shape}')
-     logger.info(f'Histology > Train Samples : {X_train.shape[0]}')
-     logger.info(f'Histology > Valid Samples : {X_valid.shape[0]}')
- 
-     if categorical:
-         # convert class vectors to binary class matrices
-         y_train = one_hot(y_train, num_classes)
-         y_valid = one_hot(y_valid, num_classes)
- 
-     return input_shape, num_classes, X_train, y_train, X_valid, y_valid
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_cnn_histology/src/tfhistology_inmemory.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_cnn_histology/src/tfhistology_inmemory.py
*** ./openfl/openfl-workspace/tf_cnn_histology/src/tfhistology_inmemory.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_cnn_histology/src/tfhistology_inmemory.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,34 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- 
- from openfl.federated import TensorFlowDataLoader
- from .tfds_utils import load_histology_shard
- 
- 
- class TensorFlowHistologyInMemory(TensorFlowDataLoader):
-     """TensorFlow Data Loader for Colorectal Histology Dataset."""
- 
-     def __init__(self, data_path, batch_size, **kwargs):
-         """
-         Initialize.
- 
-         Args:
-             data_path: File path for the dataset
-             batch_size (int): The batch size for the data loader
-             **kwargs: Additional arguments, passed to super init and load_mnist_shard
-         """
-         super().__init__(batch_size, **kwargs)
- 
-         _, num_classes, X_train, y_train, X_valid, y_valid = load_histology_shard(
-             shard_num=data_path,
-             categorical=False, **kwargs
-         )
- 
-         self.X_train = X_train
-         self.y_train = y_train
-         self.X_valid = X_valid
-         self.y_valid = y_valid
- 
-         self.num_classes = num_classes
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/tf_cnn_histology/.workspace ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_cnn_histology/.workspace
*** ./openfl/openfl-workspace/tf_cnn_histology/.workspace	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/tf_cnn_histology/.workspace	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- current_plan_name: default
- 
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_cnn_histology/plan/cols.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology/plan/cols.yaml
*** ./openfl/openfl-workspace/torch_cnn_histology/plan/cols.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology/plan/cols.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- collaborators:
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_cnn_histology/plan/data.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology/plan/data.yaml
*** ./openfl/openfl-workspace/torch_cnn_histology/plan/data.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology/plan/data.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,5 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- one,1
- two,2
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_cnn_histology/plan/plan.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology/plan/plan.yaml
*** ./openfl/openfl-workspace/torch_cnn_histology/plan/plan.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology/plan/plan.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,41 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- aggregator :
-   defaults : plan/defaults/aggregator.yaml
-   template : openfl.component.Aggregator
-   settings :
-     init_state_path : save/torch_cnn_histology_init.pbuf
-     best_state_path : save/torch_cnn_histology_best.pbuf
-     last_state_path : save/torch_cnn_histology_last.pbuf
-     rounds_to_train : 20
- 
- collaborator :
-   defaults : plan/defaults/collaborator.yaml
-   template : openfl.component.Collaborator
-   settings :
-     delta_updates    : false
-     opt_treatment    : RESET
- 
- data_loader :
-   template : src.pthistology_inmemory.PyTorchHistologyInMemory
-   settings :
-     collaborator_count : 2
-     data_group_name    : histology
-     batch_size         : 32
- 
- task_runner:
-   defaults : plan/defaults/task_runner.yaml
-   template: src.pt_cnn.PyTorchCNN
- 
- network:
-   defaults: plan/defaults/network.yaml
- 
- tasks:
-   defaults: plan/defaults/tasks_torch.yaml
- 
- assigner:
-   defaults: plan/defaults/assigner.yaml
- 
- compression_pipeline :
-   defaults : plan/defaults/compression_pipeline.yaml
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_cnn_histology/requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology/requirements.txt
*** ./openfl/openfl-workspace/torch_cnn_histology/requirements.txt	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology/requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- torchvision==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html
- torch==1.6.0 -f https://download.pytorch.org/whl/torch_stable.html
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_cnn_histology/src/histology_utils.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology/src/histology_utils.py
*** ./openfl/openfl-workspace/torch_cnn_histology/src/histology_utils.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology/src/histology_utils.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,154 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- 
- from collections.abc import Iterable
- from logging import getLogger
- from os import makedirs
- from pathlib import Path
- from urllib.request import urlretrieve
- from zipfile import ZipFile
- 
- import numpy as np
- import torch
- from torch.utils.data import random_split
- from torchvision.datasets import ImageFolder
- from torchvision.transforms import ToTensor
- from tqdm import tqdm
- 
- from openfl.utilities import validate_file_hash
- 
- logger = getLogger(__name__)
- 
- 
- class HistologyDataset(ImageFolder):
-     """Colorectal Histology Dataset."""
- 
-     URL = ('https://zenodo.org/record/53169/files/Kather_'
-            'texture_2016_image_tiles_5000.zip?download=1')
-     FILENAME = 'Kather_texture_2016_image_tiles_5000.zip'
-     FOLDER_NAME = 'Kather_texture_2016_image_tiles_5000'
-     ZIP_SHA384 = ('7d86abe1d04e68b77c055820c2a4c582a1d25d2983e38ab724e'
-                   'ac75affce8b7cb2cbf5ba68848dcfd9d84005d87d6790')
-     DEFAULT_PATH = Path.cwd().absolute() / 'data'
- 
-     def __init__(self, root: Path = DEFAULT_PATH, **kwargs) -> None:
-         """Initialize."""
-         makedirs(root, exist_ok=True)
-         filepath = root / HistologyDataset.FILENAME
-         if not filepath.is_file():
-             self.pbar = tqdm(total=None)
-             urlretrieve(HistologyDataset.URL, filepath, self.report_hook)  # nosec
-             validate_file_hash(filepath, HistologyDataset.ZIP_SHA384)
-             with ZipFile(filepath, 'r') as f:
-                 f.extractall(root)
- 
-         super(HistologyDataset, self).__init__(root / HistologyDataset.FOLDER_NAME, **kwargs)
- 
-     def report_hook(self, count, block_size, total_size):
-         """Update progressbar."""
-         if self.pbar.total is None and total_size:
-             self.pbar.total = total_size
-         progress_bytes = count * block_size
-         self.pbar.update(progress_bytes - self.pbar.n)
- 
-     def __getitem__(self, index):
-         """Allow getting items by slice index."""
-         if isinstance(index, Iterable):
-             return [super(HistologyDataset, self).__getitem__(i) for i in index]
-         else:
-             return super(HistologyDataset, self).__getitem__(index)
- 
- 
- def one_hot(labels, classes):
-     """
-     One Hot encode a vector.
- 
-     Args:
-         labels (list):  List of labels to onehot encode
-         classes (int): Total number of categorical classes
- 
-     Returns:
-         np.array: Matrix of one-hot encoded labels
-     """
-     return np.eye(classes)[labels]
- 
- 
- def _load_raw_datashards(shard_num, collaborator_count, train_split_ratio=0.8):
-     """
-     Load the raw data by shard.
- 
-     Returns tuples of the dataset shard divided into training and validation.
- 
-     Args:
-         shard_num (int): The shard number to use
-         collaborator_count (int): The number of collaborators in the federation
- 
-     Returns:
-         2 tuples: (image, label) of the training, validation dataset
-     """
-     dataset = HistologyDataset(transform=ToTensor())
-     n_train = int(train_split_ratio * len(dataset))
-     n_valid = len(dataset) - n_train
-     ds_train, ds_val = random_split(
-         dataset, lengths=[n_train, n_valid], generator=torch.manual_seed(0))
- 
-     # create the shards
-     X_train, y_train = list(zip(*ds_train[shard_num::collaborator_count]))
-     X_train, y_train = np.stack(X_train), np.array(y_train)
- 
-     X_valid, y_valid = list(zip(*ds_val[shard_num::collaborator_count]))
-     X_valid, y_valid = np.stack(X_valid), np.array(y_valid)
- 
-     return (X_train, y_train), (X_valid, y_valid)
- 
- 
- def load_histology_shard(shard_num, collaborator_count,
-                          categorical=False, channels_last=False, **kwargs):
-     """
-     Load the Histology dataset.
- 
-     Args:
-         shard_num (int): The shard to use from the dataset
-         collaborator_count (int): The number of collaborators in the federation
-         categorical (bool): True = convert the labels to one-hot encoded
-          vectors (Default = True)
-         channels_last (bool): True = The input images have the channels
-          last (Default = True)
-         **kwargs: Additional parameters to pass to the function
- 
-     Returns:
-         list: The input shape
-         int: The number of classes
-         numpy.ndarray: The training data
-         numpy.ndarray: The training labels
-         numpy.ndarray: The validation data
-         numpy.ndarray: The validation labels
-     """
-     img_rows, img_cols = 150, 150
-     num_classes = 8
- 
-     (X_train, y_train), (X_valid, y_valid) = _load_raw_datashards(
-         shard_num, collaborator_count)
- 
-     if channels_last:
-         X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)
-         X_valid = X_valid.reshape(X_valid.shape[0], img_rows, img_cols, 3)
-         input_shape = (img_rows, img_cols, 3)
-     else:
-         X_train = X_train.reshape(X_train.shape[0], 3, img_rows, img_cols)
-         X_valid = X_valid.reshape(X_valid.shape[0], 3, img_rows, img_cols)
-         input_shape = (3, img_rows, img_cols)
- 
-     logger.info(f'Histology > X_train Shape : {X_train.shape}')
-     logger.info(f'Histology > y_train Shape : {y_train.shape}')
-     logger.info(f'Histology > Train Samples : {X_train.shape[0]}')
-     logger.info(f'Histology > Valid Samples : {X_valid.shape[0]}')
- 
-     if categorical:
-         # convert class vectors to binary class matrices
-         y_train = one_hot(y_train, num_classes)
-         y_valid = one_hot(y_valid, num_classes)
- 
-     return input_shape, num_classes, X_train, y_train, X_valid, y_valid
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_cnn_histology/src/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology/src/__init__.py
*** ./openfl/openfl-workspace/torch_cnn_histology/src/__init__.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology/src/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """You may copy this file as the starting point of your own model."""
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_cnn_histology/src/pt_cnn.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology/src/pt_cnn.py
*** ./openfl/openfl-workspace/torch_cnn_histology/src/pt_cnn.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology/src/pt_cnn.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,165 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- import numpy as np
- import torch
- import torch.nn as nn
- import torch.nn.functional as F
- import torch.optim as optim
- import tqdm
- 
- from openfl.federated import PyTorchTaskRunner
- from openfl.utilities import TensorKey
- 
- 
- def cross_entropy(output, target):
-     """Calculate Cross-entropy loss."""
-     return F.cross_entropy(input=output, target=target)
- 
- 
- class PyTorchCNN(PyTorchTaskRunner):
-     """Simple CNN for classification."""
- 
-     def __init__(self, **kwargs):
-         """Initialize.
- 
-         Args:
-             **kwargs: Additional arguments to pass to the function
-         """
-         super().__init__(loss_fn=cross_entropy, **kwargs)
- 
-         torch.manual_seed(0)
-         torch.backends.cudnn.deterministic = True
-         torch.backends.cudnn.benchmark = False
- 
-         self.num_classes = self.data_loader.num_classes
-         self.init_network(device=self.device, **kwargs)
-         self._init_optimizer(lr=kwargs.get('lr'))
-         self.initialize_tensorkeys_for_functions()
- 
-     def _init_optimizer(self, lr):
-         """Initialize the optimizer."""
-         self.optimizer = optim.Adam(self.parameters(), lr=float(lr or 1e-3))
- 
-     def init_network(self,
-                      device,
-                      print_model=True,
-                      **kwargs):
-         """Create the network (model).
- 
-         Args:
-             device: The hardware device to use for training
-             print_model (bool): Print the model topology (Default=True)
-             **kwargs: Additional arguments to pass to the function
- 
-         """
-         channel = self.data_loader.get_feature_shape()[
-             0]  # (channel, dim1, dim2)
-         conv_kwargs = {'kernel_size': 3, 'stride': 1, 'padding': 1}
-         self.conv1 = nn.Conv2d(channel, 16, **conv_kwargs)
-         self.conv2 = nn.Conv2d(16, 32, **conv_kwargs)
-         self.conv3 = nn.Conv2d(32, 64, **conv_kwargs)
-         self.conv4 = nn.Conv2d(64, 128, **conv_kwargs)
-         self.conv5 = nn.Conv2d(128 + 32, 256, **conv_kwargs)
-         self.conv6 = nn.Conv2d(256, 512, **conv_kwargs)
-         self.conv7 = nn.Conv2d(512 + 128 + 32, 256, **conv_kwargs)
-         self.conv8 = nn.Conv2d(256, 512, **conv_kwargs)
-         self.fc1 = nn.Linear(1184 * 9 * 9, 128)
-         self.fc2 = nn.Linear(128, 8)
-         if print_model:
-             print(self)
-         self.to(device)
- 
-     def forward(self, x):
-         """Forward pass of the model.
- 
-         Args:
-             x: Data input to the model for the forward pass
-         """
-         x = F.relu(self.conv1(x))
-         x = F.relu(self.conv2(x))
-         maxpool = F.max_pool2d(x, 2, 2)
- 
-         x = F.relu(self.conv3(maxpool))
-         x = F.relu(self.conv4(x))
-         concat = torch.cat([maxpool, x], dim=1)
-         maxpool = F.max_pool2d(concat, 2, 2)
- 
-         x = F.relu(self.conv5(maxpool))
-         x = F.relu(self.conv6(x))
-         concat = torch.cat([maxpool, x], dim=1)
-         maxpool = F.max_pool2d(concat, 2, 2)
- 
-         x = F.relu(self.conv7(maxpool))
-         x = F.relu(self.conv8(x))
-         concat = torch.cat([maxpool, x], dim=1)
-         maxpool = F.max_pool2d(concat, 2, 2)
- 
-         x = maxpool.flatten(start_dim=1)
-         x = F.dropout(self.fc1(x), p=0.5)
-         x = self.fc2(x)
-         return x
- 
-     def validate(self, col_name, round_num, input_tensor_dict,
-                  use_tqdm=False, **kwargs):
-         """Validate.
- 
-         Run validation of the model on the local data.
- 
-         Args:
-             col_name:            Name of the collaborator
-             round_num:           What round is it
-             input_tensor_dict:   Required input tensors (for model)
-             use_tqdm (bool):     Use tqdm to print a progress
-                                  bar (Default=True)
- 
-         Returns:
-             global_output_dict:  Tensors to send back to the aggregator
-             local_output_dict:   Tensors to maintain in the local TensorDB
- 
-         """
-         self.rebuild_model(round_num, input_tensor_dict, validation=True)
-         self.eval()
-         val_score = 0
-         total_samples = 0
- 
-         loader = self.data_loader.get_valid_loader()
-         if use_tqdm:
-             loader = tqdm.tqdm(loader, desc='validate')
- 
-         with torch.no_grad():
-             for data, target in loader:
-                 samples = target.shape[0]
-                 total_samples += samples
-                 data, target = (torch.tensor(data).to(self.device),
-                                 torch.tensor(target).to(self.device))
-                 output = self(data)
-                 # get the index of the max log-probability
-                 pred = output.argmax(dim=1)
-                 val_score += pred.eq(target).sum().cpu().numpy()
- 
-         origin = col_name
-         suffix = 'validate'
-         if kwargs['apply'] == 'local':
-             suffix += '_local'
-         else:
-             suffix += '_agg'
-         tags = ('metric', suffix)
-         # TODO figure out a better way to pass in metric for
-         #  this pytorch validate function
-         output_tensor_dict = {
-             TensorKey('acc', origin, round_num, True, tags):
-                 np.array(val_score / total_samples)
-         }
- 
-         # empty list represents metrics that should only be stored locally
-         return output_tensor_dict, {}
- 
-     def reset_opt_vars(self):
-         """Reset optimizer variables.
- 
-         Resets the optimizer state variables.
- 
-         """
-         self._init_optimizer(lr=self.optimizer.defaults.get('lr'))
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_cnn_histology/src/pthistology_inmemory.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology/src/pthistology_inmemory.py
*** ./openfl/openfl-workspace/torch_cnn_histology/src/pthistology_inmemory.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology/src/pthistology_inmemory.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,32 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- 
- from openfl.federated import PyTorchDataLoader
- from .histology_utils import load_histology_shard
- 
- 
- class PyTorchHistologyInMemory(PyTorchDataLoader):
-     """PyTorch data loader for Histology dataset."""
- 
-     def __init__(self, data_path, batch_size, **kwargs):
-         """Instantiate the data object.
- 
-         Args:
-             data_path: The file path to the data
-             batch_size: The batch size of the data loader
-             **kwargs: Additional arguments, passed to super init
-              and load_mnist_shard
-         """
-         super().__init__(batch_size, random_seed=0, **kwargs)
- 
-         _, num_classes, X_train, y_train, X_valid, y_valid = load_histology_shard(
-             shard_num=int(data_path), **kwargs)
- 
-         self.X_train = X_train
-         self.y_train = y_train
-         self.X_valid = X_valid
-         self.y_valid = y_valid
- 
-         self.num_classes = num_classes
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_cnn_histology/src/requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology/src/requirements.txt
*** ./openfl/openfl-workspace/torch_cnn_histology/src/requirements.txt	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology/src/requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- torchvision==0.7.0
- Pillow==8.3.2
- tqdm==4.48.2
- numpy==1.19.1
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_cnn_histology_gramine_ready/plan/cols.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology_gramine_ready/plan/cols.yaml
*** ./openfl/openfl-workspace/torch_cnn_histology_gramine_ready/plan/cols.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology_gramine_ready/plan/cols.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- collaborators:
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_cnn_histology_gramine_ready/plan/data.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology_gramine_ready/plan/data.yaml
*** ./openfl/openfl-workspace/torch_cnn_histology_gramine_ready/plan/data.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology_gramine_ready/plan/data.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,5 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- one,1
- two,2
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_cnn_histology_gramine_ready/plan/plan.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology_gramine_ready/plan/plan.yaml
*** ./openfl/openfl-workspace/torch_cnn_histology_gramine_ready/plan/plan.yaml	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology_gramine_ready/plan/plan.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,41 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- aggregator :
-   defaults : plan/defaults/aggregator.yaml
-   template : openfl.component.Aggregator
-   settings :
-     init_state_path : save/torch_cnn_histology_init.pbuf
-     best_state_path : save/torch_cnn_histology_best.pbuf
-     last_state_path : save/torch_cnn_histology_last.pbuf
-     rounds_to_train : 20
- 
- collaborator :
-   defaults : plan/defaults/collaborator.yaml
-   template : openfl.component.Collaborator
-   settings :
-     delta_updates    : false
-     opt_treatment    : RESET
- 
- data_loader :
-   template : src.pthistology_inmemory.PyTorchHistologyInMemory
-   settings :
-     collaborator_count : 2
-     data_group_name    : histology
-     batch_size         : 32
- 
- task_runner:
-   defaults : plan/defaults/task_runner.yaml
-   template: src.pt_cnn.PyTorchCNN
- 
- network:
-   defaults: plan/defaults/network.yaml
- 
- tasks:
-   defaults: plan/defaults/tasks_torch.yaml
- 
- assigner:
-   defaults: plan/defaults/assigner.yaml
- 
- compression_pipeline :
-   defaults : plan/defaults/compression_pipeline.yaml
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_cnn_histology_gramine_ready/requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology_gramine_ready/requirements.txt
*** ./openfl/openfl-workspace/torch_cnn_histology_gramine_ready/requirements.txt	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology_gramine_ready/requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- -f https://download.pytorch.org/whl/cpu/torch_stable.html
- torch==1.6.0+cpu
- torchvision==0.7.0+cpu
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_cnn_histology_gramine_ready/src/histology_utils.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology_gramine_ready/src/histology_utils.py
*** ./openfl/openfl-workspace/torch_cnn_histology_gramine_ready/src/histology_utils.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology_gramine_ready/src/histology_utils.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,154 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- 
- from collections.abc import Iterable
- from logging import getLogger
- from os import makedirs
- from pathlib import Path
- from urllib.request import urlretrieve
- from zipfile import ZipFile
- 
- import numpy as np
- import torch
- from torch.utils.data import random_split
- from torchvision.datasets import ImageFolder
- from torchvision.transforms import ToTensor
- from tqdm import tqdm
- 
- from openfl.utilities import validate_file_hash
- 
- logger = getLogger(__name__)
- 
- 
- class HistologyDataset(ImageFolder):
-     """Colorectal Histology Dataset."""
- 
-     URL = ('https://zenodo.org/record/53169/files/Kather_'
-            'texture_2016_image_tiles_5000.zip?download=1')
-     FILENAME = 'Kather_texture_2016_image_tiles_5000.zip'
-     FOLDER_NAME = 'Kather_texture_2016_image_tiles_5000'
-     ZIP_SHA384 = ('7d86abe1d04e68b77c055820c2a4c582a1d25d2983e38ab724e'
-                   'ac75affce8b7cb2cbf5ba68848dcfd9d84005d87d6790')
-     DEFAULT_PATH = Path.cwd().absolute() / 'data'
- 
-     def __init__(self, root: Path = DEFAULT_PATH, **kwargs) -> None:
-         """Initialize."""
-         makedirs(root, exist_ok=True)
-         filepath = root / HistologyDataset.FILENAME
-         if not filepath.is_file():
-             self.pbar = tqdm(total=None)
-             urlretrieve(HistologyDataset.URL, filepath, self.report_hook)  # nosec
-             validate_file_hash(filepath, HistologyDataset.ZIP_SHA384)
-             with ZipFile(filepath, 'r') as f:
-                 f.extractall(root)
- 
-         super(HistologyDataset, self).__init__(root / HistologyDataset.FOLDER_NAME, **kwargs)
- 
-     def report_hook(self, count, block_size, total_size):
-         """Update progressbar."""
-         if self.pbar.total is None and total_size:
-             self.pbar.total = total_size
-         progress_bytes = count * block_size
-         self.pbar.update(progress_bytes - self.pbar.n)
- 
-     def __getitem__(self, index):
-         """Allow getting items by slice index."""
-         if isinstance(index, Iterable):
-             return [super(HistologyDataset, self).__getitem__(i) for i in index]
-         else:
-             return super(HistologyDataset, self).__getitem__(index)
- 
- 
- def one_hot(labels, classes):
-     """
-     One Hot encode a vector.
- 
-     Args:
-         labels (list):  List of labels to onehot encode
-         classes (int): Total number of categorical classes
- 
-     Returns:
-         np.array: Matrix of one-hot encoded labels
-     """
-     return np.eye(classes)[labels]
- 
- 
- def _load_raw_datashards(shard_num, collaborator_count, train_split_ratio=0.8):
-     """
-     Load the raw data by shard.
- 
-     Returns tuples of the dataset shard divided into training and validation.
- 
-     Args:
-         shard_num (int): The shard number to use
-         collaborator_count (int): The number of collaborators in the federation
- 
-     Returns:
-         2 tuples: (image, label) of the training, validation dataset
-     """
-     dataset = HistologyDataset(transform=ToTensor())
-     n_train = int(train_split_ratio * len(dataset))
-     n_valid = len(dataset) - n_train
-     ds_train, ds_val = random_split(
-         dataset, lengths=[n_train, n_valid], generator=torch.manual_seed(0))
- 
-     # create the shards
-     X_train, y_train = list(zip(*ds_train[shard_num::collaborator_count]))
-     X_train, y_train = np.stack(X_train), np.array(y_train)
- 
-     X_valid, y_valid = list(zip(*ds_val[shard_num::collaborator_count]))
-     X_valid, y_valid = np.stack(X_valid), np.array(y_valid)
- 
-     return (X_train, y_train), (X_valid, y_valid)
- 
- 
- def load_histology_shard(shard_num, collaborator_count,
-                          categorical=False, channels_last=False, **kwargs):
-     """
-     Load the Histology dataset.
- 
-     Args:
-         shard_num (int): The shard to use from the dataset
-         collaborator_count (int): The number of collaborators in the federation
-         categorical (bool): True = convert the labels to one-hot encoded
-          vectors (Default = True)
-         channels_last (bool): True = The input images have the channels
-          last (Default = True)
-         **kwargs: Additional parameters to pass to the function
- 
-     Returns:
-         list: The input shape
-         int: The number of classes
-         numpy.ndarray: The training data
-         numpy.ndarray: The training labels
-         numpy.ndarray: The validation data
-         numpy.ndarray: The validation labels
-     """
-     img_rows, img_cols = 150, 150
-     num_classes = 8
- 
-     (X_train, y_train), (X_valid, y_valid) = _load_raw_datashards(
-         shard_num, collaborator_count)
- 
-     if channels_last:
-         X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)
-         X_valid = X_valid.reshape(X_valid.shape[0], img_rows, img_cols, 3)
-         input_shape = (img_rows, img_cols, 3)
-     else:
-         X_train = X_train.reshape(X_train.shape[0], 3, img_rows, img_cols)
-         X_valid = X_valid.reshape(X_valid.shape[0], 3, img_rows, img_cols)
-         input_shape = (3, img_rows, img_cols)
- 
-     logger.info(f'Histology > X_train Shape : {X_train.shape}')
-     logger.info(f'Histology > y_train Shape : {y_train.shape}')
-     logger.info(f'Histology > Train Samples : {X_train.shape[0]}')
-     logger.info(f'Histology > Valid Samples : {X_valid.shape[0]}')
- 
-     if categorical:
-         # convert class vectors to binary class matrices
-         y_train = one_hot(y_train, num_classes)
-         y_valid = one_hot(y_valid, num_classes)
- 
-     return input_shape, num_classes, X_train, y_train, X_valid, y_valid
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_cnn_histology_gramine_ready/src/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology_gramine_ready/src/__init__.py
*** ./openfl/openfl-workspace/torch_cnn_histology_gramine_ready/src/__init__.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology_gramine_ready/src/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """You may copy this file as the starting point of your own model."""
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_cnn_histology_gramine_ready/src/pt_cnn.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology_gramine_ready/src/pt_cnn.py
*** ./openfl/openfl-workspace/torch_cnn_histology_gramine_ready/src/pt_cnn.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology_gramine_ready/src/pt_cnn.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,165 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- import numpy as np
- import torch
- import torch.nn as nn
- import torch.nn.functional as F
- import torch.optim as optim
- import tqdm
- 
- from openfl.federated import PyTorchTaskRunner
- from openfl.utilities import TensorKey
- 
- 
- def cross_entropy(output, target):
-     """Calculate Cross-entropy loss."""
-     return F.cross_entropy(input=output, target=target)
- 
- 
- class PyTorchCNN(PyTorchTaskRunner):
-     """Simple CNN for classification."""
- 
-     def __init__(self, **kwargs):
-         """Initialize.
- 
-         Args:
-             **kwargs: Additional arguments to pass to the function
-         """
-         super().__init__(loss_fn=cross_entropy, **kwargs)
- 
-         torch.manual_seed(0)
-         torch.backends.cudnn.deterministic = True
-         torch.backends.cudnn.benchmark = False
- 
-         self.num_classes = self.data_loader.num_classes
-         self.init_network(device=self.device, **kwargs)
-         self._init_optimizer(lr=kwargs.get('lr'))
-         self.initialize_tensorkeys_for_functions()
- 
-     def _init_optimizer(self, lr):
-         """Initialize the optimizer."""
-         self.optimizer = optim.Adam(self.parameters(), lr=float(lr or 1e-3))
- 
-     def init_network(self,
-                      device,
-                      print_model=True,
-                      **kwargs):
-         """Create the network (model).
- 
-         Args:
-             device: The hardware device to use for training
-             print_model (bool): Print the model topology (Default=True)
-             **kwargs: Additional arguments to pass to the function
- 
-         """
-         channel = self.data_loader.get_feature_shape()[
-             0]  # (channel, dim1, dim2)
-         conv_kwargs = {'kernel_size': 3, 'stride': 1, 'padding': 1}
-         self.conv1 = nn.Conv2d(channel, 16, **conv_kwargs)
-         self.conv2 = nn.Conv2d(16, 32, **conv_kwargs)
-         self.conv3 = nn.Conv2d(32, 64, **conv_kwargs)
-         self.conv4 = nn.Conv2d(64, 128, **conv_kwargs)
-         self.conv5 = nn.Conv2d(128 + 32, 256, **conv_kwargs)
-         self.conv6 = nn.Conv2d(256, 512, **conv_kwargs)
-         self.conv7 = nn.Conv2d(512 + 128 + 32, 256, **conv_kwargs)
-         self.conv8 = nn.Conv2d(256, 512, **conv_kwargs)
-         self.fc1 = nn.Linear(1184 * 9 * 9, 128)
-         self.fc2 = nn.Linear(128, 8)
-         if print_model:
-             print(self)
-         self.to(device)
- 
-     def forward(self, x):
-         """Forward pass of the model.
- 
-         Args:
-             x: Data input to the model for the forward pass
-         """
-         x = F.relu(self.conv1(x))
-         x = F.relu(self.conv2(x))
-         maxpool = F.max_pool2d(x, 2, 2)
- 
-         x = F.relu(self.conv3(maxpool))
-         x = F.relu(self.conv4(x))
-         concat = torch.cat([maxpool, x], dim=1)
-         maxpool = F.max_pool2d(concat, 2, 2)
- 
-         x = F.relu(self.conv5(maxpool))
-         x = F.relu(self.conv6(x))
-         concat = torch.cat([maxpool, x], dim=1)
-         maxpool = F.max_pool2d(concat, 2, 2)
- 
-         x = F.relu(self.conv7(maxpool))
-         x = F.relu(self.conv8(x))
-         concat = torch.cat([maxpool, x], dim=1)
-         maxpool = F.max_pool2d(concat, 2, 2)
- 
-         x = maxpool.flatten(start_dim=1)
-         x = F.dropout(self.fc1(x), p=0.5)
-         x = self.fc2(x)
-         return x
- 
-     def validate(self, col_name, round_num, input_tensor_dict,
-                  use_tqdm=False, **kwargs):
-         """Validate.
- 
-         Run validation of the model on the local data.
- 
-         Args:
-             col_name:            Name of the collaborator
-             round_num:           What round is it
-             input_tensor_dict:   Required input tensors (for model)
-             use_tqdm (bool):     Use tqdm to print a progress
-                                  bar (Default=True)
- 
-         Returns:
-             global_output_dict:  Tensors to send back to the aggregator
-             local_output_dict:   Tensors to maintain in the local TensorDB
- 
-         """
-         self.rebuild_model(round_num, input_tensor_dict, validation=True)
-         self.eval()
-         val_score = 0
-         total_samples = 0
- 
-         loader = self.data_loader.get_valid_loader()
-         if use_tqdm:
-             loader = tqdm.tqdm(loader, desc='validate')
- 
-         with torch.no_grad():
-             for data, target in loader:
-                 samples = target.shape[0]
-                 total_samples += samples
-                 data, target = (torch.tensor(data).to(self.device),
-                                 torch.tensor(target).to(self.device))
-                 output = self(data)
-                 # get the index of the max log-probability
-                 pred = output.argmax(dim=1)
-                 val_score += pred.eq(target).sum().cpu().numpy()
- 
-         origin = col_name
-         suffix = 'validate'
-         if kwargs['apply'] == 'local':
-             suffix += '_local'
-         else:
-             suffix += '_agg'
-         tags = ('metric', suffix)
-         # TODO figure out a better way to pass in metric for
-         #  this pytorch validate function
-         output_tensor_dict = {
-             TensorKey('acc', origin, round_num, True, tags):
-                 np.array(val_score / total_samples)
-         }
- 
-         # empty list represents metrics that should only be stored locally
-         return output_tensor_dict, {}
- 
-     def reset_opt_vars(self):
-         """Reset optimizer variables.
- 
-         Resets the optimizer state variables.
- 
-         """
-         self._init_optimizer(lr=self.optimizer.defaults.get('lr'))
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_cnn_histology_gramine_ready/src/pthistology_inmemory.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology_gramine_ready/src/pthistology_inmemory.py
*** ./openfl/openfl-workspace/torch_cnn_histology_gramine_ready/src/pthistology_inmemory.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_histology_gramine_ready/src/pthistology_inmemory.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,32 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- 
- from openfl.federated import PyTorchDataLoader
- from .histology_utils import load_histology_shard
- 
- 
- class PyTorchHistologyInMemory(PyTorchDataLoader):
-     """PyTorch data loader for Histology dataset."""
- 
-     def __init__(self, data_path, batch_size, **kwargs):
-         """Instantiate the data object.
- 
-         Args:
-             data_path: The file path to the data
-             batch_size: The batch size of the data loader
-             **kwargs: Additional arguments, passed to super init
-              and load_mnist_shard
-         """
-         super().__init__(batch_size, random_seed=0, **kwargs)
- 
-         _, num_classes, X_train, y_train, X_valid, y_valid = load_histology_shard(
-             shard_num=int(data_path), **kwargs)
- 
-         self.X_train = X_train
-         self.y_train = y_train
-         self.X_valid = X_valid
-         self.y_valid = y_valid
- 
-         self.num_classes = num_classes
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_cnn_mnist/plan/cols.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_mnist/plan/cols.yaml
*** ./openfl/openfl-workspace/torch_cnn_mnist/plan/cols.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_mnist/plan/cols.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,5 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- collaborators:
-   
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_cnn_mnist/plan/data.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_mnist/plan/data.yaml
*** ./openfl/openfl-workspace/torch_cnn_mnist/plan/data.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_mnist/plan/data.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,9 ****
- ## Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- # all keys under 'collaborators' corresponds to a specific colaborator name the corresponding dictionary has data_name, data_path pairs.
- # Note that in the mnist case we do not store the data locally, and the data_path is used to pass an integer that helps the data object
- # construct the shard of the mnist dataset to be use for this collaborator.
- 
- # collaborator_name ,data_directory_path
- one,1
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_cnn_mnist/plan/defaults ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_mnist/plan/defaults
*** ./openfl/openfl-workspace/torch_cnn_mnist/plan/defaults	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_mnist/plan/defaults	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- ../../workspace/plan/defaults
- 
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_cnn_mnist/plan/plan.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_mnist/plan/plan.yaml
*** ./openfl/openfl-workspace/torch_cnn_mnist/plan/plan.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_mnist/plan/plan.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,45 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- aggregator :
-   defaults : plan/defaults/aggregator.yaml
-   template : openfl.component.Aggregator
-   settings :
-     init_state_path     : save/torch_cnn_mnist_init.pbuf
-     best_state_path     : save/torch_cnn_mnist_best.pbuf
-     last_state_path     : save/torch_cnn_mnist_last.pbuf
-     rounds_to_train     : 10
-     log_metric_callback :
-       template : src.mnist_utils.write_metric
- 
- 
- collaborator :
-   defaults : plan/defaults/collaborator.yaml
-   template : openfl.component.Collaborator
-   settings :
-     delta_updates    : false
-     opt_treatment    : RESET
- 
- data_loader :
-   defaults : plan/defaults/data_loader.yaml
-   template : src.ptmnist_inmemory.PyTorchMNISTInMemory
-   settings :
-     collaborator_count : 2
-     data_group_name    : mnist
-     batch_size         : 256
- 
- task_runner :
-   defaults : plan/defaults/task_runner.yaml
-   template : src.pt_cnn.PyTorchCNN
- 
- network :
-   defaults : plan/defaults/network.yaml
- 
- assigner :
-   defaults : plan/defaults/assigner.yaml
-   
- tasks :
-   defaults : plan/defaults/tasks_torch.yaml
- 
- compression_pipeline :
-   defaults : plan/defaults/compression_pipeline.yaml
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_cnn_mnist/requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_mnist/requirements.txt
*** ./openfl/openfl-workspace/torch_cnn_mnist/requirements.txt	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_mnist/requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- torch == 1.8.1
- torchvision == 0.9.1
- tensorboard
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_cnn_mnist/src/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_mnist/src/__init__.py
*** ./openfl/openfl-workspace/torch_cnn_mnist/src/__init__.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_mnist/src/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """You may copy this file as the starting point of your own model."""
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_cnn_mnist/src/mnist_utils.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_mnist/src/mnist_utils.py
*** ./openfl/openfl-workspace/torch_cnn_mnist/src/mnist_utils.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_mnist/src/mnist_utils.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,115 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- 
- from logging import getLogger
- 
- import numpy as np
- from torch.utils.tensorboard import SummaryWriter
- from torchvision import datasets
- from torchvision import transforms
- 
- logger = getLogger(__name__)
- 
- writer = None
- 
- 
- def get_writer():
-     """Create global writer object."""
-     global writer
-     if not writer:
-         writer = SummaryWriter('./logs/cnn_mnist', flush_secs=5)
- 
- 
- def write_metric(node_name, task_name, metric_name, metric, round_number):
-     """Write metric callback."""
-     get_writer()
-     writer.add_scalar(f'{node_name}/{task_name}/{metric_name}', metric, round_number)
- 
- 
- def one_hot(labels, classes):
-     """
-     One Hot encode a vector.
- 
-     Args:
-         labels (list):  List of labels to onehot encode
-         classes (int): Total number of categorical classes
- 
-     Returns:
-         np.array: Matrix of one-hot encoded labels
-     """
-     return np.eye(classes)[labels]
- 
- 
- def _load_raw_datashards(shard_num, collaborator_count, transform=None):
-     """
-     Load the raw data by shard.
- 
-     Returns tuples of the dataset shard divided into training and validation.
- 
-     Args:
-         shard_num (int): The shard number to use
-         collaborator_count (int): The number of collaborators in the federation
-         transform: torchvision.transforms.Transform to apply to images
- 
-     Returns:
-         2 tuples: (image, label) of the training, validation dataset
-     """
-     train_data, val_data = (
-         datasets.MNIST('data', train=train, download=True, transform=transform)
-         for train in (True, False)
-     )
-     X_train_tot, y_train_tot = train_data.train_data, train_data.train_labels
-     X_valid_tot, y_valid_tot = val_data.test_data, val_data.test_labels
- 
-     # create the shards
-     shard_num = int(shard_num)
-     X_train = X_train_tot[shard_num::collaborator_count].unsqueeze(1).float()
-     y_train = y_train_tot[shard_num::collaborator_count]
- 
-     X_valid = X_valid_tot[shard_num::collaborator_count].unsqueeze(1).float()
-     y_valid = y_valid_tot[shard_num::collaborator_count]
- 
-     return (X_train, y_train), (X_valid, y_valid)
- 
- 
- def load_mnist_shard(shard_num, collaborator_count,
-                      categorical=False, channels_last=True, **kwargs):
-     """
-     Load the MNIST dataset.
- 
-     Args:
-         shard_num (int): The shard to use from the dataset
-         collaborator_count (int): The number of collaborators in the
-                                   federation
-         categorical (bool): True = convert the labels to one-hot encoded
-                             vectors (Default = True)
-         channels_last (bool): True = The input images have the channels
-                               last (Default = True)
-         **kwargs: Additional parameters to pass to the function
- 
-     Returns:
-         list: The input shape
-         int: The number of classes
-         numpy.ndarray: The training data
-         numpy.ndarray: The training labels
-         numpy.ndarray: The validation data
-         numpy.ndarray: The validation labels
-     """
-     num_classes = 10
- 
-     (X_train, y_train), (X_valid, y_valid) = _load_raw_datashards(
-         shard_num, collaborator_count, transform=transforms.ToTensor())
- 
-     logger.info(f'MNIST > X_train Shape : {X_train.shape}')
-     logger.info(f'MNIST > y_train Shape : {y_train.shape}')
-     logger.info(f'MNIST > Train Samples : {X_train.shape[0]}')
-     logger.info(f'MNIST > Valid Samples : {X_valid.shape[0]}')
- 
-     if categorical:
-         # convert class vectors to binary class matrices
-         y_train = one_hot(y_train, num_classes)
-         y_valid = one_hot(y_valid, num_classes)
- 
-     return num_classes, X_train, y_train, X_valid, y_valid
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_cnn_mnist/src/pt_cnn.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_mnist/src/pt_cnn.py
*** ./openfl/openfl-workspace/torch_cnn_mnist/src/pt_cnn.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_mnist/src/pt_cnn.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,195 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- import numpy as np
- import torch
- import torch.nn as nn
- import torch.nn.functional as F
- import torch.optim as optim
- import tqdm
- 
- from openfl.federated import PyTorchTaskRunner
- from openfl.utilities import TensorKey
- 
- 
- def cross_entropy(output, target):
-     """Binary cross-entropy metric.
- 
-     Args:
-         output: The mode prediction
-         target: The target (ground truth label)
- 
-     Returns:
-         Binary cross-entropy with logits
- 
-     """
-     return F.cross_entropy(input=output, target=target)
- 
- 
- class PyTorchCNN(PyTorchTaskRunner):
-     """Simple CNN for classification."""
- 
-     def __init__(self, device='cpu', **kwargs):
-         """Initialize.
- 
-         Args:
-             data: The data loader class
-             device: The hardware device to use for training (Default = "cpu")
-             **kwargs: Additional arguments to pass to the function
- 
-         """
-         super().__init__(device=device, **kwargs)
- 
-         self.num_classes = self.data_loader.num_classes
-         self.init_network(device=self.device, **kwargs)
-         self._init_optimizer()
-         self.loss_fn = cross_entropy
-         self.initialize_tensorkeys_for_functions()
- 
-     def _init_optimizer(self):
-         """Initialize the optimizer."""
-         self.optimizer = optim.Adam(self.parameters(), lr=1e-4)
- 
-     def init_network(self,
-                      device,
-                      print_model=True,
-                      pool_sqrkernel_size=2,
-                      conv_sqrkernel_size=5,
-                      conv1_channels_out=20,
-                      conv2_channels_out=50,
-                      fc2_insize=500,
-                      **kwargs):
-         """Create the network (model).
- 
-         Args:
-             device: The hardware device to use for training
-             print_model (bool): Print the model topology (Default=True)
-             pool_sqrkernel_size (int): Max pooling kernel size (Default=2),
-                                        assumes square 2x2
-             conv_sqrkernel_size (int): Convolutional filter size (Default=5),
-                                        assumes square 5x5
-             conv1_channels_out (int): Number of filters in first
-                                       convolutional layer (Default=20)
-             conv2_channels_out: Number of filters in second convolutional
-                                 layer (Default=50)
-             fc2_insize (int): Number of neurons in the
-                               fully-connected layer (Default = 500)
-             **kwargs: Additional arguments to pass to the function
- 
-         FIXME: We are tracking only side lengths (rather than
-         length and width) as we are assuming square
-         shapes for feature and kernels.
-         In order that all of the input and activation components are
-         used (not cut off), we rely on a criterion: appropriate integers
-         are divisible so that all casting to int perfomed below does no
-         rounding (i.e. all int casting simply converts a float with '0'
-         in the decimal part to an int.)
- 
-         (Note this criterion held for the original input sizes considered
-         for this model: 28x28 and 32x32 when used with the default values
-         above)
-         """
-         self.pool_sqrkernel_size = pool_sqrkernel_size
-         channel = self.data_loader.get_feature_shape()[0]  # (channel, dim1, dim2)
-         self.conv1 = nn.Conv2d(channel, conv1_channels_out, conv_sqrkernel_size, 1)
- 
-         # perform some calculations to track the size of the single channel activations
-         # channels are first for pytorch
-         conv1_sqrsize_in = self.feature_shape[-1]
-         conv1_sqrsize_out = conv1_sqrsize_in - (conv_sqrkernel_size - 1)
-         # a pool operation happens after conv1 out
-         # (note dependence on 'forward' function below)
-         conv2_sqrsize_in = int(conv1_sqrsize_out / pool_sqrkernel_size)
- 
-         self.conv2 = nn.Conv2d(conv1_channels_out, conv2_channels_out, conv_sqrkernel_size, 1)
- 
-         # more tracking of single channel activation size
-         conv2_sqrsize_out = conv2_sqrsize_in - (conv_sqrkernel_size - 1)
-         # a pool operation happens after conv2 out
-         # (note dependence on 'forward' function below)
-         l0 = int(conv2_sqrsize_out / pool_sqrkernel_size)
-         self.fc1_insize = l0 * l0 * conv2_channels_out
-         self.fc1 = nn.Linear(self.fc1_insize, fc2_insize)
-         self.fc2 = nn.Linear(fc2_insize, self.num_classes)
-         if print_model:
-             print(self)
-         self.to(device)
- 
-     def forward(self, x):
-         """Forward pass of the model.
- 
-         Args:
-             x: Data input to the model for the forward pass
-         """
-         x = F.relu(self.conv1(x))
-         pl = self.pool_sqrkernel_size
-         x = F.max_pool2d(x, pl, pl)
-         x = F.relu(self.conv2(x))
-         x = F.max_pool2d(x, pl, pl)
-         x = x.view(-1, self.fc1_insize)
-         x = F.relu(self.fc1(x))
-         x = self.fc2(x)
-         return x
- 
-     def validate(self, col_name, round_num, input_tensor_dict, use_tqdm=False, **kwargs):
-         """Validate.
- 
-         Run validation of the model on the local data.
- 
-         Args:
-             col_name:            Name of the collaborator
-             round_num:           What round is it
-             input_tensor_dict:   Required input tensors (for model)
-             use_tqdm (bool):     Use tqdm to print a progress bar (Default=True)
- 
-         Returns:
-             global_output_dict:  Tensors to send back to the aggregator
-             local_output_dict:   Tensors to maintain in the local TensorDB
- 
-         """
-         self.rebuild_model(round_num, input_tensor_dict, validation=True)
-         self.eval()
-         val_score = 0
-         total_samples = 0
- 
-         loader = self.data_loader.get_valid_loader()
-         if use_tqdm:
-             loader = tqdm.tqdm(loader, desc='validate')
- 
-         with torch.no_grad():
-             for data, target in loader:
-                 samples = target.shape[0]
-                 total_samples += samples
-                 data, target = torch.tensor(data).to(
-                     self.device), torch.tensor(target).to(
-                     self.device, dtype=torch.int64)
-                 output = self(data)
-                 # get the index of the max log-probability
-                 pred = output.argmax(dim=1)
-                 val_score += pred.eq(target).sum().cpu().numpy()
- 
-         origin = col_name
-         suffix = 'validate'
-         if kwargs['apply'] == 'local':
-             suffix += '_local'
-         else:
-             suffix += '_agg'
-         tags = ('metric', suffix)
-         # TODO figure out a better way to pass
-         #  in metric for this pytorch validate function
-         output_tensor_dict = {
-             TensorKey('acc', origin, round_num, True, tags):
-                 np.array(val_score / total_samples)
-         }
- 
-         # Empty list represents metrics that should only be stored locally
-         return output_tensor_dict, {}
- 
-     def reset_opt_vars(self):
-         """Reset optimizer variables.
- 
-         Resets the optimizer state variables.
- 
-         """
-         self._init_optimizer()
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_cnn_mnist/src/ptmnist_inmemory.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_mnist/src/ptmnist_inmemory.py
*** ./openfl/openfl-workspace/torch_cnn_mnist/src/ptmnist_inmemory.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_mnist/src/ptmnist_inmemory.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,41 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- 
- from openfl.federated import PyTorchDataLoader
- from .mnist_utils import load_mnist_shard
- 
- 
- class PyTorchMNISTInMemory(PyTorchDataLoader):
-     """PyTorch data loader for MNIST dataset."""
- 
-     def __init__(self, data_path, batch_size, **kwargs):
-         """Instantiate the data object.
- 
-         Args:
-             data_path: The file path to the data
-             batch_size: The batch size of the data loader
-             **kwargs: Additional arguments, passed to super
-              init and load_mnist_shard
-         """
-         super().__init__(batch_size, **kwargs)
- 
-         # TODO: We should be downloading the dataset shard into a directory
-         # TODO: There needs to be a method to ask how many collaborators and
-         #  what index/rank is this collaborator.
-         # Then we have a way to automatically shard based on rank and size
-         # of collaborator list.
- 
-         num_classes, X_train, y_train, X_valid, y_valid = load_mnist_shard(
-             shard_num=int(data_path), **kwargs)
- 
-         self.X_train = X_train
-         self.y_train = y_train
-         self.train_loader = self.get_train_loader()
- 
-         self.X_valid = X_valid
-         self.y_valid = y_valid
-         self.val_loader = self.get_valid_loader()
- 
-         self.num_classes = num_classes
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_cnn_mnist/.workspace ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_mnist/.workspace
*** ./openfl/openfl-workspace/torch_cnn_mnist/.workspace	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_cnn_mnist/.workspace	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- current_plan_name: default
- 
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_unet_kvasir/plan/cols.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir/plan/cols.yaml
*** ./openfl/openfl-workspace/torch_unet_kvasir/plan/cols.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir/plan/cols.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- collaborators:
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_unet_kvasir/plan/data.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir/plan/data.yaml
*** ./openfl/openfl-workspace/torch_unet_kvasir/plan/data.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir/plan/data.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,10 ****
- ## Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- # all keys under 'collaborators' corresponds to a specific colaborator name the corresponding dictionary has data_name, data_path pairs.
- # Note that in the kvasir case we split general dataset by shards, and the data_path is used to pass an integer that helps the data object
- # construct the shard of the kvasir dataset to be use for this collaborator.
- 
- # collaborator_name ,data_directory_path
- one,1
- two,2
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_unet_kvasir/plan/defaults ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir/plan/defaults
*** ./openfl/openfl-workspace/torch_unet_kvasir/plan/defaults	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir/plan/defaults	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- ../../workspace/plan/defaults
- 
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_unet_kvasir/plan/plan.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir/plan/plan.yaml
*** ./openfl/openfl-workspace/torch_unet_kvasir/plan/plan.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir/plan/plan.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,60 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- aggregator :
-   defaults : plan/defaults/aggregator.yaml
-   template : openfl.component.Aggregator
-   settings :
-     init_state_path : save/torch_unet_kvasir_init.pbuf
-     best_state_path : save/torch_unet_kvasir_best.pbuf
-     last_state_path : save/torch_unet_kvasir_last.pbuf
-     rounds_to_train : 40
- 
- collaborator :
-   defaults : plan/defaults/collaborator.yaml
-   template : openfl.component.Collaborator
-   settings :
-     epochs_per_round : 1.0
-     polling_interval : 4
-     delta_updates    : false
-     opt_treatment    : RESET
- 
- data_loader :
-   defaults : plan/defaults/data_loader.yaml
-   template : src.data_loader.PyTorchKvasirDataLoader
-   settings :
-     collaborator_count : 2
-     data_group_name    : kvasir
-     batch_size         : 4
- 
- task_runner :
-   defaults : plan/defaults/task_runner.yaml
-   template : src.fed_unet_runner.PyTorchFederatedUnet
-   settings :
-     n_channels : 3
-     n_classes  : 1
- 
- network :
-   defaults : plan/defaults/network.yaml
- 
- assigner :
-   defaults : plan/defaults/assigner.yaml
- 
- tasks :
-   defaults : plan/defaults/tasks_torch.yaml
-   aggregated_model_validation:
-     function  : validate
-     kwargs    :
-       apply   : global
-       metrics :
-       - dice_coef
-   
-   locally_tuned_model_validation:
-     function  : validate
-     kwargs    :
-       apply   : local
-       metrics :
-       - dice_coef
- 
- compression_pipeline :
-   defaults : plan/defaults/compression_pipeline.yaml
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_unet_kvasir/requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir/requirements.txt
*** ./openfl/openfl-workspace/torch_unet_kvasir/requirements.txt	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir/requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- torch==1.7.1
- torchvision==0.8.2
- scikit-image==0.17.2
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_unet_kvasir/src/data_loader.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir/src/data_loader.py
*** ./openfl/openfl-workspace/torch_unet_kvasir/src/data_loader.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir/src/data_loader.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,149 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- 
- import zipfile
- from os import listdir
- from pathlib import Path
- 
- import numpy as np
- import PIL
- from skimage import io
- from torch.utils.data import DataLoader
- from torch.utils.data import Dataset
- from torchvision import transforms as tsf
- from torchvision.datasets.utils import download_url
- from tqdm import tqdm
- 
- from openfl.federated import PyTorchDataLoader
- from openfl.utilities import validate_file_hash
- 
- 
- def read_data(image_path, mask_path):
-     """Read image and mask from disk.
- 
-     Args:
-         image_path: Path to image
-         mask_path:  Path to mask
- 
-     Returns:
-         Numpy image and mask
- 
-     """
-     img = io.imread(image_path)
-     assert(img.shape[2] == 3)
-     mask = io.imread(mask_path)
-     return (img, mask[:, :, 0].astype(np.uint8))
- 
- 
- class KvasirDataset(Dataset):
-     """Kvasir dataset. Splits data by shards for each collaborator."""
- 
-     def __init__(self, is_validation, shard_num, collaborator_count, **kwargs):
-         """Initialize dataset.
- 
-         Args:
-             is_validation: Validation dataset or not
-             shard_num: Number of collaborator for which the data is splited
-             collaborator_count: Total number of collaborators
- 
-         """
-         self.images_path = './data/segmented-images/images/'
-         self.masks_path = './data/segmented-images/masks/'
-         self.images_names = [
-             img_name
-             for img_name in sorted(listdir(self.images_path))
-             if len(img_name) > 3 and img_name[-3:] == 'jpg'
-         ]
- 
-         self.images_names = self.images_names[shard_num:: collaborator_count]
-         self.is_validation = is_validation
-         assert(len(self.images_names) > 8)
-         validation_size = len(self.images_names) // 8
- 
-         if is_validation:
-             self.images_names = self.images_names[-validation_size:]
-         else:
-             self.images_names = self.images_names[: -validation_size]
- 
-         self.img_trans = tsf.Compose([
-             tsf.ToPILImage(),
-             tsf.Resize((332, 332)),
-             tsf.ToTensor(),
-             tsf.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])
-         self.mask_trans = tsf.Compose([
-             tsf.ToPILImage(),
-             tsf.Resize((332, 332), interpolation=PIL.Image.NEAREST),
-             tsf.ToTensor()])
- 
-     def __getitem__(self, index):
-         """Get items by slice index."""
-         name = self.images_names[index]
-         img, mask = read_data(self.images_path + name, self.masks_path + name)
-         img = self.img_trans(img)
-         mask = self.mask_trans(mask)
-         return img, mask
- 
-     def __len__(self):
-         """Length of spltted data."""
-         return len(self.images_names)
- 
- 
- def load_kvasir_dataset():
-     """Load and unzip kvasir dataset."""
-     zip_sha384 = ('e30d18a772c6520476e55b610a4db457237f151e'
-                   '19182849d54b49ae24699881c1e18e0961f77642be900450ef8b22e7')
-     data_url = ('https://datasets.simula.no/downloads/'
-                 'hyper-kvasir/hyper-kvasir-segmented-images.zip')
-     filename = 'kvasir.zip'
-     data_folder_path = Path.cwd().absolute() / 'data'
-     kvasir_archive_path = data_folder_path / filename
-     if not kvasir_archive_path.is_file():
-         download_url(data_url, data_folder_path, filename=filename)
-         validate_file_hash(kvasir_archive_path, zip_sha384)
-         with zipfile.ZipFile(kvasir_archive_path, 'r') as zip_ref:
-             for member in tqdm(iterable=zip_ref.infolist(), desc='Unzipping dataset'):
-                 zip_ref.extract(member, './data')
- 
- 
- class PyTorchKvasirDataLoader(PyTorchDataLoader):
-     """PyTorch data loader for Kvasir dataset."""
- 
-     def __init__(self, data_path, batch_size, **kwargs):
-         """Instantiate the data object.
- 
-         Args:
-             data_path: The file path to the data
-             batch_size: The batch size of the data loader
-             **kwargs: Additional arguments, passed to super
-              init and load_mnist_shard
-         """
-         super().__init__(batch_size, **kwargs)
- 
-         load_kvasir_dataset()
-         self.valid_dataset = KvasirDataset(True, shard_num=int(data_path), **kwargs)
-         self.train_dataset = KvasirDataset(False, shard_num=int(data_path), **kwargs)
-         self.train_loader = self.get_train_loader()
-         self.val_loader = self.get_valid_loader()
-         self.batch_size = batch_size
- 
-     def get_valid_loader(self, num_batches=None):
-         """Return validation dataloader."""
-         return DataLoader(self.valid_dataset, batch_size=self.batch_size)
- 
-     def get_train_loader(self, num_batches=None):
-         """Return train dataloader."""
-         return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)
- 
-     def get_train_data_size(self):
-         """Return size of train dataset."""
-         return len(self.train_dataset)
- 
-     def get_valid_data_size(self):
-         """Return size of validation dataset."""
-         return len(self.valid_dataset)
- 
-     def get_feature_shape(self):
-         """Return data shape."""
-         return self.valid_dataset[0][0].shape
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_unet_kvasir/src/fed_unet_runner.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir/src/fed_unet_runner.py
*** ./openfl/openfl-workspace/torch_unet_kvasir/src/fed_unet_runner.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir/src/fed_unet_runner.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,148 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- import numpy as np
- import torch
- import torch.nn as nn
- import torch.optim as optim
- import tqdm
- 
- from openfl.federated import PyTorchTaskRunner
- from openfl.utilities import TensorKey
- from .pt_unet_parts import DoubleConv
- from .pt_unet_parts import Down
- from .pt_unet_parts import soft_dice_coef
- from .pt_unet_parts import soft_dice_loss
- from .pt_unet_parts import Up
- 
- 
- class PyTorchFederatedUnet(PyTorchTaskRunner):
-     """Simple Unet for segmentation."""
- 
-     def __init__(self, device='cpu', **kwargs):
-         """Initialize.
- 
-         Args:
-             device: The hardware device to use for training (Default = "cpu")
-             **kwargs: Additional arguments to pass to the function
- 
-         """
-         super().__init__(device=device, **kwargs)
-         self.init_network(device=self.device, **kwargs)
-         self._init_optimizer()
-         self.loss_fn = soft_dice_loss
-         self.initialize_tensorkeys_for_functions()
- 
-     def _init_optimizer(self):
-         """Initialize the optimizer."""
-         self.optimizer = optim.Adam(self.parameters(), lr=1e-3)
- 
-     def init_network(self,
-                      device,
-                      n_channels,
-                      n_classes,
-                      print_model=True,
-                      **kwargs):
-         """Create the network (model).
- 
-         Args:
-             device: The hardware device to use for training
-             n_channels: Number of input image channels
-             n_classes: Number of output classes (1 for segmentation)
-             print_model: Print the model topology (Default=True)
-             **kwargs: Additional arguments to pass to the function
- 
-         """
-         self.n_channels = n_channels
-         self.n_classes = n_classes
-         self.inc = DoubleConv(self.n_channels, 64)
-         self.down1 = Down(64, 128)
-         self.down2 = Down(128, 256)
-         self.down3 = Down(256, 512)
-         self.down4 = Down(512, 1024)
-         self.up1 = Up(1024, 512)
-         self.up2 = Up(512, 256)
-         self.up3 = Up(256, 128)
-         self.up4 = Up(128, 64)
-         self.outc = nn.Conv2d(64, self.n_classes, 1)
-         if print_model:
-             print(self)
-         self.to(device)
- 
-     def forward(self, x):
-         """Forward pass of the model.
- 
-         Args:
-             x: Data input to the model for the forward pass
-         """
-         x1 = self.inc(x)
-         x2 = self.down1(x1)
-         x3 = self.down2(x2)
-         x4 = self.down3(x3)
-         x5 = self.down4(x4)
-         x = self.up1(x5, x4)
-         x = self.up2(x, x3)
-         x = self.up3(x, x2)
-         x = self.up4(x, x1)
-         x = self.outc(x)
-         x = torch.sigmoid(x)
-         return x
- 
-     def validate(self, col_name, round_num, input_tensor_dict, use_tqdm=True, **kwargs):
-         """Run validation of the model on the local data.
- 
-         Args:
-             col_name:            Name of the collaborator
-             round_num:           What round is it
-             input_tensor_dict:   Required input tensors (for model)
-             use_tqdm:     Use tqdm to print a progress bar (Default=True)
- 
-         Returns:
-             global_output_dict:  Tensors to send back to the aggregator
-             local_output_dict:   Tensors to maintain in the local TensorDB
-         """
-         self.rebuild_model(round_num, input_tensor_dict, validation=True)
-         self.eval()
-         self.to(self.device)
-         val_score = 0
-         total_samples = 0
- 
-         loader = self.data_loader.get_valid_loader()
-         if use_tqdm:
-             loader = tqdm.tqdm(loader, desc='validate')
- 
-         with torch.no_grad():
-             for data, target in loader:
-                 samples = target.shape[0]
-                 total_samples += samples
-                 data, target = torch.tensor(data).to(self.device), torch.tensor(
-                     target).to(self.device)
-                 output = self(data)
-                 # get the index of the max log-probability
-                 val = soft_dice_coef(output, target)
-                 val_score += val.sum().cpu().numpy()
- 
-         origin = col_name
-         suffix = 'validate'
-         if kwargs['apply'] == 'local':
-             suffix += '_local'
-         else:
-             suffix += '_agg'
-         tags = ('metric', suffix)
-         # TODO figure out a better way to pass in metric for this pytorch
-         #  validate function
-         output_tensor_dict = {
-             TensorKey('dice_coef', origin, round_num, True, tags):
-                 np.array(val_score / total_samples)
-         }
- 
-         return output_tensor_dict, {}
- 
-     def reset_opt_vars(self):
-         """Reset optimizer variables.
- 
-         Resets the optimizer state variables.
- 
-         """
-         self._init_optimizer()
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_unet_kvasir/src/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir/src/__init__.py
*** ./openfl/openfl-workspace/torch_unet_kvasir/src/__init__.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir/src/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """You may copy this file as the starting point of your own model."""
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_unet_kvasir/src/pt_unet_parts.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir/src/pt_unet_parts.py
*** ./openfl/openfl-workspace/torch_unet_kvasir/src/pt_unet_parts.py	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir/src/pt_unet_parts.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,111 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- import torch
- import torch.nn as nn
- import torch.nn.functional as F
- 
- 
- def soft_dice_loss(output, target):
-     """Dice loss function."""
-     num = target.size(0)
-     m1 = output.view(num, -1)
-     m2 = target.view(num, -1)
-     intersection = (m1 * m2)
-     score = 2. * (intersection.sum(1) + 1) / (m1.sum(1) + m2.sum(1) + 1)
-     score = 1 - score.sum() / num
-     return score
- 
- 
- def soft_dice_coef(output, target):
-     """Dice coef metric function."""
-     num = target.size(0)
-     m1 = output.view(num, -1)
-     m2 = target.view(num, -1)
-     intersection = (m1 * m2)
-     score = 2. * (intersection.sum(1) + 1) / (m1.sum(1) + m2.sum(1) + 1)
-     return score.sum()
- 
- 
- class DoubleConv(nn.Module):
-     """Convolutions with BN and activation."""
- 
-     def __init__(self, in_ch, out_ch):
-         """Initialize.
- 
-         Args:
-             in_ch: number of input channels
-             out_ch: number of output channels
- 
-         """
-         super(DoubleConv, self).__init__()
-         self.in_ch = in_ch
-         self.out_ch = out_ch
-         self.conv = nn.Sequential(
-             nn.Conv2d(in_ch, out_ch, 3, padding=1),
-             nn.BatchNorm2d(out_ch),
-             nn.ReLU(inplace=True),
-             nn.Conv2d(out_ch, out_ch, 3, padding=1),
-             nn.BatchNorm2d(out_ch),
-             nn.ReLU(inplace=True)
-         )
- 
-     def forward(self, x):
-         """Run forward."""
-         x = self.conv(x)
-         return x
- 
- 
- class Down(nn.Module):
-     """UNet downscaling. MaxPool with double convolution."""
- 
-     def __init__(self, in_ch, out_ch):
-         """Initialize.
- 
-         Args:
-             in_ch: number of input channels
-             out_ch: number of output channels
- 
-         """
-         super(Down, self).__init__()
-         self.mpconv = nn.Sequential(
-             nn.MaxPool2d(2),
-             DoubleConv(in_ch, out_ch)
-         )
- 
-     def forward(self, x):
-         """Run forward."""
-         x = self.mpconv(x)
-         return x
- 
- 
- class Up(nn.Module):
-     """UNet upscaling."""
- 
-     def __init__(self, in_ch, out_ch):
-         """Initialize.
- 
-         Args:
-             in_ch: number of input channels
-             out_ch: number of output channels
- 
-         """
-         super(Up, self).__init__()
-         self.in_ch = in_ch
-         self.out_ch = out_ch
-         self.up = nn.ConvTranspose2d(in_ch, in_ch // 2, 2, stride=2)
-         self.conv = DoubleConv(in_ch, out_ch)
- 
-     def forward(self, x1, x2):
-         """Run forward."""
-         x1 = self.up(x1)
-         diff_y = x2.size()[2] - x1.size()[2]
-         diff_x = x2.size()[3] - x1.size()[3]
- 
-         x1 = F.pad(x1, (diff_x // 2, diff_x - diff_x // 2,
-                         diff_y // 2, diff_y - diff_y // 2))
- 
-         x = torch.cat([x2, x1], dim=1)
-         x = self.conv(x)
-         return x
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_unet_kvasir/.workspace ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir/.workspace
*** ./openfl/openfl-workspace/torch_unet_kvasir/.workspace	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir/.workspace	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- current_plan_name: default
- 
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_unet_kvasir_gramine_ready/plan/cols.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir_gramine_ready/plan/cols.yaml
*** ./openfl/openfl-workspace/torch_unet_kvasir_gramine_ready/plan/cols.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir_gramine_ready/plan/cols.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- collaborators:
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_unet_kvasir_gramine_ready/plan/data.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir_gramine_ready/plan/data.yaml
*** ./openfl/openfl-workspace/torch_unet_kvasir_gramine_ready/plan/data.yaml	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir_gramine_ready/plan/data.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,10 ****
- ## Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- # all keys under 'collaborators' corresponds to a specific colaborator name the corresponding dictionary has data_name, data_path pairs.
- # Note that in the kvasir case we split general dataset by shards, and the data_path is used to pass an integer that helps the data object
- # construct the shard of the kvasir dataset to be use for this collaborator.
- 
- # collaborator_name ,data_directory_path
- one,1
- two,2
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_unet_kvasir_gramine_ready/plan/defaults ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir_gramine_ready/plan/defaults
*** ./openfl/openfl-workspace/torch_unet_kvasir_gramine_ready/plan/defaults	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir_gramine_ready/plan/defaults	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- ../../workspace/plan/defaults
- 
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_unet_kvasir_gramine_ready/plan/plan.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir_gramine_ready/plan/plan.yaml
*** ./openfl/openfl-workspace/torch_unet_kvasir_gramine_ready/plan/plan.yaml	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir_gramine_ready/plan/plan.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,60 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- aggregator :
-   defaults : plan/defaults/aggregator.yaml
-   template : openfl.component.Aggregator
-   settings :
-     init_state_path : save/torch_unet_kvasir_init.pbuf
-     best_state_path : save/torch_unet_kvasir_best.pbuf
-     last_state_path : save/torch_unet_kvasir_last.pbuf
-     rounds_to_train : 40
- 
- collaborator :
-   defaults : plan/defaults/collaborator.yaml
-   template : openfl.component.Collaborator
-   settings :
-     epochs_per_round : 1.0
-     polling_interval : 4
-     delta_updates    : false
-     opt_treatment    : RESET
- 
- data_loader :
-   defaults : plan/defaults/data_loader.yaml
-   template : src.data_loader.PyTorchKvasirDataLoader
-   settings :
-     collaborator_count : 2
-     data_group_name    : kvasir
-     batch_size         : 4
- 
- task_runner :
-   defaults : plan/defaults/task_runner.yaml
-   template : src.fed_unet_runner.PyTorchFederatedUnet
-   settings :
-     n_channels : 3
-     n_classes  : 1
- 
- network :
-   defaults : plan/defaults/network.yaml
- 
- assigner :
-   defaults : plan/defaults/assigner.yaml
- 
- tasks :
-   defaults : plan/defaults/tasks_torch.yaml
-   aggregated_model_validation:
-     function  : validate
-     kwargs    :
-       apply   : global
-       metrics :
-       - dice_coef
-   
-   locally_tuned_model_validation:
-     function  : validate
-     kwargs    :
-       apply   : local
-       metrics :
-       - dice_coef
- 
- compression_pipeline :
-   defaults : plan/defaults/compression_pipeline.yaml
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_unet_kvasir_gramine_ready/requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir_gramine_ready/requirements.txt
*** ./openfl/openfl-workspace/torch_unet_kvasir_gramine_ready/requirements.txt	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir_gramine_ready/requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- -f https://download.pytorch.org/whl/cpu/torch_stable.html
- torch==1.7.1+cpu
- torchvision==0.8.2+cpu
- scikit-image==0.17.2
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_unet_kvasir_gramine_ready/src/data_loader.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir_gramine_ready/src/data_loader.py
*** ./openfl/openfl-workspace/torch_unet_kvasir_gramine_ready/src/data_loader.py	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir_gramine_ready/src/data_loader.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,149 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- 
- import zipfile
- from os import listdir
- from pathlib import Path
- 
- import numpy as np
- import PIL
- from skimage import io
- from torch.utils.data import DataLoader
- from torch.utils.data import Dataset
- from torchvision import transforms as tsf
- from torchvision.datasets.utils import download_url
- from tqdm import tqdm
- 
- from openfl.federated import PyTorchDataLoader
- from openfl.utilities import validate_file_hash
- 
- 
- def read_data(image_path, mask_path):
-     """Read image and mask from disk.
- 
-     Args:
-         image_path: Path to image
-         mask_path:  Path to mask
- 
-     Returns:
-         Numpy image and mask
- 
-     """
-     img = io.imread(image_path)
-     assert(img.shape[2] == 3)
-     mask = io.imread(mask_path)
-     return (img, mask[:, :, 0].astype(np.uint8))
- 
- 
- class KvasirDataset(Dataset):
-     """Kvasir dataset. Splits data by shards for each collaborator."""
- 
-     def __init__(self, is_validation, shard_num, collaborator_count, **kwargs):
-         """Initialize dataset.
- 
-         Args:
-             is_validation: Validation dataset or not
-             shard_num: Number of collaborator for which the data is splited
-             collaborator_count: Total number of collaborators
- 
-         """
-         self.images_path = './data/segmented-images/images/'
-         self.masks_path = './data/segmented-images/masks/'
-         self.images_names = [
-             img_name
-             for img_name in sorted(listdir(self.images_path))
-             if len(img_name) > 3 and img_name[-3:] == 'jpg'
-         ]
- 
-         self.images_names = self.images_names[shard_num:: collaborator_count]
-         self.is_validation = is_validation
-         assert(len(self.images_names) > 8)
-         validation_size = len(self.images_names) // 8
- 
-         if is_validation:
-             self.images_names = self.images_names[-validation_size:]
-         else:
-             self.images_names = self.images_names[: -validation_size]
- 
-         self.img_trans = tsf.Compose([
-             tsf.ToPILImage(),
-             tsf.Resize((332, 332)),
-             tsf.ToTensor(),
-             tsf.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])
-         self.mask_trans = tsf.Compose([
-             tsf.ToPILImage(),
-             tsf.Resize((332, 332), interpolation=PIL.Image.NEAREST),
-             tsf.ToTensor()])
- 
-     def __getitem__(self, index):
-         """Get items by slice index."""
-         name = self.images_names[index]
-         img, mask = read_data(self.images_path + name, self.masks_path + name)
-         img = self.img_trans(img)
-         mask = self.mask_trans(mask)
-         return img, mask
- 
-     def __len__(self):
-         """Length of spltted data."""
-         return len(self.images_names)
- 
- 
- def load_kvasir_dataset():
-     """Load and unzip kvasir dataset."""
-     zip_sha384 = ('e30d18a772c6520476e55b610a4db457237f151e'
-                   '19182849d54b49ae24699881c1e18e0961f77642be900450ef8b22e7')
-     data_url = ('https://datasets.simula.no/downloads/'
-                 'hyper-kvasir/hyper-kvasir-segmented-images.zip')
-     filename = 'kvasir.zip'
-     data_folder_path = Path.cwd().absolute() / 'data'
-     kvasir_archive_path = data_folder_path / filename
-     if not kvasir_archive_path.is_file():
-         download_url(data_url, data_folder_path, filename=filename)
-         validate_file_hash(kvasir_archive_path, zip_sha384)
-         with zipfile.ZipFile(kvasir_archive_path, 'r') as zip_ref:
-             for member in tqdm(iterable=zip_ref.infolist(), desc='Unzipping dataset'):
-                 zip_ref.extract(member, './data')
- 
- 
- class PyTorchKvasirDataLoader(PyTorchDataLoader):
-     """PyTorch data loader for Kvasir dataset."""
- 
-     def __init__(self, data_path, batch_size, **kwargs):
-         """Instantiate the data object.
- 
-         Args:
-             data_path: The file path to the data
-             batch_size: The batch size of the data loader
-             **kwargs: Additional arguments, passed to super
-              init and load_mnist_shard
-         """
-         super().__init__(batch_size, **kwargs)
- 
-         load_kvasir_dataset()
-         self.valid_dataset = KvasirDataset(True, shard_num=int(data_path), **kwargs)
-         self.train_dataset = KvasirDataset(False, shard_num=int(data_path), **kwargs)
-         self.train_loader = self.get_train_loader()
-         self.val_loader = self.get_valid_loader()
-         self.batch_size = batch_size
- 
-     def get_valid_loader(self, num_batches=None):
-         """Return validation dataloader."""
-         return DataLoader(self.valid_dataset, batch_size=self.batch_size)
- 
-     def get_train_loader(self, num_batches=None):
-         """Return train dataloader."""
-         return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)
- 
-     def get_train_data_size(self):
-         """Return size of train dataset."""
-         return len(self.train_dataset)
- 
-     def get_valid_data_size(self):
-         """Return size of validation dataset."""
-         return len(self.valid_dataset)
- 
-     def get_feature_shape(self):
-         """Return data shape."""
-         return self.valid_dataset[0][0].shape
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_unet_kvasir_gramine_ready/src/fed_unet_runner.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir_gramine_ready/src/fed_unet_runner.py
*** ./openfl/openfl-workspace/torch_unet_kvasir_gramine_ready/src/fed_unet_runner.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir_gramine_ready/src/fed_unet_runner.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,148 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- import numpy as np
- import torch
- import torch.nn as nn
- import torch.optim as optim
- import tqdm
- 
- from openfl.federated import PyTorchTaskRunner
- from openfl.utilities import TensorKey
- from .pt_unet_parts import DoubleConv
- from .pt_unet_parts import Down
- from .pt_unet_parts import soft_dice_coef
- from .pt_unet_parts import soft_dice_loss
- from .pt_unet_parts import Up
- 
- 
- class PyTorchFederatedUnet(PyTorchTaskRunner):
-     """Simple Unet for segmentation."""
- 
-     def __init__(self, device='cpu', **kwargs):
-         """Initialize.
- 
-         Args:
-             device: The hardware device to use for training (Default = "cpu")
-             **kwargs: Additional arguments to pass to the function
- 
-         """
-         super().__init__(device=device, **kwargs)
-         self.init_network(device=self.device, **kwargs)
-         self._init_optimizer()
-         self.loss_fn = soft_dice_loss
-         self.initialize_tensorkeys_for_functions()
- 
-     def _init_optimizer(self):
-         """Initialize the optimizer."""
-         self.optimizer = optim.Adam(self.parameters(), lr=1e-3)
- 
-     def init_network(self,
-                      device,
-                      n_channels,
-                      n_classes,
-                      print_model=True,
-                      **kwargs):
-         """Create the network (model).
- 
-         Args:
-             device: The hardware device to use for training
-             n_channels: Number of input image channels
-             n_classes: Number of output classes (1 for segmentation)
-             print_model: Print the model topology (Default=True)
-             **kwargs: Additional arguments to pass to the function
- 
-         """
-         self.n_channels = n_channels
-         self.n_classes = n_classes
-         self.inc = DoubleConv(self.n_channels, 64)
-         self.down1 = Down(64, 128)
-         self.down2 = Down(128, 256)
-         self.down3 = Down(256, 512)
-         self.down4 = Down(512, 1024)
-         self.up1 = Up(1024, 512)
-         self.up2 = Up(512, 256)
-         self.up3 = Up(256, 128)
-         self.up4 = Up(128, 64)
-         self.outc = nn.Conv2d(64, self.n_classes, 1)
-         if print_model:
-             print(self)
-         self.to(device)
- 
-     def forward(self, x):
-         """Forward pass of the model.
- 
-         Args:
-             x: Data input to the model for the forward pass
-         """
-         x1 = self.inc(x)
-         x2 = self.down1(x1)
-         x3 = self.down2(x2)
-         x4 = self.down3(x3)
-         x5 = self.down4(x4)
-         x = self.up1(x5, x4)
-         x = self.up2(x, x3)
-         x = self.up3(x, x2)
-         x = self.up4(x, x1)
-         x = self.outc(x)
-         x = torch.sigmoid(x)
-         return x
- 
-     def validate(self, col_name, round_num, input_tensor_dict, use_tqdm=True, **kwargs):
-         """Run validation of the model on the local data.
- 
-         Args:
-             col_name:            Name of the collaborator
-             round_num:           What round is it
-             input_tensor_dict:   Required input tensors (for model)
-             use_tqdm:     Use tqdm to print a progress bar (Default=True)
- 
-         Returns:
-             global_output_dict:  Tensors to send back to the aggregator
-             local_output_dict:   Tensors to maintain in the local TensorDB
-         """
-         self.rebuild_model(round_num, input_tensor_dict, validation=True)
-         self.eval()
-         self.to(self.device)
-         val_score = 0
-         total_samples = 0
- 
-         loader = self.data_loader.get_valid_loader()
-         if use_tqdm:
-             loader = tqdm.tqdm(loader, desc='validate')
- 
-         with torch.no_grad():
-             for data, target in loader:
-                 samples = target.shape[0]
-                 total_samples += samples
-                 data, target = torch.tensor(data).to(self.device), torch.tensor(
-                     target).to(self.device)
-                 output = self(data)
-                 # get the index of the max log-probability
-                 val = soft_dice_coef(output, target)
-                 val_score += val.sum().cpu().numpy()
- 
-         origin = col_name
-         suffix = 'validate'
-         if kwargs['apply'] == 'local':
-             suffix += '_local'
-         else:
-             suffix += '_agg'
-         tags = ('metric', suffix)
-         # TODO figure out a better way to pass in metric for this pytorch
-         #  validate function
-         output_tensor_dict = {
-             TensorKey('dice_coef', origin, round_num, True, tags):
-                 np.array(val_score / total_samples)
-         }
- 
-         return output_tensor_dict, {}
- 
-     def reset_opt_vars(self):
-         """Reset optimizer variables.
- 
-         Resets the optimizer state variables.
- 
-         """
-         self._init_optimizer()
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_unet_kvasir_gramine_ready/src/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir_gramine_ready/src/__init__.py
*** ./openfl/openfl-workspace/torch_unet_kvasir_gramine_ready/src/__init__.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir_gramine_ready/src/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """You may copy this file as the starting point of your own model."""
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_unet_kvasir_gramine_ready/src/pt_unet_parts.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir_gramine_ready/src/pt_unet_parts.py
*** ./openfl/openfl-workspace/torch_unet_kvasir_gramine_ready/src/pt_unet_parts.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir_gramine_ready/src/pt_unet_parts.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,111 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """You may copy this file as the starting point of your own model."""
- import torch
- import torch.nn as nn
- import torch.nn.functional as F
- 
- 
- def soft_dice_loss(output, target):
-     """Dice loss function."""
-     num = target.size(0)
-     m1 = output.view(num, -1)
-     m2 = target.view(num, -1)
-     intersection = (m1 * m2)
-     score = 2. * (intersection.sum(1) + 1) / (m1.sum(1) + m2.sum(1) + 1)
-     score = 1 - score.sum() / num
-     return score
- 
- 
- def soft_dice_coef(output, target):
-     """Dice coef metric function."""
-     num = target.size(0)
-     m1 = output.view(num, -1)
-     m2 = target.view(num, -1)
-     intersection = (m1 * m2)
-     score = 2. * (intersection.sum(1) + 1) / (m1.sum(1) + m2.sum(1) + 1)
-     return score.sum()
- 
- 
- class DoubleConv(nn.Module):
-     """Convolutions with BN and activation."""
- 
-     def __init__(self, in_ch, out_ch):
-         """Initialize.
- 
-         Args:
-             in_ch: number of input channels
-             out_ch: number of output channels
- 
-         """
-         super(DoubleConv, self).__init__()
-         self.in_ch = in_ch
-         self.out_ch = out_ch
-         self.conv = nn.Sequential(
-             nn.Conv2d(in_ch, out_ch, 3, padding=1),
-             nn.BatchNorm2d(out_ch),
-             nn.ReLU(inplace=True),
-             nn.Conv2d(out_ch, out_ch, 3, padding=1),
-             nn.BatchNorm2d(out_ch),
-             nn.ReLU(inplace=True)
-         )
- 
-     def forward(self, x):
-         """Run forward."""
-         x = self.conv(x)
-         return x
- 
- 
- class Down(nn.Module):
-     """UNet downscaling. MaxPool with double convolution."""
- 
-     def __init__(self, in_ch, out_ch):
-         """Initialize.
- 
-         Args:
-             in_ch: number of input channels
-             out_ch: number of output channels
- 
-         """
-         super(Down, self).__init__()
-         self.mpconv = nn.Sequential(
-             nn.MaxPool2d(2),
-             DoubleConv(in_ch, out_ch)
-         )
- 
-     def forward(self, x):
-         """Run forward."""
-         x = self.mpconv(x)
-         return x
- 
- 
- class Up(nn.Module):
-     """UNet upscaling."""
- 
-     def __init__(self, in_ch, out_ch):
-         """Initialize.
- 
-         Args:
-             in_ch: number of input channels
-             out_ch: number of output channels
- 
-         """
-         super(Up, self).__init__()
-         self.in_ch = in_ch
-         self.out_ch = out_ch
-         self.up = nn.ConvTranspose2d(in_ch, in_ch // 2, 2, stride=2)
-         self.conv = DoubleConv(in_ch, out_ch)
- 
-     def forward(self, x1, x2):
-         """Run forward."""
-         x1 = self.up(x1)
-         diff_y = x2.size()[2] - x1.size()[2]
-         diff_x = x2.size()[3] - x1.size()[3]
- 
-         x1 = F.pad(x1, (diff_x // 2, diff_x - diff_x // 2,
-                         diff_y // 2, diff_y - diff_y // 2))
- 
-         x = torch.cat([x2, x1], dim=1)
-         x = self.conv(x)
-         return x
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/torch_unet_kvasir_gramine_ready/.workspace ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir_gramine_ready/.workspace
*** ./openfl/openfl-workspace/torch_unet_kvasir_gramine_ready/.workspace	2022-11-18 11:06:29.747187476 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/torch_unet_kvasir_gramine_ready/.workspace	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- current_plan_name: default
- 
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/workspace/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/__init__.py
*** ./openfl/openfl-workspace/workspace/__init__.py	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """You may copy this file as the starting point of your own model."""
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/workspace/plan/defaults/aggregator.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/plan/defaults/aggregator.yaml
*** ./openfl/openfl-workspace/workspace/plan/defaults/aggregator.yaml	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/plan/defaults/aggregator.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- template : openfl.component.Aggregator
- settings :
-     db_store_rounds   : 2
-     write_logs : false
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/workspace/plan/defaults/assigner.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/plan/defaults/assigner.yaml
*** ./openfl/openfl-workspace/workspace/plan/defaults/assigner.yaml	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/plan/defaults/assigner.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,9 ****
- template : openfl.component.RandomGroupedAssigner
- settings :
-   task_groups  :
-     - name       : train_and_validate
-       percentage : 1.0
-       tasks      :
-         - aggregated_model_validation
-         - train
-         - locally_tuned_model_validation
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/workspace/plan/defaults/collaborator.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/plan/defaults/collaborator.yaml
*** ./openfl/openfl-workspace/workspace/plan/defaults/collaborator.yaml	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/plan/defaults/collaborator.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,5 ****
- template : openfl.component.Collaborator
- settings :
-     opt_treatment     : 'CONTINUE_LOCAL'
-     delta_updates     : True
-     db_store_rounds   : 1
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/workspace/plan/defaults/compression_pipeline.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/plan/defaults/compression_pipeline.yaml
*** ./openfl/openfl-workspace/workspace/plan/defaults/compression_pipeline.yaml	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/plan/defaults/compression_pipeline.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1 ****
- template: openfl.pipelines.NoCompressionPipeline
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/workspace/plan/defaults/data_loader.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/plan/defaults/data_loader.yaml
*** ./openfl/openfl-workspace/workspace/plan/defaults/data_loader.yaml	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/plan/defaults/data_loader.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1 ****
- template: openfl.federated.DataLoader
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/workspace/plan/defaults/network.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/plan/defaults/network.yaml
*** ./openfl/openfl-workspace/workspace/plan/defaults/network.yaml	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/plan/defaults/network.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,9 ****
- template: openfl.federation.Network
- settings:
-     agg_addr                   : auto
-     agg_port                   : auto
-     hash_salt                  : auto
-     tls                        : True
-     client_reconnect_interval  : 5
-     disable_client_auth        : False
-     cert_folder                : cert
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/workspace/plan/defaults/task_runner.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/plan/defaults/task_runner.yaml
*** ./openfl/openfl-workspace/workspace/plan/defaults/task_runner.yaml	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/plan/defaults/task_runner.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1 ****
- template: openfl.federated.task_runner.CoreTaskRunner
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/workspace/plan/defaults/tasks_fast_estimator.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/plan/defaults/tasks_fast_estimator.yaml
*** ./openfl/openfl-workspace/workspace/plan/defaults/tasks_fast_estimator.yaml	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/plan/defaults/tasks_fast_estimator.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,26 ****
- aggregated_model_validation:
-   function : validate
-   kwargs   :
-     batch_size : 32
-     apply      : global
-     metrics    :
-       - clean_accuracy
-       - adversarial_accuracy
- 
- locally_tuned_model_validation:
-   function : validate
-   kwargs   :
-     batch_size : 32
-     apply      : local
-     metrics    :
-       - clean_accuracy
-       - adversarial_accuracy
- 
- train:
-   function : train
-   kwargs   :
-     batch_size : 32
-     epochs     : 1
-     metrics    :
-     - adv_ce
-     - base_ce
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/workspace/plan/defaults/tasks_keras.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/plan/defaults/tasks_keras.yaml
*** ./openfl/openfl-workspace/workspace/plan/defaults/tasks_keras.yaml	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/plan/defaults/tasks_keras.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,23 ****
- aggregated_model_validation:
-   function : validate
-   kwargs   :
-     batch_size : 32
-     apply      : global
-     metrics    :
-       - accuracy
- 
- locally_tuned_model_validation:
-   function : validate
-   kwargs   :
-     batch_size : 32
-     apply      : local
-     metrics    :
-       - accuracy
- 
- train:
-   function : train
-   kwargs   :
-     batch_size : 32
-     epochs     : 1
-     metrics    :
-     - loss
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/workspace/plan/defaults/tasks_tensorflow.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/plan/defaults/tasks_tensorflow.yaml
*** ./openfl/openfl-workspace/workspace/plan/defaults/tasks_tensorflow.yaml	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/plan/defaults/tasks_tensorflow.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,23 ****
- aggregated_model_validation:
-   function : validate
-   kwargs   :
-     batch_size : 32
-     apply      : global
-     metrics    :
-       - acc
- 
- locally_tuned_model_validation:
-   function : validate
-   kwargs   :
-     batch_size : 32
-     apply      : local
-     metrics    :
-       - acc
- 
- train:
-   function : train_batches
-   kwargs   :
-     batch_size  : 32
-     metrics     :
-     - loss
-     epochs      : 1
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/workspace/plan/defaults/tasks_torch.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/plan/defaults/tasks_torch.yaml
*** ./openfl/openfl-workspace/workspace/plan/defaults/tasks_torch.yaml	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/plan/defaults/tasks_torch.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,20 ****
- aggregated_model_validation:
-   function : validate
-   kwargs   :
-     apply   : global
-     metrics :
-       - acc
-   
- locally_tuned_model_validation:
-   function  : validate
-   kwargs    :
-     apply: local
-     metrics :
-       - acc
-   
- train:
-   function : train_batches
-   kwargs   :
-     metrics     :
-     - loss
-     epochs : 1
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/workspace/plan/plans/default/base_plan_interactive_api.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/plan/plans/default/base_plan_interactive_api.yaml
*** ./openfl/openfl-workspace/workspace/plan/plans/default/base_plan_interactive_api.yaml	2022-11-18 11:08:33.043181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/plan/plans/default/base_plan_interactive_api.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,33 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- aggregator :
-   defaults : plan/defaults/aggregator.yaml
-   template : openfl.component.Aggregator
-   settings :
-     init_state_path : save/init.pbuf
-     best_state_path : save/best.pbuf
-     last_state_path : save/last.pbuf
-     rounds_to_train : 10
- 
- collaborator :
-   defaults : plan/defaults/collaborator.yaml
-   template : openfl.component.Collaborator
-   settings :
-     delta_updates    : false
-     opt_treatment    : RESET
- 
- data_loader :
-   defaults : plan/defaults/data_loader.yaml
- 
- task_runner :
-   template : openfl.federated.task.task_runner.CoreTaskRunner
- 
- network :
-   defaults : plan/defaults/network.yaml
- 
- assigner :
-   defaults : plan/defaults/assigner.yaml
- 
- tasks :
-   defaults : null
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/workspace/plan/plans/default/plan.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/plan/plans/default/plan.yaml
*** ./openfl/openfl-workspace/workspace/plan/plans/default/plan.yaml	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/plan/plans/default/plan.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,39 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # Licensed subject to the terms of the separately executed evaluation license agreement between Intel Corporation and you.
- 
- aggregator :
-   defaults : plan/defaults/aggregator.yaml
-   template : openfl.component.Aggregator
-   settings :
-     init_state_path : save/init.pbuf
-     best_state_path : save/best.pbuf
-     last_state_path : save/last.pbuf
-     rounds_to_train : 10
- 
- collaborator :
-   defaults : plan/defaults/collaborator.yaml
-   template : openfl.component.Collaborator
-   settings :
-     delta_updates    : false
-     opt_treatment    : RESET
- 
- data_loader :
-   defaults : plan/defaults/data_loader.yaml
-   template : src.tfmnist_inmemory.TensorFlowMNISTInMemory
-   settings :
-     collaborator_count : 2
-     data_group_name    : mnist
-     batch_size         : 256
- 
- task_runner :
-   defaults : plan/defaults/task_runner.yaml
-   template : src.keras_cnn.KerasCNN
- 
- network :
-   defaults : plan/defaults/network.yaml
- 
- assigner :
-   defaults : plan/defaults/assigner.yaml
- 
- tasks :
-   defaults : plan/defaults/tasks_keras.yaml
--- 0 ----
diff -crB --new-file ./openfl/openfl-workspace/workspace/.workspace ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/.workspace
*** ./openfl/openfl-workspace/workspace/.workspace	2022-11-18 11:06:29.751187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/openfl-workspace/workspace/.workspace	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- current_plan_name: default
- 
--- 0 ----
diff -crB --new-file ./openfl/README.md ../mlwins-simulation-framework/ml-frameworks/federated-learning/README.md
*** ./openfl/README.md	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/README.md	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,103 ****
- # OpenFL - An Open-Source Framework For Federated Learning
- 
- [![PyPI - Python Version](https://img.shields.io/badge/python-3.6%20%7C%203.7%20%7C%203.8-blue)](https://pypi.org/project/openfl/)
- [![Jenkins](https://img.shields.io/jenkins/build?jobUrl=http%3A%2F%2F213.221.44.203%2Fjob%2FFederated-Learning%2Fjob%2Fnightly%2F)](http://213.221.44.203/job/Federated-Learning/job/nightly/)
- [![Documentation Status](https://readthedocs.org/projects/openfl/badge/?version=latest)](https://openfl.readthedocs.io/en/latest/?badge=latest)
- [![Downloads](https://pepy.tech/badge/openfl)](https://pepy.tech/project/openfl)
- [![PyPI version](https://img.shields.io/pypi/v/openfl)](https://pypi.org/project/openfl/)
- [<img src="https://img.shields.io/badge/slack-@openfl-blue.svg?logo=slack">](https://join.slack.com/t/openfl/shared_invite/zt-ovzbohvn-T5fApk05~YS_iZhjJ5yaTw) 
- [![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
- [![Citation](https://img.shields.io/badge/cite-citation-blue)](https://arxiv.org/abs/2105.06413)
- [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/intel/openfl/blob/develop/openfl-tutorials/interactive_api/numpy_linear_regression/workspace/SingleNotebook.ipynb)
- 
- OpenFL is a Python 3 framework for Federated Learning. OpenFL is designed to be a _flexible_, _extensible_ and _easily learnable_ tool for data scientists. OpenFL is developed by Intel Internet of Things Group (IOTG) and Intel Labs. 
- 
- ## Installation
- 
- You can simply install OpenFL from PyPI:
- 
- ```
- $ pip install openfl
- ```
- For more installation options check out the [online documentation](https://openfl.readthedocs.io/en/latest/install.html).
- 
- ## Getting Started
- 
- 
- OpenFL enables data scientists to set up a federated learning experiment following one of the workflows:
- 
- - [Director-based Workflow](https://openfl.readthedocs.io/en/latest/running_the_federation.html#director-based-workflow) [preferred]:
- a federation created with this workflow continues to be available to distribute more experiments in series.
- 
- - [Aggregator-based Workflow](https://openfl.readthedocs.io/en/latest/running_the_federation.html#aggregator-based-workflow):
- with this workflow, the federation is terminated when the experiment is finished.
- 
- The quickest way to test OpenFL is to follow our [tutorials](https://github.com/intel/openfl/tree/develop/openfl-tutorials). </br>
- Read the [blog post](https://towardsdatascience.com/go-federated-with-openfl-8bc145a5ead1) explaining steps to train a model with OpenFL. </br>
- Check out the [online documentation](https://openfl.readthedocs.io/en/latest/index.html) to launch your first federation.
- 
- 
- ## Requirements
- 
- - Ubuntu Linux 16.04 or 18.04.
- - Python 3.6+ (recommended to use with [Virtualenv](https://virtualenv.pypa.io/en/latest/)).
- 
- OpenFL supports training with TensorFlow 2+ or PyTorch 1.3+ which should be installed separately. User can extend the list of supported Deep Learning frameworks if needed.
- 
- ## Project Overview
- ### What is Federated Learning
- 
- [Federated learning](https://en.wikipedia.org/wiki/Federated_learning) is a distributed machine learning approach that enables collaboration on machine learning projects without having to share sensitive data, such as, patient records, financial data, or classified information. The minimum data movement needed across the federation is solely the model parameters and their updates.
- 
- ![Federated Learning](https://raw.githubusercontent.com/intel/openfl/develop/docs/images/diagram_fl_new.png)
- 
- 
- ### Background
- OpenFL builds on the [OpenFederatedLearning](https://github.com/IntelLabs/OpenFederatedLearning) framework, which was a collaboration between Intel and the University of Pennsylvania (UPenn) to develop the [Federated Tumor Segmentation (FeTS, www.fets.ai)](https://www.fets.ai/) platform (grant award number: U01-CA242871). 
- 
- The grant for FeTS was awarded to the [Center for Biomedical Image Computing and Analytics (CBICA)](https://www.cbica.upenn.edu/) at UPenn (PI: S. Bakas) from the [Informatics Technology for Cancer Research (ITCR)](https://itcr.cancer.gov/) program of the National Cancer Institute (NCI) of the National Institutes of Health (NIH). 
- 
- FeTS is a real-world medical federated learning platform with international collaborators. The original OpenFederatedLearning project and OpenFL are designed to serve as the backend for the FeTS platform, 
- and OpenFL developers and researchers continue to work very closely with UPenn on the FeTS project. An example is the [FeTS-AI/Front-End](https://github.com/FETS-AI/Front-End), which integrates UPenn’s medical AI expertise with Intel’s framework to create a federated learning solution for medical imaging. 
- 
- Although initially developed for use in medical imaging, OpenFL designed to be agnostic to the use-case, the industry, and the machine learning framework.
- 
- You can find more details in the following articles:
- - [Sheller MJ,  et al., 2020](https://www.nature.com/articles/s41598-020-69250-1) 
- - [Sheller MJ, et al., 2019](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6589345)
- - [Yang Y, et al., 2019](https://arxiv.org/abs/1902.04885)
- - [McMahan HB, et al., 2016](https://arxiv.org/abs/1602.05629)
- 
- 
- ### Supported Aggregation Algorithms
- | Algorithm Name | Paper | PyTorch implementation | TensorFlow implementation | Other frameworks compatibility | How to use | 
- | -------------- | ----- | :--------------------: | :-----------------------: | :----------------------------: | ---------- |
- | FedAvg | [McMahan et al., 2017](https://arxiv.org/pdf/1602.05629.pdf) | ✅ | ✅ | ✅ | [docs](http://openfl.readthedocs.io/en/latest/supported_aggregation_algorithms.html#fedavg) |
- | FedProx | [Li et al., 2020](https://arxiv.org/pdf/1812.06127.pdf) | ✅ | ✅ | ❌ | [docs](http://openfl.readthedocs.io/en/latest/supported_aggregation_algorithms.html#fedprox) |
- | FedOpt | [Reddi et al., 2020](https://arxiv.org/abs/2003.00295) | ✅ | ✅ | ✅ | [docs](http://openfl.readthedocs.io/en/latest/supported_aggregation_algorithms.html#fedopt) |
- | FedCurv | [Shoham et al., 2019](https://arxiv.org/pdf/1910.07796.pdf) | ✅ | ❌ | ❌ | [docs](http://openfl.readthedocs.io/en/latest/supported_aggregation_algorithms.html#fedcurv) |
- 
- ## Support
- We welcome questions, issue reports, and suggestions:
- 
- * [GitHub Issues](https://github.com/intel/openfl/issues)
- * [Slack workspace](https://join.slack.com/t/openfl/shared_invite/zt-ovzbohvn-T5fApk05~YS_iZhjJ5yaTw)
- 
- 
- ## License
- This project is licensed under [Apache License Version 2.0](LICENSE). By contributing to the project, you agree to the license and copyright terms therein and release your contribution under these terms.
- 
- 
- ## Citation
- 
- ```
- @misc{reina2021openfl,
-       title={OpenFL: An open-source framework for Federated Learning}, 
-       author={G Anthony Reina and Alexey Gruzdev and Patrick Foley and Olga Perepelkina and Mansi Sharma and Igor Davidyuk and Ilya Trushkin and Maksim Radionov and Aleksandr Mokrov and Dmitry Agapov and Jason Martin and Brandon Edwards and Micah J. Sheller and Sarthak Pati and Prakash Narayana Moorthy and Shih-han Wang and Prashant Shah and Spyridon Bakas},
-       year={2021},
-       eprint={2105.06413},
-       archivePrefix={arXiv},
-       primaryClass={cs.LG}
- }
- ```
- 
--- 0 ----
diff -crB --new-file ./openfl/requirements-linters.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/requirements-linters.txt
*** ./openfl/requirements-linters.txt	2022-11-18 11:08:33.047181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/requirements-linters.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,13 ****
- flake8
- flake8-broken-line
- flake8-bugbear
- flake8-builtins
- flake8-comprehensions
- flake8-copyright
- flake8-docstrings
- flake8-eradicate
- flake8-import-order
- flake8-import-single
- flake8-quotes
- flake8-use-fstring
- pep8-naming
--- 0 ----
diff -crB --new-file ./openfl/requirements-test.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/requirements-test.txt
*** ./openfl/requirements-test.txt	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/requirements-test.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,2 ****
- pytest==6.1.2
- pytest-mock==3.4.0
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/scripts/build_base_docker_image.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/scripts/build_base_docker_image.sh
*** ./openfl/scripts/build_base_docker_image.sh	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/scripts/build_base_docker_image.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,7 ****
- #!/bin/bash
- set -e
- 
- TAG=${1:-'openfl'}
- 
- docker build -t ${TAG} \
-         -f openfl-docker/Dockerfile.base .
--- 0 ----
diff -crB --new-file ./openfl/scripts/build_wheel.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/scripts/build_wheel.sh
*** ./openfl/scripts/build_wheel.sh	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/scripts/build_wheel.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,7 ****
- #!/bin/bash
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- if python3 setup.py sdist bdist_wheel ; then
-    echo "Pip wheel built and installed in dist directory"
- fi
--- 0 ----
diff -crB --new-file ./openfl/SECURITY.md ../mlwins-simulation-framework/ml-frameworks/federated-learning/SECURITY.md
*** ./openfl/SECURITY.md	2022-11-18 11:06:29.707187478 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/SECURITY.md	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,12 ****
- # Security Policy
- 
- ## Report a Vulnerability
- 
- Please report security issues or vulnerabilities to the [Intel® Security Center].
- 
- For more information on how Intel® works to resolve security issues, see
- [Vulnerability Handling Guidelines].
- 
- [Intel® Security Center]:https://www.intel.com/security
- 
- [Vulnerability Handling Guidelines]:https://www.intel.com/content/www/us/en/security-center/vulnerability-handling-guidelines.html
--- 0 ----
diff -crB --new-file ./openfl/setup.cfg ../mlwins-simulation-framework/ml-frameworks/federated-learning/setup.cfg
*** ./openfl/setup.cfg	2022-11-18 11:08:33.047181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/setup.cfg	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,18 ****
- [flake8]
- 
- # W503 Line break occurred before a binary operator. Update by W504 Line
- # break occurred after a binary operator
- # N812: lowercase imported as non lowercase. Allow "import torch.nn.functional as F"
- ignore = W503, N812
- select = E,F,W,C4,C90,C801
- inline-quotes = '
- multiline-quotes = '
- docstring-quotes = """
- exclude = *_pb2*,tests/github/interactive_api,tests/github/interactive_api_director
- max-line-length = 99
- avoid-escape = False
- import-order-style = smarkets
- application-import-names = openfl
- ignore-names=X_*,X,X1,X2
- copyright-check = True
- copyright-regexp = Copyright\s+(\(C\)\s+)?\d{4}([-,]\d{4})*\s+Intel\sCorporation(\s)*\n\s*#*\sSPDX-License-Identifier:\sApache-2.0
--- 0 ----
diff -crB --new-file ./openfl/setup.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/setup.py
*** ./openfl/setup.py	2022-11-18 11:08:33.047181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/setup.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,110 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """This package includes dependencies of the openfl project."""
- 
- from setuptools import setup
- 
- with open('README.md') as f:
-     long_description = f.read()
- 
- setup(
-     name='openfl',
-     version='1.3',
-     author='Intel Corporation',
-     description='Federated Learning for the Edge',
-     long_description=long_description,
-     long_description_content_type='text/markdown',
-     url='https://github.com/intel/openfl',
-     packages=[
-         'openfl',
-         'openfl.component',
-         'openfl.component.aggregation_functions',
-         'openfl.component.aggregation_functions.core',
-         'openfl.component.aggregator',
-         'openfl.component.assigner',
-         'openfl.component.ca',
-         'openfl.component.collaborator',
-         'openfl.component.director',
-         'openfl.component.envoy',
-         'openfl.cryptography',
-         'openfl.databases',
-         'openfl.federated',
-         'openfl.federated.data',
-         'openfl.federated.plan',
-         'openfl.federated.task',
-         'openfl.interface',
-         'openfl.interface.interactive_api',
-         'openfl.native',
-         'openfl.pipelines',
-         'openfl.plugins',
-         'openfl.plugins.frameworks_adapters',
-         'openfl.plugins.interface_serializer',
-         'openfl.plugins.processing_units_monitor',
-         'openfl.protocols',
-         'openfl.transport',
-         'openfl.transport.grpc',
-         'openfl.utilities',
-         'openfl.utilities.data_splitters',
-         'openfl.utilities.fedcurv',
-         'openfl.utilities.fedcurv.torch',
-         'openfl.utilities.optimizers.keras',
-         'openfl.utilities.optimizers.numpy',
-         'openfl.utilities.optimizers.torch',
-         'openfl-docker',
-         'openfl-gramine',
-         'openfl-tutorials',
-         'openfl-workspace',
-     ],
-     include_package_data=True,
-     install_requires=[
-         'Click==8.0.1',
-         'PyYAML>=5.4.1',
-         'cloudpickle',
-         'cryptography>=3.4.6',
-         'docker',
-         'dynaconf==3.1.7',
-         'flatten_json',
-         'grpcio-tools~=1.34.0',
-         'grpcio~=1.34.0',
-         'ipykernel',
-         'jupyterlab',
-         'numpy',
-         'pandas',
-         'protobuf',
-         'requests',
-         'rich==9.1.0',
-         'scikit-learn',
-         'tensorboard',
-         'tensorboardX',
-         'tqdm',
-     ],
-     python_requires='>=3.6, <3.9',
-     project_urls={
-         'Bug Tracker': 'https://github.com/intel/openfl/issues',
-         'Documentation': 'https://openfl.readthedocs.io/en/stable/',
-         'Source Code': 'https://github.com/intel/openfl',
-     },
-     classifiers=[
-         'Environment :: Console',
-         # How mature is this project? Common values are
-         #   3 - Alpha, 4 - Beta, 5 - Production/Stable
-         'Development Status :: 4 - Beta',
-         # Indicate who your project is intended for
-         'Intended Audience :: Developers',
-         'Topic :: Scientific/Engineering :: Artificial Intelligence',
-         'Topic :: Scientific/Engineering :: Image Recognition',
-         'Topic :: System :: Distributed Computing',
-         # Pick your license as you wish
-         'License :: OSI Approved :: Apache Software License',
-         # Specify the Python versions you support here. In particular, ensure
-         # that you indicate whether you support Python 2, Python 3 or both.
-         'Programming Language :: Python :: 3',
-         'Programming Language :: Python :: 3.6',
-         'Programming Language :: Python :: 3.7',
-         'Programming Language :: Python :: 3.8',
-     ],
-     entry_points={
-         'console_scripts': ['fx=openfl.interface.cli:entry']
-     }
- )
--- 0 ----
diff -crB --new-file ./openfl/.signatures/cla.json ../mlwins-simulation-framework/ml-frameworks/federated-learning/.signatures/cla.json
*** ./openfl/.signatures/cla.json	2022-11-18 11:08:33.039181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/.signatures/cla.json	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,124 ****
- {
-   "signedContributors": [
-     {
-       "name": "grib0ed0v",
-       "id": 10911871,
-       "comment_id": 811036981,
-       "created_at": "2021-03-31T12:41:17Z",
-       "repoId": 329117231,
-       "pullRequestNo": 50
-     },
-     {
-       "name": "walteriviera",
-       "id": 78015934,
-       "comment_id": 811258002,
-       "created_at": "2021-03-31T17:06:50Z",
-       "repoId": 329117231,
-       "pullRequestNo": 35
-     },
-     {
-       "name": "walteriviera",
-       "id": 78015934,
-       "comment_id": 811349094,
-       "created_at": "2021-03-31T19:00:38Z",
-       "repoId": 329117231,
-       "pullRequestNo": 35
-     },
-     {
-       "name": "sarthakpati",
-       "id": 11719673,
-       "comment_id": 841339208,
-       "created_at": "2021-05-14T16:06:18Z",
-       "repoId": 329117231,
-       "pullRequestNo": 80
-     },
-     {
-       "name": "karol-brejna-i",
-       "id": 10846210,
-       "comment_id": 845054725,
-       "created_at": "2021-05-20T12:23:06Z",
-       "repoId": 329117231,
-       "pullRequestNo": 87
-     },
-     {
-       "name": "rstoki",
-       "id": 32607323,
-       "comment_id": 853893873,
-       "created_at": "2021-06-03T14:02:12Z",
-       "repoId": 329117231,
-       "pullRequestNo": 100
-     },
-     {
-       "name": "TortoiseHam",
-       "id": 8201565,
-       "comment_id": 873280780,
-       "created_at": "2021-07-02T22:13:07Z",
-       "repoId": 329117231,
-       "pullRequestNo": 115
-     },
-     {
-       "name": "tanertopal",
-       "id": 423981,
-       "comment_id": 897179463,
-       "created_at": "2021-08-11T21:53:41Z",
-       "repoId": 329117231,
-       "pullRequestNo": 145
-     },
-     {
-       "name": "katerina-merkulova",
-       "id": 87072230,
-       "comment_id": 900903309,
-       "created_at": "2021-08-18T07:58:20Z",
-       "repoId": 329117231,
-       "pullRequestNo": 156
-     },
-     {
-       "name": "alexey-khorkin",
-       "id": 89856652,
-       "comment_id": 909503518,
-       "created_at": "2021-08-31T18:42:50Z",
-       "repoId": 329117231,
-       "pullRequestNo": 164
-     },
-     {
-       "name": "louis-yong",
-       "id": 90028246,
-       "comment_id": 958961930,
-       "created_at": "2021-11-03T11:58:04Z",
-       "repoId": 329117231,
-       "pullRequestNo": 220
-     },
-     {
-       "name": "ViktoriiaRomanova",
-       "id": 92929046,
-       "comment_id": 978929847,
-       "created_at": "2021-11-25T08:08:08Z",
-       "repoId": 329117231,
-       "pullRequestNo": 247
-     },
-     {
-       "name": "Alexsandruss",
-       "id": 24354279,
-       "comment_id": 1018063406,
-       "created_at": "2022-01-21T00:57:57Z",
-       "repoId": 329117231,
-       "pullRequestNo": 297
-     },
-     {
-       "name": "IgorDavidyuk",
-       "id": 48272539,
-       "comment_id": 1055177967,
-       "created_at": "2022-03-01T09:00:06Z",
-       "repoId": 329117231,
-       "pullRequestNo": 355
-     },
-     {
-       "name": "saransh09",
-       "id": 16311847,
-       "comment_id": 1068928160,
-       "created_at": "2022-03-16T09:46:19Z",
-       "repoId": 329117231,
-       "pullRequestNo": 371
-     }
-   ]
- }
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/tests/github/dockerization_test.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/dockerization_test.sh
*** ./openfl/tests/github/dockerization_test.sh	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/dockerization_test.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,109 ****
- #!/bin/bash
- set -e
- 
- # 1. Create the workspace
- 
- TEMPLATE=${1:-'keras_cnn_mnist'}  # ['torch_cnn_mnist', 'keras_cnn_mnist']
- FED_WORKSPACE=${2:-'fed_work12345alpha81671'}   # This can be whatever unique directory name you want
- COL=${3:-'one123dragons'}  # This can be any unique label (lowercase)
- DATA_PATH=${4:-1}
- BASE_IMAGE_TAG=${5:-'openfl'}
- 
- # If an aggregator container will run on another machine
- # a relevant FQDN should be provided
- FQDN=${6:-$(hostname --all-fqdns | awk '{print $1}')}
- 
- # Build base image
- bash ./scripts/build_base_docker_image.sh ${BASE_IMAGE_TAG}
- 
- # Create FL workspace
- rm -rf ${FED_WORKSPACE}
- fx workspace create --prefix ${FED_WORKSPACE} --template ${TEMPLATE}
- cd ${FED_WORKSPACE}
- FED_DIRECTORY=`pwd`  # Get the absolute directory path for the workspace
- 
- # Initialize FL plan
- fx plan initialize -a ${FQDN}
- 
- # 2. Build the workspace image and save it to a tarball
- 
- # This commant builds an image tagged $FED_WORKSPACE
- # Then it saves it to a ${FED_WORKSPACE}_image.tar
- fx workspace dockerize --base_image ${BASE_IMAGE_TAG}
- 
- # We remove the base OpenFL image as well
- # as built workspace image to simulate starting 
- # on another machine
- WORSPACE_IMAGE_NAME=${FED_WORKSPACE}
- docker image rm -f ${BASE_IMAGE_TAG} ${WORSPACE_IMAGE_NAME}
- 
- 
- # 3. Generate certificates for the aggregator and the collaborator
- 
- # Create certificate authority for the workspace
- fx workspace certify
- 
- # We do certs exchage for all participants in a single workspace
- # to speed up this test run.
- # Do not do this in real experiments
- # in untrusted environments
- create_signed_cert_for_collaborator() {
-         COL_NAME=$1
-         DATA_PATH=$2
-         echo "certifying collaborator $COL_NAME with data path $DATA_PATH"
-         # Create collaborator certificate request
-         fx collaborator generate-cert-request -d ${DATA_PATH} -n ${COL_NAME} --silent
-         # Sign collaborator certificate 
-         fx collaborator certify --request-pkg col_${COL_NAME}_to_agg_cert_request.zip --silent
- 
-         # Pack the collaborators private key and the signed cert
-         # as well as it's data.yaml to a tarball
-         tar -cf cert_col_${COL_NAME}.tar plan/data.yaml \
-                 cert/client/*key agg_to_col_${COL_NAME}_signed_cert.zip --remove-files 
- 
-         # Remove request archive
-         rm -rf col_${COL_NAME}_to_agg_cert_request.zip
- }
- 
- # Prepare a tarball with the collab's private key, the singed cert,
- # and data.yaml for collaborator container
- # This step can be repeated for each collaborator
- create_signed_cert_for_collaborator ${COL} ${DATA_PATH} 
- 
- # Also perform certificate generation for the aggregator.
- # Create aggregator certificate
- fx aggregator generate-cert-request --fqdn ${FQDN}
- # Sign aggregator certificate
- fx aggregator certify --fqdn ${FQDN} --silent # Remove '--silent' if you run this manually
- 
- # Pack all files that aggregator need to start training
- AGGREGATOR_REQUIRED_FILES='cert_agg.tar'
- tar -cf ${AGGREGATOR_REQUIRED_FILES} plan/ cert/ save/ --remove-files 
- 
- 
- # 4. Load the image
- IMAGE_TAR=${FED_WORKSPACE}_image.tar
- docker load --input $IMAGE_TAR
- 
- 
- # 5. Start federation in containers
- 
- # Start the aggregator
- docker run --rm \
-         --network host \
-         -v $(pwd)/${AGGREGATOR_REQUIRED_FILES}:/certs.tar \
-         -e "CONTAINER_TYPE=aggregator" \
-         ${WORSPACE_IMAGE_NAME} \
-         bash /openfl/openfl-docker/start_actor_in_container.sh &
- 
- # Start the collaborator
- docker run --rm \
-         --network host \
-         -v $(pwd)/cert_col_${COL_NAME}.tar:/certs.tar \
-         -e "CONTAINER_TYPE=collaborator" \
-         -e "COL=${COL_NAME}" \
-         ${WORSPACE_IMAGE_NAME} \
-         bash /openfl/openfl-docker/start_actor_in_container.sh 
- 
- # If containers are started but collaborator will fail to 
- # conect the aggregator, the pipeline will go to the infinite loop
--- 0 ----
diff -crB --new-file ./openfl/tests/github/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/__init__.py
*** ./openfl/tests/github/__init__.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Tests package."""
--- 0 ----
diff -crB --new-file ./openfl/tests/github/interactive_api_director/exp_1.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/exp_1.py
*** ./openfl/tests/github/interactive_api_director/exp_1.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/exp_1.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,36 ****
- from time import sleep
- import getpass
- 
- 
- from tests.github.interactive_api_director.experiment_runner import run_federation
- from tests.github.interactive_api_director.experiment_runner import stop_federation
- from tests.github.interactive_api_director.experiment_runner import Shard
- from tests.github.interactive_api_director.experiment_runner import create_federation
- 
- 
- col_names = ['one', 'two']
- username = getpass.getuser()
- director_path = f'/home/{username}/test/exp_1/director'
- 
- director_host = 'localhost'
- director_port = 50051
- 
- shards = {
-     f'/home/{username}/test/exp_1/{col_name}':
-         Shard(
-             shard_name=col_name,
-             director_host=director_host,
-             director_port=director_port,
-             data_path=f'/home/{username}/test/data/{col_name}'
-         )
-     for col_name in col_names
- }
- 
- create_federation(director_path, shards.keys())
- 
- processes = run_federation(shards, director_path)
- 
- # run experiments
- sleep(5)
- 
- stop_federation(processes)
--- 0 ----
diff -crB --new-file ./openfl/tests/github/interactive_api_director/experiment_runner.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiment_runner.py
*** ./openfl/tests/github/interactive_api_director/experiment_runner.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiment_runner.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,140 ****
- import os
- import logging
- import shutil
- import subprocess
- import typing
- from time import sleep
- from dataclasses import dataclass
- from rich.console import Console
- from rich.logging import RichHandler
- 
- 
- root = logging.getLogger()
- root.setLevel(logging.INFO)
- console = Console(width=160)
- handler = RichHandler(console=console)
- formatter = logging.Formatter(
-     "[%(asctime)s][%(name)s][%(levelname)s] - %(message)s"
- )
- handler.setFormatter(formatter)
- root.addHandler(handler)
- 
- logger = logging.getLogger(__name__)
- 
- 
- def prepare_collaborator_workspace(col_dir, arch_path):
-     logger.info(f'Prepare collaborator directory: {col_dir}')
-     if os.path.exists(col_dir):
-         shutil.rmtree(col_dir)
-     os.makedirs(col_dir)
-     arch_col_path = shutil.copy(arch_path, col_dir)
-     shutil.unpack_archive(arch_col_path, col_dir)
-     logger.info('Collaborator directory prepared')
- 
- 
- def run_aggregator(model_interface, fl_experiment):
-     logger.info('Aggregator has been started.')
-     fl_experiment.start_experiment(model_interface)
-     logger.info('Aggregator has been stopped.')
- 
- 
- def run_experiment(col_data_paths, model_interface, arch_path, fl_experiment):
-     logger.info('Starting the experiment!')
-     for col_dir in col_data_paths:
-         prepare_collaborator_workspace(col_dir, arch_path)
- 
-     processes = []
-     for col_name in col_data_paths:
-         logger.info(f'Starting collaborator: {col_name}')
-         p = subprocess.Popen(
-             f"fx collaborator start -n {col_name} -p plan/plan.yaml -d data.yaml".split(' '),
-             cwd=os.path.join(os.getcwd(), col_name)
-         )
-         processes.append(p)
- 
-     run_aggregator(model_interface, fl_experiment)
-     for p in processes:
-         p.terminate()
- 
-     logger.info('The experiment completed!')
- 
- 
- def create_director(director_path, recreate, config):
-     logger.info(f'Creating the director in {director_path}!')
-     if os.path.exists(director_path):
-         if not recreate:
-             return
-         shutil.rmtree(director_path)
-     subprocess.Popen(
-         f'fx director create-workspace -p {director_path}',
-         shell=True
-     ).wait()
-     shutil.copy(config, director_path)
- 
- 
- def create_envoy(col_path, recreate, envoy_config, shard_descriptor):
-     logger.info(f'Creating the envoy in {col_path}!')
-     if os.path.exists(col_path):
-         if not recreate:
-             return
-         shutil.rmtree(col_path)
-     subprocess.Popen(
-         f'fx envoy create-workspace -p {col_path}',
-         shell=True
-     ).wait()
-     shutil.copy(envoy_config, col_path)
-     shutil.copy(shard_descriptor, col_path)
- 
- 
- def create_federation(
-     director_path: str,
-     collaborator_paths: typing.Iterable[str],
-     director_config,
-     envoy_config,
-     shard_descriptor,
-     recreate=False
- ):
-     logger.info('Creating the federation!')
-     create_director(director_path, recreate, director_config)
-     for col_path in collaborator_paths:
-         create_envoy(col_path, recreate, envoy_config, shard_descriptor)
-     # TODO: create mTLS
-     logger.info('Federation was created')
- 
- 
- @dataclass
- class Shard:
-     shard_name: str
-     director_host: str
-     director_port: int
-     data_path: str
- 
- 
- def run_federation(shards: typing.Dict[str, Shard], director_path: str):
-     logger.info('Starting the experiment!')
-     running_processes = []
-     p = subprocess.Popen(
-         f"fx director start --disable-tls",
-         shell=True,
-         cwd=os.path.join(director_path)
-     )
-     sleep(2)
-     running_processes.append(p)
-     for collaborator_path, shard in shards.items():
-         p = subprocess.Popen(
-             f'fx envoy start '
-             f'-n {shard.shard_name} -dh {shard.director_host} '
-             f'-dp {shard.director_port} -p {shard.data_path}',
-             shell=True,
-             cwd=os.path.join(collaborator_path)
-         )
-         running_processes.append(p)
-     logger.info('The federation started!')
-     return running_processes
- 
- 
- def stop_federation(running_processes):
-     logger.info('Stopping the federation')
-     for p in running_processes:
-         p.terminate()
-     logger.info('Federation was stopped')
--- 0 ----
diff -crB --new-file ./openfl/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/data_loader.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/data_loader.py
*** ./openfl/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/data_loader.py	2022-11-18 11:08:33.047181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/data_loader.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,24 ****
- import os
- from skimage import io
- import numpy as np
- from openfl.utilities import validate_file_hash
- 
- 
- def load_data():
-     os.makedirs('data', exist_ok=True)
-     os.system("wget -nc 'https://datasets.simula.no/downloads/hyper-kvasir/hyper-kvasir-segmented-images.zip'"
-               " -O ./data/kvasir.zip")
-     zip_sha384 = 'e30d18a772c6520476e55b610a4db457237f151e' \
-                  '19182849d54b49ae24699881c1e18e0961f77642be900450ef8b22e7'
-     validate_file_hash('./data/kvasir.zip', zip_sha384)
-     os.system('unzip -n ./data/kvasir.zip -d ./data')
- 
- 
- def read_data(image_path, mask_path):
-     """
-     Read image and mask from disk.
-     """
-     img = io.imread(image_path)
-     assert (img.shape[2] == 3)
-     mask = io.imread(mask_path)
-     return img, mask[:, :, 0].astype(np.uint8)
--- 0 ----
diff -crB --new-file ./openfl/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/dataset.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/dataset.py
*** ./openfl/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/dataset.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/dataset.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,110 ****
- import os
- import PIL
- from torch.utils.data import Dataset, DataLoader
- from torchvision import transforms as tsf
- 
- from tests.github.interactive_api_director.experiments.pytorch_kvasir_unet.data_loader import read_data
- from openfl.interface.interactive_api.experiment import DataInterface
- 
- 
- class KvasirDataset(Dataset):
-     """
-     Kvasir dataset contains 1000 images for all collaborators.
-     Args:
-         data_path: path to dataset on disk
-         collaborator_count: total number of collaborators
-         collaborator_num: number of current collaborator
-         is_validation: validation option
-     """
- 
-     def __init__(self, images_path='./data/segmented-images/images/',
-                  masks_path='./data/segmented-images/masks/',
-                  validation_fraction=1 / 8, is_validation=False):
- 
-         self.images_path = images_path
-         self.masks_path = masks_path
-         self.images_names = [
-             img_name
-             for img_name in sorted(os.listdir(self.images_path))
-             if len(img_name) > 3 and img_name[-3:] == 'jpg'
-         ]
- 
-         assert (len(self.images_names) > 2), "Too few images"
- 
-         validation_size = max(1, int(len(self.images_names) * validation_fraction))
- 
-         if is_validation:
-             self.images_names = self.images_names[-validation_size:]
-         else:
-             self.images_names = self.images_names[: -validation_size]
- 
-         # Prepare transforms
-         self.img_trans = tsf.Compose([
-             tsf.ToPILImage(),
-             tsf.Resize((332, 332)),
-             tsf.ToTensor(),
-             tsf.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])
-         self.mask_trans = tsf.Compose([
-             tsf.ToPILImage(),
-             tsf.Resize((332, 332), interpolation=PIL.Image.NEAREST),
-             tsf.ToTensor()])
- 
-     def __getitem__(self, index):
-         name = self.images_names[index]
-         img, mask = read_data(self.images_path + name, self.masks_path + name)
-         img = self.img_trans(img).numpy()
-         mask = self.mask_trans(mask).numpy()
-         return img, mask
- 
-     def __len__(self):
-         return len(self.images_names)
- 
- 
- class FedDataset(DataInterface):
- 
-     def _delayed_init(self, data_path='1,1'):
-         # With the next command the local dataset will be loaded on the collaborator node
-         # For this example we have the same dataset on the same path, and we will shard it
-         # So we use `data_path` information for this purpose.
-         self.rank, self.world_size = [int(part) for part in data_path.split(',')]
- 
-         validation_fraction = 1 / 8
-         self.train_set = self.UserDatasetClass(validation_fraction=validation_fraction,
-                                                is_validation=False)
-         self.valid_set = self.UserDatasetClass(validation_fraction=validation_fraction,
-                                                is_validation=True)
- 
-         # Do the actual sharding
-         self._do_sharding(self.rank, self.world_size)
- 
-     def _do_sharding(self, rank, world_size):
-         # This method relies on the dataset's implementation
-         # i.e. coupled in a bad way
-         self.train_set.images_names = self.train_set.images_names[rank - 1:: world_size]
- 
-     def get_train_loader(self, **kwargs):
-         """
-         Output of this method will be provided to tasks with optimizer in contract
-         """
-         return DataLoader(
-             self.train_set, num_workers=8, batch_size=self.kwargs['train_bs'], shuffle=True
-         )
- 
-     def get_valid_loader(self, **kwargs):
-         """
-         Output of this method will be provided to tasks without optimizer in contract
-         """
-         return DataLoader(self.valid_set, num_workers=8, batch_size=self.kwargs['valid_bs'])
- 
-     def get_train_data_size(self):
-         """
-         Information for aggregation
-         """
-         return len(self.train_set)
- 
-     def get_valid_data_size(self):
-         """
-         Information for aggregation
-         """
-         return len(self.valid_set)
- 
--- 0 ----
diff -crB --new-file ./openfl/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/director/director_config.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/director/director_config.yaml
*** ./openfl/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/director/director_config.yaml	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/director/director_config.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- settings:
-   sample_shape: [ '300', '400', '3' ]
-   target_shape: [ '300', '400' ]
--- 0 ----
diff -crB --new-file ./openfl/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/director/start_director.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/director/start_director.sh
*** ./openfl/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/director/start_director.sh	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/director/start_director.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- 
- fx director start --disable-tls -c director_config.yaml
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/envoy/envoy_config.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/envoy/envoy_config.yaml
*** ./openfl/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/envoy/envoy_config.yaml	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/envoy/envoy_config.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,11 ****
- params:
-   cuda_devices: [ ]
- 
- optional_plugin_components: { }
- 
- shard_descriptor:
-   template: kvasir_shard_descriptor.KvasirShardDescriptor
-   params:
-     data_folder: kvasir_data
-     rank_worldsize: 1,90
-     enforce_image_hw: '300,400'
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/envoy/kvasir_shard_descriptor.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/envoy/kvasir_shard_descriptor.py
*** ./openfl/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/envoy/kvasir_shard_descriptor.py	2022-11-18 11:08:33.047181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/envoy/kvasir_shard_descriptor.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,157 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Kvasir shard descriptor."""
- 
- import os
- from pathlib import Path
- 
- import numpy as np
- from PIL import Image
- 
- from openfl.interface.interactive_api.shard_descriptor import ShardDataset
- from openfl.interface.interactive_api.shard_descriptor import ShardDescriptor
- from openfl.utilities import validate_file_hash
- 
- 
- class KvasirShardDataset(ShardDataset):
-     """Kvasir Shard dataset class."""
- 
-     def __init__(self, dataset_dir: Path, rank=1, worldsize=1, enforce_image_hw=None):
-         """Initialize KvasirShardDataset."""
-         self.rank = rank
-         self.worldsize = worldsize
-         self.dataset_dir = dataset_dir
-         self.enforce_image_hw = enforce_image_hw
-         self.images_path = self.dataset_dir / 'segmented-images' / 'images'
-         self.masks_path = self.dataset_dir / 'segmented-images' / 'masks'
- 
-         self.images_names = [
-             img_name
-             for img_name in sorted(os.listdir(self.images_path))
-             if len(img_name) > 3 and img_name[-3:] == 'jpg'
-         ]
-         # Sharding
-         self.images_names = self.images_names[self.rank - 1::self.worldsize]
- 
-     def __getitem__(self, index):
-         """Return a item by the index."""
-         name = self.images_names[index]
-         # Reading data
-         img = Image.open(self.images_path / name)
-         mask = Image.open(self.masks_path / name)
-         if self.enforce_image_hw is not None:
-             # If we need to resize data
-             # PIL accepts (w,h) tuple, not (h,w)
-             img = img.resize(self.enforce_image_hw[::-1])
-             mask = mask.resize(self.enforce_image_hw[::-1])
-         img = np.asarray(img)
-         mask = np.asarray(mask)
-         assert img.shape[2] == 3
- 
-         return img, mask[:, :, 0].astype(np.uint8)
- 
-     def __len__(self):
-         """Return the len of the dataset."""
-         return len(self.images_names)
- 
- 
- class KvasirShardDescriptor(ShardDescriptor):
-     """Shard descriptor class."""
- 
-     def __init__(self, data_folder: str = 'kvasir_data',
-                  rank_worldsize: str = '1,1',
-                  enforce_image_hw: str = None) -> None:
-         """Initialize KvasirShardDescriptor."""
-         super().__init__()
-         # Settings for sharding the dataset
-         self.rank, self.worldsize = tuple(int(num) for num in rank_worldsize.split(','))
- 
-         self.data_folder = Path.cwd() / data_folder
-         self.download_data(self.data_folder)
- 
-         # Settings for resizing data
-         self.enforce_image_hw = None
-         if enforce_image_hw is not None:
-             self.enforce_image_hw = tuple(int(size) for size in enforce_image_hw.split(','))
- 
-         # Calculating data and target shapes
-         ds = self.get_dataset()
-         sample, target = ds[0]
-         self._sample_shape = [str(dim) for dim in sample.shape]
-         self._target_shape = [str(dim) for dim in target.shape]
- 
-     def get_dataset(self, dataset_type='train'):
-         """Return a shard dataset by type."""
-         return KvasirShardDataset(
-             dataset_dir=self.data_folder,
-             rank=self.rank,
-             worldsize=self.worldsize,
-             enforce_image_hw=self.enforce_image_hw
-         )
- 
-     @staticmethod
-     def download_data(data_folder):
-         """Download data."""
-         zip_file_path = data_folder / 'kvasir.zip'
-         os.makedirs(data_folder, exist_ok=True)
-         os.system('wget -nc'
-                   " 'https://datasets.simula.no/downloads/hyper-kvasir/hyper-kvasir-segmented-images.zip'"
-                   f' -O {zip_file_path.relative_to(Path.cwd())}')
-         zip_sha384 = ('e30d18a772c6520476e55b610a4db457237f151e'
-                       '19182849d54b49ae24699881c1e18e0961f77642be900450ef8b22e7')
-         validate_file_hash(zip_file_path, zip_sha384)
-         os.system(f'unzip -n {zip_file_path.relative_to(Path.cwd())}'
-                   f' -d {data_folder.relative_to(Path.cwd())}')
- 
-     @property
-     def sample_shape(self):
-         """Return the sample shape info."""
-         return self._sample_shape
- 
-     @property
-     def target_shape(self):
-         """Return the target shape info."""
-         return self._target_shape
- 
-     @property
-     def dataset_description(self) -> str:
-         """Return the dataset description."""
-         return (f'Kvasir dataset, shard number {self.rank} '
-                 f'out of {self.worldsize}')
- 
- 
- if __name__ == '__main__':
-     from openfl.interface.cli import setup_logging
- 
-     setup_logging()
- 
-     data_folder = 'data'
-     rank_worldsize = '1,100'
-     enforce_image_hw = '529,622'
- 
-     kvasir_sd = KvasirShardDescriptor(
-         data_folder,
-         rank_worldsize=rank_worldsize,
-         enforce_image_hw=enforce_image_hw)
- 
-     print(kvasir_sd.dataset_description)
-     print(kvasir_sd.sample_shape, kvasir_sd.target_shape)
- 
-     from openfl.component.envoy.envoy import Envoy
- 
-     shard_name = 'one'
-     director_host = 'localhost'
-     director_port = 50051
- 
-     keeper = Envoy(
-         shard_name=shard_name,
-         director_host=director_host,
-         director_port=director_port,
-         shard_descriptor=kvasir_sd,
-         tls=True,
-         root_certificate='./cert/root_ca.crt',
-         private_key='./cert/one.key',
-         certificate='./cert/one.crt',
-     )
- 
-     keeper.start()
--- 0 ----
diff -crB --new-file ./openfl/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/envoy/sd_requirements.txt ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/envoy/sd_requirements.txt
*** ./openfl/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/envoy/sd_requirements.txt	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/envoy/sd_requirements.txt	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- numpy
- pillow
- scikit-image
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/envoy/start_envoy.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/envoy/start_envoy.sh
*** ./openfl/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/envoy/start_envoy.sh	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/envoy/start_envoy.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- 
- fx envoy start -n env_one --disable-tls --envoy-config-path envoy_config.yaml -dh localhost -dp 50051
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/experiment.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/experiment.py
*** ./openfl/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/experiment.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/experiment.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,154 ****
- from copy import deepcopy
- 
- import numpy as np
- import PIL
- import torch.optim as optim
- from tests.github.interactive_api_director.experiments.pytorch_kvasir_unet.model import UNet
- from tests.github.interactive_api_director.experiments.pytorch_kvasir_unet.tasks import task_interface
- from tests.github.interactive_api_director.experiments.pytorch_kvasir_unet.tasks import validate
- from torch.utils.data import DataLoader
- from torch.utils.data import Dataset
- from torch.utils.data import SubsetRandomSampler
- from torchvision import transforms as tsf
- 
- from openfl.interface.interactive_api.experiment import DataInterface
- from openfl.interface.interactive_api.experiment import FLExperiment
- from openfl.interface.interactive_api.experiment import ModelInterface
- from openfl.interface.interactive_api.federation import Federation
- 
- 
- federation = Federation(
-     client_id='frontend',
-     director_node_fqdn='localhost',
-     director_port=50051,
-     tls=False
- )
- 
- shard_registry = federation.get_shard_registry()
- 
- dummy_shard_desc = federation.get_dummy_shard_descriptor(size=10)
- dummy_shard_dataset = dummy_shard_desc.get_dataset('')
- sample, target = dummy_shard_dataset[0]
- 
- 
- # Register dataset
- # We extract User dataset class implementation. Is it convinient? What if the dataset is not a class?
- class KvasirShardDataset(Dataset):
- 
-     def __init__(self, dataset):
-         self._dataset = dataset
- 
-         # Prepare transforms
-         self.img_trans = tsf.Compose([
-             tsf.ToPILImage(),
-             tsf.Resize((332, 332)),
-             tsf.ToTensor(),
-             tsf.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])
-         self.mask_trans = tsf.Compose([
-             tsf.ToPILImage(),
-             tsf.Resize((332, 332), interpolation=PIL.Image.NEAREST),
-             tsf.ToTensor()])
- 
-     def __getitem__(self, index):
-         img, mask = self._dataset[index]
-         img = self.img_trans(img).numpy()
-         mask = self.mask_trans(mask).numpy()
-         return img, mask
- 
-     def __len__(self):
-         return len(self._dataset)
- 
- 
- # Now you can implement you data loaders using dummy_shard_desc
- class KvasirSD(DataInterface):
- 
-     def __init__(self, validation_fraction=1 / 8, **kwargs):
-         super().__init__(**kwargs)
- 
-         self.validation_fraction = validation_fraction
- 
-     @property
-     def shard_descriptor(self):
-         return self._shard_descriptor
- 
-     @shard_descriptor.setter
-     def shard_descriptor(self, shard_descriptor):
-         """
-         Describe per-collaborator procedures or sharding.
- 
-         This method will be called during a collaborator initialization.
-         Local shard_descriptor  will be set by Envoy.
-         """
-         self._shard_descriptor = shard_descriptor
-         self._shard_dataset = KvasirShardDataset(shard_descriptor.get_dataset('train'))
- 
-         validation_size = max(1, int(len(self._shard_dataset) * self.validation_fraction))
- 
-         self.train_indeces = np.arange(len(self._shard_dataset) - validation_size)
-         self.val_indeces = np.arange(len(self._shard_dataset) - validation_size, len(self._shard_dataset))
- 
-     def get_train_loader(self, **kwargs):
-         """
-         Output of this method will be provided to tasks with optimizer in contract
-         """
-         train_sampler = SubsetRandomSampler(self.train_indeces)
-         return DataLoader(
-             self._shard_dataset,
-             num_workers=8,
-             batch_size=self.kwargs['train_bs'],
-             sampler=train_sampler
-         )
- 
-     def get_valid_loader(self, **kwargs):
-         """
-         Output of this method will be provided to tasks without optimizer in contract
-         """
-         val_sampler = SubsetRandomSampler(self.val_indeces)
-         return DataLoader(
-             self._shard_dataset,
-             num_workers=8,
-             batch_size=self.kwargs['valid_bs'],
-             sampler=val_sampler
-         )
- 
-     def get_train_data_size(self):
-         """
-         Information for aggregation
-         """
-         return len(self.train_indeces)
- 
-     def get_valid_data_size(self):
-         """
-         Information for aggregation
-         """
-         return len(self.val_indeces)
- 
- fed_dataset = KvasirSD(train_bs=4, valid_bs=8)
- fed_dataset.shard_descriptor = dummy_shard_desc
- for i, (sample, target) in enumerate(fed_dataset.get_train_loader()):
-     print(sample.shape)
- 
- model_unet = UNet()
- optimizer_adam = optim.Adam(model_unet.parameters(), lr=1e-4)
- 
- framework_adapter = 'openfl.plugins.frameworks_adapters.pytorch_adapter.FrameworkAdapterPlugin'
- MI = ModelInterface(model=model_unet, optimizer=optimizer_adam, framework_plugin=framework_adapter)
- 
- # Save the initial model state
- initial_model = deepcopy(model_unet)
- 
- # create an experimnet in federation
- experiment_name = 'kvasir_test_experiment'
- fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)
- 
- fl_experiment.start(model_provider=MI, 
-                     task_keeper=task_interface,
-                     data_loader=fed_dataset,
-                     rounds_to_train=2,
-                     opt_treatment='CONTINUE_GLOBAL')
- fl_experiment.stream_metrics()
- best_model = fl_experiment.get_best_model()
- fl_experiment.remove_experiment_data()
- best_model.inc.conv[0].weight
- validate(initial_model, fed_dataset.get_valid_loader(), 'cpu')
- validate(best_model, fed_dataset.get_valid_loader(), 'cpu')
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/__init__.py
*** ./openfl/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/__init__.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Pytorch kvasir unet example package."""
--- 0 ----
diff -crB --new-file ./openfl/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/layers.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/layers.py
*** ./openfl/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/layers.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/layers.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,100 ****
- """Layers for Unet model."""
- 
- import torch
- import torch.nn as nn
- import torch.nn.functional as F
- 
- 
- def soft_dice_loss(output, target):
-     """Calculate loss."""
-     num = target.size(0)
-     m1 = output.view(num, -1)
-     m2 = target.view(num, -1)
-     intersection = m1 * m2
-     score = 2.0 * (intersection.sum(1) + 1) / (m1.sum(1) + m2.sum(1) + 1)
-     score = 1 - score.sum() / num
-     return score
- 
- 
- def soft_dice_coef(output, target):
-     """Calculate soft DICE coefficient."""
-     num = target.size(0)
-     m1 = output.view(num, -1)
-     m2 = target.view(num, -1)
-     intersection = m1 * m2
-     score = 2.0 * (intersection.sum(1) + 1) / (m1.sum(1) + m2.sum(1) + 1)
-     return score.sum()
- 
- 
- class DoubleConv(nn.Module):
-     """Pytorch double conv class."""
- 
-     def __init__(self, in_ch, out_ch):
-         """Initialize layer."""
-         super(DoubleConv, self).__init__()
-         self.in_ch = in_ch
-         self.out_ch = out_ch
-         self.conv = nn.Sequential(
-             nn.Conv2d(in_ch, out_ch, 3, padding=1),
-             nn.BatchNorm2d(out_ch),
-             nn.ReLU(inplace=True),
-             nn.Conv2d(out_ch, out_ch, 3, padding=1),
-             nn.BatchNorm2d(out_ch),
-             nn.ReLU(inplace=True),
-         )
- 
-     def forward(self, x):
-         """Do forward pass."""
-         x = self.conv(x)
-         return x
- 
- 
- class Down(nn.Module):
-     """Pytorch nn module subclass."""
- 
-     def __init__(self, in_ch, out_ch):
-         """Initialize layer."""
-         super(Down, self).__init__()
-         self.mpconv = nn.Sequential(
-             nn.MaxPool2d(2),
-             DoubleConv(in_ch, out_ch)
-         )
- 
-     def forward(self, x):
-         """Do forward pass."""
-         x = self.mpconv(x)
-         return x
- 
- 
- class Up(nn.Module):
-     """Pytorch nn module subclass."""
- 
-     def __init__(self, in_ch, out_ch, bilinear=False):
-         """Initialize layer."""
-         super(Up, self).__init__()
-         self.in_ch = in_ch
-         self.out_ch = out_ch
-         if bilinear:
-             self.up = nn.Upsample(
-                 scale_factor=2,
-                 mode='bilinear',
-                 align_corners=True
-             )
-         else:
-             self.up = nn.ConvTranspose2d(in_ch, in_ch // 2, 2, stride=2)
-         self.conv = DoubleConv(in_ch, out_ch)
- 
-     def forward(self, x1, x2):
-         """Do forward pass."""
-         x1 = self.up(x1)
-         diff_y = x2.size()[2] - x1.size()[2]
-         diff_x = x2.size()[3] - x1.size()[3]
- 
-         x1 = F.pad(
-             x1,
-             (diff_x // 2, diff_x - diff_x // 2, diff_y // 2, diff_y - diff_y // 2)
-         )
- 
-         x = torch.cat([x2, x1], dim=1)
-         x = self.conv(x)
-         return x
--- 0 ----
diff -crB --new-file ./openfl/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/model.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/model.py
*** ./openfl/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/model.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/model.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,37 ****
- import torch
- import torch.nn as nn
- 
- from tests.github.interactive_api_director.experiments.pytorch_kvasir_unet.layers import DoubleConv, Down, Up
- 
- """
- UNet model definition
- """
- 
- 
- class UNet(nn.Module):
-     def __init__(self, n_channels=3, n_classes=1):
-         super().__init__()
-         self.inc = DoubleConv(n_channels, 64)
-         self.down1 = Down(64, 128)
-         self.down2 = Down(128, 256)
-         self.down3 = Down(256, 512)
-         self.down4 = Down(512, 1024)
-         self.up1 = Up(1024, 512)
-         self.up2 = Up(512, 256)
-         self.up3 = Up(256, 128)
-         self.up4 = Up(128, 64)
-         self.outc = nn.Conv2d(64, n_classes, 1)
- 
-     def forward(self, x):
-         x1 = self.inc(x)
-         x2 = self.down1(x1)
-         x3 = self.down2(x2)
-         x4 = self.down3(x3)
-         x5 = self.down4(x4)
-         x = self.up1(x5, x4)
-         x = self.up2(x, x3)
-         x = self.up3(x, x2)
-         x = self.up4(x, x1)
-         x = self.outc(x)
-         x = torch.sigmoid(x)
-         return x
--- 0 ----
diff -crB --new-file ./openfl/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/run.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/run.sh
*** ./openfl/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/run.sh	2022-11-18 11:08:33.047181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/run.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,31 ****
- #!/bin/bash
- set -e
- 
- cd director
- bash start_director.sh &
- PID=$!
- 
- sleep 3
- if ! ps -p $PID > /dev/null
- then
-   echo 'Error: failed to create director'
-   exit 1
- fi
- 
- 
- cd ../envoy
- pip install -r sd_requirements.txt
- bash start_envoy.sh &
- PID=$!
- sleep 3
- if ! ps -p $PID > /dev/null
- then
-   echo 'Error: failed to create envoy'
-   exit 1
- else
-   echo "Found $PID in $(ps -p $PID)"
- fi
- 
- 
- cd ../../../../../..
- python -m tests.github.interactive_api_director.experiments.pytorch_kvasir_unet.experiment
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/tasks.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/tasks.py
*** ./openfl/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/tasks.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/pytorch_kvasir_unet/tasks.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,67 ****
- import tqdm
- import torch
- import numpy as np
- 
- from openfl.interface.interactive_api.experiment import TaskInterface
- from tests.github.interactive_api_director.experiments.pytorch_kvasir_unet.layers import soft_dice_loss, soft_dice_coef
- 
- 
- task_interface = TaskInterface()
- 
- 
- def function_defined_in_notebook(some_parameter):
-     print('I will cause problems')
-     print(f'Also I accept a parameter and it is {some_parameter}')
- 
- 
- # We do not actually need to register additional kwargs, Just serialize them
- @task_interface.add_kwargs(**{'some_parameter': 42})
- @task_interface.register_fl_task(model='unet_model', data_loader='train_loader',
-                                  device='device', optimizer='optimizer')
- def train(unet_model, train_loader, optimizer, device, loss_fn=soft_dice_loss, some_parameter=None):
-     if not torch.cuda.is_available():
-         device = 'cpu'
- 
-     function_defined_in_notebook(some_parameter)
- 
-     train_loader = tqdm.tqdm(train_loader, desc="train")
- 
-     unet_model.train()
-     unet_model.to(device)
- 
-     losses = []
- 
-     for data, target in train_loader:
-         data, target = torch.tensor(data).to(device), torch.tensor(
-             target).to(device, dtype=torch.float32)
-         optimizer.zero_grad()
-         output = unet_model(data)
-         loss = loss_fn(output=output, target=target)
-         loss.backward()
-         optimizer.step()
-         losses.append(loss.detach().cpu().numpy())
- 
-     return {'train_loss': np.mean(losses), }
- 
- 
- @task_interface.register_fl_task(model='unet_model', data_loader='val_loader', device='device')
- def validate(unet_model, val_loader, device):
-     unet_model.eval()
-     unet_model.to(device)
- 
-     val_loader = tqdm.tqdm(val_loader, desc="validate")
- 
-     val_score = 0
-     total_samples = 0
- 
-     with torch.no_grad():
-         for data, target in val_loader:
-             samples = target.shape[0]
-             total_samples += samples
-             data, target = torch.tensor(data).to(device), \
-                            torch.tensor(target).to(device, dtype=torch.int64)
-             output = unet_model(data)
-             val = soft_dice_coef(output, target)
-             val_score += val.sum().cpu().numpy()
- 
-     return {'dice_coef': val_score / total_samples, }
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/tests/github/interactive_api_director/experiments/tensorflow_mnist/dataset.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/tensorflow_mnist/dataset.py
*** ./openfl/tests/github/interactive_api_director/experiments/tensorflow_mnist/dataset.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/tensorflow_mnist/dataset.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,62 ****
- import tensorflow as tf
- import numpy as np
- 
- from openfl.interface.interactive_api.experiment import DataInterface
- 
- 
- class FedDataset(DataInterface):
-     def __init__(self, train_bs, valid_bs, **kwargs):
-         super().__init__(**kwargs)
-         self.train_bs = train_bs
-         self.valid_bs = valid_bs
- 
-     @property
-     def shard_descriptor(self):
-         return self._shard_descriptor
-         
-     @shard_descriptor.setter
-     def shard_descriptor(self, shard_descriptor):
-         """
-         Describe per-collaborator procedures or sharding.
- 
-         This method will be called during a collaborator initialization.
-         Local shard_descriptor  will be set by Envoy.
-         """
-         self._shard_descriptor = shard_descriptor
-         validation_size = len(self.shard_descriptor) // 10
-         self.train_indices = np.arange(len(self.shard_descriptor) - validation_size)
-         self.val_indices = np.arange(len(self.shard_descriptor) - validation_size, len(self.shard_descriptor))
- 
-     def get_train_loader(self, **kwargs):
-         """
-         Output of this method will be provided to tasks with optimizer in contract
-         """
-         samples, targets = [], []
-         for i in self.train_indices:
-             sample, target = self.shard_descriptor[i]
-             samples.append(sample)
-             targets.append(target)
-         samples = np.array(samples)
-         targets = np.array(targets)
-         return tf.data.Dataset.from_tensor_slices((samples, targets)).batch(self.train_bs)
- 
-     def get_valid_loader(self, **kwargs):
-         """
-         Output of this method will be provided to tasks without optimizer in contract
-         """
-         samples, targets = zip(*[self.shard_descriptor[i] for i in self.val_indices])
-         samples = np.array(samples)
-         targets = np.array(targets)
-         return tf.data.Dataset.from_tensor_slices((samples, targets)).batch(self.valid_bs)
- 
-     def get_train_data_size(self):
-         """
-         Information for aggregation
-         """
-         return len(self.train_indices)
- 
-     def get_valid_data_size(self):
-         """
-         Information for aggregation
-         """
-         return len(self.val_indices)
--- 0 ----
diff -crB --new-file ./openfl/tests/github/interactive_api_director/experiments/tensorflow_mnist/director/config.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/tensorflow_mnist/director/config.yaml
*** ./openfl/tests/github/interactive_api_director/experiments/tensorflow_mnist/director/config.yaml	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/tensorflow_mnist/director/config.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,11 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- # Director's config.
- # Parameters:
- #   1. sample_shape - sample shape interface unified across the Federation
- #   1. target_shape - target shape interface unified across the Federation
- 
- settings:
-   sample_shape: ['784']
-   target_shape: ['0']
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/tests/github/interactive_api_director/experiments/tensorflow_mnist/director/start_director.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/tensorflow_mnist/director/start_director.sh
*** ./openfl/tests/github/interactive_api_director/experiments/tensorflow_mnist/director/start_director.sh	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/tensorflow_mnist/director/start_director.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- 
- fx director start --disable-tls -c config.yaml
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/tests/github/interactive_api_director/experiments/tensorflow_mnist/envoy/envoy_config.yaml ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/tensorflow_mnist/envoy/envoy_config.yaml
*** ./openfl/tests/github/interactive_api_director/experiments/tensorflow_mnist/envoy/envoy_config.yaml	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/tensorflow_mnist/envoy/envoy_config.yaml	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,9 ****
- params:
-   cuda_devices: []
- 
- optional_plugin_components: {}
- 
- shard_descriptor:
-   template: shard_descriptor.MNISTShardDescriptor
-   params:
-     rank_worldsize: 1,90
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/tests/github/interactive_api_director/experiments/tensorflow_mnist/envoy/shard_descriptor.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/tensorflow_mnist/envoy/shard_descriptor.py
*** ./openfl/tests/github/interactive_api_director/experiments/tensorflow_mnist/envoy/shard_descriptor.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/tensorflow_mnist/envoy/shard_descriptor.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,92 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Kvasir shard descriptor."""
- 
- import numpy as np
- from tensorflow import keras
- 
- from openfl.interface.interactive_api.shard_descriptor import ShardDescriptor
- 
- 
- class MNISTShardDescriptor(ShardDescriptor):
-     """Shard descriptor class."""
- 
-     def __init__(self, rank_worldsize: str = '1,1') -> None:
-         """Initialize KvasirShardDescriptor."""
-         super().__init__()
- 
-         (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
-         x_train = np.reshape(x_train, (-1, 784))
-         x_test = np.reshape(x_test, (-1, 784))
-         self.rank, self.worldsize = tuple(int(num) for num in rank_worldsize.split(','))
- 
-         # Sharding
-         self.X_train = x_train[self.rank - 1::self.worldsize]
-         self.y_train = y_train[self.rank - 1::self.worldsize]
-         self.X_test = x_test[self.rank - 1::self.worldsize]
-         self.y_test = y_test[self.rank - 1::self.worldsize]
- 
- 
-         # Calculating data and target shapes
-         sample, _ = self[0]
-         self._sample_shape = [str(dim) for dim in sample.shape]
-         self._target_shape = ['0']
- 
- 
-     def __getitem__(self, index):
-         """Return a item by the index."""
-         if index < len(self.X_train):
-             return self.X_train[index], self.y_train[index]
-         index -= len(self.X_train) + 1
-         return self.X_test[index], self.y_test[index]
- 
-     def __len__(self):
-         """Return the len of the dataset."""
-         return len(self.X_train) + len(self.X_test)
- 
-     @property
-     def sample_shape(self):
-         """Return the sample shape info."""
-         return self._sample_shape
- 
-     @property
-     def target_shape(self):
-         """Return the target shape info."""
-         return self._target_shape
- 
-     @property
-     def dataset_description(self) -> str:
-         """Return the dataset description."""
-         return (f'MNIST dataset, shard number {self.rank}'
-                 f' out of {self.worldsize}')
- 
- 
- if __name__ == '__main__':
-     from openfl.interface.cli import setup_logging
-     setup_logging()
- 
-     data_folder = 'data'
-     rank_worldsize = '1,100'
- 
-     mnist_sd = MNISTShardDescriptor(
-         rank_worldsize=rank_worldsize)
- 
-     print(mnist_sd.dataset_description)
-     print(mnist_sd.sample_shape, mnist_sd.target_shape)
- 
-     from openfl.component.envoy.envoy import Envoy
- 
-     shard_name = 'one'
-     director_uri = 'localhost:50051'
- 
-     keeper = Envoy(
-         shard_name=shard_name,
-         director_uri=director_uri,
-         shard_descriptor=mnist_sd,
-         tls=False,
-         root_ca='./cert/root_ca.crt',
-         key='./cert/one.key',
-         cert='./cert/one.crt',
-     )
- 
-     keeper.start()
--- 0 ----
diff -crB --new-file ./openfl/tests/github/interactive_api_director/experiments/tensorflow_mnist/envoy/start_envoy.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/tensorflow_mnist/envoy/start_envoy.sh
*** ./openfl/tests/github/interactive_api_director/experiments/tensorflow_mnist/envoy/start_envoy.sh	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/tensorflow_mnist/envoy/start_envoy.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,4 ****
- #!/bin/bash
- set -e
- 
- fx envoy start -n env_one --disable-tls --envoy-config-path envoy_config.yaml -dh localhost -dp 50051
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/tests/github/interactive_api_director/experiments/tensorflow_mnist/experiment.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/tensorflow_mnist/experiment.py
*** ./openfl/tests/github/interactive_api_director/experiments/tensorflow_mnist/experiment.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/tensorflow_mnist/experiment.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,127 ****
- import time
- import tensorflow as tf
- # Create a federation
- from openfl.interface.interactive_api.federation import Federation
- from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment
- from tests.github.interactive_api_director.experiments.tensorflow_mnist.dataset import FedDataset
- from tests.github.interactive_api_director.experiments.tensorflow_mnist.settings import model
- from tests.github.interactive_api_director.experiments.tensorflow_mnist.settings import optimizer
- from tests.github.interactive_api_director.experiments.tensorflow_mnist.settings import loss_fn
- from tests.github.interactive_api_director.experiments.tensorflow_mnist.settings import train_acc_metric
- from tests.github.interactive_api_director.experiments.tensorflow_mnist.settings import val_acc_metric
- from tests.github.interactive_api_director.experiments.tensorflow_mnist.envoy.shard_descriptor import MNISTShardDescriptor
- from copy import deepcopy
- 
- 
- # please use the same identificator that was used in signed certificate
- client_id = 'frontend'
- 
- # 1) Run with API layer - Director mTLS 
- # If the user wants to enable mTLS their must provide CA root chain, and signed key pair to the federation interface
- # cert_chain = 'cert/root_ca.crt'
- # API_certificate = 'cert/frontend.crt'
- # API_private_key = 'cert/frontend.key'
- 
- # federation = Federation(client_id='frontend', director_node_fqdn='localhost', director_port='50051',
- #                        cert_chain=cert_chain, api_cert=API_certificate, api_private_key=API_private_key)
- 
- # --------------------------------------------------------------------------------------------------------------------
- 
- # 2) Run with TLS disabled (trusted environment)
- # Federation can also determine local fqdn automatically
- federation = Federation(client_id=client_id, director_node_fqdn='localhost', director_port='50051', tls=False)
- 
- shard_registry = federation.get_shard_registry()
- print(shard_registry)
- print(federation.target_shape)
- fed_dataset = FedDataset(train_bs=4, valid_bs=8)
- fed_dataset.shard_descriptor = MNISTShardDescriptor()
- for batch in fed_dataset.get_train_loader():
-     samples, _ = batch
-     for sample in samples:
-         print(sample.shape)
- 
- 
- framework_adapter = 'openfl.plugins.frameworks_adapters.keras_adapter.FrameworkAdapterPlugin'
- MI = ModelInterface(model=model, optimizer=optimizer, framework_plugin=framework_adapter)
- 
- 
- def function_defined_in_notebook(some_parameter):
-     print(f'Also I accept a parameter and it is {some_parameter}')
- 
- 
- TI = TaskInterface()
- # Task interface currently supports only standalone functions.
- @TI.register_fl_task(model='model', data_loader='train_dataset',
-                      device='device', optimizer='optimizer')     
- def train(model, train_dataset, optimizer, device, loss_fn=loss_fn, warmup=False):
- 
-     # Iterate over the batches of the dataset.
-     for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):
-         with tf.GradientTape() as tape:
-             logits = model(x_batch_train, training=True)
-             loss_value = loss_fn(y_batch_train, logits)
-         grads = tape.gradient(loss_value, model.trainable_weights)
-         optimizer.apply_gradients(zip(grads, model.trainable_weights))
- 
-         # Update training metric.
-         train_acc_metric.update_state(y_batch_train, logits)
- 
-         # Log every 200 batches.
-         if step % 200 == 0:
-             print(
-                 "Training loss (for one batch) at step %d: %.4f"
-                 % (step, float(loss_value))
-             )
-             print("Seen so far: %d samples" % ((step + 1) * 64))
-         if warmup:
-             break
- 
-     # Display metrics at the end of each epoch.
-     train_acc = train_acc_metric.result()
-     print("Training acc over epoch: %.4f" % (float(train_acc),))
- 
-     # Reset training metrics at the end of each epoch
-     train_acc_metric.reset_states()
- 
-     return {'train_acc': train_acc}
- 
- 
- @TI.register_fl_task(model='model', data_loader='val_dataset', device='device')     
- def validate(model, val_dataset, device):
-     # Run a validation loop at the end of each epoch.
-     for x_batch_val, y_batch_val in val_dataset:
-         val_logits = model(x_batch_val, training=False)
-         # Update val metrics
-         val_acc_metric.update_state(y_batch_val, val_logits)
-     val_acc = val_acc_metric.result()
-     val_acc_metric.reset_states()
-     print("Validation acc: %.4f" % (float(val_acc),))
-             
-     return {'validation_accuracy': val_acc,}
- # Save the initial model state
- train(model,fed_dataset.get_train_loader(), optimizer, 'cpu', warmup=True)
- initial_model = tf.keras.models.clone_model(model)
- 
- 
- 
- # The Interactive API supports registering functions definied in main module or imported.
- 
- 
- # create an experimnet in federation
- experiment_name = 'mnist_test_experiment'
- fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)
- # If I use autoreload I got a pickling error
- 
- # The following command zips the workspace and python requirements to be transfered to collaborator nodes
- fl_experiment.start(model_provider=MI, 
-                     task_keeper=TI,
-                     data_loader=fed_dataset,
-                     rounds_to_train=2,
-                     opt_treatment='CONTINUE_GLOBAL')
- 
- fl_experiment.stream_metrics()
- best_model = fl_experiment.get_best_model()
- fl_experiment.remove_experiment_data()
- validate(initial_model, fed_dataset.get_valid_loader(), 'cpu')
- validate(best_model, fed_dataset.get_valid_loader(), 'cpu')
--- 0 ----
diff -crB --new-file ./openfl/tests/github/interactive_api_director/experiments/tensorflow_mnist/run.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/tensorflow_mnist/run.sh
*** ./openfl/tests/github/interactive_api_director/experiments/tensorflow_mnist/run.sh	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/tensorflow_mnist/run.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,31 ****
- #!/bin/bash
- set -e
- 
- cd director
- bash start_director.sh &
- PID=$!
- 
- sleep 3
- if ! ps -p $PID > /dev/null
- then
-   echo 'Error: failed to create director'
-   exit 1
- fi
- 
- 
- cd ../envoy
- pip install -r sd_requirements.txt
- bash start_envoy.sh &
- PID=$!
- sleep 3
- if ! ps -p $PID > /dev/null
- then
-   echo 'Error: failed to create envoy'
-   exit 1
- else
-   echo "Found $PID in $(ps -p $PID)"
- fi
- 
- 
- cd ../../../../../..
- python -m tests.github.interactive_api_director.experiments.tensorflow_mnist.experiment
\ No newline at end of file
--- 0 ----
diff -crB --new-file ./openfl/tests/github/interactive_api_director/experiments/tensorflow_mnist/settings.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/tensorflow_mnist/settings.py
*** ./openfl/tests/github/interactive_api_director/experiments/tensorflow_mnist/settings.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/tensorflow_mnist/settings.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,36 ****
- import tensorflow as tf
- from tensorflow import keras
- from tensorflow.keras import layers
- import numpy as np
- 
- 
- # Describe the model and optimizer
- 
- inputs = keras.Input(shape=(784,), name="digits")
- x1 = layers.Dense(64, activation="relu")(inputs)
- x2 = layers.Dense(64, activation="relu")(x1)
- outputs = layers.Dense(10, name="predictions")(x2)
- model = keras.Model(inputs=inputs, outputs=outputs)
- 
- # Instantiate an optimizer.
- optimizer = keras.optimizers.SGD(learning_rate=1e-3)
- # Instantiate a loss function.
- loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)
- model.compile(optimizer, loss_fn)
- # Prepare the metrics.
- train_acc_metric = keras.metrics.SparseCategoricalAccuracy()
- val_acc_metric = keras.metrics.SparseCategoricalAccuracy()
- 
- 
- # Prepare data
- 
- # Prepare the training dataset.
- batch_size = 64
- (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
- x_train = np.reshape(x_train, (-1, 784))
- x_test = np.reshape(x_test, (-1, 784))
- 
- X_valid = x_train[-10000:]
- y_valid = y_train[-10000:]
- X_train = x_train[:-10000]
- y_train = y_train[:-10000]
--- 0 ----
diff -crB --new-file ./openfl/tests/github/interactive_api_director/experiments/tensorflow_mnist/tasks.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/tensorflow_mnist/tasks.py
*** ./openfl/tests/github/interactive_api_director/experiments/tensorflow_mnist/tasks.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/experiments/tensorflow_mnist/tasks.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,55 ****
- from openfl.interface.interactive_api.experiment import TaskInterface
- from tests.github.interactive_api.experiments.tensorflow_mnist.settings import loss_fn, \
-     train_acc_metric, val_acc_metric
- 
- task_interface = TaskInterface()
- 
- 
- @task_interface.register_fl_task(model='model', data_loader='train_dataset',
-                                  device='device', optimizer='optimizer')
- def train(model, train_dataset, optimizer, device, loss_fn=loss_fn, warmup=False):
-     import tensorflow as tf
- 
-     # Iterate over the batches of the dataset.
-     for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):
-         with tf.GradientTape() as tape:
-             logits = model(x_batch_train, training=True)
-             loss_value = loss_fn(y_batch_train, logits)
-         grads = tape.gradient(loss_value, model.trainable_weights)
-         optimizer.apply_gradients(zip(grads, model.trainable_weights))
- 
-         # Update training metric.
-         train_acc_metric.update_state(y_batch_train, logits)
- 
-         # Log every 200 batches.
-         if step % 200 == 0:
-             print(
-                 "Training loss (for one batch) at step %d: %.4f"
-                 % (step, float(loss_value))
-             )
-             print("Seen so far: %d samples" % ((step + 1) * 64))
-         if warmup:
-             break
- 
-     # Display metrics at the end of each epoch.
-     train_acc = train_acc_metric.result()
-     print("Training acc over epoch: %.4f" % (float(train_acc),))
- 
-     # Reset training metrics at the end of each epoch
-     train_acc_metric.reset_states()
- 
-     return {'train_acc': train_acc}
- 
- 
- @task_interface.register_fl_task(model='model', data_loader='val_dataset', device='device')
- def validate(model, val_dataset, device):
-     # Run a validation loop at the end of each epoch.
-     for x_batch_val, y_batch_val in val_dataset:
-         val_logits = model(x_batch_val, training=False)
-         # Update val metrics
-         val_acc_metric.update_state(y_batch_val, val_logits)
-     val_acc = val_acc_metric.result()
-     val_acc_metric.reset_states()
-     print("Validation acc: %.4f" % (float(val_acc),))
- 
-     return {'validation_accuracy': val_acc}
--- 0 ----
diff -crB --new-file ./openfl/tests/github/interactive_api_director/voc_shard_descriptor.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/voc_shard_descriptor.py
*** ./openfl/tests/github/interactive_api_director/voc_shard_descriptor.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/interactive_api_director/voc_shard_descriptor.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,124 ****
- import os
- import numpy as np
- import xml.etree.ElementTree as ET
- from PIL import Image
- 
- 
- class ShardDescriptor:
- 
-     def __len__(self):
-         raise NotImplementedError
- 
-     def get_item(self, index: int):
-         # -> Tuple(np.ndarray, np.ndarray)
-         raise NotImplementedError
- 
-     @property
-     def sample_shape(self):
-         # int( sum( [str(dim) for dim in sample.shape] ) )
-         raise NotImplementedError
- 
-     @property
-     def target_shape(self):
-         raise NotImplementedError
- 
-     @property
-     def dataset_description(self) -> str:
-         return ''
- 
- 
- class VOCDataset_SD(ShardDescriptor):
-     class_names = ('__background__',
-                    'aeroplane', 'bicycle', 'bird', 'boat',
-                    'bottle', 'bus', 'car', 'cat', 'chair',
-                    'cow', 'diningtable', 'dog', 'horse',
-                    'motorbike', 'person', 'pottedplant',
-                    'sheep', 'sofa', 'train', 'tvmonitor')
- 
-     def __init__(self, data_dir, split, keep_difficult=False):
-         """Dataset for VOC data.
-         Args:
-             data_dir: the root of the VOC2007 or VOC2012 dataset,
-                 the directory contains the following sub-directories:
-                 Annotations, ImageSets, JPEGImages, SegmentationClass, SegmentationObject.
-         """
-         self.data_dir = data_dir
-         self.split = split
-         image_sets_file = os.path.join(self.data_dir, "ImageSets", "Main", "%s.txt" % self.split)
-         self.ids = self._read_image_ids(image_sets_file)
-         self.keep_difficult = keep_difficult
- 
-         self.class_dict = {class_name: i for i, class_name in enumerate(self.class_names)}
- 
-     def get_item(self, index: int):
-         # -> Tuple(np.ndarray, np.ndarray)
-         img_id = self.ids[index]
-         img = self._read_image(img_id)
-         target = self.get_annotation(index)[1]
-         return img, target
- 
-     def __len__(self):
-         return len(self.ids)
- 
-     @property
-     def sample_shape(self):
-         # int( sum( [str(dim) for dim in sample.shape] ) )
-         return self.get_img_info(0)
- 
-     @property
-     def target_shape(self) -> int:
-         return 1
- 
-     @property
-     def dataset_description(self) -> str:
-         return 'VOC2007' if '2007' in self.data_dir else 'VOC2012'
- 
-     def get_annotation(self, index):
-         image_id = self.ids[index]
-         return image_id, self._get_annotation(image_id)
- 
-     @staticmethod
-     def _read_image_ids(image_sets_file):
-         ids = []
-         with open(image_sets_file) as f:
-             for line in f:
-                 ids.append(line.split(' ')[0])
-         return ids
- 
-     def _get_annotation(self, image_id):
-         annotation_file = os.path.join(self.data_dir, "Annotations", "%s.xml" % image_id)
-         objects = ET.parse(annotation_file).findall("object")
-         boxes = []
-         labels = []
-         is_difficult = []
-         for obj in objects:
-             class_name = obj.find('name').text.lower().strip()
-             bbox = obj.find('bndbox')
-             # VOC dataset format follows Matlab, in which indexes start from 0
-             x1 = float(bbox.find('xmin').text) - 1
-             y1 = float(bbox.find('ymin').text) - 1
-             x2 = float(bbox.find('xmax').text) - 1
-             y2 = float(bbox.find('ymax').text) - 1
-             boxes.append([x1, y1, x2, y2])
-             labels.append(self.class_dict[class_name])
-             is_difficult_str = obj.find('difficult').text
-             is_difficult.append(int(is_difficult_str) if is_difficult_str else 0)
- 
-         return (np.array(boxes, dtype=np.float32),
-                 np.array(labels, dtype=np.int64),
-                 np.array(is_difficult, dtype=np.uint8))
- 
-     def get_img_info(self, index):
-         img_id = self.ids[index]
-         annotation_file = os.path.join(self.data_dir, "Annotations", "%s.xml" % img_id)
-         anno = ET.parse(annotation_file).getroot()
-         size = anno.find("size")
-         im_info = tuple(map(int, (
-             size.find('height').text, size.find('width').text, size.find('depth').text)))
-         return np.array(im_info)
- 
-     def _read_image(self, image_id):
-         image_file = os.path.join(self.data_dir, "JPEGImages", "%s.jpg" % image_id)
-         image = Image.open(image_file).convert("RGB")
-         image = np.array(image)
-         return image
--- 0 ----
diff -crB --new-file ./openfl/tests/github/python_native_tf.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/python_native_tf.py
*** ./openfl/tests/github/python_native_tf.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/python_native_tf.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,140 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Python native tests."""
- 
- import numpy as np
- 
- import openfl.native as fx
- 
- 
- def one_hot(labels, classes):
-     """
-     One Hot encode a vector.
- 
-     Args:
-         labels (list):  List of labels to onehot encode
-         classes (int): Total number of categorical classes
- 
-     Returns:
-         np.array: Matrix of one-hot encoded labels
-     """
-     return np.eye(classes)[labels]
- 
- 
- def build_model(input_shape,
-                 num_classes,
-                 conv_kernel_size=(4, 4),
-                 conv_strides=(2, 2),
-                 conv1_channels_out=16,
-                 conv2_channels_out=32,
-                 final_dense_inputsize=100,
-                 **kwargs):
-     """
-     Define the model architecture.
- 
-     Args:
-         input_shape (numpy.ndarray): The shape of the data
-         num_classes (int): The number of classes of the dataset
- 
-     Returns:
-         tensorflow.python.keras.engine.sequential.Sequential: The model defined in Keras
- 
-     """
-     import tensorflow as tf # NOQA
-     import tensorflow.keras as ke # NOQA
- 
-     from tensorflow.keras import Sequential # NOQA
-     from tensorflow.keras.layers import Conv2D, Flatten, Dense # NOQA
-     config = tf.compat.v1.ConfigProto()
-     config.gpu_options.allow_growth = True
-     config.intra_op_parallelism_threads = 112
-     config.inter_op_parallelism_threads = 1
-     sess = tf.compat.v1.Session(config=config)
-     model = Sequential()
- 
-     model.add(Conv2D(conv1_channels_out,
-                      kernel_size=conv_kernel_size,
-                      strides=conv_strides,
-                      activation='relu',
-                      input_shape=input_shape))
- 
-     model.add(Conv2D(conv2_channels_out,
-                      kernel_size=conv_kernel_size,
-                      strides=conv_strides,
-                      activation='relu'))
- 
-     model.add(Flatten())
- 
-     model.add(Dense(final_dense_inputsize, activation='relu'))
- 
-     model.add(Dense(num_classes, activation='softmax'))
- 
-     model.compile(loss=ke.losses.categorical_crossentropy,
-                   optimizer=ke.optimizers.Adam(),
-                   metrics=['accuracy'])
- 
-     # initialize the optimizer variables
-     opt_vars = model.optimizer.variables()
- 
-     for v in opt_vars:
-         v.initializer.run(session=sess)
- 
-     return model
- 
- 
- if __name__ == '__main__':
-     fx.init('keras_cnn_mnist')
-     from openfl.federated import FederatedDataSet
-     from openfl.federated import FederatedModel
-     from tensorflow.python.keras.utils.data_utils import get_file
- 
-     origin_folder = 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/'
-     path = get_file('mnist.npz',
-                     origin=origin_folder + 'mnist.npz',
-                     file_hash='731c5ac602752760c8e48fbffcf8c3b850d9dc2a2aedcf2cc48468fc17b673d1')
- 
-     with np.load(path) as f:
-         # get all of mnist
-         X_train = f['x_train']
-         y_train = f['y_train']
- 
-         X_valid = f['x_test']
-         y_valid = f['y_test']
-     img_rows, img_cols = 28, 28
-     X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)
-     X_valid = X_valid.reshape(X_valid.shape[0], img_rows, img_cols, 1)
-     X_train = X_train.astype('float32')
-     X_valid = X_valid.astype('float32')
-     X_train /= 255
-     X_valid /= 255
- 
-     classes = 10
-     y_train = one_hot(y_train, classes)
-     y_valid = one_hot(y_valid, classes)
- 
-     feature_shape = X_train.shape[1]
- 
-     fl_data = FederatedDataSet(X_train, y_train, X_valid, y_valid,
-                                batch_size=32, num_classes=classes)
-     fl_model = FederatedModel(build_model=build_model, data_loader=fl_data)
-     collaborator_models = fl_model.setup(num_collaborators=2)
-     collaborators = {'one': collaborator_models[0], 'two': collaborator_models[1]}
-     print(f'Original training data size: {len(X_train)}')
-     print(f'Original validation data size: {len(X_valid)}\n')
- 
-     # Collaborator one's data
-     print(f'Collaborator one\'s training data size: '
-           f'{len(collaborator_models[0].data_loader.X_train)}')
-     print(f'Collaborator one\'s validation data size: '
-           f'{len(collaborator_models[0].data_loader.X_valid)}\n')
- 
-     # Collaborator two's data
-     print(f'Collaborator two\'s training data size: '
-           f'{len(collaborator_models[1].data_loader.X_train)}')
-     print(f'Collaborator two\'s validation data size: '
-           f'{len(collaborator_models[1].data_loader.X_valid)}\n')
- 
-     print(fx.get_plan())
-     final_fl_model = fx.run_experiment(collaborators, {'aggregator.settings.rounds_to_train': 5})
-     final_fl_model.save_native('final_pytorch_model.h5')
--- 0 ----
diff -crB --new-file ./openfl/tests/github/python_native_torch.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/python_native_torch.py
*** ./openfl/tests/github/python_native_torch.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/python_native_torch.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,97 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- 
- """Python native tests."""
- 
- import numpy as np
- 
- import openfl.native as fx
- 
- 
- def one_hot(labels, classes):
-     """One-hot encode `labels` using `classes` classes."""
-     return np.eye(classes)[labels]
- 
- 
- fx.init('torch_cnn_mnist')
- 
- if __name__ == '__main__':
-     import torch
-     import torch.nn as nn
-     import torch.nn.functional as F
-     import torch.optim as optim
-     from torchvision import datasets
-     from torchvision import transforms
- 
-     from openfl.federated import FederatedDataSet
-     from openfl.federated import FederatedModel
- 
-     def cross_entropy(output, target):
-         """Binary cross-entropy metric."""
-         return F.cross_entropy(input=output, target=target)
- 
-     class Net(nn.Module):
-         """PyTorch Neural Network."""
- 
-         def __init__(self):
-             """Initialize."""
-             super(Net, self).__init__()
-             self.conv1 = nn.Conv2d(1, 16, 3)
-             self.pool = nn.MaxPool2d(2, 2)
-             self.conv2 = nn.Conv2d(16, 32, 3)
-             self.fc1 = nn.Linear(32 * 5 * 5, 32)
-             self.fc2 = nn.Linear(32, 84)
-             self.fc3 = nn.Linear(84, 10)
- 
-         def forward(self, x):
-             """Forward pass of the network."""
-             x = self.pool(F.relu(self.conv1(x)))
-             x = self.pool(F.relu(self.conv2(x)))
-             x = x.view(x.size(0), -1)
-             x = F.relu(self.fc1(x))
-             x = F.relu(self.fc2(x))
-             x = self.fc3(x)
-             return x
- 
-     transform = transforms.Compose([transforms.ToTensor(),
-                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
- 
-     trainset = datasets.MNIST(root='./data', train=True,
-                               download=True, transform=transform)
- 
-     train_images, train_labels = trainset.train_data, np.array(trainset.train_labels)
-     train_images = torch.from_numpy(np.expand_dims(train_images, axis=1)).float()
- 
-     validset = datasets.MNIST(root='./data', train=False,
-                               download=True, transform=transform)
- 
-     valid_images, valid_labels = validset.test_data, np.array(validset.test_labels)
-     valid_images = torch.from_numpy(np.expand_dims(valid_images, axis=1)).float()
-     valid_labels = one_hot(valid_labels, 10)
-     feature_shape = train_images.shape[1]
-     classes = 10
- 
-     fl_data = FederatedDataSet(train_images, train_labels, valid_images, valid_labels,
-                                batch_size=32, num_classes=classes)
-     fl_model = FederatedModel(build_model=Net, optimizer=lambda x: optim.Adam(x, lr=1e-4),
-                               loss_fn=cross_entropy, data_loader=fl_data)
-     collaborator_models = fl_model.setup(num_collaborators=2)
-     collaborators = {'one': collaborator_models[0], 'two': collaborator_models[1]}
-     print(f'Original training data size: {len(train_images)}')
-     print(f'Original validation data size: {len(valid_images)}\n')
- 
-     # Collaborator one's data
-     print(f'Collaborator one\'s training data size: '
-           f'{len(collaborator_models[0].data_loader.X_train)}')
-     print(f'Collaborator one\'s validation data size: '
-           f'{len(collaborator_models[0].data_loader.X_valid)}\n')
- 
-     # Collaborator two's data
-     print(f'Collaborator two\'s training data size: '
-           f'{len(collaborator_models[1].data_loader.X_train)}')
-     print(f'Collaborator two\'s validation data size: '
-           f'{len(collaborator_models[1].data_loader.X_valid)}\n')
- 
-     print(fx.get_plan())
-     final_fl_model = fx.run_experiment(collaborators, {'aggregator.settings.rounds_to_train': 5})
-     final_fl_model.save_native('final_pytorch_model')
--- 0 ----
diff -crB --new-file ./openfl/tests/github/test_double_ws_export.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/test_double_ws_export.sh
*** ./openfl/tests/github/test_double_ws_export.sh	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/test_double_ws_export.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,143 ****
- set -e
- # Test the pipeline
- 
- TEMPLATE=${1:-'keras_cnn_mnist'}  # ['torch_cnn_mnist', 'keras_cnn_mnist']
- FED_WORKSPACE=${2:-'fed_work12345alpha81671'}   # This can be whatever unique directory name you want
- COL1=${3:-'one123dragons'}  # This can be any unique label (lowercase)
- COL2=${4:-'beta34unicorns'} # This can be any unique label (lowercase)
- 
- FQDN=${5:-$(hostname --all-fqdns | awk '{print $1}')}
- 
- COL1_DATA_PATH=1
- COL2_DATA_PATH=2
- 
- help() {
-     echo "Usage: test_hello_federation.sh TEMPLATE FED_WORKSPACE COL1 COL2 [OPTIONS]"
-     echo
-     echo "Options:"
-     echo "--rounds-to-train     rounds to train"
-     echo "--col1-data-path      data path for collaborator 1"
-     echo "--col2-data-path      data path for collaborator 2"
-     echo "-h, --help            display this help and exit"
- }
- 
- # Getting additional options
- ADD_OPTS=$(getopt -o "h" -l "rounds-to-train:,col1-data-path:,
- col2-data-path:,help" -n test_hello_federation.sh -- "$@")
- eval set -- "$ADD_OPTS"
- while (($#)); do
-     case "${1:-}" in
-     (--rounds-to-train) ROUNDS_TO_TRAIN="$2" ; shift 2 ;;
-     (--col1-data-path) COL1_DATA_PATH="$2" ; shift 2 ;;
-     (--col2-data-path) COL2_DATA_PATH="$2" ; shift 2 ;;
-     (-h|--help) help ; exit 0 ;;
- 
-     (--)        shift ; break ;;
-     (*)         echo "Invalid option: ${1:-}"; exit 1 ;;
-     esac
- done
- 
- 
- create_collaborator() {
- 
-     FED_WORKSPACE=$1
-     FED_DIRECTORY=$2
-     COL=$3
-     COL_DIRECTORY=$4
-     DATA_PATH=$5
- 
-     ARCHIVE_NAME="${FED_WORKSPACE}.zip"
- 
-     # Copy workspace to collaborator directories (these can be on different machines)
-     rm -rf ${COL_DIRECTORY}    # Remove any existing directory
-     mkdir -p ${COL_DIRECTORY}  # Create a new directory for the collaborator
-     cd ${COL_DIRECTORY}
-     fx workspace import --archive ${FED_DIRECTORY}/${ARCHIVE_NAME} # Import the workspace to this collaborator
- 
-     # Create collaborator certificate request
-     cd ${COL_DIRECTORY}/${FED_WORKSPACE}
-     fx collaborator generate-cert-request -d ${DATA_PATH} -n ${COL} --silent # Remove '--silent' if you run this manually
- 
-     # Sign collaborator certificate 
-     cd ${FED_DIRECTORY}  # Move back to the Aggregator
-     fx collaborator certify --request-pkg ${COL_DIRECTORY}/${FED_WORKSPACE}/col_${COL}_to_agg_cert_request.zip --silent # Remove '--silent' if you run this manually
- 
-     #Import the signed certificate from the aggregator
-     cd ${COL_DIRECTORY}/${FED_WORKSPACE}
-     fx collaborator certify --import ${FED_DIRECTORY}/agg_to_col_${COL}_signed_cert.zip
- 
- }
- 
- # START
- # =====
- # Make sure you are in a Python virtual environment with the FL package installed.
- 
- # Create FL workspace
- rm -rf ${FED_WORKSPACE}
- fx workspace create --prefix ${FED_WORKSPACE} --template ${TEMPLATE}
- cd ${FED_WORKSPACE}
- FED_DIRECTORY=`pwd`  # Get the absolute directory path for the workspace
- 
- # Initialize FL plan
- fx plan initialize -a ${FQDN}
- 
- # Set rounds to train if given
- if [[ ! -z "$ROUNDS_TO_TRAIN" ]]
- then
-     sed -i "/rounds_to_train/c\    rounds_to_train: $ROUNDS_TO_TRAIN" plan/plan.yaml
- fi
- 
- # Create certificate authority for workspace
- fx workspace certify
- 
- # Export FL workspace
- fx workspace export
- 
- # Create aggregator certificate
- fx aggregator generate-cert-request --fqdn ${FQDN}
- 
- # Sign aggregator certificate
- fx aggregator certify --fqdn ${FQDN} --silent # Remove '--silent' if you run this manually
- 
- # Create collaborator #1
- COL1_DIRECTORY=${FED_DIRECTORY}/${COL1}
- create_collaborator ${FED_WORKSPACE} ${FED_DIRECTORY} ${COL1} ${COL1_DIRECTORY} ${COL1_DATA_PATH}
- 
- # # Run the federation
- cd ${FED_DIRECTORY}
- fx aggregator start & 
- sleep 5 
- cd ${COL1_DIRECTORY}/${FED_WORKSPACE}
- fx collaborator start -n ${COL1} & 
- wait
- 
- # # The second run. 
- # Imagine some parameters changed so we want to run
- # the Federation again from the same folder
- 
- # do the cleaning
- rm -rf ${COL1_DIRECTORY} && if pgrep fx; then pkill fx; fi
- 
- cd ${FED_DIRECTORY}
- # Initialize FL plan
- fx plan initialize -a ${FQDN}
- # Create certificate authority for workspace
- fx workspace certify
- # Export FL workspace
- fx workspace export
- # Create aggregator certificate
- fx aggregator generate-cert-request --fqdn ${FQDN}
- # Sign aggregator certificate
- fx aggregator certify --fqdn ${FQDN} --silent # Remove '--silent' if you run this 
- # Create collaborator #1
- create_collaborator ${FED_WORKSPACE} ${FED_DIRECTORY} ${COL1} ${COL1_DIRECTORY} ${COL1_DATA_PATH}
- 
- # # Run the federation
- cd ${FED_DIRECTORY}
- fx aggregator start & 
- sleep 5 
- cd ${COL1_DIRECTORY}/${FED_WORKSPACE}
- fx collaborator start -n ${COL1} & 
- wait
- 
- rm -rf ${FED_DIRECTORY}
--- 0 ----
diff -crB --new-file ./openfl/tests/github/test_graminize.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/test_graminize.sh
*** ./openfl/tests/github/test_graminize.sh	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/test_graminize.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,142 ****
- set -euxo pipefail
- # Test the pipeline
- # =========== Set SGX_RUN variable to 0 or 1 ============
- 
- SGX_RUN=${1:-1} # Pass 0 for no-sgx run (gramine-direct)
- REBUILD_IMAGES=${2:-0} # Pass 1 to build images with `--no-cache` option
- TEMPLATE=${3:-'torch_unet_kvasir_gramine_ready'}  # ['torch_cnn_histology_gramine_ready', 'keras_nlp_gramine_ready']
- FED_WORKSPACE=${4:-'fed_gramine'}   # This can be whatever unique directory name you want
- COL1=${5:-'one'}  # This can be any unique label (lowercase)
- COL2=${6:-'two'} # This can be any unique label (lowercase)
- 
- FQDN=localhost
- # FQDN=${6:-$(hostname --all-fqdns | awk '{print $1}')}
- 
- COL1_DATA_PATH=1
- COL2_DATA_PATH=2
- 
- # START
- # =====
- # Make sure you are in a Python virtual environment with the FL package installed.
- 
- # Create FL workspace
- rm -rf ${FED_WORKSPACE}
- fx workspace create --prefix ${FED_WORKSPACE} --template ${TEMPLATE}
- cd ${FED_WORKSPACE}
- FED_DIRECTORY=`pwd`  # Get the absolute directory path for the workspace
- 
- # Initialize FL plan
- fx plan initialize -a ${FQDN}
- 
- openssl genrsa -3 -out ${FED_DIRECTORY}/key.pem 3072
- 
- # Build graminized app image
- if [ $REBUILD_IMAGES -gt 0 ]
- then
- fx workspace graminize -s ${FED_DIRECTORY}/key.pem --no-save --rebuild
- else
- fx workspace graminize -s ${FED_DIRECTORY}/key.pem --no-save
- fi
- 
- # CERTIFICATION PART------------------------------
- # ================================================
- create_collaborator() {
- 
-     FED_WORKSPACE=$1
-     FED_DIRECTORY=$2
-     COL=$3
-     COL_DIRECTORY=$4
-     DATA_PATH=$5
- 
-     ARCHIVE_NAME="${FED_WORKSPACE}.zip"
- 
-     # Copy workspace to collaborator directories (these can be on different machines)
-     rm -rf ${COL_DIRECTORY}    # Remove any existing directory
-     mkdir -p ${COL_DIRECTORY}  # Create a new directory for the collaborator
-     cd ${COL_DIRECTORY}
-     fx workspace import --archive ${FED_DIRECTORY}/${ARCHIVE_NAME} # Import the workspace to this collaborator
- 
-     # Create collaborator certificate request
-     cd ${COL_DIRECTORY}/${FED_WORKSPACE}
-     fx collaborator generate-cert-request -d ${DATA_PATH} -n ${COL} --silent # Remove '--silent' if you run this manually
- 
-     # Sign collaborator certificate 
-     cd ${FED_DIRECTORY}  # Move back to the Aggregator
-     fx collaborator certify --request-pkg ${COL_DIRECTORY}/${FED_WORKSPACE}/col_${COL}_to_agg_cert_request.zip --silent # Remove '--silent' if you run this manually
- 
-     #Import the signed certificate from the aggregator
-     cd ${COL_DIRECTORY}/${FED_WORKSPACE}
-     fx collaborator certify --import ${FED_DIRECTORY}/agg_to_col_${COL}_signed_cert.zip
- 
-     cp -r ${FED_DIRECTORY}/data ${COL_DIRECTORY}/${FED_WORKSPACE}
- 
- }
- # Create certificate authority for workspace
- fx workspace certify
- 
- # Create aggregator certificate
- fx aggregator generate-cert-request --fqdn ${FQDN}
- 
- # Sign aggregator certificate
- fx aggregator certify --fqdn ${FQDN} --silent # Remove '--silent' if you run this manually
- 
- # Create collaborator #1
- COL1_DIRECTORY=${FED_DIRECTORY}/${COL1}
- create_collaborator ${FED_WORKSPACE} ${FED_DIRECTORY} ${COL1} ${COL1_DIRECTORY} ${COL1_DATA_PATH}
- 
- # Create collaborator #2
- COL2_DIRECTORY=${FED_DIRECTORY}/${COL2}
- create_collaborator ${FED_WORKSPACE} ${FED_DIRECTORY} ${COL2} ${COL2_DIRECTORY} ${COL2_DATA_PATH}
- 
- # CERTIFICATION PART ENDS-------------------------
- # ================================================
- 
- # # Run the federation
- cd ${FED_DIRECTORY}
- 
- RUN_START="docker run --rm --detach "
- if [ $SGX_RUN -gt 0 ]
- then
- RUN_START=${RUN_START}"--device=/dev/sgx_enclave --volume=/var/run/aesmd/aesm.socket:/var/run/aesmd/aesm.socket"
- else
- RUN_START=${RUN_START}"--security-opt seccomp=unconfined -e GRAMINE_EXECUTABLE=gramine-direct"
- fi
- 
- # fx aggregator start & 
- $RUN_START \
- --network=host --name Aggregator \
- --volume=${FED_DIRECTORY}/cert:/workspace/cert \
- --volume=${FED_DIRECTORY}/logs:/workspace/logs \
- --volume=${FED_DIRECTORY}/plan/cols.yaml:/workspace/plan/cols.yaml \
- --mount type=bind,src=${FED_DIRECTORY}/save,dst=/workspace/save,readonly=0 \
- ${FED_WORKSPACE} aggregator start
- 
- sleep 5 
- 
- # cd ${COL1_DIRECTORY}/${FED_WORKSPACE}
- # fx collaborator start -n ${COL1} & 
- $RUN_START \
- --network=host --name ${COL1} \
- --volume=${COL1_DIRECTORY}/${FED_WORKSPACE}/cert:/workspace/cert \
- --volume=${COL1_DIRECTORY}/${FED_WORKSPACE}/plan/data.yaml:/workspace/plan/data.yaml \
- --volume=${COL1_DIRECTORY}/${FED_WORKSPACE}/data:/workspace/data \
- ${FED_WORKSPACE} collaborator start -n ${COL1}
- 
- # cd ${COL2_DIRECTORY}/${FED_WORKSPACE}
- # fx collaborator start -n ${COL2}
- $RUN_START \
- --network=host --name ${COL2} \
- --volume=${COL2_DIRECTORY}/${FED_WORKSPACE}/cert:/workspace/cert \
- --volume=${COL2_DIRECTORY}/${FED_WORKSPACE}/plan/data.yaml:/workspace/plan/data.yaml \
- --volume=${COL2_DIRECTORY}/${FED_WORKSPACE}/data:/workspace/data \
- ${FED_WORKSPACE} collaborator start -n ${COL2}
- 
- # tail -f `docker inspect --format='{{.LogPath}}' Aggregator`
- docker logs --follow Aggregator &
- docker logs --follow ${COL1} &
- docker logs --follow ${COL2}
- 
- wait
- 
- docker stop Aggregator ${COL1} ${COL2}
- # rm -rf ${FED_DIRECTORY}
--- 0 ----
diff -crB --new-file ./openfl/tests/github/test_hello_federation.sh ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/test_hello_federation.sh
*** ./openfl/tests/github/test_hello_federation.sh	2022-11-18 11:08:33.047181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/github/test_hello_federation.sh	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,120 ****
- set -e
- # Test the pipeline
- 
- TEMPLATE=${1:-'keras_cnn_mnist'}  # ['torch_cnn_mnist', 'keras_cnn_mnist']
- FED_WORKSPACE=${2:-'fed_work12345alpha81671'}   # This can be whatever unique directory name you want
- COL1=${3:-'one123dragons'}  # This can be any unique label (lowercase)
- COL2=${4:-'beta34unicorns'} # This can be any unique label (lowercase)
- 
- FQDN=${5:-$(hostname --all-fqdns | awk '{print $1}')}
- 
- COL1_DATA_PATH=1
- COL2_DATA_PATH=2
- 
- help() {
-     echo "Usage: test_hello_federation.sh TEMPLATE FED_WORKSPACE COL1 COL2 [OPTIONS]"
-     echo
-     echo "Options:"
-     echo "--rounds-to-train     rounds to train"
-     echo "--col1-data-path      data path for collaborator 1"
-     echo "--col2-data-path      data path for collaborator 2"
-     echo "-h, --help            display this help and exit"
- }
- 
- # Getting additional options
- ADD_OPTS=$(getopt -o "h" -l "rounds-to-train:,col1-data-path:,
- col2-data-path:,help" -n test_hello_federation.sh -- "$@")
- eval set -- "$ADD_OPTS"
- while (($#)); do
-     case "${1:-}" in
-     (--rounds-to-train) ROUNDS_TO_TRAIN="$2" ; shift 2 ;;
-     (--col1-data-path) COL1_DATA_PATH="$2" ; shift 2 ;;
-     (--col2-data-path) COL2_DATA_PATH="$2" ; shift 2 ;;
-     (-h|--help) help ; exit 0 ;;
- 
-     (--)        shift ; break ;;
-     (*)         echo "Invalid option: ${1:-}"; exit 1 ;;
-     esac
- done
- 
- 
- 
- create_collaborator() {
- 
-     FED_WORKSPACE=$1
-     FED_DIRECTORY=$2
-     COL=$3
-     COL_DIRECTORY=$4
-     DATA_PATH=$5
- 
-     ARCHIVE_NAME="${FED_WORKSPACE}.zip"
- 
-     # Copy workspace to collaborator directories (these can be on different machines)
-     rm -rf ${COL_DIRECTORY}    # Remove any existing directory
-     mkdir -p ${COL_DIRECTORY}  # Create a new directory for the collaborator
-     cd ${COL_DIRECTORY}
-     fx workspace import --archive ${FED_DIRECTORY}/${ARCHIVE_NAME} # Import the workspace to this collaborator
- 
-     # Create collaborator certificate request
-     cd ${COL_DIRECTORY}/${FED_WORKSPACE}
-     fx collaborator generate-cert-request -d ${DATA_PATH} -n ${COL} --silent # Remove '--silent' if you run this manually
- 
-     # Sign collaborator certificate 
-     cd ${FED_DIRECTORY}  # Move back to the Aggregator
-     fx collaborator certify --request-pkg ${COL_DIRECTORY}/${FED_WORKSPACE}/col_${COL}_to_agg_cert_request.zip --silent # Remove '--silent' if you run this manually
- 
-     #Import the signed certificate from the aggregator
-     cd ${COL_DIRECTORY}/${FED_WORKSPACE}
-     fx collaborator certify --import ${FED_DIRECTORY}/agg_to_col_${COL}_signed_cert.zip
- 
- }
- 
- # START
- # =====
- # Make sure you are in a Python virtual environment with the FL package installed.
- 
- # Create FL workspace
- rm -rf ${FED_WORKSPACE}
- fx workspace create --prefix ${FED_WORKSPACE} --template ${TEMPLATE}
- cd ${FED_WORKSPACE}
- FED_DIRECTORY=`pwd`  # Get the absolute directory path for the workspace
- 
- # Initialize FL plan
- fx plan initialize -a ${FQDN}
- 
- # Set rounds to train if given
- if [[ ! -z "$ROUNDS_TO_TRAIN" ]]
- then
-     sed -i "/rounds_to_train/c\    rounds_to_train: $ROUNDS_TO_TRAIN" plan/plan.yaml
- fi
- 
- # Create certificate authority for workspace
- fx workspace certify
- 
- # Export FL workspace
- fx workspace export
- 
- # Create aggregator certificate
- fx aggregator generate-cert-request --fqdn ${FQDN}
- 
- # Sign aggregator certificate
- fx aggregator certify --fqdn ${FQDN} --silent # Remove '--silent' if you run this manually
- 
- # Create collaborator #1
- COL1_DIRECTORY=${FED_DIRECTORY}/${COL1}
- create_collaborator ${FED_WORKSPACE} ${FED_DIRECTORY} ${COL1} ${COL1_DIRECTORY} ${COL1_DATA_PATH}
- 
- # Create collaborator #2
- COL2_DIRECTORY=${FED_DIRECTORY}/${COL2}
- create_collaborator ${FED_WORKSPACE} ${FED_DIRECTORY} ${COL2} ${COL2_DIRECTORY} ${COL2_DATA_PATH}
- 
- # # Run the federation
- cd ${FED_DIRECTORY}
- fx aggregator start & 
- sleep 5 
- cd ${COL1_DIRECTORY}/${FED_WORKSPACE}
- fx collaborator start -n ${COL1} & 
- cd ${COL2_DIRECTORY}/${FED_WORKSPACE}
- fx collaborator start -n ${COL2}
- wait
- rm -rf ${FED_DIRECTORY}
--- 0 ----
diff -crB --new-file ./openfl/tests/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/__init__.py
*** ./openfl/tests/__init__.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Tests package."""
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/api_layer/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/api_layer/__init__.py
*** ./openfl/tests/openfl/api_layer/__init__.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/api_layer/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """tests.openfl.ap_layer package."""
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/api_layer/test_experiment.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/api_layer/test_experiment.py
*** ./openfl/tests/openfl/api_layer/test_experiment.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/api_layer/test_experiment.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,32 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Experiment API tests module."""
- 
- import pytest
- 
- from openfl.interface.interactive_api.experiment import FLExperiment
- from .test_federation import federation_object  # NOQA
- # TaskInterface, DataInterface, ModelInterface,
- 
- EXPERIMENT_MAME = 'test experiment'
- 
- 
- @pytest.fixture
- def experiment_object(federation_object):  # NOQA
-     """Experiment object fixture."""
-     experiment_object = FLExperiment(
-         federation=federation_object,
-         experiment_name=EXPERIMENT_MAME)
-     return experiment_object
- 
- 
- def test_initialization(experiment_object):
-     """Test experimnet object initialization."""
-     assert not experiment_object.experiment_accepted
-     assert experiment_object.serializer_plugin
- 
- 
- def test_get_best_model(experiment_object):
-     """Test get_best_model method."""
-     with pytest.raises(Exception):
-         experiment_object.get_best_model()
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/api_layer/test_federation.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/api_layer/test_federation.py
*** ./openfl/tests/openfl/api_layer/test_federation.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/api_layer/test_federation.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,39 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Federation API tests module."""
- 
- from unittest import mock
- 
- import pytest
- 
- from openfl.interface.interactive_api.federation import Federation
- 
- CLIENT_ID = 'id test'
- SAMPLE_SHAPE = (10, 10, 3)
- TARGET_SHAPE = (2,)
- 
- 
- @pytest.fixture
- @mock.patch('openfl.interface.interactive_api.federation.DirectorClient')
- def federation_object(mock_client_class):
-     """Federation object fixture."""
-     mock_client_instance = mock.Mock()
-     mock_client_class.return_value = mock_client_instance
-     mock_client_instance.get_dataset_info.return_value = (SAMPLE_SHAPE, TARGET_SHAPE)
-     return Federation(client_id=CLIENT_ID)
- 
- 
- def test_federation_initialization(federation_object):
-     """Test Federation initialization."""
-     assert federation_object.sample_shape == SAMPLE_SHAPE
-     assert federation_object.target_shape == TARGET_SHAPE
-     federation_object.dir_client.get_dataset_info.assert_called_once()
- 
- 
- def test_dummy_shard_descriptor(federation_object):
-     """Test dummy shard descriptor object."""
-     dummy_shard_desc = federation_object.get_dummy_shard_descriptor(10)
-     dummy_shard_dataset = dummy_shard_desc.get_dataset('')
-     sample, target = dummy_shard_dataset[0]
-     assert sample.shape == SAMPLE_SHAPE
-     assert target.shape == TARGET_SHAPE
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/communication/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/communication/__init__.py
*** ./openfl/tests/openfl/communication/__init__.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/communication/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """tests.openfl.communication package."""
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/communication/test_api_client.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/communication/test_api_client.py
*** ./openfl/tests/openfl/communication/test_api_client.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/communication/test_api_client.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,61 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Derector API's client tests module."""
- 
- import sys
- from unittest import mock
- 
- import pytest
- 
- from openfl.protocols import director_pb2
- from openfl.transport.grpc.director_client import DirectorClient
- 
- 
- @pytest.fixture
- @mock.patch('openfl.transport.grpc.director_client.director_pb2_grpc')
- def director_client(director_pb2_grpc):
-     """Director client fixture."""
-     director_pb2_grpc.DirectorStub.return_value = mock.Mock()
- 
-     client_id = 'one'
-     director_host = 'localhost'
-     director_port = 50051
-     tls = False
-     root_certificate, private_key, certificate = None, None, None
-     director_client = DirectorClient(
-         director_host=director_host,
-         director_port=director_port,
-         client_id=client_id,
-         tls=tls,
-         root_certificate=root_certificate,
-         private_key=private_key,
-         certificate=certificate
-     )
-     return director_client
- 
- 
- def test_get_dataset_info(director_client):
-     """Test get_dataset_info RPC."""
-     director_client.get_dataset_info()
-     director_client.stub.GetDatasetInfo.assert_called_once()
- 
- 
- @pytest.mark.parametrize(
-     'clients_method,model_type', [
-         ('get_best_model', 'BEST_MODEL'),
-         ('get_last_model', 'LAST_MODEL'),
-     ])
- @mock.patch('openfl.transport.grpc.director_client.deconstruct_model_proto')
- def test_get_best_model(deconstruct_model_proto, director_client,
-                         clients_method, model_type):
-     """Test get_best_model RPC."""
-     deconstruct_model_proto.return_value = {}, {}
-     getattr(director_client, clients_method)('test name')
-     director_client.stub.GetTrainedModel.assert_called_once()
- 
-     request = director_client.stub.GetTrainedModel.call_args
-     if sys.version_info < (3, 8):
-         incoming_model_type = request[0][0].model_type
-     else:
-         incoming_model_type = request.args[0].model_type
-     assert incoming_model_type == getattr(director_pb2.GetTrainedModelRequest, model_type)
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/communication/test_envoys_client.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/communication/test_envoys_client.py
*** ./openfl/tests/openfl/communication/test_envoys_client.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/communication/test_envoys_client.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,54 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Derector Envoy's client tests module."""
- 
- import sys
- from unittest import mock
- 
- import pytest
- 
- from openfl.transport.grpc.director_client import ShardDirectorClient
- 
- 
- @pytest.fixture
- @mock.patch('openfl.transport.grpc.director_client.director_pb2_grpc')
- def director_client(director_pb2_grpc):
-     """Director client fixture."""
-     director_pb2_grpc.DirectorStub.return_value = mock.Mock()
- 
-     director_host = 'fqdn'
-     director_port = 50051
-     shard_name = 'test shard'
-     tls = False
-     root_certificate, private_key, certificate = None, None, None
-     director_client = ShardDirectorClient(
-         director_host=director_host,
-         director_port=director_port,
-         shard_name=shard_name,
-         tls=tls,
-         root_certificate=root_certificate,
-         private_key=private_key,
-         certificate=certificate,
-     )
-     return director_client
- 
- 
- def test_report_shard_info(director_client):
-     """Test report_shard_info RPC."""
-     shard_descriptor = mock.MagicMock()
-     shard_descriptor.dataset_description = 'description'
-     shard_descriptor.__len__.return_value = 10
-     shard_descriptor.sample_shape = [str(dim) for dim in (1, 2)]
-     shard_descriptor.target_shape = [str(dim) for dim in (10,)]
- 
-     cuda_devices = ()
- 
-     director_client.report_shard_info(shard_descriptor, cuda_devices)
- 
-     director_client.stub.UpdateShardInfo.assert_called_once()
-     if sys.version_info < (3, 8):
-         resp = director_client.stub.UpdateShardInfo.call_args[0][0]
-     else:
-         resp = director_client.stub.UpdateShardInfo.call_args.args[0]
-     assert resp.shard_info.shard_description == shard_descriptor.dataset_description
-     assert resp.shard_info.sample_shape == shard_descriptor.sample_shape
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/component/aggregator/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/component/aggregator/__init__.py
*** ./openfl/tests/openfl/component/aggregator/__init__.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/component/aggregator/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """tests.openfl.component.aggregator package."""
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/component/aggregator/test_aggregator.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/component/aggregator/test_aggregator.py
*** ./openfl/tests/openfl/component/aggregator/test_aggregator.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/component/aggregator/test_aggregator.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,250 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Aggregator tests module."""
- 
- from unittest import mock
- 
- import pytest
- 
- from openfl.component import aggregator
- from openfl.component.assigner import Assigner
- from openfl.protocols import base_pb2
- from openfl.utilities import TaskResultKey
- 
- 
- @pytest.fixture
- def model():
-     """Initialize the model."""
-     model = base_pb2.ModelProto()
-     tensor = model.tensors.add()
-     tensor.name = 'test-tensor-name'
-     tensor.round_number = 0
-     tensor.lossless = True
-     tensor.report = True
-     tensor.tags.append('some_tag')
-     metadata = tensor.transformer_metadata.add()
-     metadata.int_to_float[1] = 1.
-     metadata.int_list.extend([1, 8])
-     metadata.bool_list.append(True)
-     tensor.data_bytes = 32 * b'1'
- 
-     return model
- 
- 
- @pytest.fixture()
- def assigner():
-     """Initialize the assigner."""
-     Assigner.define_task_assignments = mock.Mock()
-     assigner = Assigner(None, None, None)
-     assigner.define_task_assignments = mock.Mock()
-     return assigner
- 
- 
- @pytest.fixture
- def agg(mocker, model, assigner):
-     """Initialize the aggregator."""
-     mocker.patch('openfl.protocols.utils.load_proto', return_value=model)
-     agg = aggregator.Aggregator(
-         'some_uuid',
-         'federation_uuid',
-         ['col1', 'col2'],
- 
-         'init_state_path',
-         'best_state_path',
-         'last_state_path',
- 
-         assigner,
-     )
-     return agg
- 
- 
- @pytest.mark.parametrize(
-     'cert_common_name,collaborator_common_name,authorized_cols,single_cccn,expected_is_valid', [
-         ('col1', 'col1', ['col1', 'col2'], '', True),
-         ('col2', 'col2', ['col1', 'col2'], '', True),
-         ('col3', 'col3', ['col1', 'col2'], '', False),
-         ('col3', 'col3', ['col1', 'col2'], '', False),
-         ('col1', 'col2', ['col1', 'col2'], '', False),
-         ('col2', 'col1', ['col1', 'col2'], '', False),
-         ('col1', 'col1', [], '', False),
-         ('col1', 'col1', ['col1', 'col2'], 'col1', True),
-         ('col1', 'col1', ['col1', 'col2'], 'col2', False),
-         ('col3', 'col3', ['col1', 'col2'], 'col3', False),
-         ('col1', 'col1', ['col1', 'col2'], 'col3', False),
-     ])
- def test_valid_collaborator_cn_and_id(agg, cert_common_name, collaborator_common_name,
-                                       authorized_cols, single_cccn, expected_is_valid):
-     """Test that valid_collaborator_cn_and_id works correctly."""
-     ac = agg.authorized_cols
-     agg.authorized_cols = authorized_cols
-     agg.single_col_cert_common_name = single_cccn
-     is_valid = agg.valid_collaborator_cn_and_id(cert_common_name, collaborator_common_name)
-     agg.authorized_cols = ac
-     agg.single_col_cert_common_name = ''
- 
-     assert is_valid == expected_is_valid
- 
- 
- @pytest.mark.parametrize('quit_job_sent_to,authorized_cols,expected', [
-     (['col1', 'col2'], ['col1', 'col2'], True),
-     (['col1'], ['col1', 'col2'], False),
-     ([], [], True),
- ])
- def test_all_quit_jobs_sent(agg, quit_job_sent_to, authorized_cols, expected):
-     """Test that valid_collaborator_cn_and_id works correctly."""
-     ac = agg.authorized_cols
-     agg.authorized_cols = authorized_cols
-     agg.quit_job_sent_to = quit_job_sent_to
-     all_quit_jobs_sent = agg.all_quit_jobs_sent()
-     agg.authorized_cols = ac
-     agg.quit_job_sent_to = []
- 
-     assert all_quit_jobs_sent == expected
- 
- 
- def test_get_sleep_time(agg):
-     """Test that get_sleep_time returns 10."""
-     assert 10 == agg._get_sleep_time()
- 
- 
- @pytest.mark.parametrize('round_number,rounds_to_train,expected', [
-     (0, 10, False), (10, 10, True), (9, 10, False), (10, 0, True)
- ])
- def test_time_to_quit(agg, round_number, rounds_to_train, expected):
-     """Test that test_time_to_quit works correctly."""
-     rn = agg.round_number
-     rtt = agg.rounds_to_train
-     agg.round_number = round_number
-     agg.rounds_to_train = rounds_to_train
-     time_to_quit = agg._time_to_quit()
-     assert expected == time_to_quit
- 
-     agg.round_number = rn
-     agg.rounds_to_train = rtt
- 
- 
- @pytest.mark.parametrize(
-     'col_name,tasks,time_to_quit,exp_tasks,exp_sleep_time,exp_time_to_quit', [
-         ('col1', ['task_name'], True, None, 0, True),
-         ('col1', [], False, None, 10, False),
-         ('col1', ['task_name'], False, ['task_name'], 0, False),
-     ])
- def test_get_tasks(agg, col_name, tasks, time_to_quit,
-                    exp_tasks, exp_sleep_time, exp_time_to_quit):
-     """Test that test_get_tasks works correctly."""
-     agg.assigner.get_tasks_for_collaborator = mock.Mock(return_value=tasks)
-     agg._time_to_quit = mock.Mock(return_value=time_to_quit)
-     tasks, round_number, sleep_time, time_to_quit = agg.get_tasks('col1')
-     assert (tasks, sleep_time, time_to_quit) == (exp_tasks, exp_sleep_time, exp_time_to_quit)
- 
- 
- def test_get_aggregated_tensor(agg):
-     """Test that test_get_tasks is failed without a correspond data."""
-     collaborator_name = 'col1'
-     tensor_name = 'test_tensor_name'
-     require_lossless = False
-     round_number = 0
-     report = False
-     tags = ['compressed']
-     with pytest.raises(ValueError):
-         agg.get_aggregated_tensor(
-             collaborator_name, tensor_name, round_number, report, tags, require_lossless)
- 
- 
- def test_collaborator_task_completed_none(agg):
-     """Test that returns False if there are not collaborator tasks results."""
-     round_num = 0
-     is_completed = agg._collaborator_task_completed(
-         'col1', 'task_name', round_num)
-     assert is_completed is False
- 
- 
- def test_collaborator_task_completed_true(agg):
-     """Test that returns True if there are collaborator tasks results."""
-     round_num = 0
-     task_name = 'test_task_name'
-     col1 = 'one'
-     agg.collaborator_tasks_results = {
-         TaskResultKey(task_name, col1, round_num): 1
-     }
-     is_completed = agg._collaborator_task_completed(
-         col1, task_name, round_num)
- 
-     assert is_completed is True
- 
- 
- def test_is_task_done_no_cols(agg):
-     """Test that is_task_done returns True without corresponded collaborators."""
-     task_name = 'test_task_name'
-     agg.assigner.get_collaborators_for_task = mock.Mock(return_value=[])
-     is_task_done = agg._is_task_done(task_name)
- 
-     assert is_task_done is True
- 
- 
- def test_is_task_done_not_done(agg):
-     """Test that is_task_done returns False in the corresponded case."""
-     task_name = 'test_task_name'
-     col1 = 'one'
-     col2 = 'two'
-     agg.assigner.get_collaborators_for_task = mock.Mock(return_value=[col1, col2])
-     is_task_done = agg._is_task_done(task_name)
- 
-     assert is_task_done is False
- 
- 
- def test_is_task_done_done(agg):
-     """Test that is_task_done returns True in the corresponded case."""
-     round_num = 0
-     task_name = 'test_task_name'
-     col1 = 'one'
-     col2 = 'two'
-     agg.assigner.get_collaborators_for_task = mock.Mock(return_value=[col1, col2])
-     agg.collaborator_tasks_results = {
-         TaskResultKey(task_name, col1, round_num): 1,
-         TaskResultKey(task_name, col2, round_num): 1
-     }
-     is_task_done = agg._is_task_done(task_name)
- 
-     assert is_task_done is True
- 
- 
- def test_is_round_done_no_tasks(agg):
-     """Test that is_round_done returns True in the corresponded case."""
-     agg.assigner.get_all_tasks_for_round = mock.Mock(return_value=[])
-     is_round_done = agg._is_round_done()
- 
-     assert is_round_done is True
- 
- 
- def test_is_round_done_not_done(agg):
-     """Test that is_round_done returns False in the corresponded case."""
-     round_num = 0
-     task_name = 'test_task_name'
-     col1 = 'one'
-     col2 = 'two'
-     agg.assigner.get_all_tasks_for_round = mock.Mock(return_value=[task_name])
-     agg.assigner.get_collaborators_for_task = mock.Mock(return_value=[col1, col2])
-     agg.collaborator_tasks_results = {
-         TaskResultKey(task_name, col1, round_num): 1,
-     }
-     is_round_done = agg._is_round_done()
- 
-     assert is_round_done is False
- 
- 
- def test_is_round_done_done(agg):
-     """Test that is_round_done returns True in the corresponded case."""
-     round_num = 0
-     task_name = 'test_task_name'
-     col1 = 'one'
-     col2 = 'two'
-     agg.assigner.get_all_tasks_for_round = mock.Mock(return_value=[task_name])
-     agg.assigner.get_collaborators_for_task = mock.Mock(return_value=[col1, col2])
-     agg.collaborator_tasks_results = {
-         TaskResultKey(task_name, col1, round_num): 1,
-         TaskResultKey(task_name, col2, round_num): 1
-     }
-     is_round_done = agg._is_round_done()
- 
-     assert is_round_done is True
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/component/assigner/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/component/assigner/__init__.py
*** ./openfl/tests/openfl/component/assigner/__init__.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/component/assigner/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """tests.openfl.component.assigner package."""
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/component/assigner/test_assigner.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/component/assigner/test_assigner.py
*** ./openfl/tests/openfl/component/assigner/test_assigner.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/component/assigner/test_assigner.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,51 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Assigner tests module."""
- 
- from unittest import mock
- 
- import pytest
- 
- from openfl.component.assigner import Assigner
- 
- 
- @pytest.fixture()
- def assigner():
-     """Initialize the assigner."""
-     assigner = Assigner
-     assigner.define_task_assignments = mock.Mock()
-     return assigner
- 
- 
- def test_get_aggregation_type_for_task_none(assigner):
-     """Assert that aggregation type of custom task is None."""
-     task_name = 'test_name'
-     tasks = {task_name: {}}
- 
-     assigner = assigner(tasks, None, None)
- 
-     aggregation_type = assigner.get_aggregation_type_for_task(task_name)
- 
-     assert aggregation_type is None
- 
- 
- def test_get_aggregation_type_for_task(assigner):
-     """Assert that aggregation type of task is getting correctly."""
-     task_name = 'test_name'
-     test_aggregation_type = 'test_aggregation_type'
-     tasks = {task_name: {
-         'aggregation_type': test_aggregation_type
-     }}
-     assigner = assigner(tasks, None, None)
- 
-     aggregation_type = assigner.get_aggregation_type_for_task(task_name)
- 
-     assert aggregation_type == test_aggregation_type
- 
- 
- def test_get_all_tasks_for_round(assigner):
-     """Assert that assigner tasks object is list."""
-     assigner = Assigner(None, None, None)
-     tasks = assigner.get_all_tasks_for_round('test')
- 
-     assert isinstance(tasks, list)
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/component/assigner/test_custom_assigner.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/component/assigner/test_custom_assigner.py
*** ./openfl/tests/openfl/component/assigner/test_custom_assigner.py	2022-11-18 11:08:33.047181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/component/assigner/test_custom_assigner.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,102 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """CustomAssigner tests."""
- 
- from unittest import mock
- 
- import pytest
- 
- from openfl.component.aggregation_functions import GeometricMedian
- from openfl.component.aggregation_functions import WeightedAverage
- from openfl.component.assigner.custom_assigner import Assigner
- from openfl.component.assigner.tasks import TrainTask
- from openfl.component.assigner.tasks import ValidateTask
- 
- 
- default_tasks = [
-     TrainTask(
-         name='train',
-         function_name='train_func',
-     ),
-     ValidateTask(
-         name='locally_tuned_model_validate',
-         function_name='validate',
-         apply_local=True,
-     ),
-     ValidateTask(
-         name='aggregated_model_validate',
-         function_name='validate',
-     ),
- ]
- 
- 
- def assigner_function(collaborators, round_number, **kwargs):
-     """Return tasks by collaborator."""
-     tasks_by_collaborator = {}
-     for collaborator in collaborators:
-         tasks_by_collaborator[collaborator] = default_tasks
-     return tasks_by_collaborator
- 
- 
- @pytest.fixture()
- def assigner():
-     """Return Assigner fixture."""
-     assigner = Assigner(
-         assigner_function=assigner_function,
-         aggregation_functions_by_task={
-             'train_func': GeometricMedian()
-         },
-         authorized_cols=['one', 'two'],
-         rounds_to_train=10,
-     )
-     assigner.define_task_assignments = mock.Mock()
-     return assigner
- 
- 
- def test_define_task_assignments(assigner):
-     """Test `define_task_assignments` is working."""
-     assigner.define_task_assignments()
- 
- 
- def test_get_tasks_for_collaborator(assigner):
-     """Test `get_tasks_for_collaborator` base working."""
-     tasks = assigner.get_tasks_for_collaborator('one', 2)
- 
-     assert tasks == default_tasks
-     assert len(tasks) == 3
-     assert isinstance(tasks[0], TrainTask)
-     assert isinstance(tasks[1], ValidateTask)
- 
- 
- def test_get_collaborators_for_task(assigner):
-     """Test `get_collaborators_for_task` base working."""
-     collaborators = assigner.get_collaborators_for_task('train', 2)
- 
-     assert collaborators == ['one', 'two']
- 
- 
- def test_get_all_tasks_for_round(assigner):
-     """Test `get_all_tasks_for_round` base working."""
-     all_tasks = assigner.get_all_tasks_for_round(2)
- 
-     assert all_tasks == [task.name for task in default_tasks]
- 
- 
- def test_get_aggregation_type_for_task(assigner):
-     """Test `get_aggregation_type_for_task` base working."""
-     agg_fn = assigner.get_aggregation_type_for_task('train')
- 
-     assert isinstance(agg_fn, GeometricMedian)
- 
- 
- def test_get_aggregation_type_for_task_by_default():
-     """Test get_aggregation_type_for_task working without assigned agg functions."""
-     assigner = Assigner(
-         assigner_function=assigner_function,
-         aggregation_functions_by_task={},
-         authorized_cols=['one', 'two'],
-         rounds_to_train=10,
-     )
-     agg_fn = assigner.get_aggregation_type_for_task('train')
- 
-     assert isinstance(agg_fn, WeightedAverage)
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/component/assigner/test_random_grouped_assigner.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/component/assigner/test_random_grouped_assigner.py
*** ./openfl/tests/openfl/component/assigner/test_random_grouped_assigner.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/component/assigner/test_random_grouped_assigner.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,67 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """RandomGroupedAssigner tests."""
- 
- import pytest
- 
- from openfl.component.assigner import RandomGroupedAssigner
- 
- ROUNDS_TO_TRAIN = 10
- 
- 
- @pytest.fixture
- def task_groups():
-     """Initialize task groups."""
-     task_groups = [
-         {
-             'name': 'train_and_validate',
-             'percentage': 1.0,
-             'tasks': [
-                 'aggregated_model_validation',
-                 'train',
-                 'locally_tuned_model_validation'
-             ]
-         }
-     ]
-     return task_groups
- 
- 
- @pytest.fixture
- def authorized_cols():
-     """Initialize authorized cols."""
-     return ['one', 'two']
- 
- 
- @pytest.fixture
- def assigner(task_groups, authorized_cols):
-     """Initialize assigner."""
-     assigner = RandomGroupedAssigner
- 
-     assigner = assigner(task_groups,
-                         tasks=None,
-                         authorized_cols=authorized_cols,
-                         rounds_to_train=ROUNDS_TO_TRAIN)
-     return assigner
- 
- 
- def test_define_task_assignments(assigner):
-     """Test `define_task_assignments` is working."""
-     assigner.define_task_assignments()
- 
- 
- @pytest.mark.parametrize('round_number', range(ROUNDS_TO_TRAIN))
- def test_get_tasks_for_collaborator(assigner, task_groups,
-                                     authorized_cols, round_number):
-     """Test that assigner tasks correspond to task groups defined."""
-     tasks = assigner.get_tasks_for_collaborator(
-         authorized_cols[0], round_number)
-     assert tasks == task_groups[0]['tasks']
- 
- 
- @pytest.mark.parametrize('round_number', range(ROUNDS_TO_TRAIN))
- def test_get_collaborators_for_task(
-         assigner, task_groups, round_number, authorized_cols):
-     """Check that assigner collaborators set is equal to authorized collaborators set."""
-     for task_name in task_groups[0]['tasks']:
-         cols = assigner.get_collaborators_for_task(task_name, round_number)
-         assert set(cols) == set(authorized_cols)
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/component/assigner/test_static_grouped_assigner.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/component/assigner/test_static_grouped_assigner.py
*** ./openfl/tests/openfl/component/assigner/test_static_grouped_assigner.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/component/assigner/test_static_grouped_assigner.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,68 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """StaticGroupedAssigner tests."""
- 
- import pytest
- 
- from openfl.component.assigner import StaticGroupedAssigner
- 
- ROUNDS_TO_TRAIN = 10
- 
- 
- @pytest.fixture
- def authorized_cols():
-     """Initialize authorized collaborator list."""
-     return ['one', 'two']
- 
- 
- @pytest.fixture
- def task_groups(authorized_cols):
-     """Initialize task groups."""
-     task_groups = [
-         {
-             'name': 'train_and_validate',
-             'percentage': 1.0,
-             'collaborators': authorized_cols,
-             'tasks': [
-                 'aggregated_model_validation',
-                 'train',
-                 'locally_tuned_model_validation'
-             ]
-         }
-     ]
-     return task_groups
- 
- 
- @pytest.fixture
- def assigner(task_groups, authorized_cols):
-     """Initialize assigner."""
-     assigner = StaticGroupedAssigner
- 
-     assigner = assigner(task_groups,
-                         tasks=None,
-                         authorized_cols=authorized_cols,
-                         rounds_to_train=ROUNDS_TO_TRAIN)
-     return assigner
- 
- 
- def test_define_task_assignments(assigner):
-     """Test that `define_task_assignments` is working."""
-     assigner.define_task_assignments()
- 
- 
- @pytest.mark.parametrize('round_number', range(ROUNDS_TO_TRAIN))
- def test_get_tasks_for_collaborator(assigner, task_groups,
-                                     authorized_cols, round_number):
-     """Assert assigner tasks correspond to task groups."""
-     tasks = assigner.get_tasks_for_collaborator(
-         authorized_cols[0], round_number)
-     assert tasks == task_groups[0]['tasks']
- 
- 
- @pytest.mark.parametrize('round_number', range(ROUNDS_TO_TRAIN))
- def test_get_collaborators_for_task(
-         assigner, task_groups, round_number, authorized_cols):
-     """Assert that assigner collaborators set is equal to authorized collaborator set defined."""
-     for task_name in task_groups[0]['tasks']:
-         cols = assigner.get_collaborators_for_task(task_name, round_number)
-         assert set(cols) == set(authorized_cols)
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/component/collaborator/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/component/collaborator/__init__.py
*** ./openfl/tests/openfl/component/collaborator/__init__.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/component/collaborator/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """tests.openfl.component.collaborator package."""
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/component/collaborator/test_collaborator.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/component/collaborator/test_collaborator.py
*** ./openfl/tests/openfl/component/collaborator/test_collaborator.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/component/collaborator/test_collaborator.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,236 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Collaborator tests module."""
- 
- from unittest import mock
- 
- import numpy
- import pytest
- 
- from openfl.component.collaborator import Collaborator
- from openfl.protocols import base_pb2
- from openfl.utilities.types import TensorKey
- 
- 
- @pytest.fixture
- def collaborator_mock():
-     """Initialize the collaborator mock."""
-     col = Collaborator('col1', 'some_uuid', 'federation_uuid',
-                        mock.Mock(), mock.Mock(), mock.Mock(), opt_treatment='RESET')
-     col.tensor_db = mock.Mock()
- 
-     return col
- 
- 
- @pytest.fixture
- def named_tensor():
-     """Initialize the named_tensor mock."""
-     tensor = base_pb2.NamedTensor(
-         name='tensor_name',
-         round_number=0,
-         lossless=False,
-         report=False,
-         data_bytes=32 * b'1'
-     )
-     tensor.tags.append('model')
-     metadata = tensor.transformer_metadata.add()
-     metadata.int_to_float[1] = 1.
-     metadata.int_list.extend([1, 8])
-     metadata.bool_list.append(True)
- 
-     return tensor
- 
- 
- @pytest.fixture
- def tensor_key(collaborator_mock, named_tensor):
-     """Initialize the tensor_key mock."""
-     tensor_key = TensorKey(
-         named_tensor.name,
-         collaborator_mock.collaborator_name,
-         named_tensor.round_number,
-         named_tensor.report,
-         tuple(named_tensor.tags)
-     )
-     return tensor_key
- 
- 
- @pytest.fixture
- def tensor_key_trained(collaborator_mock, named_tensor):
-     """Initialize the tensor_key_trained mock."""
-     named_tensor.tags.append('trained')
-     named_tensor.tags.remove('model')
-     tensor_key = TensorKey(
-         named_tensor.name,
-         collaborator_mock.collaborator_name,
-         named_tensor.round_number,
-         named_tensor.report,
-         tuple(named_tensor.tags)
-     )
-     return tensor_key
- 
- 
- def test_get_tasks(collaborator_mock):
-     """Test that get_tasks works correctly."""
-     results = (['task_name'], 0, 0, True)
-     collaborator_mock.client.get_tasks = mock.Mock(return_value=results)
-     tasks, round_number, sleep_time, time_to_quit = collaborator_mock.get_tasks()
-     assert results == (tasks, round_number, sleep_time, time_to_quit)
- 
- 
- def test_send_task_results(collaborator_mock):
-     """Test that send_task_results works correctly."""
-     task_name = 'task_name'
-     tensor_dict = {}
-     round_number = 0
-     data_size = -1
-     collaborator_mock.nparray_to_named_tensor = mock.Mock()
-     collaborator_mock.client.send_local_task_results = mock.Mock()
-     collaborator_mock.send_task_results(tensor_dict, round_number, task_name)
- 
-     collaborator_mock.client.send_local_task_results.assert_called_with(
-         collaborator_mock.collaborator_name, round_number, task_name, data_size, [])
- 
- 
- def test_send_task_results_train(collaborator_mock):
-     """Test that send_task_results for train tasks works correctly."""
-     task_name = 'train_task'
-     tensor_dict = {}
-     round_number = 0
-     data_size = 200
-     collaborator_mock.nparray_to_named_tensor = mock.Mock()
-     collaborator_mock.task_runner.get_train_data_size = mock.Mock(return_value=data_size)
-     collaborator_mock.client.send_local_task_results = mock.Mock()
-     collaborator_mock.send_task_results(tensor_dict, round_number, task_name)
- 
-     collaborator_mock.client.send_local_task_results.assert_called_with(
-         collaborator_mock.collaborator_name, round_number, task_name, data_size, [])
- 
- 
- def test_send_task_results_valid(collaborator_mock):
-     """Test that send_task_results for validation tasks works correctly."""
-     task_name = 'valid_task'
-     tensor_dict = {}
-     round_number = 0
-     data_size = 400
-     collaborator_mock.nparray_to_named_tensor = mock.Mock()
-     collaborator_mock.task_runner.get_valid_data_size = mock.Mock(return_value=data_size)
-     collaborator_mock.client.send_local_task_results = mock.Mock()
-     collaborator_mock.send_task_results(tensor_dict, round_number, task_name)
- 
-     collaborator_mock.client.send_local_task_results.assert_called_with(
-         collaborator_mock.collaborator_name, round_number, task_name, data_size, [])
- 
- 
- def test_named_tensor_to_nparray_without_tags(collaborator_mock, named_tensor):
-     """Test that named_tensor_to_nparray works correctly for tensor without tags."""
-     nparray = collaborator_mock.named_tensor_to_nparray(named_tensor)
- 
-     assert named_tensor.data_bytes == nparray
- 
- 
- @pytest.mark.parametrize('tag', ['compressed', 'lossy_compressed'])
- def test_named_tensor_to_nparray_compressed_tag(collaborator_mock, named_tensor, tag):
-     """Test that named_tensor_to_nparray works correctly for tensor with tags."""
-     named_tensor.tags.append(tag)
-     nparray = collaborator_mock.named_tensor_to_nparray(named_tensor)
- 
-     assert isinstance(nparray, numpy.ndarray)
- 
- 
- def test_nparray_to_named_tensor(collaborator_mock, tensor_key, named_tensor):
-     """Test that nparray_to_named_tensor works correctly."""
-     named_tensor.tags.append('compressed')
-     nparray = collaborator_mock.named_tensor_to_nparray(named_tensor)
-     tensor = collaborator_mock.nparray_to_named_tensor(tensor_key, nparray)
-     assert tensor.data_bytes == named_tensor.data_bytes
-     assert tensor.lossless is True
- 
- 
- def test_nparray_to_named_tensor_trained(collaborator_mock, tensor_key_trained, named_tensor):
-     """Test that nparray_to_named_tensor works correctly for trained tensor."""
-     named_tensor.tags.append('compressed')
-     collaborator_mock.delta_updates = True
-     nparray = collaborator_mock.named_tensor_to_nparray(named_tensor)
-     collaborator_mock.tensor_db.get_tensor_from_cache = mock.Mock(
-         return_value=nparray)
-     tensor = collaborator_mock.nparray_to_named_tensor(tensor_key_trained, nparray)
-     assert len(tensor.data_bytes) == 32
-     assert tensor.lossless is False
-     assert 'delta' in tensor.tags
- 
- 
- @pytest.mark.parametrize('require_lossless', [True, False])
- def test_get_aggregated_tensor_from_aggregator(collaborator_mock, tensor_key,
-                                                named_tensor, require_lossless):
-     """Test that get_aggregated_tensor works correctly."""
-     collaborator_mock.client.get_aggregated_tensor = mock.Mock(return_value=named_tensor)
-     nparray = collaborator_mock.get_aggregated_tensor_from_aggregator(tensor_key, require_lossless)
- 
-     collaborator_mock.client.get_aggregated_tensor.assert_called_with(
-         collaborator_mock.collaborator_name, tensor_key.tensor_name, tensor_key.round_number,
-         tensor_key.report, tensor_key.tags, require_lossless)
-     assert nparray == named_tensor.data_bytes
- 
- 
- def test_get_data_for_tensorkey_from_db(collaborator_mock, tensor_key):
-     """Test that get_data_for_tensorkey works correctly for data form db."""
-     expected_nparray = 'some_data'
-     collaborator_mock.tensor_db.get_tensor_from_cache = mock.Mock(
-         return_value='some_data')
-     nparray = collaborator_mock.get_data_for_tensorkey(tensor_key)
- 
-     assert nparray == expected_nparray
- 
- 
- def test_get_data_for_tensorkey(collaborator_mock, tensor_key):
-     """Test that get_data_for_tensorkey works correctly if data is not in db."""
-     collaborator_mock.tensor_db.get_tensor_from_cache = mock.Mock(
-         return_value=None)
-     collaborator_mock.get_aggregated_tensor_from_aggregator = mock.Mock()
-     collaborator_mock.get_data_for_tensorkey(tensor_key)
-     collaborator_mock.get_aggregated_tensor_from_aggregator.assert_called_with(
-         tensor_key, require_lossless=True)
- 
- 
- def test_get_numpy_dict_for_tensorkeys(collaborator_mock, tensor_key):
-     """Test that get_numpy_dict_for_tensorkeys works."""
-     expected_nparray = 'some_data'
-     collaborator_mock.tensor_db.get_tensor_from_cache = mock.Mock(
-         return_value='some_data')
-     numpy_dict = collaborator_mock.get_numpy_dict_for_tensorkeys([tensor_key])
- 
-     assert numpy_dict == {tensor_key.tensor_name: expected_nparray}
- 
- 
- def test_run_time_to_quit(collaborator_mock):
-     """Test that run works correctly if is time to quit."""
-     collaborator_mock.get_tasks = mock.Mock(return_value=([], 0, 0, True))
-     collaborator_mock.run()
- 
- 
- def test_run(collaborator_mock):
-     """Test that run works correctly."""
-     round_number = 0
-     collaborator_mock.get_tasks = mock.Mock()
-     collaborator_mock.get_tasks.side_effect = [(['task'], round_number, 0, False),
-                                                (['task'], round_number, 0, True)]
-     collaborator_mock.do_task = mock.Mock()
-     collaborator_mock.run()
-     collaborator_mock.do_task.assert_called_with('task', round_number)
- 
- 
- def test_run_simulation_time_to_quit(collaborator_mock):
-     """Test that run_simulation works correctly if is time to quit."""
-     round_number = 0
-     collaborator_mock.get_tasks = mock.Mock(return_value=([], round_number, 0, True))
-     collaborator_mock.run_simulation()
- 
- 
- def test_run_simulation(collaborator_mock):
-     """Test that run_simulation works correctly."""
-     round_number = 0
-     collaborator_mock.get_tasks = mock.Mock(return_value=(['task'], round_number, 0, False))
- 
-     collaborator_mock.do_task = mock.Mock()
-     collaborator_mock.run_simulation()
-     collaborator_mock.do_task.assert_called_with('task', round_number)
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/component/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/component/__init__.py
*** ./openfl/tests/openfl/component/__init__.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/component/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """tests.openfl.component package."""
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/databases/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/databases/__init__.py
*** ./openfl/tests/openfl/databases/__init__.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/databases/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """tests.openfl.databases package."""
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/databases/test_tensor_db.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/databases/test_tensor_db.py
*** ./openfl/tests/openfl/databases/test_tensor_db.py	2022-11-18 11:08:33.047181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/databases/test_tensor_db.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,228 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Collaborator tests module."""
- 
- import numpy as np
- import pytest
- 
- from openfl.component.aggregation_functions import AggregationFunction
- from openfl.component.aggregation_functions import WeightedAverage
- from openfl.databases.tensor_db import TensorDB
- from openfl.protocols import base_pb2
- from openfl.utilities.types import TensorKey
- 
- 
- @pytest.fixture
- def named_tensor():
-     """Initialize the named_tensor mock."""
-     tensor = base_pb2.NamedTensor(
-         name='tensor_name',
-         round_number=0,
-         lossless=False,
-         report=False,
-         data_bytes=32 * b'1'
-     )
-     metadata = tensor.transformer_metadata.add()
-     metadata.int_to_float[1] = 1.
-     metadata.int_list.extend([1, 8])
-     metadata.bool_list.append(True)
- 
-     return tensor
- 
- 
- @pytest.fixture
- def tensor_key(named_tensor):
-     """Initialize the tensor_key mock."""
-     tensor_key = TensorKey(
-         named_tensor.name,
-         'col1',
-         named_tensor.round_number,
-         named_tensor.report,
-         tuple(named_tensor.tags)
-     )
-     return tensor_key
- 
- 
- @pytest.fixture
- def nparray(named_tensor):
-     """Initialize the nparray."""
-     proto = named_tensor.transformer_metadata.pop()
-     metadata = {
-         'int_to_float': proto.int_to_float,
-         'int_list': proto.int_list,
-         'bool_list': proto.bool_list
-     }
-     array_shape = tuple(metadata['int_list'])
-     flat_array = np.frombuffer(named_tensor.data_bytes, dtype=np.float32)
- 
-     nparray = np.reshape(flat_array, newshape=array_shape, order='C')
- 
-     return nparray
- 
- 
- def test_cache_and_get_tensor(nparray, tensor_key):
-     """Test that cash and get work correctly."""
-     db = TensorDB()
-     db.cache_tensor({tensor_key: nparray})
-     cached_nparray = db.get_tensor_from_cache(tensor_key)
- 
-     assert np.array_equal(nparray, cached_nparray)
- 
- 
- def test_tensor_from_cache_empty(tensor_key):
-     """Test get works returns None if tensor key is not in the db."""
-     db = TensorDB()
-     cached_nparray = db.get_tensor_from_cache(tensor_key)
-     assert cached_nparray is None
- 
- 
- def test_clean_up(nparray, tensor_key):
-     """Test that clean_up remove old records."""
-     db = TensorDB()
- 
-     db.cache_tensor({tensor_key: nparray})
-     db.tensor_db['round'] = 2
-     db.clean_up()
-     cached_nparray = db.get_tensor_from_cache(tensor_key)
- 
-     assert cached_nparray is None
- 
- 
- def test_clean_up_not_old(nparray, tensor_key):
-     """Test that clean_up don't remove not old records."""
-     db = TensorDB()
- 
-     db.cache_tensor({tensor_key: nparray})
-     db.clean_up()
-     cached_nparray = db.get_tensor_from_cache(tensor_key)
- 
-     assert np.array_equal(nparray, cached_nparray)
- 
- 
- def test_clean_up_not_clean_up_with_negative_argument(nparray, tensor_key):
-     """Test that clean_up don't remove if records remove_older_than is negative."""
-     db = TensorDB()
- 
-     db.cache_tensor({tensor_key: nparray})
-     db.tensor_db['round'] = 2
-     db.clean_up(remove_older_than=-1)
-     db.tensor_db['round'] = 0
-     cached_nparray = db.get_tensor_from_cache(tensor_key)
- 
-     assert np.array_equal(nparray, cached_nparray)
- 
- 
- def test_get_aggregated_tensor_directly(nparray, tensor_key):
-     """Test that get_aggregated_tensor returns tensors directly."""
-     db = TensorDB()
-     db.cache_tensor({tensor_key: nparray})
-     tensor_name, origin, round_number, report, tags = tensor_key
-     tensor_key = TensorKey(
-         tensor_name, 'col2', round_number, report, ('model',)
-     )
- 
-     db.cache_tensor({tensor_key: nparray})
-     agg_nparray, agg_metadata_dict = db.get_aggregated_tensor(tensor_key, {}, WeightedAverage())
- 
-     assert np.array_equal(nparray, agg_nparray)
- 
- 
- def test_get_aggregated_tensor_only_col(nparray, tensor_key):
-     """Test that get_aggregated_tensor returns None if data presents for only collaborator."""
-     db = TensorDB()
-     db.cache_tensor({tensor_key: nparray})
-     tensor_name, origin, round_number, report, tags = tensor_key
-     tensor_key = TensorKey(
-         tensor_name, 'col2', round_number, report, ('model',)
-     )
- 
-     collaborator_weight_dict = {'col1': 0.5, 'col2': 0.5}
-     agg_nparray = db.get_aggregated_tensor(
-         tensor_key, collaborator_weight_dict, WeightedAverage())
- 
-     assert agg_nparray is None
- 
- 
- def test_get_aggregated_tensor(nparray, tensor_key):
-     """Test that get_aggregated_tensor returns tensors directly."""
-     db = TensorDB()
-     db.cache_tensor({tensor_key: nparray})
-     tensor_name, origin, round_number, report, tags = tensor_key
-     tensor_key = TensorKey(
-         tensor_name, 'col2', round_number, report, ('model',)
-     )
-     db.cache_tensor({tensor_key: nparray})
- 
-     collaborator_weight_dict = {'col1': 0.5, 'col2': 0.5}
-     agg_nparray, agg_metadata_dict = db.get_aggregated_tensor(
-         tensor_key, collaborator_weight_dict, WeightedAverage())
- 
-     assert np.array_equal(nparray, agg_nparray)
- 
- 
- def test_get_aggregated_tensor_raise_wrong_weights(nparray, tensor_key):
-     """Test that get_aggregated_tensor raises if collaborator weights do not sum to 1.0."""
-     db = TensorDB()
-     db.cache_tensor({tensor_key: nparray})
- 
-     collaborator_weight_dict = {'col1': 0.5, 'col2': 0.8}
-     with pytest.raises(AssertionError):
-         db.get_aggregated_tensor(
-             tensor_key, collaborator_weight_dict, WeightedAverage())
- 
- 
- @pytest.fixture
- def tensor_db():
-     """Prepare tensor db."""
-     db = TensorDB()
-     array_1 = np.array([0, 1, 2, 3, 4])
-     tensor_key_1 = TensorKey('tensor_name', 'agg', 0, False, ('col1',))
-     array_2 = np.array([2, 3, 4, 5, 6])
-     tensor_key_2 = TensorKey('tensor_name', 'agg', 0, False, ('col2',))
-     db.cache_tensor({
-         tensor_key_1: array_1,
-         tensor_key_2: array_2
-     })
-     return db
- 
- 
- def test_get_aggregated_tensor_weights(tensor_db):
-     """Test that get_aggregated_tensor calculates correctly."""
-     collaborator_weight_dict = {'col1': 0.1, 'col2': 0.9}
-     tensor_key = TensorKey('tensor_name', 'agg', 0, False, ())
-     agg_nparray = tensor_db.get_aggregated_tensor(
-         tensor_key, collaborator_weight_dict, WeightedAverage())
- 
-     control_nparray = np.average(
-         [np.array([0, 1, 2, 3, 4]), np.array([2, 3, 4, 5, 6])],
-         weights=np.array(list(collaborator_weight_dict.values())),
-         axis=0
-     )
- 
-     assert np.array_equal(agg_nparray, control_nparray)
- 
- 
- def test_get_aggregated_tensor_error_aggregation_function(tensor_db):
-     """Test that get_aggregated_tensor raise error if aggregation function is not callable."""
-     collaborator_weight_dict = {'col1': 0.1, 'col2': 0.9}
-     tensor_key = TensorKey('tensor_name', 'agg', 0, False, ())
-     with pytest.raises(TypeError):
-         tensor_db.get_aggregated_tensor(
-             tensor_key, collaborator_weight_dict, 'fake_agg_function')
- 
- 
- def test_get_aggregated_tensor_new_aggregation_function(tensor_db):
-     """Test that get_aggregated_tensor works correctly with a given agg function."""
-     collaborator_weight_dict = {'col1': 0.1, 'col2': 0.9}
- 
-     class Sum(AggregationFunction):
-         def call(self, local_tensors, *_):
-             tensors = [local_tensor.tensor for local_tensor in local_tensors]
-             return np.sum(tensors, axis=0)
- 
-     tensor_key = TensorKey('tensor_name', 'agg', 0, False, ())
- 
-     agg_nparray = tensor_db.get_aggregated_tensor(
-         tensor_key, collaborator_weight_dict, Sum())
- 
-     assert np.array_equal(agg_nparray, np.array([2, 4, 6, 8, 10]))
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/__init__.py
*** ./openfl/tests/openfl/__init__.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """tests.openfl package."""
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/interface/interactive_api/test_experiment.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/interface/interactive_api/test_experiment.py
*** ./openfl/tests/openfl/interface/interactive_api/test_experiment.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/interface/interactive_api/test_experiment.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,97 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Experiment tests."""
- 
- from unittest import mock
- 
- import pytest
- 
- from openfl.component.assigner.tasks import TrainTask
- from openfl.component.assigner.tasks import ValidateTask
- from openfl.interface.interactive_api.experiment import FLExperiment
- from openfl.interface.interactive_api.experiment import TaskKeeper
- 
- 
- @pytest.fixture()
- def all_registered_tasks():
-     """Return all registered tasks fixture."""
-     return {
-         'train': TrainTask(
-             name='train',
-             function_name='train_func',
-         ),
-         'locally_tuned_model_validate': ValidateTask(
-             name='locally_tuned_model_validate',
-             function_name='validate',
-             apply_local=True,
-         ),
-         'aggregated_model_validate': ValidateTask(
-             name='aggregated_model_validate',
-             function_name='validate',
-         ),
-     }
- 
- 
- def test_define_task_assigner_all_tasks(all_registered_tasks):
-     """Test define_task_assigner if all task types are registered."""
-     task_keeper = TaskKeeper()
-     task_keeper.get_registered_tasks = mock.Mock(return_value=all_registered_tasks)
-     rounds_to_train = 10
-     task_assigner_fn = FLExperiment(None).define_task_assigner(task_keeper, rounds_to_train)
-     tasks_by_collaborator = task_assigner_fn(['one', 'two'], 1)
-     assert tasks_by_collaborator['one'] == list(all_registered_tasks.values())
- 
- 
- def test_define_task_assigner_val_tasks():
-     """Test define_task_assigner if only validate types are registered."""
-     task_keeper = TaskKeeper()
-     agg_task = ValidateTask(
-         name='aggregated_model_validate',
-         function_name='validate',
-     )
-     task_keeper.get_registered_tasks = mock.Mock(return_value={
-         'aggregated_model_validate': agg_task
-     })
-     rounds_to_train = 1
-     task_assigner_fn = FLExperiment(None).define_task_assigner(task_keeper, rounds_to_train)
-     tasks_by_collaborator = task_assigner_fn(['one', 'two'], 1)
-     assert tasks_by_collaborator['one'] == [agg_task]
- 
- 
- def test_define_task_assigner_exception_validate():
-     """Test define_task_assigner if only validate tasks are registered and rounds more than 1."""
-     task_keeper = TaskKeeper()
-     agg_task = ValidateTask(
-         name='aggregated_model_validate',
-         function_name='validate',
-     )
-     task_keeper.get_registered_tasks = mock.Mock(return_value={
-         'aggregated_model_validate': agg_task
-     })
-     rounds_to_train = 10
-     with pytest.raises(Exception):
-         FLExperiment(None).define_task_assigner(task_keeper, rounds_to_train)
- 
- 
- def test_define_task_assigner_exception_only_train():
-     """Test define_task_assigner if only train task types are registered."""
-     task_keeper = TaskKeeper()
-     train_task = TrainTask(
-         name='train',
-         function_name='train',
-     )
-     task_keeper.get_registered_tasks = mock.Mock(return_value={
-         'train': train_task
-     })
-     rounds_to_train = 10
-     with pytest.raises(Exception):
-         FLExperiment(None).define_task_assigner(task_keeper, rounds_to_train)
- 
- 
- def test_define_task_assigner_exception_no_tasks():
-     """Test define_task_assigner if no tasks are registered."""
-     task_keeper = TaskKeeper()
-     task_keeper.get_registered_tasks = mock.Mock(return_value={})
-     rounds_to_train = 1
-     with pytest.raises(Exception):
-         FLExperiment(None).define_task_assigner(task_keeper, rounds_to_train)
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/pipelines/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/pipelines/__init__.py
*** ./openfl/tests/openfl/pipelines/__init__.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/pipelines/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """tests.openfl.pipelines package."""
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/pipelines/test_pipeline.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/pipelines/test_pipeline.py
*** ./openfl/tests/openfl/pipelines/test_pipeline.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/pipelines/test_pipeline.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,147 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Pipeline tests module."""
- 
- import numpy as np
- import pytest
- 
- from openfl.pipelines.pipeline import Float32NumpyArrayToBytes
- from openfl.pipelines.pipeline import TransformationPipeline
- from openfl.pipelines.pipeline import Transformer
- from openfl.protocols import base_pb2
- 
- 
- @pytest.fixture
- def named_tensor():
-     """Initialize the named_tensor mock."""
-     tensor = base_pb2.NamedTensor(
-         name='tensor_name',
-         round_number=0,
-         lossless=False,
-         report=False,
-         data_bytes=32 * b'1'
-     )
-     metadata = tensor.transformer_metadata.add()
-     metadata.int_to_float[1] = 1.
-     metadata.int_list.extend([1, 8])
-     metadata.bool_list.append(True)
- 
-     return tensor
- 
- 
- def test_transformer_forward():
-     """Test that Transformer.forward is declared and is not implemented."""
-     t = Transformer()
- 
-     with pytest.raises(NotImplementedError):
-         t.forward(None)
- 
- 
- def test_transformer_backward():
-     """Test that Transformer.backward is declared and is not implemented."""
-     t = Transformer()
- 
-     with pytest.raises(NotImplementedError):
-         t.backward(None, None)
- 
- 
- def test_f32natb_is_lossy():
-     """Test that Float32NumpyArrayToBytes object creates with lossy = False."""
-     t = Float32NumpyArrayToBytes()
-     assert t.lossy is False
- 
- 
- def test_f32natb_forward(named_tensor):
-     """Test that Float32NumpyArrayToBytes.forward works correctly."""
-     t = Float32NumpyArrayToBytes()
-     proto = named_tensor.transformer_metadata.pop()
-     metadata = {'int_to_float': proto.int_to_float,
-                 'int_list': proto.int_list,
-                 'bool_list': proto.bool_list
-                 }
-     array_shape = tuple(metadata['int_list'])
-     flat_array = np.frombuffer(named_tensor.data_bytes, dtype=np.float32)
- 
-     nparray = np.reshape(flat_array, newshape=array_shape, order='C')
- 
-     data_bytes, t_metadata = t.forward(nparray)
-     assert t_metadata['int_list'] == metadata['int_list']
- 
- 
- def test_f32natb_backward(named_tensor):
-     """Test that Float32NumpyArrayToBytes.backward works correctly."""
-     t = Float32NumpyArrayToBytes()
-     proto = named_tensor.transformer_metadata.pop()
-     metadata = {'int_to_float': proto.int_to_float,
-                 'int_list': proto.int_list,
-                 'bool_list': proto.bool_list
-                 }
-     array_shape = tuple(metadata['int_list'])
-     flat_array = np.frombuffer(named_tensor.data_bytes, dtype=np.float32)
- 
-     nparray = np.reshape(flat_array, newshape=array_shape, order='C')
- 
-     data = t.backward(nparray, metadata)
- 
-     assert data.shape == tuple(metadata['int_list'])
- 
- 
- def test_transformation_pipeline_forward(named_tensor):
-     """Test that TransformationPipeline.forward works correctly."""
-     transformer = Float32NumpyArrayToBytes()
-     tp = TransformationPipeline([transformer])
-     proto = named_tensor.transformer_metadata.pop()
-     metadata = {'int_to_float': proto.int_to_float,
-                 'int_list': proto.int_list,
-                 'bool_list': proto.bool_list
-                 }
-     array_shape = tuple(metadata['int_list'])
-     flat_array = np.frombuffer(named_tensor.data_bytes, dtype=np.float32)
- 
-     nparray = np.reshape(flat_array, newshape=array_shape, order='C')
- 
-     data, transformer_metadata = tp.forward(nparray)
- 
-     assert len(transformer_metadata) == 1
-     assert isinstance(data, bytes)
- 
- 
- def test_transformation_pipeline_backward(named_tensor):
-     """Test that TransformationPipeline.backward works correctly."""
-     transformer = Float32NumpyArrayToBytes()
-     tp = TransformationPipeline([transformer])
-     proto = named_tensor.transformer_metadata.pop()
-     metadata = {'int_to_float': proto.int_to_float,
-                 'int_list': proto.int_list,
-                 'bool_list': proto.bool_list
-                 }
-     array_shape = tuple(metadata['int_list'])
-     flat_array = np.frombuffer(named_tensor.data_bytes, dtype=np.float32)
- 
-     nparray = np.reshape(flat_array, newshape=array_shape, order='C')
- 
-     data = tp.backward(nparray, [metadata])
- 
-     assert data.shape == tuple(metadata['int_list'])
- 
- 
- def test_transformation_pipeline_is_lossy_false(named_tensor):
-     """Test that TransformationPipeline.is_lossy returns False if all transformers is not lossy."""
-     transformer = Float32NumpyArrayToBytes()
-     tp = TransformationPipeline([transformer])
- 
-     is_lossy = tp.is_lossy()
- 
-     assert is_lossy is False
- 
- 
- def test_transformation_pipeline_is_lossy(named_tensor):
-     """Test that TransformationPipeline.is_lossy returns False if any transformer is lossy."""
-     transformer1 = Float32NumpyArrayToBytes()
-     transformer2 = Float32NumpyArrayToBytes()
-     transformer2.lossy = True
-     tp = TransformationPipeline([transformer1, transformer2])
- 
-     is_lossy = tp.is_lossy()
- 
-     assert is_lossy is True
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/pipelines/test_tensor_codec.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/pipelines/test_tensor_codec.py
*** ./openfl/tests/openfl/pipelines/test_tensor_codec.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/pipelines/test_tensor_codec.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,391 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Tensor codec tests module."""
- 
- 
- from unittest import mock
- 
- import numpy as np
- import pytest
- 
- from openfl.pipelines import NoCompressionPipeline
- from openfl.pipelines import SKCPipeline
- from openfl.pipelines import TensorCodec
- from openfl.protocols import base_pb2
- from openfl.utilities.types import TensorKey
- 
- 
- @pytest.fixture
- def named_tensor():
-     """Initialize the named_tensor mock."""
-     tensor = base_pb2.NamedTensor(
-         name='tensor_name',
-         round_number=0,
-         lossless=False,
-         report=False,
-         data_bytes=32 * b'1'
-     )
-     metadata = tensor.transformer_metadata.add()
-     metadata.int_to_float[1] = 1.
-     metadata.int_list.extend([1, 8])
-     metadata.bool_list.append(True)
- 
-     return tensor
- 
- 
- @pytest.fixture
- def tensor_key(named_tensor):
-     """Initialize the tensor_key mock."""
-     tensor_key = TensorKey(
-         named_tensor.name,
-         'col1',
-         named_tensor.round_number,
-         named_tensor.report,
-         tuple(named_tensor.tags)
-     )
-     return tensor_key
- 
- 
- def test_compress(tensor_key, named_tensor):
-     """Test that compress works correctly."""
-     tensor_codec = TensorCodec(NoCompressionPipeline())
-     metadata = [{'int_to_float': proto.int_to_float,
-                  'int_list': proto.int_list,
-                  'bool_list': proto.bool_list
-                  } for proto in named_tensor.transformer_metadata]
-     array_shape = tuple(metadata[0]['int_list'])
-     flat_array = np.frombuffer(named_tensor.data_bytes, dtype=np.float32)
- 
-     nparray = np.reshape(flat_array, newshape=array_shape, order='C')
-     compressed_tensor_key, compressed_nparray, metadata = tensor_codec.compress(
-         tensor_key, nparray)
- 
-     assert 'compressed' in compressed_tensor_key.tags
-     assert compressed_tensor_key.tensor_name == tensor_key.tensor_name
-     assert compressed_tensor_key.origin == tensor_key.origin
-     assert compressed_tensor_key.round_number == tensor_key.round_number
- 
- 
- def test_compress_lossless(tensor_key, named_tensor):
-     """Test that compress works correctly with require_lossless flag."""
-     tensor_codec = TensorCodec(NoCompressionPipeline())
-     metadata = [{'int_to_float': proto.int_to_float,
-                  'int_list': proto.int_list,
-                  'bool_list': proto.bool_list
-                  } for proto in named_tensor.transformer_metadata]
-     array_shape = tuple(metadata[0]['int_list'])
-     flat_array = np.frombuffer(named_tensor.data_bytes, dtype=np.float32)
- 
-     nparray = np.reshape(flat_array, newshape=array_shape, order='C')
-     compressed_tensor_key, compressed_nparray, metadata = tensor_codec.compress(
-         tensor_key, nparray, require_lossless=True)
- 
-     assert 'compressed' in compressed_tensor_key.tags
-     assert compressed_tensor_key.tensor_name == tensor_key.tensor_name
-     assert compressed_tensor_key.origin == tensor_key.origin
-     assert compressed_tensor_key.round_number == tensor_key.round_number
- 
- 
- def test_compress_not_lossy_lossless(tensor_key, named_tensor):
-     """Test that compress works correctly with require_lossless flag and lossless pipeline."""
-     tensor_codec = TensorCodec(SKCPipeline())
-     metadata = [{'int_to_float': proto.int_to_float,
-                  'int_list': proto.int_list,
-                  'bool_list': proto.bool_list
-                  } for proto in named_tensor.transformer_metadata]
-     array_shape = tuple(metadata[0]['int_list'])
-     flat_array = np.frombuffer(named_tensor.data_bytes, dtype=np.float32)
- 
-     nparray = np.reshape(flat_array, newshape=array_shape, order='C')
-     compressed_tensor_key, compressed_nparray, metadata = tensor_codec.compress(
-         tensor_key, nparray, require_lossless=True)
- 
-     assert 'compressed' in compressed_tensor_key.tags
-     assert compressed_tensor_key.tensor_name == tensor_key.tensor_name
-     assert compressed_tensor_key.origin == tensor_key.origin
-     assert compressed_tensor_key.round_number == tensor_key.round_number
- 
- 
- def test_compress_not_require_lossless(tensor_key, named_tensor):
-     """Test that compress works correctly flag with lossless pipeline without require_lossless."""
-     tensor_codec = TensorCodec(SKCPipeline())
-     metadata = [{'int_to_float': proto.int_to_float,
-                  'int_list': proto.int_list,
-                  'bool_list': proto.bool_list
-                  } for proto in named_tensor.transformer_metadata]
-     array_shape = tuple(metadata[0]['int_list'])
-     flat_array = np.frombuffer(named_tensor.data_bytes, dtype=np.float32)
- 
-     nparray = np.reshape(flat_array, newshape=array_shape, order='C')
-     tensor_codec.compression_pipeline.forward = mock.Mock(return_value=(nparray, metadata[0]))
-     compressed_tensor_key, compressed_nparray, metadata = tensor_codec.compress(
-         tensor_key, nparray)
- 
-     assert 'lossy_compressed' in compressed_tensor_key.tags
-     assert compressed_tensor_key.tensor_name == tensor_key.tensor_name
-     assert compressed_tensor_key.origin == tensor_key.origin
-     assert compressed_tensor_key.round_number == tensor_key.round_number
- 
- 
- def test_decompress_no_metadata(tensor_key, named_tensor):
-     """Test that decompress raises exception without metadata."""
-     tensor_codec = TensorCodec(NoCompressionPipeline())
-     metadata = []
-     with pytest.raises(AssertionError):
-         tensor_codec.decompress(
-             tensor_key, named_tensor.data_bytes, metadata
-         )
- 
- 
- def test_decompress_no_tags(tensor_key, named_tensor):
-     """Test that decompress raises exception without tags."""
-     tensor_codec = TensorCodec(NoCompressionPipeline())
-     metadata = [{'int_to_float': proto.int_to_float,
-                  'int_list': proto.int_list,
-                  'bool_list': proto.bool_list
-                  } for proto in named_tensor.transformer_metadata]
-     with pytest.raises(AssertionError):
-         tensor_codec.decompress(
-             tensor_key, named_tensor.data_bytes, metadata
-         )
- 
- 
- def test_decompress_require_lossless_no_compressed_in_tags(tensor_key, named_tensor):
-     """Test that decompress raises error when require_lossless is True and is no compressed tag."""
-     tensor_codec = TensorCodec(NoCompressionPipeline())
-     tensor_name, origin, round_number, report, tags = tensor_key
-     tensor_key = TensorKey(
-         tensor_name, origin, round_number, report, ('lossy_compressed',)
-     )
-     metadata = [{'int_to_float': proto.int_to_float,
-                  'int_list': proto.int_list,
-                  'bool_list': proto.bool_list
-                  } for proto in named_tensor.transformer_metadata]
-     with pytest.raises(AssertionError):
-         tensor_codec.decompress(
-             tensor_key, named_tensor.data_bytes, metadata, require_lossless=True
-         )
- 
- 
- def test_decompress_call_lossless_pipeline_with_require_lossless(tensor_key, named_tensor):
-     """Test that decompress calls lossless pipeline when require_lossless is True."""
-     tensor_codec = TensorCodec(NoCompressionPipeline())
-     tensor_name, origin, round_number, report, tags = tensor_key
-     tensor_key = TensorKey(
-         tensor_name, origin, round_number, report, ('compressed',)
-     )
-     metadata = [{'int_to_float': proto.int_to_float,
-                  'int_list': proto.int_list,
-                  'bool_list': proto.bool_list
-                  } for proto in named_tensor.transformer_metadata]
-     tensor_codec.lossless_pipeline = mock.Mock()
-     tensor_codec.decompress(
-         tensor_key, named_tensor.data_bytes, metadata, require_lossless=True
-     )
-     tensor_codec.lossless_pipeline.backward.assert_called_with(
-         named_tensor.data_bytes, metadata)
- 
- 
- def test_decompress_call_compression_pipeline(tensor_key, named_tensor):
-     """Test that decompress calls compression pipeline when there is no compressed tag."""
-     tensor_codec = TensorCodec(NoCompressionPipeline())
-     tensor_name, origin, round_number, report, tags = tensor_key
-     tensor_key = TensorKey(
-         tensor_name, origin, round_number, report, ('lossy_compressed',)
-     )
-     metadata = [{'int_to_float': proto.int_to_float,
-                  'int_list': proto.int_list,
-                  'bool_list': proto.bool_list
-                  } for proto in named_tensor.transformer_metadata]
-     tensor_codec.compression_pipeline = mock.Mock()
-     tensor_codec.decompress(
-         tensor_key, named_tensor.data_bytes, metadata
-     )
-     tensor_codec.compression_pipeline.backward.assert_called_with(
-         named_tensor.data_bytes, metadata)
- 
- 
- def test_decompress_lossy_compressed_in_tags(tensor_key, named_tensor):
-     """Test that decompress works correctly when there is lossy_compressed tag."""
-     tensor_codec = TensorCodec(NoCompressionPipeline())
-     tensor_name, origin, round_number, report, tags = tensor_key
-     tensor_key = TensorKey(
-         tensor_name, origin, round_number, report, ('lossy_compressed',)
-     )
-     metadata = [{'int_to_float': proto.int_to_float,
-                  'int_list': proto.int_list,
-                  'bool_list': proto.bool_list
-                  } for proto in named_tensor.transformer_metadata]
-     decompressed_tensor_key, decompressed_nparray = tensor_codec.decompress(
-         tensor_key, named_tensor.data_bytes, metadata
-     )
-     assert 'lossy_decompressed' in decompressed_tensor_key.tags
- 
- 
- def test_decompress_compressed_in_tags(tensor_key, named_tensor):
-     """Test that decompress works correctly when there is compressed tag."""
-     tensor_codec = TensorCodec(NoCompressionPipeline())
-     tensor_name, origin, round_number, report, tags = tensor_key
-     tensor_key = TensorKey(
-         tensor_name, origin, round_number, report, ('compressed',)
-     )
-     metadata = [{'int_to_float': proto.int_to_float,
-                  'int_list': proto.int_list,
-                  'bool_list': proto.bool_list
-                  } for proto in named_tensor.transformer_metadata]
-     decompressed_tensor_key, decompressed_nparray = tensor_codec.decompress(
-         tensor_key, named_tensor.data_bytes, metadata
-     )
-     assert 'compressed' not in decompressed_tensor_key.tags
- 
- 
- def test_generate(tensor_key, named_tensor):
-     """Test that generate_delta works correctly."""
-     tensor_codec = TensorCodec(NoCompressionPipeline())
-     metadata = [{'int_to_float': proto.int_to_float,
-                  'int_list': proto.int_list,
-                  'bool_list': proto.bool_list
-                  } for proto in named_tensor.transformer_metadata]
-     array_shape = tuple(metadata[0]['int_list'])
-     flat_array = np.frombuffer(named_tensor.data_bytes, dtype=np.float32)
- 
-     nparray = np.reshape(flat_array, newshape=array_shape, order='C')
- 
-     delta_tensor_key, delta_nparray = tensor_codec.generate_delta(tensor_key, nparray, nparray)
- 
-     assert np.array_equal(delta_nparray, nparray - nparray)
-     assert 'delta' in delta_tensor_key.tags
- 
- 
- def test_generate_delta_assert_model_in_tags(tensor_key, named_tensor):
-     """Test that generate_delta raises exception when there is model tag."""
-     tensor_codec = TensorCodec(NoCompressionPipeline())
-     tensor_name, origin, round_number, report, tags = tensor_key
-     tensor_key = TensorKey(
-         tensor_name, origin, round_number, report, ('model',)
-     )
-     metadata = [{'int_to_float': proto.int_to_float,
-                  'int_list': proto.int_list,
-                  'bool_list': proto.bool_list
-                  } for proto in named_tensor.transformer_metadata]
-     array_shape = tuple(metadata[0]['int_list'])
-     flat_array = np.frombuffer(named_tensor.data_bytes, dtype=np.float32)
- 
-     nparray = np.reshape(flat_array, newshape=array_shape, order='C')
- 
-     with pytest.raises(AssertionError):
-         tensor_codec.generate_delta(tensor_key, nparray, nparray)
- 
- 
- def test_apply_delta_agg(tensor_key, named_tensor):
-     """Test that apply_delta works for aggregator tensor_key."""
-     tensor_codec = TensorCodec(NoCompressionPipeline())
-     tensor_name, origin, round_number, report, tags = tensor_key
-     tensor_key = TensorKey(
-         tensor_name, 'aggregator_1', round_number, report, ('delta',)
-     )
-     metadata = [{'int_to_float': proto.int_to_float,
-                  'int_list': proto.int_list,
-                  'bool_list': proto.bool_list
-                  } for proto in named_tensor.transformer_metadata]
-     array_shape = tuple(metadata[0]['int_list'])
-     flat_array = np.frombuffer(named_tensor.data_bytes, dtype=np.float32)
- 
-     nparray = np.reshape(flat_array, newshape=array_shape, order='C')
- 
-     new_model_tensor_key, nparray_with_delta = tensor_codec.apply_delta(
-         tensor_key, nparray, nparray)
- 
-     assert 'delta' not in new_model_tensor_key.tags
-     assert np.array_equal(nparray_with_delta, nparray + nparray)
- 
- 
- def test_apply_delta_col(tensor_key, named_tensor):
-     """Test that apply_delta works for collaborator tensor_key."""
-     tensor_codec = TensorCodec(NoCompressionPipeline())
-     tensor_name, origin, round_number, report, tags = tensor_key
-     tensor_key = TensorKey(
-         tensor_name, origin, round_number, report, ('delta',)
-     )
-     metadata = [{'int_to_float': proto.int_to_float,
-                  'int_list': proto.int_list,
-                  'bool_list': proto.bool_list
-                  } for proto in named_tensor.transformer_metadata]
-     array_shape = tuple(metadata[0]['int_list'])
-     flat_array = np.frombuffer(named_tensor.data_bytes, dtype=np.float32)
- 
-     nparray = np.reshape(flat_array, newshape=array_shape, order='C')
- 
-     new_model_tensor_key, nparray_with_delta = tensor_codec.apply_delta(
-         tensor_key, nparray, nparray)
- 
-     assert 'model' in new_model_tensor_key.tags
-     assert 'delta' not in new_model_tensor_key.tags
-     assert np.array_equal(nparray_with_delta, nparray + nparray)
- 
- 
- def test_find_dependencies_without_send_model_deltas(tensor_key):
-     """Test that find_dependencies returns empty list when send_model_deltas = False."""
-     tensor_codec = TensorCodec(NoCompressionPipeline())
-     tensor_name, origin, round_number, report, tags = tensor_key
-     tensor_key = TensorKey(
-         tensor_name, origin, 5, report, ('model',)
-     )
-     tensor_key_dependencies = tensor_codec.find_dependencies(tensor_key, False)
- 
-     assert len(tensor_key_dependencies) == 0
- 
- 
- def test_find_dependencies_without_model_in_tags(tensor_key):
-     """Test that find_dependencies returns empty list when there is no model tag."""
-     tensor_codec = TensorCodec(NoCompressionPipeline())
-     tensor_key_dependencies = tensor_codec.find_dependencies(tensor_key, True)
- 
-     assert len(tensor_key_dependencies) == 0
- 
- 
- def test_find_dependencies_with_zero_round(tensor_key):
-     """Test that find_dependencies returns empty list when round number is 0."""
-     tensor_codec = TensorCodec(NoCompressionPipeline())
-     tensor_name, origin, round_number, report, tags = tensor_key
-     tensor_key = TensorKey(
-         tensor_name, origin, round_number, report, ('model',)
-     )
-     tensor_key_dependencies = tensor_codec.find_dependencies(tensor_key, True)
- 
-     assert len(tensor_key_dependencies) == 0
- 
- 
- def test_find_dependencies(tensor_key):
-     """Test that find_dependencies works correctly."""
-     tensor_codec = TensorCodec(NoCompressionPipeline())
-     tensor_name, origin, round_number, report, tags = tensor_key
-     round_number = 2
-     tensor_key = TensorKey(
-         tensor_name, origin, round_number, report, ('model',)
-     )
-     tensor_key_dependencies = tensor_codec.find_dependencies(tensor_key, True)
- 
-     assert len(tensor_key_dependencies) == 2
-     tensor_key_dependency_0, tensor_key_dependency_1 = tensor_key_dependencies
-     assert tensor_key_dependency_0.round_number == round_number - 1
-     assert tensor_key_dependency_0.tags == tensor_key.tags
-     assert tensor_key_dependency_1.tags == ('aggregated', 'delta', 'compressed')
- 
- 
- def test_find_dependencies_is_lossy(tensor_key):
-     """Test that find_dependencies works correctly with lossy_compressed."""
-     tensor_codec = TensorCodec(NoCompressionPipeline())
-     tensor_codec.compression_pipeline.is_lossy = mock.Mock(return_value=True)
-     tensor_name, origin, round_number, report, tags = tensor_key
-     round_number = 2
-     tensor_key = TensorKey(
-         tensor_name, origin, round_number, report, ('model',)
-     )
-     tensor_key_dependencies = tensor_codec.find_dependencies(tensor_key, True)
- 
-     assert len(tensor_key_dependencies) == 2
-     tensor_key_dependency_0, tensor_key_dependency_1 = tensor_key_dependencies
-     assert tensor_key_dependency_0.round_number == round_number - 1
-     assert tensor_key_dependency_0.tags == tensor_key.tags
-     assert tensor_key_dependency_1.tags == ('aggregated', 'delta', 'lossy_compressed')
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/transport/grpc/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/transport/grpc/__init__.py
*** ./openfl/tests/openfl/transport/grpc/__init__.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/transport/grpc/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """tests.openfl.transport.grpc package."""
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/transport/grpc/test_director_server.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/transport/grpc/test_director_server.py
*** ./openfl/tests/openfl/transport/grpc/test_director_server.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/transport/grpc/test_director_server.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,79 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Director tests module."""
- 
- from pathlib import Path
- from unittest import mock
- 
- import pytest
- 
- from openfl.component.director import Director
- from openfl.transport import DirectorGRPCServer
- 
- 
- @pytest.fixture
- def insecure_director():
-     """Initialize an insecure director mock."""
-     director = DirectorGRPCServer(director_cls=Director, tls=False)
- 
-     return director
- 
- 
- @pytest.fixture
- def secure_director():
-     """Initialize a secure director mock."""
-     director = DirectorGRPCServer(
-         director_cls=Director,
-         root_certificate=Path('./cert/root_ca.crt').absolute(),
-         private_key=Path('./cert/localhost.key').absolute(),
-         certificate=Path('./cert/localhost.crt').absolute()
-     )
-     return director
- 
- 
- def test_fill_certs(insecure_director, secure_director):
-     """Test that fill_cert fill certificates params correctly."""
-     assert insecure_director.root_certificate is None
-     assert insecure_director.private_key is None
-     assert insecure_director.certificate is None
-     assert isinstance(secure_director.root_certificate, Path)
-     assert isinstance(secure_director.private_key, Path)
-     assert isinstance(secure_director.certificate, Path)
-     with pytest.raises(Exception):
-         secure_director._fill_certs('.', '.', None)
-     with pytest.raises(Exception):
-         secure_director._fill_certs('.', None, '.')
-     with pytest.raises(Exception):
-         secure_director._fill_certs(None, '.', '.')
-     secure_director._fill_certs('.', '.', '.')
- 
- 
- def test_get_caller_tls(insecure_director):
-     """Test that get_caller works correctly with TLS."""
-     insecure_director.tls = True
-     context = mock.Mock()
-     client_id = 'client_id'
-     context.auth_context = mock.Mock(
-         return_value={'x509_common_name': [client_id.encode('utf-8')]}
-     )
-     result = insecure_director.get_caller(context)
-     assert result == client_id
- 
- 
- def test_get_sender_no_tls(insecure_director):
-     """Test that get_sender works correctly without TLS."""
-     context = mock.Mock()
-     client_id = 'client_id'
-     context.invocation_metadata.return_value = (('client_id', client_id),)
-     result = insecure_director.get_caller(context)
-     assert result == client_id
- 
- 
- def test_get_sender_no_tls_no_client_id(insecure_director):
-     """Test that get_sender works correctly without TLS and client_id."""
-     context = mock.Mock()
-     context.invocation_metadata = mock.Mock()
-     context.invocation_metadata.return_value = (('key', 'value'),)
-     default_client_id = '__default__'
-     result = insecure_director.get_caller(context)
-     assert result == default_client_id
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/transport/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/transport/__init__.py
*** ./openfl/tests/openfl/transport/__init__.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/transport/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """tests.openfl.transport package."""
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/utilities/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/utilities/__init__.py
*** ./openfl/tests/openfl/utilities/__init__.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/utilities/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """tests.openfl.utilities package."""
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/utilities/optimizers/func_for_optimization.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/utilities/optimizers/func_for_optimization.py
*** ./openfl/tests/openfl/utilities/optimizers/func_for_optimization.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/utilities/optimizers/func_for_optimization.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,54 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Numpy optimizers test functions module."""
- from typing import Dict
- 
- import numpy as np
- 
- 
- def rosenbrock_func(point: Dict[str, np.ndarray]) -> float:
-     """
-     Calculate Rosenbrock function.
- 
-     More details: https://en.wikipedia.org/wiki/Rosenbrock_function
-     """
-     return (1 - point['x'])**2 + 100 * (point['y'] - point['x']**2)**2
- 
- 
- def _get_rosenbrock_grads(point: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:
-     """Calculate gradients for Rosenbrock function."""
-     grads = {'x': np.array([0]), 'y': np.array([0])}
-     grads['x'] = -2 * (1 - point['x']) - 400 * point['x'] * (point['y'] - point['x']**2)
-     grads['y'] = grads['y'] + 200 * (point['y'] - point['x']**2)
-     return grads
- 
- 
- def mc_cormick_func(point: Dict[str, np.ndarray]) -> float:
-     """
-     Calculate McCormick function.
- 
-     More details: https://en.wikipedia.org/wiki/Test_functions_for_optimization
-     """
-     return (np.sin(point['x'] + point['y'])
-             + (point['x'] - point['y'])**2
-             - 1.5 * point['x'] + 2.5 * point['y'] + 1)
- 
- 
- def _get_mc_cormick_grads(point: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:
-     """Calculate gradients for McCormick function."""
-     grads = {'x': np.array([0]), 'y': np.array([0])}
-     grads['x'] = np.cos(point['x'] + point['y']) + 2 * (point['x'] - point['y']) - 1.5
-     grads['y'] = np.cos(point['x'] + point['y']) - 2 * (point['x'] - point['y']) + 2.5
-     return grads
- 
- 
- rosenbrock_func.get_grads = _get_rosenbrock_grads
- rosenbrock_func.true_answer = {'x': np.array([1.0]), 'y': np.array([1.0])}
- 
- mc_cormick_func.get_grads = _get_mc_cormick_grads
- mc_cormick_func.true_answer = {'x': np.array([-0.54719]), 'y': np.array([-1.54719])}
- 
- __all__ = [
-     'rosenbrock_func',
-     'mc_cormick_func',
- ]
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/utilities/optimizers/__init__.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/utilities/optimizers/__init__.py
*** ./openfl/tests/openfl/utilities/optimizers/__init__.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/utilities/optimizers/__init__.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,3 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """tests.openfl.utilities.optimizers package."""
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/utilities/optimizers/test_numpy_optimizers.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/utilities/optimizers/test_numpy_optimizers.py
*** ./openfl/tests/openfl/utilities/optimizers/test_numpy_optimizers.py	2022-11-18 11:08:33.047181428 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/utilities/optimizers/test_numpy_optimizers.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,57 ****
- # Copyright (C) 2021-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Numpy optimizers tests module."""
- 
- import numpy as np
- import pytest
- 
- from openfl.utilities.optimizers.numpy.adagrad_optimizer import NumPyAdagrad
- from openfl.utilities.optimizers.numpy.adam_optimizer import NumPyAdam
- from openfl.utilities.optimizers.numpy.yogi_optimizer import NumPyYogi
- from.func_for_optimization import mc_cormick_func
- from.func_for_optimization import rosenbrock_func
- 
- EPS = 5e-5
- 
- 
- @pytest.mark.parametrize(
-     'func,optim,num_iter', [
-         (rosenbrock_func,
-          NumPyAdagrad(params={'x': np.array([0.0]), 'y': np.array([0.0])},
-                       learning_rate=0.08),
-          5000),
-         (rosenbrock_func,
-          NumPyAdam(params={'x': np.array([0.0]), 'y': np.array([0.0])},
-                    learning_rate=0.01),
-          1000),
-         (rosenbrock_func,
-          NumPyYogi(params={'x': np.array([0.0]), 'y': np.array([0.0])},
-                    learning_rate=0.01),
-          1000),
-         (mc_cormick_func,
-          NumPyAdagrad(params={'x': np.array([0.0]), 'y': np.array([0.0])},
-                       learning_rate=0.03),
-          5000),
-         (mc_cormick_func,
-          NumPyAdam(params={'x': np.array([0.0]), 'y': np.array([0.0])},
-                    learning_rate=0.01),
-          1000),
-         (mc_cormick_func,
-          NumPyYogi(params={'x': np.array([0.0]), 'y': np.array([0.0])},
-                    learning_rate=0.01),
-          1000),
-     ])
- def test_opt(func, optim, num_iter):
-     """Test optimizer by performing gradient descent iterations."""
-     for i in range(num_iter):
-         if i % 125 == 0:
-             print(f'Iter: {i}', '\t',
-                   f'current point: {optim.params}',
-                   '\t', f'func value={func(optim.params)}')
-         grads = func.get_grads(optim.params)
-         optim.step(grads)
- 
-     diff = np.array([optim.params[param_name]
-                      - func.true_answer[param_name] for param_name in optim.params])
-     diff = (diff**2).sum()  # calculate L2 norm
-     assert diff <= EPS, f'Found parameters are not optimal, L2 difference: {diff}'
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/utilities/test_data_splitters.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/utilities/test_data_splitters.py
*** ./openfl/tests/openfl/utilities/test_data_splitters.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/utilities/test_data_splitters.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,70 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Data Splitters tests module."""
- import numpy as np
- import pytest
- 
- from openfl.utilities.data_splitters import DirichletNumPyDataSplitter
- from openfl.utilities.data_splitters import EqualNumPyDataSplitter
- from openfl.utilities.data_splitters import LogNormalNumPyDataSplitter
- from openfl.utilities.data_splitters import RandomNumPyDataSplitter
- 
- np.random.seed(0)
- y_train = np.random.randint(0, 10, 1000)
- 
- 
- @pytest.mark.parametrize(
-     'num_collaborators,expected_result', [
-         (10, [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]),
-         (11, [91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 90]),
-     ])
- def test_equal(num_collaborators, expected_result):
-     """Test equal splitter."""
-     splitter = EqualNumPyDataSplitter()
-     shards = splitter.split(y_train, num_collaborators)
-     assert [len(shard) for shard in shards] == expected_result
- 
- 
- @pytest.mark.parametrize(
-     'num_collaborators,expected_result', [
-         (10, [18, 258, 110, 120, 26, 69, 70, 174, 94, 61]),
-         (11, [18, 183, 75, 110, 120, 26, 69, 70, 174, 94, 61]),
-     ])
- def test_random(num_collaborators, expected_result):
-     """Test random splitter."""
-     splitter = RandomNumPyDataSplitter()
-     shards = splitter.split(y_train, num_collaborators)
-     print([len(shard) for shard in shards])
-     assert [len(shard) for shard in shards] == expected_result
- 
- 
- @pytest.mark.parametrize(
-     'num_collaborators,expected_result', [
-         (10, [154, 9, 33, 64, 85, 35, 48, 18, 26, 4]),
-         (20, [36, 81, 35, 56, 105, 6, 114, 46, 57, 50, 24, 55, 30, 9, 14, 10, 15, 48, 12, 4]),
-     ])
- def test_lognormal(num_collaborators, expected_result):
-     """Test lognormal splitter."""
-     splitter = LogNormalNumPyDataSplitter(
-         mu=1,
-         sigma=1,
-         num_classes=10,
-         classes_per_col=2,
-         min_samples_per_class=2
-     )
-     shards = splitter.split(y_train, num_collaborators)
-     print([len(shard) for shard in shards])
-     assert [len(shard) for shard in shards] == expected_result
- 
- 
- @pytest.mark.parametrize(
-     'num_collaborators,expected_result', [
-         (10, [56, 51, 107, 64, 158, 122, 131, 103, 104, 104]),
-         (11, [60, 95, 112, 111, 31, 106, 90, 96, 123, 97, 79]),
-     ])
- def test_dirichlet(num_collaborators, expected_result):
-     """Test dirichlet splitter."""
-     splitter = DirichletNumPyDataSplitter()
-     shards = splitter.split(y_train, num_collaborators)
-     print([len(shard) for shard in shards])
-     assert [len(shard) for shard in shards] == expected_result
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/utilities/test_dump_requirements.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/utilities/test_dump_requirements.py
*** ./openfl/tests/openfl/utilities/test_dump_requirements.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/utilities/test_dump_requirements.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,127 ****
- # Copyright (C) 2020-2022 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Dump requirements file test module."""
- 
- from pathlib import Path
- 
- import pytest
- from pip._internal.operations import freeze
- 
- from openfl.utilities.workspace import dump_requirements_file
- 
- ORIGINAL_PREFIXE_LINES = ['-o option\n', ]
- ORIGINAL_PACKAGE_LINES = ['package==0.0.1\n', ]
- LINES = ORIGINAL_PREFIXE_LINES + ORIGINAL_PACKAGE_LINES
- 
- PREFIXES = ('-u test',)
- NEW_PREFIX_LINES = [p + '\n' for p in PREFIXES]
- PREFIXES_OVERLAP = ('-u test', '-o option')
- NEW_PREFIXES_OVERLAP = [p + '\n' for p in PREFIXES_OVERLAP]
- 
- 
- @pytest.fixture
- def requirements_file():
-     """Prepare test requirements file."""
-     path = Path('./test_requirements.txt').absolute()
-     with open(path, 'w') as f:
-         f.writelines(LINES)
-     yield path
-     path.unlink()
- 
- 
- @pytest.mark.parametrize('keep_original_prefixes,prefixes,expected_lines', [
-     (False, None, LINES[1:]),
-     (True, None, LINES),
-     (False, PREFIXES, NEW_PREFIX_LINES + ORIGINAL_PACKAGE_LINES),
-     (True, PREFIXES, NEW_PREFIX_LINES + LINES),
-     (True, PREFIXES_OVERLAP, NEW_PREFIXES_OVERLAP + ORIGINAL_PACKAGE_LINES),
- ])
- def test_dump(requirements_file, monkeypatch,
-               keep_original_prefixes, prefixes, expected_lines):
-     """Test dump_requirements_file function."""
-     def mock_pip_freeze():
-         return [line.replace('\n', '') for line in ORIGINAL_PACKAGE_LINES]
-     monkeypatch.setattr(freeze, 'freeze', mock_pip_freeze)
- 
-     dump_requirements_file(path=requirements_file,
-                            keep_original_prefixes=keep_original_prefixes,
-                            prefixes=prefixes)
- 
-     with open(requirements_file) as f:
-         read_lines = f.readlines()
- 
-     read_options = []
-     for li in read_lines:
-         if li[0] == '-':
-             read_options.append(li)
-         else:
-             break
-     read_packages = read_lines[len(read_options):]
- 
-     expected_options = []
-     for li in expected_lines:
-         if li[0] == '-':
-             expected_options.append(li)
-         else:
-             break
-     expected_packages = expected_lines[len(expected_options):]
- 
-     assert len(read_options) == len(expected_options)
-     assert len(read_packages) == len(expected_packages)
-     assert set(read_options) == set(expected_options)
-     assert set(read_packages) == set(expected_packages)
- 
- 
- @pytest.mark.parametrize('touch_file,keep_original_prefixes,prefixes,expected_lines', [
-     (False, False, None, LINES[1:]),
-     (True, False, None, LINES[1:]),
-     (False, True, None, LINES[1:]),
-     (True, True, None, LINES[1:]),
-     (False, False, PREFIXES, NEW_PREFIX_LINES + ORIGINAL_PACKAGE_LINES),
-     (True, False, PREFIXES, NEW_PREFIX_LINES + ORIGINAL_PACKAGE_LINES),
-     (False, True, PREFIXES, NEW_PREFIX_LINES + ORIGINAL_PACKAGE_LINES),
-     (True, True, PREFIXES, NEW_PREFIX_LINES + ORIGINAL_PACKAGE_LINES),
-     (False, True, PREFIXES_OVERLAP, NEW_PREFIXES_OVERLAP + ORIGINAL_PACKAGE_LINES),
-     (True, True, PREFIXES_OVERLAP, NEW_PREFIXES_OVERLAP + ORIGINAL_PACKAGE_LINES),
- ])
- def test_dump_empty_original_list(
-         monkeypatch, touch_file,
-         keep_original_prefixes, prefixes, expected_lines):
-     """Test dump_requirements_file function with no file to start."""
-     def mock_pip_freeze():
-         return [line.replace('\n', '') for line in ORIGINAL_PACKAGE_LINES]
-     monkeypatch.setattr(freeze, 'freeze', mock_pip_freeze)
- 
-     requirements_file = Path('./test_requirements_2.txt').absolute()
-     if touch_file:
-         requirements_file.touch()
-     try:
-         dump_requirements_file(path=requirements_file,
-                                keep_original_prefixes=keep_original_prefixes,
-                                prefixes=prefixes)
- 
-         with open(requirements_file) as f:
-             read_lines = f.readlines()
-     finally:
-         requirements_file.unlink(missing_ok=True)
- 
-     read_options = []
-     for li in read_lines:
-         if li[0] == '-':
-             read_options.append(li)
-         else:
-             break
-     read_packages = read_lines[len(read_options):]
- 
-     expected_options = []
-     for li in expected_lines:
-         if li[0] == '-':
-             expected_options.append(li)
-         else:
-             break
-     expected_packages = expected_lines[len(expected_options):]
- 
-     assert len(read_options) == len(expected_options)
-     assert len(read_packages) == len(expected_packages)
-     assert set(read_options) == set(expected_options)
-     assert set(read_packages) == set(expected_packages)
--- 0 ----
diff -crB --new-file ./openfl/tests/openfl/utilities/test_path_check.py ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/utilities/test_path_check.py
*** ./openfl/tests/openfl/utilities/test_path_check.py	2022-11-18 11:06:29.759187475 -0800
--- ../mlwins-simulation-framework/ml-frameworks/federated-learning/tests/openfl/utilities/test_path_check.py	1969-12-31 16:00:00.000000000 -0800
***************
*** 1,31 ****
- # Copyright (C) 2020-2021 Intel Corporation
- # SPDX-License-Identifier: Apache-2.0
- """Path checks tests module."""
- 
- import os
- from pathlib import Path
- 
- import pytest
- 
- from openfl.utilities.path_check import is_directory_traversal
- 
- 
- @pytest.mark.parametrize(
-     'directory,expected_result', [
-         ('first_level', False),
-         ('first_level/second_level', False),
-         (os.getcwd(), False),
-         (Path(os.getcwd(), 'first_level'), False),
-         (Path(os.getcwd(), 'first_level/second_level'), False),
-         ('first_level/second_level/..', False),
-         ('first_level/../first_level', False),
-         ('..', True),
-         ('../../file', True),
-         ('/home/naive_hacker', True),
-         ('first_level/second_level/../../..', True),
-         ('..', True),
-         ('../../file', True),
-     ])
- def test_is_directory_traversal(directory, expected_result):
-     """Test that is_directory_traversal works."""
-     assert is_directory_traversal(directory) is expected_result
--- 0 ----
